{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description: Code used to train and optimise the models used to predict future electricty consumption\n",
    "\n",
    "#Author: Katie Roberts\n",
    "#Date: 26-04-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgm\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-e4819816757b>:333: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_reading']=bow_day_avg_reading\n",
      "<ipython-input-45-e4819816757b>:334: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_maxtemp']=bow_day_avg_maxtemp\n",
      "<ipython-input-45-e4819816757b>:335: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_mintemp']=bow_day_avg_mintemp\n",
      "<ipython-input-45-e4819816757b>:336: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_snow']=bow_day_avg_snow\n",
      "<ipython-input-45-e4819816757b>:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_sunhour']=bow_day_avg_sunhour\n",
      "<ipython-input-45-e4819816757b>:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_uvindex']=bow_day_avg_uvindex\n",
      "<ipython-input-45-e4819816757b>:339: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_moonillumination']=bow_day_avg_moonillumination\n",
      "<ipython-input-45-e4819816757b>:340: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_sunrise_hr']=bow_day_avg_sunrise_hr\n",
      "<ipython-input-45-e4819816757b>:341: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_sunrise_min']=bow_day_avg_sunrise_min\n",
      "<ipython-input-45-e4819816757b>:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_sunset_hr']=bow_day_avg_sunset_hr\n",
      "<ipython-input-45-e4819816757b>:343: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_sunset_min']=bow_day_avg_sunset_min\n",
      "<ipython-input-45-e4819816757b>:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_dewpoint']=bow_day_avg_dewpoint\n",
      "<ipython-input-45-e4819816757b>:345: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_feelslike']=bow_day_avg_feelslike\n",
      "<ipython-input-45-e4819816757b>:346: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_heatindex']=bow_day_avg_heatindex\n",
      "<ipython-input-45-e4819816757b>:347: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_windchill']=bow_day_avg_windchill\n",
      "<ipython-input-45-e4819816757b>:348: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_windgust']=bow_day_avg_windgust\n",
      "<ipython-input-45-e4819816757b>:349: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_cloud']=bow_day_avg_cloud\n",
      "<ipython-input-45-e4819816757b>:350: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_humidity']=bow_day_avg_humidity\n",
      "<ipython-input-45-e4819816757b>:351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_precip']=bow_day_avg_precip\n",
      "<ipython-input-45-e4819816757b>:352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_pressure']=bow_day_avg_pressure\n",
      "<ipython-input-45-e4819816757b>:353: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_temp']=bow_day_avg_temp\n",
      "<ipython-input-45-e4819816757b>:354: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_visibility']=bow_day_avg_visibility\n",
      "<ipython-input-45-e4819816757b>:355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_winddir']=bow_day_avg_winddir\n",
      "<ipython-input-45-e4819816757b>:356: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_windspeed']=bow_day_avg_windspeed\n",
      "<ipython-input-45-e4819816757b>:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_as_client']=bow_day_avg_as_client\n",
      "<ipython-input-45-e4819816757b>:358: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['day_avg_auth_client']=bow_day_avg_auth_client\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-e4819816757b>:444: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_reading']=l_day_avg_reading\n",
      "<ipython-input-45-e4819816757b>:445: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_maxtemp']=l_day_avg_maxtemp\n",
      "<ipython-input-45-e4819816757b>:446: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_mintemp']=l_day_avg_mintemp\n",
      "<ipython-input-45-e4819816757b>:447: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_snow']=l_day_avg_snow\n",
      "<ipython-input-45-e4819816757b>:448: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_sunhour']=l_day_avg_sunhour\n",
      "<ipython-input-45-e4819816757b>:449: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_uvindex']=l_day_avg_uvindex\n",
      "<ipython-input-45-e4819816757b>:450: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_moonillumination']=l_day_avg_moonillumination\n",
      "<ipython-input-45-e4819816757b>:451: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_sunrise_hr']=l_day_avg_sunrise_hr\n",
      "<ipython-input-45-e4819816757b>:452: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_sunrise_min']=l_day_avg_sunrise_min\n",
      "<ipython-input-45-e4819816757b>:453: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_sunset_hr']=l_day_avg_sunset_hr\n",
      "<ipython-input-45-e4819816757b>:454: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_sunset_min']=l_day_avg_sunset_min\n",
      "<ipython-input-45-e4819816757b>:455: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_dewpoint']=l_day_avg_dewpoint\n",
      "<ipython-input-45-e4819816757b>:456: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_feelslike']=l_day_avg_feelslike\n",
      "<ipython-input-45-e4819816757b>:457: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_heatindex']=l_day_avg_heatindex\n",
      "<ipython-input-45-e4819816757b>:458: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_windchill']=l_day_avg_windchill\n",
      "<ipython-input-45-e4819816757b>:459: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_windgust']=l_day_avg_windgust\n",
      "<ipython-input-45-e4819816757b>:460: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_cloud']=l_day_avg_cloud\n",
      "<ipython-input-45-e4819816757b>:461: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_humidity']=l_day_avg_humidity\n",
      "<ipython-input-45-e4819816757b>:462: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_precip']=l_day_avg_precip\n",
      "<ipython-input-45-e4819816757b>:463: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_pressure']=l_day_avg_pressure\n",
      "<ipython-input-45-e4819816757b>:464: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_temp']=l_day_avg_temp\n",
      "<ipython-input-45-e4819816757b>:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_visibility']=l_day_avg_visibility\n",
      "<ipython-input-45-e4819816757b>:466: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_winddir']=l_day_avg_winddir\n",
      "<ipython-input-45-e4819816757b>:467: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_windspeed']=l_day_avg_windspeed\n",
      "<ipython-input-45-e4819816757b>:468: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_as_client']=l_day_avg_as_client\n",
      "<ipython-input-45-e4819816757b>:469: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['day_avg_auth_client']=l_day_avg_auth_client\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-e4819816757b>:558: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_reading']=day_avg_reading_no_occ\n",
      "<ipython-input-45-e4819816757b>:559: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_maxtemp']=day_avg_maxtemp_no_occ\n",
      "<ipython-input-45-e4819816757b>:560: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_mintemp']=day_avg_mintemp_no_occ\n",
      "<ipython-input-45-e4819816757b>:561: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_snow']=day_avg_snow_no_occ\n",
      "<ipython-input-45-e4819816757b>:562: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_sunhour']=day_avg_sunhour_no_occ\n",
      "<ipython-input-45-e4819816757b>:563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_uvindex']=day_avg_uvindex_no_occ\n",
      "<ipython-input-45-e4819816757b>:564: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_moonillumination']=day_avg_moonillumination_no_occ\n",
      "<ipython-input-45-e4819816757b>:565: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_sunrise_hr']=day_avg_sunrise_hr_no_occ\n",
      "<ipython-input-45-e4819816757b>:566: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_sunrise_min']=day_avg_sunrise_min_no_occ\n",
      "<ipython-input-45-e4819816757b>:567: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_sunset_hr']=day_avg_sunset_hr_no_occ\n",
      "<ipython-input-45-e4819816757b>:568: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_sunset_min']=day_avg_sunset_min_no_occ\n",
      "<ipython-input-45-e4819816757b>:569: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_dewpoint']=day_avg_dewpoint_no_occ\n",
      "<ipython-input-45-e4819816757b>:570: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_feelslike']=day_avg_feelslike_no_occ\n",
      "<ipython-input-45-e4819816757b>:571: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_heatindex']=day_avg_heatindex_no_occ\n",
      "<ipython-input-45-e4819816757b>:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_windchill']=day_avg_windchill_no_occ\n",
      "<ipython-input-45-e4819816757b>:573: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_windgust']=day_avg_windgust_no_occ\n",
      "<ipython-input-45-e4819816757b>:574: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_cloud']=day_avg_cloud_no_occ\n",
      "<ipython-input-45-e4819816757b>:575: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_humidity']=day_avg_humidity_no_occ\n",
      "<ipython-input-45-e4819816757b>:576: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_precip']=day_avg_precip_no_occ\n",
      "<ipython-input-45-e4819816757b>:577: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_pressure']=day_avg_pressure_no_occ\n",
      "<ipython-input-45-e4819816757b>:578: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_temp']=day_avg_temp_no_occ\n",
      "<ipython-input-45-e4819816757b>:579: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_visibility']=day_avg_visibility_no_occ\n",
      "<ipython-input-45-e4819816757b>:580: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_winddir']=day_avg_winddir_no_occ\n",
      "<ipython-input-45-e4819816757b>:581: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['day_avg_windspeed']=day_avg_windspeed_no_occ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-e4819816757b>:664: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_reading']=lday_avg_reading_no_occ\n",
      "<ipython-input-45-e4819816757b>:665: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_maxtemp']=lday_avg_maxtemp_no_occ\n",
      "<ipython-input-45-e4819816757b>:666: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_mintemp']=lday_avg_mintemp_no_occ\n",
      "<ipython-input-45-e4819816757b>:667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_snow']=lday_avg_snow_no_occ\n",
      "<ipython-input-45-e4819816757b>:668: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_sunhour']=lday_avg_sunhour_no_occ\n",
      "<ipython-input-45-e4819816757b>:669: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_uvindex']=lday_avg_uvindex_no_occ\n",
      "<ipython-input-45-e4819816757b>:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_moonillumination']=lday_avg_moonillumination_no_occ\n",
      "<ipython-input-45-e4819816757b>:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_sunrise_hr']=lday_avg_sunrise_hr_no_occ\n",
      "<ipython-input-45-e4819816757b>:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_sunrise_min']=lday_avg_sunrise_min_no_occ\n",
      "<ipython-input-45-e4819816757b>:673: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_sunset_hr']=lday_avg_sunset_hr_no_occ\n",
      "<ipython-input-45-e4819816757b>:674: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_sunset_min']=lday_avg_sunset_min_no_occ\n",
      "<ipython-input-45-e4819816757b>:675: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_dewpoint']=lday_avg_dewpoint_no_occ\n",
      "<ipython-input-45-e4819816757b>:676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_feelslike']=lday_avg_feelslike_no_occ\n",
      "<ipython-input-45-e4819816757b>:677: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_heatindex']=lday_avg_heatindex_no_occ\n",
      "<ipython-input-45-e4819816757b>:678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_windchill']=lday_avg_windchill_no_occ\n",
      "<ipython-input-45-e4819816757b>:679: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_windgust']=lday_avg_windgust_no_occ\n",
      "<ipython-input-45-e4819816757b>:680: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_cloud']=lday_avg_cloud_no_occ\n",
      "<ipython-input-45-e4819816757b>:681: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_humidity']=lday_avg_humidity_no_occ\n",
      "<ipython-input-45-e4819816757b>:682: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_precip']=lday_avg_precip_no_occ\n",
      "<ipython-input-45-e4819816757b>:683: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_pressure']=lday_avg_pressure_no_occ\n",
      "<ipython-input-45-e4819816757b>:684: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_temp']=lday_avg_temp_no_occ\n",
      "<ipython-input-45-e4819816757b>:685: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_visibility']=lday_avg_visibility_no_occ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-e4819816757b>:686: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_winddir']=lday_avg_winddir_no_occ\n",
      "<ipython-input-45-e4819816757b>:687: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['day_avg_windspeed']=lday_avg_windspeed_no_occ\n",
      "<ipython-input-45-e4819816757b>:771: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_reading']=week_avg_reading\n",
      "<ipython-input-45-e4819816757b>:772: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_maxtemp']=week_avg_maxtemp\n",
      "<ipython-input-45-e4819816757b>:773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_mintemp']=week_avg_mintemp\n",
      "<ipython-input-45-e4819816757b>:774: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_snow']=week_avg_snow\n",
      "<ipython-input-45-e4819816757b>:775: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_sunhour']=week_avg_sunhour\n",
      "<ipython-input-45-e4819816757b>:776: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_uvindex']=week_avg_uvindex\n",
      "<ipython-input-45-e4819816757b>:777: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_moonillumination']=week_avg_moonillumination\n",
      "<ipython-input-45-e4819816757b>:778: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_sunrise_hr']=week_avg_sunrise_hr\n",
      "<ipython-input-45-e4819816757b>:779: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_sunrise_min']=week_avg_sunrise_min\n",
      "<ipython-input-45-e4819816757b>:780: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_sunset_hr']=week_avg_sunset_hr\n",
      "<ipython-input-45-e4819816757b>:781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_sunset_min']=week_avg_sunset_min\n",
      "<ipython-input-45-e4819816757b>:782: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_dewpoint']=week_avg_dewpoint\n",
      "<ipython-input-45-e4819816757b>:783: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_feelslike']=week_avg_feelslike\n",
      "<ipython-input-45-e4819816757b>:784: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_heatindex']=week_avg_heatindex\n",
      "<ipython-input-45-e4819816757b>:785: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_windchill']=week_avg_windchill\n",
      "<ipython-input-45-e4819816757b>:786: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_windgust']=week_avg_windgust\n",
      "<ipython-input-45-e4819816757b>:787: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_cloud']=week_avg_cloud\n",
      "<ipython-input-45-e4819816757b>:788: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_bow['week_avg_humidity']=week_avg_humidity\n",
      "<ipython-input-45-e4819816757b>:880: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_reading']=lweek_avg_reading\n",
      "<ipython-input-45-e4819816757b>:881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_maxtemp']=lweek_avg_maxtemp\n",
      "<ipython-input-45-e4819816757b>:882: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_mintemp']=lweek_avg_mintemp\n",
      "<ipython-input-45-e4819816757b>:883: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_snow']=lweek_avg_snow\n",
      "<ipython-input-45-e4819816757b>:884: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_sunhour']=lweek_avg_sunhour\n",
      "<ipython-input-45-e4819816757b>:885: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_uvindex']=lweek_avg_uvindex\n",
      "<ipython-input-45-e4819816757b>:886: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_moonillumination']=lweek_avg_moonillumination\n",
      "<ipython-input-45-e4819816757b>:887: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_sunrise_hr']=lweek_avg_sunrise_hr\n",
      "<ipython-input-45-e4819816757b>:888: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_sunrise_min']=lweek_avg_sunrise_min\n",
      "<ipython-input-45-e4819816757b>:889: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_sunset_hr']=lweek_avg_sunset_hr\n",
      "<ipython-input-45-e4819816757b>:890: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_sunset_min']=lweek_avg_sunset_min\n",
      "<ipython-input-45-e4819816757b>:891: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_dewpoint']=lweek_avg_dewpoint\n",
      "<ipython-input-45-e4819816757b>:892: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_feelslike']=lweek_avg_feelslike\n",
      "<ipython-input-45-e4819816757b>:893: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_heatindex']=lweek_avg_heatindex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-e4819816757b>:894: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_windchill']=lweek_avg_windchill\n",
      "<ipython-input-45-e4819816757b>:895: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_windgust']=lweek_avg_windgust\n",
      "<ipython-input-45-e4819816757b>:896: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_cloud']=lweek_avg_cloud\n",
      "<ipython-input-45-e4819816757b>:897: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_lec['week_avg_humidity']=lweek_avg_humidity\n",
      "<ipython-input-45-e4819816757b>:986: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_reading']=week_avg_reading_no_occ\n",
      "<ipython-input-45-e4819816757b>:987: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_maxtemp']=week_avg_maxtemp_no_occ\n",
      "<ipython-input-45-e4819816757b>:988: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_mintemp']=week_avg_mintemp_no_occ\n",
      "<ipython-input-45-e4819816757b>:989: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_snow']=week_avg_snow_no_occ\n",
      "<ipython-input-45-e4819816757b>:990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_sunhour']=week_avg_sunhour_no_occ\n",
      "<ipython-input-45-e4819816757b>:991: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_uvindex']=week_avg_uvindex_no_occ\n",
      "<ipython-input-45-e4819816757b>:992: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_moonillumination']=week_avg_moonillumination_no_occ\n",
      "<ipython-input-45-e4819816757b>:993: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_sunrise_hr']=week_avg_sunrise_hr_no_occ\n",
      "<ipython-input-45-e4819816757b>:994: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_sunrise_min']=week_avg_sunrise_min_no_occ\n",
      "<ipython-input-45-e4819816757b>:995: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_sunset_hr']=week_avg_sunset_hr_no_occ\n",
      "<ipython-input-45-e4819816757b>:996: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_sunset_min']=week_avg_sunset_min_no_occ\n",
      "<ipython-input-45-e4819816757b>:997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_dewpoint']=week_avg_dewpoint_no_occ\n",
      "<ipython-input-45-e4819816757b>:998: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_feelslike']=week_avg_feelslike_no_occ\n",
      "<ipython-input-45-e4819816757b>:999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_heatindex']=week_avg_heatindex_no_occ\n",
      "<ipython-input-45-e4819816757b>:1000: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_windchill']=week_avg_windchill_no_occ\n",
      "<ipython-input-45-e4819816757b>:1001: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_windgust']=week_avg_windgust_no_occ\n",
      "<ipython-input-45-e4819816757b>:1002: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_cloud']=week_avg_cloud_no_occ\n",
      "<ipython-input-45-e4819816757b>:1003: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_no_occ['week_avg_humidity']=week_avg_humidity_no_occ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-e4819816757b>:1090: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_reading']=lweek_avg_reading_no_occ\n",
      "<ipython-input-45-e4819816757b>:1091: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_maxtemp']=lweek_avg_maxtemp_no_occ\n",
      "<ipython-input-45-e4819816757b>:1092: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_mintemp']=lweek_avg_mintemp_no_occ\n",
      "<ipython-input-45-e4819816757b>:1093: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_snow']=lweek_avg_snow_no_occ\n",
      "<ipython-input-45-e4819816757b>:1094: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_sunhour']=lweek_avg_sunhour_no_occ\n",
      "<ipython-input-45-e4819816757b>:1095: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_uvindex']=lweek_avg_uvindex_no_occ\n",
      "<ipython-input-45-e4819816757b>:1096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_moonillumination']=lweek_avg_moonillumination_no_occ\n",
      "<ipython-input-45-e4819816757b>:1097: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_sunrise_hr']=lweek_avg_sunrise_hr_no_occ\n",
      "<ipython-input-45-e4819816757b>:1098: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_sunrise_min']=lweek_avg_sunrise_min_no_occ\n",
      "<ipython-input-45-e4819816757b>:1099: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_sunset_hr']=lweek_avg_sunset_hr_no_occ\n",
      "<ipython-input-45-e4819816757b>:1100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_sunset_min']=lweek_avg_sunset_min_no_occ\n",
      "<ipython-input-45-e4819816757b>:1101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_dewpoint']=lweek_avg_dewpoint_no_occ\n",
      "<ipython-input-45-e4819816757b>:1102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_feelslike']=lweek_avg_feelslike_no_occ\n",
      "<ipython-input-45-e4819816757b>:1103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_heatindex']=lweek_avg_heatindex_no_occ\n",
      "<ipython-input-45-e4819816757b>:1104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_windchill']=lweek_avg_windchill_no_occ\n",
      "<ipython-input-45-e4819816757b>:1105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_windgust']=lweek_avg_windgust_no_occ\n",
      "<ipython-input-45-e4819816757b>:1106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_cloud']=lweek_avg_cloud_no_occ\n",
      "<ipython-input-45-e4819816757b>:1107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltrain_data_no_occ['week_avg_humidity']=lweek_avg_humidity_no_occ\n"
     ]
    }
   ],
   "source": [
    "#load the data sets that will be used for training \n",
    "bm=pd.read_csv('bowland_main.csv')\n",
    "bow_main=bm.drop(columns={'Unnamed: 0'})\n",
    "bow_main=bow_main.sort_values(by='timestamp')#order the data frame in ascending order of date and time\n",
    "#create a column with only the date and hour\n",
    "bow_main['Date_Hour']=bow_main['timestamp'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d %H'))\n",
    "\n",
    "lec=pd.read_csv('lec_main_df.csv')\n",
    "lec_main=lec.drop(columns={'Unnamed: 0'})\n",
    "lec_main=lec_main.sort_values(by='timestamp')\n",
    "lec_main['Date_Hour']=lec_main['timestamp'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d %H'))\n",
    "\n",
    "occ_df=pd.read_csv('occupancy_dataframe.csv')\n",
    "bow_tow_occ=occ_df.loc[(occ_df['Building']==' Bowland Twr (Old Bowland Annexe) ')]\n",
    "bow_tow_occ_total=bow_tow_occ.groupby([\"time\"])[['Associated Client Count', 'Authenticated Client Count']].sum()\n",
    "bow_tow_occ_df=pd.DataFrame(data=bow_tow_occ_total).reset_index()\n",
    "bow_tow_occ_df['Date_Hour']=bow_tow_occ_df['time'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d %H'))\n",
    "bow_tow_occ_df['min']=bow_tow_occ_df['time'].apply(lambda x:pd.Timestamp(x).strftime('%M'))\n",
    "bow_tow_occ_df['min']=bow_tow_occ_df['min'].astype(int)\n",
    "bow_tow_occ_df['min']=round(bow_tow_occ_df['min']/10)*10\n",
    "bow_tow_occ_df=bow_tow_occ_df.groupby(['Date_Hour','min'], as_index=False)[['Associated Client Count', 'Authenticated Client Count']].mean()\n",
    "bow_main['min']=bow_main['Time'].apply(lambda x:pd.Timestamp(x).strftime('%M'))\n",
    "bow_main['min']=bow_main['min'].astype(int)\n",
    "bow_main['min']=round(bow_main['min']/10)*10\n",
    "bow_tow_with_occ=pd.merge(bow_tow_occ_df, bow_main, left_on=['Date_Hour','min'], right_on = ['Date_Hour','min'], how='inner')\n",
    "bow_tow_with_occ=bow_tow_with_occ.sort_values(by='timestamp')\n",
    "bow_tow_with_occ=bow_tow_with_occ.reset_index(drop=True)\n",
    "\n",
    "\n",
    "lec_occ=occ_df.loc[(occ_df['Building']==' LEC ')]\n",
    "lec_occ_total=lec_occ.groupby([\"time\"])[['Associated Client Count', 'Authenticated Client Count']].sum()\n",
    "lec_occ_df=pd.DataFrame(data=lec_occ_total).reset_index()\n",
    "lec_occ_df['Date_Hour']=lec_occ_df['time'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d %H'))\n",
    "lec_occ_df['min']=lec_occ_df['time'].apply(lambda x:pd.Timestamp(x).strftime('%M'))\n",
    "lec_occ_df['min']=lec_occ_df['min'].astype(int)\n",
    "lec_occ_df['min']=round(lec_occ_df['min']/10)*10\n",
    "lec_occ_df=lec_occ_df.groupby(['Date_Hour','min'], as_index=False)[['Associated Client Count', 'Authenticated Client Count']].mean()\n",
    "lec_main['min']=lec_main['Time'].apply(lambda x:pd.Timestamp(x).strftime('%M'))\n",
    "lec_main['min']=lec_main['min'].astype(int)\n",
    "lec_main['min']=round(lec_main['min']/10)*10\n",
    "lec_main_with_occ=pd.merge(lec_occ_df, lec_main, left_on=['Date_Hour','min'], right_on = ['Date_Hour','min'], how='inner')\n",
    "lec_main_with_occ=lec_main_with_occ.sort_values(by='timestamp')\n",
    "lec_main_with_occ=lec_main_with_occ.reset_index(drop=True)\n",
    "\n",
    "\n",
    "weather=pd.read_csv('LA14YW.csv')\n",
    "weather['Date_Hour']=weather['date_time'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d %H'))\n",
    "bow_tow_with_weather= pd.merge(weather, bow_tow_with_occ, how='right', left_on='Date_Hour', right_on='Date_Hour')\n",
    "bow_tow_with_weather_no_occ= pd.merge(weather, bow_main, how='right', left_on='Date_Hour', right_on='Date_Hour')\n",
    "\n",
    "lec_with_weather= pd.merge(weather, lec_main_with_occ, how='right', left_on='Date_Hour', right_on='Date_Hour')\n",
    "lec_with_weather_no_occ= pd.merge(weather, lec_main, how='right', left_on='Date_Hour', right_on='Date_Hour')\n",
    "\n",
    "#bow_tow_with_weather=bow_tow_with_weather.append(lec_with_weather)\n",
    "#bow_tow_with_weather_no_occ=bow_tow_with_weather_no_occ.append(lec_with_weather_no_occ)\n",
    "\n",
    "\n",
    "bow_tow_with_weather[\"Year\"] = bow_tow_with_weather['Date'].apply(lambda x:pd.Timestamp(x).strftime('%Y')).astype(float)\n",
    "bow_tow_with_weather[\"Month\"] = bow_tow_with_weather['Date'].apply(lambda x:pd.Timestamp(x).strftime('%m')).astype(float)\n",
    "bow_tow_with_weather[\"Day\"] = bow_tow_with_weather['Date'].apply(lambda x:pd.Timestamp(x).strftime('%d')).astype(float)\n",
    "\n",
    "bow_tow_with_weather[\"hour\"] = bow_tow_with_weather['Time'].apply(lambda x:pd.Timestamp(x).strftime('%H')).astype(float)\n",
    "bow_tow_with_weather[\"minute\"] = bow_tow_with_weather['Time'].apply(lambda x:pd.Timestamp(x).strftime('%M')).astype(float)\n",
    "bow_tow_with_weather[\"second\"] = bow_tow_with_weather['Time'].apply(lambda x:pd.Timestamp(x).strftime('%S')).astype(float)\n",
    "bow_tow_with_weather[\"sunrise\"]=pd.to_datetime(bow_tow_with_weather[\"sunrise\"])\n",
    "bow_tow_with_weather[\"sunrise_hour\"] = bow_tow_with_weather['sunrise'].dt.strftime('%H').astype(float)\n",
    "bow_tow_with_weather[\"sunrise_minute\"] = bow_tow_with_weather['sunrise'].dt.strftime('%M').astype(float)\n",
    "bow_tow_with_weather[\"sunset\"]=pd.to_datetime(bow_tow_with_weather[\"sunset\"])\n",
    "bow_tow_with_weather[\"sunset_hour\"] = bow_tow_with_weather['sunset'].dt.strftime('%H').astype(float)\n",
    "bow_tow_with_weather[\"sunset_minute\"] = bow_tow_with_weather['sunset'].dt.strftime('%M').astype(float)\n",
    "\n",
    "bow_tow_with_weather['previous_mintempC'] = bow_tow_with_weather.groupby(['Meter Type'])['mintempC'].ffill()\n",
    "bow_tow_with_weather['previous_maxtempC'] = bow_tow_with_weather.groupby(['Meter Type'])['maxtempC'].ffill()\n",
    "bow_tow_with_weather['previous_totalSnow_cm'] = bow_tow_with_weather.groupby(['Meter Type'])['totalSnow_cm'].ffill()\n",
    "bow_tow_with_weather['previous_sunHour'] = bow_tow_with_weather.groupby(['Meter Type'])['sunHour'].ffill()\n",
    "bow_tow_with_weather['previous_uvIndex'] = bow_tow_with_weather.groupby(['Meter Type'])['uvIndex'].ffill()\n",
    "bow_tow_with_weather['previous_moon_illumination'] = bow_tow_with_weather.groupby(['Meter Type'])['moon_illumination'].ffill()\n",
    "bow_tow_with_weather['previous_sunrise_hour'] = bow_tow_with_weather.groupby(['Meter Type'])['sunrise_hour'].ffill()\n",
    "bow_tow_with_weather['previous_sunrise_minute'] = bow_tow_with_weather.groupby(['Meter Type'])['sunrise_hour'].ffill()\n",
    "bow_tow_with_weather['previous_sunset_hour'] = bow_tow_with_weather.groupby(['Meter Type'])['sunset_hour'].ffill()\n",
    "bow_tow_with_weather['previous_sunset_minute'] = bow_tow_with_weather.groupby(['Meter Type'])['sunset_minute'].ffill()\n",
    "bow_tow_with_weather['previous_DewPointC'] = bow_tow_with_weather.groupby(['Meter Type'])['DewPointC'].ffill()\n",
    "bow_tow_with_weather['previous_FeelsLikeC'] = bow_tow_with_weather.groupby(['Meter Type'])['FeelsLikeC'].ffill()\n",
    "bow_tow_with_weather['previous_HeatIndexC'] = bow_tow_with_weather.groupby(['Meter Type'])['HeatIndexC'].ffill()\n",
    "bow_tow_with_weather['previous_WindChillC'] = bow_tow_with_weather.groupby(['Meter Type'])['WindChillC'].ffill()\n",
    "bow_tow_with_weather['previous_WindGustKmph'] = bow_tow_with_weather.groupby(['Meter Type'])['WindGustKmph'].ffill()\n",
    "bow_tow_with_weather['previous_cloudcover'] = bow_tow_with_weather.groupby(['Meter Type'])['cloudcover'].ffill()\n",
    "bow_tow_with_weather['previous_humidity'] = bow_tow_with_weather.groupby(['Meter Type'])['humidity'].ffill()\n",
    "bow_tow_with_weather['previous_precipMM'] = bow_tow_with_weather.groupby(['Meter Type'])['precipMM'].ffill()\n",
    "bow_tow_with_weather['previous_pressure'] = bow_tow_with_weather.groupby(['Meter Type'])['pressure'].ffill()\n",
    "bow_tow_with_weather['previous_tempC'] = bow_tow_with_weather.groupby(['Meter Type'])['tempC'].ffill()\n",
    "bow_tow_with_weather['previous_visibility'] = bow_tow_with_weather.groupby(['Meter Type'])['visibility'].ffill()\n",
    "bow_tow_with_weather['previous_winddirDegree'] = bow_tow_with_weather.groupby(['Meter Type'])['winddirDegree'].ffill()\n",
    "bow_tow_with_weather['previous_mintempC'] = bow_tow_with_weather.groupby(['Meter Type'])['mintempC'].ffill()\n",
    "bow_tow_with_weather['previous_windspeedKmph'] = bow_tow_with_weather.groupby(['Meter Type'])['windspeedKmph'].ffill()\n",
    "bow_tow_with_weather['previous_Associated Client Count'] = bow_tow_with_weather.groupby(['Meter Type'])['Associated Client Count'].ffill()\n",
    "bow_tow_with_weather['previous_Authenticated Client Count'] = bow_tow_with_weather.groupby(['Meter Type'])['Authenticated Client Count'].ffill()\n",
    "\n",
    "bow_tow_with_weather_no_occ[\"Year\"] = bow_tow_with_weather_no_occ['Date'].apply(lambda x:pd.Timestamp(x).strftime('%Y')).astype(float)\n",
    "bow_tow_with_weather_no_occ[\"Month\"] = bow_tow_with_weather_no_occ['Date'].apply(lambda x:pd.Timestamp(x).strftime('%m')).astype(float)\n",
    "bow_tow_with_weather_no_occ[\"Day\"] = bow_tow_with_weather_no_occ['Date'].apply(lambda x:pd.Timestamp(x).strftime('%d')).astype(float)\n",
    "\n",
    "bow_tow_with_weather_no_occ[\"hour\"] = bow_tow_with_weather_no_occ['Time'].apply(lambda x:pd.Timestamp(x).strftime('%H')).astype(float)\n",
    "bow_tow_with_weather_no_occ[\"minute\"] = bow_tow_with_weather_no_occ['Time'].apply(lambda x:pd.Timestamp(x).strftime('%M')).astype(float)\n",
    "bow_tow_with_weather_no_occ[\"second\"] = bow_tow_with_weather_no_occ['Time'].apply(lambda x:pd.Timestamp(x).strftime('%S')).astype(float)\n",
    "bow_tow_with_weather_no_occ[\"sunrise\"]=pd.to_datetime(bow_tow_with_weather_no_occ[\"sunrise\"])\n",
    "bow_tow_with_weather_no_occ[\"sunrise_hour\"] = bow_tow_with_weather_no_occ['sunrise'].dt.strftime('%H').astype(float)\n",
    "bow_tow_with_weather_no_occ[\"sunrise_minute\"] = bow_tow_with_weather_no_occ['sunrise'].dt.strftime('%M').astype(float)\n",
    "bow_tow_with_weather_no_occ[\"sunset\"]=pd.to_datetime(bow_tow_with_weather_no_occ[\"sunset\"])\n",
    "bow_tow_with_weather_no_occ[\"sunset_hour\"] = bow_tow_with_weather_no_occ['sunset'].dt.strftime('%H').astype(float)\n",
    "bow_tow_with_weather_no_occ[\"sunset_minute\"] = bow_tow_with_weather_no_occ['sunset'].dt.strftime('%M').astype(float)\n",
    "\n",
    "bow_tow_with_weather_no_occ['previous_mintempC'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['mintempC'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_maxtempC'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['maxtempC'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_totalSnow_cm'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['totalSnow_cm'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_sunHour'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['sunHour'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_uvIndex'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['uvIndex'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_moon_illumination'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['moon_illumination'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_sunrise_hour'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['sunrise_hour'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_sunrise_minute'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['sunrise_hour'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_sunset_hour'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['sunset_hour'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_sunset_minute'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['sunset_minute'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_DewPointC'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['DewPointC'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_FeelsLikeC'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['FeelsLikeC'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_HeatIndexC'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['HeatIndexC'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_WindChillC'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['WindChillC'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_WindGustKmph'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['WindGustKmph'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_cloudcover'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['cloudcover'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_humidity'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['humidity'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_precipMM'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['precipMM'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_pressure'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['pressure'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_tempC'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['tempC'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_visibility'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['visibility'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_winddirDegree'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['winddirDegree'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_mintempC'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['mintempC'].ffill()\n",
    "bow_tow_with_weather_no_occ['previous_windspeedKmph'] = bow_tow_with_weather_no_occ.groupby(['Meter Type'])['windspeedKmph'].ffill()\n",
    "\n",
    "bow_tow_with_weather=bow_tow_with_weather.sort_values(by='timestamp')\n",
    "bow_tow_with_weather.reset_index(drop=True)\n",
    "\n",
    "bow_tow_with_weather_no_occ=bow_tow_with_weather_no_occ.sort_values(by='timestamp')\n",
    "bow_tow_with_weather_no_occ.reset_index(drop=True)\n",
    "\n",
    "\n",
    "lec_with_weather[\"Year\"] = lec_with_weather['Date'].apply(lambda x:pd.Timestamp(x).strftime('%Y')).astype(float)\n",
    "lec_with_weather[\"Month\"] = lec_with_weather['Date'].apply(lambda x:pd.Timestamp(x).strftime('%m')).astype(float)\n",
    "lec_with_weather[\"Day\"] = lec_with_weather['Date'].apply(lambda x:pd.Timestamp(x).strftime('%d')).astype(float)\n",
    "\n",
    "lec_with_weather[\"hour\"] = lec_with_weather['Time'].apply(lambda x:pd.Timestamp(x).strftime('%H')).astype(float)\n",
    "lec_with_weather[\"minute\"] = lec_with_weather['Time'].apply(lambda x:pd.Timestamp(x).strftime('%M')).astype(float)\n",
    "lec_with_weather[\"second\"] = lec_with_weather['Time'].apply(lambda x:pd.Timestamp(x).strftime('%S')).astype(float)\n",
    "lec_with_weather[\"sunrise\"]=pd.to_datetime(lec_with_weather[\"sunrise\"])\n",
    "lec_with_weather[\"sunrise_hour\"] = lec_with_weather['sunrise'].dt.strftime('%H').astype(float)\n",
    "lec_with_weather[\"sunrise_minute\"] = lec_with_weather['sunrise'].dt.strftime('%M').astype(float)\n",
    "lec_with_weather[\"sunset\"]=pd.to_datetime(lec_with_weather[\"sunset\"])\n",
    "lec_with_weather[\"sunset_hour\"] = lec_with_weather['sunset'].dt.strftime('%H').astype(float)\n",
    "lec_with_weather[\"sunset_minute\"] = lec_with_weather['sunset'].dt.strftime('%M').astype(float)\n",
    "\n",
    "lec_with_weather['previous_mintempC'] = lec_with_weather.groupby(['Meter Type'])['mintempC'].ffill()\n",
    "lec_with_weather['previous_maxtempC'] = lec_with_weather.groupby(['Meter Type'])['maxtempC'].ffill()\n",
    "lec_with_weather['previous_totalSnow_cm'] = lec_with_weather.groupby(['Meter Type'])['totalSnow_cm'].ffill()\n",
    "lec_with_weather['previous_sunHour'] = lec_with_weather.groupby(['Meter Type'])['sunHour'].ffill()\n",
    "lec_with_weather['previous_uvIndex'] = lec_with_weather.groupby(['Meter Type'])['uvIndex'].ffill()\n",
    "lec_with_weather['previous_moon_illumination'] = lec_with_weather.groupby(['Meter Type'])['moon_illumination'].ffill()\n",
    "lec_with_weather['previous_sunrise_hour'] = lec_with_weather.groupby(['Meter Type'])['sunrise_hour'].ffill()\n",
    "lec_with_weather['previous_sunrise_minute'] = lec_with_weather.groupby(['Meter Type'])['sunrise_hour'].ffill()\n",
    "lec_with_weather['previous_sunset_hour'] = lec_with_weather.groupby(['Meter Type'])['sunset_hour'].ffill()\n",
    "lec_with_weather['previous_sunset_minute'] = lec_with_weather.groupby(['Meter Type'])['sunset_minute'].ffill()\n",
    "lec_with_weather['previous_DewPointC'] = lec_with_weather.groupby(['Meter Type'])['DewPointC'].ffill()\n",
    "lec_with_weather['previous_FeelsLikeC'] = lec_with_weather.groupby(['Meter Type'])['FeelsLikeC'].ffill()\n",
    "lec_with_weather['previous_HeatIndexC'] = lec_with_weather.groupby(['Meter Type'])['HeatIndexC'].ffill()\n",
    "lec_with_weather['previous_WindChillC'] = lec_with_weather.groupby(['Meter Type'])['WindChillC'].ffill()\n",
    "lec_with_weather['previous_WindGustKmph'] = lec_with_weather.groupby(['Meter Type'])['WindGustKmph'].ffill()\n",
    "lec_with_weather['previous_cloudcover'] = lec_with_weather.groupby(['Meter Type'])['cloudcover'].ffill()\n",
    "lec_with_weather['previous_humidity'] = lec_with_weather.groupby(['Meter Type'])['humidity'].ffill()\n",
    "lec_with_weather['previous_precipMM'] = lec_with_weather.groupby(['Meter Type'])['precipMM'].ffill()\n",
    "lec_with_weather['previous_pressure'] = lec_with_weather.groupby(['Meter Type'])['pressure'].ffill()\n",
    "lec_with_weather['previous_tempC'] = lec_with_weather.groupby(['Meter Type'])['tempC'].ffill()\n",
    "lec_with_weather['previous_visibility'] = lec_with_weather.groupby(['Meter Type'])['visibility'].ffill()\n",
    "lec_with_weather['previous_winddirDegree'] = lec_with_weather.groupby(['Meter Type'])['winddirDegree'].ffill()\n",
    "lec_with_weather['previous_mintempC'] = lec_with_weather.groupby(['Meter Type'])['mintempC'].ffill()\n",
    "lec_with_weather['previous_windspeedKmph'] = lec_with_weather.groupby(['Meter Type'])['windspeedKmph'].ffill()\n",
    "lec_with_weather['previous_Associated Client Count'] = lec_with_weather.groupby(['Meter Type'])['Associated Client Count'].ffill()\n",
    "lec_with_weather['previous_Authenticated Client Count'] = lec_with_weather.groupby(['Meter Type'])['Authenticated Client Count'].ffill()\n",
    "\n",
    "lec_with_weather_no_occ[\"Year\"] = lec_with_weather_no_occ['Date'].apply(lambda x:pd.Timestamp(x).strftime('%Y')).astype(float)\n",
    "lec_with_weather_no_occ[\"Month\"] = lec_with_weather_no_occ['Date'].apply(lambda x:pd.Timestamp(x).strftime('%m')).astype(float)\n",
    "lec_with_weather_no_occ[\"Day\"] = lec_with_weather_no_occ['Date'].apply(lambda x:pd.Timestamp(x).strftime('%d')).astype(float)\n",
    "\n",
    "lec_with_weather_no_occ[\"hour\"] =lec_with_weather_no_occ['Time'].apply(lambda x:pd.Timestamp(x).strftime('%H')).astype(float)\n",
    "lec_with_weather_no_occ[\"minute\"] = lec_with_weather_no_occ['Time'].apply(lambda x:pd.Timestamp(x).strftime('%M')).astype(float)\n",
    "lec_with_weather_no_occ[\"second\"] = lec_with_weather_no_occ['Time'].apply(lambda x:pd.Timestamp(x).strftime('%S')).astype(float)\n",
    "lec_with_weather_no_occ[\"sunrise\"]=pd.to_datetime(lec_with_weather_no_occ[\"sunrise\"])\n",
    "lec_with_weather_no_occ[\"sunrise_hour\"] = lec_with_weather_no_occ['sunrise'].dt.strftime('%H').astype(float)\n",
    "lec_with_weather_no_occ[\"sunrise_minute\"] = lec_with_weather_no_occ['sunrise'].dt.strftime('%M').astype(float)\n",
    "lec_with_weather_no_occ[\"sunset\"]=pd.to_datetime(lec_with_weather_no_occ[\"sunset\"])\n",
    "lec_with_weather_no_occ[\"sunset_hour\"] = lec_with_weather_no_occ['sunset'].dt.strftime('%H').astype(float)\n",
    "lec_with_weather_no_occ[\"sunset_minute\"] = lec_with_weather_no_occ['sunset'].dt.strftime('%M').astype(float)\n",
    "\n",
    "lec_with_weather_no_occ['previous_mintempC'] = lec_with_weather_no_occ.groupby(['Meter Type'])['mintempC'].ffill()\n",
    "lec_with_weather_no_occ['previous_maxtempC'] = lec_with_weather_no_occ.groupby(['Meter Type'])['maxtempC'].ffill()\n",
    "lec_with_weather_no_occ['previous_totalSnow_cm'] = lec_with_weather_no_occ.groupby(['Meter Type'])['totalSnow_cm'].ffill()\n",
    "lec_with_weather_no_occ['previous_sunHour'] = lec_with_weather_no_occ.groupby(['Meter Type'])['sunHour'].ffill()\n",
    "lec_with_weather_no_occ['previous_uvIndex'] = lec_with_weather_no_occ.groupby(['Meter Type'])['uvIndex'].ffill()\n",
    "lec_with_weather_no_occ['previous_moon_illumination'] = lec_with_weather_no_occ.groupby(['Meter Type'])['moon_illumination'].ffill()\n",
    "lec_with_weather_no_occ['previous_sunrise_hour'] = lec_with_weather_no_occ.groupby(['Meter Type'])['sunrise_hour'].ffill()\n",
    "lec_with_weather_no_occ['previous_sunrise_minute'] = lec_with_weather_no_occ.groupby(['Meter Type'])['sunrise_hour'].ffill()\n",
    "lec_with_weather_no_occ['previous_sunset_hour'] = lec_with_weather_no_occ.groupby(['Meter Type'])['sunset_hour'].ffill()\n",
    "lec_with_weather_no_occ['previous_sunset_minute'] = lec_with_weather_no_occ.groupby(['Meter Type'])['sunset_minute'].ffill()\n",
    "lec_with_weather_no_occ['previous_DewPointC'] = lec_with_weather_no_occ.groupby(['Meter Type'])['DewPointC'].ffill()\n",
    "lec_with_weather_no_occ['previous_FeelsLikeC'] = lec_with_weather_no_occ.groupby(['Meter Type'])['FeelsLikeC'].ffill()\n",
    "lec_with_weather_no_occ['previous_HeatIndexC'] = lec_with_weather_no_occ.groupby(['Meter Type'])['HeatIndexC'].ffill()\n",
    "lec_with_weather_no_occ['previous_WindChillC'] = lec_with_weather_no_occ.groupby(['Meter Type'])['WindChillC'].ffill()\n",
    "lec_with_weather_no_occ['previous_WindGustKmph'] = lec_with_weather_no_occ.groupby(['Meter Type'])['WindGustKmph'].ffill()\n",
    "lec_with_weather_no_occ['previous_cloudcover'] = lec_with_weather_no_occ.groupby(['Meter Type'])['cloudcover'].ffill()\n",
    "lec_with_weather_no_occ['previous_humidity'] = lec_with_weather_no_occ.groupby(['Meter Type'])['humidity'].ffill()\n",
    "lec_with_weather_no_occ['previous_precipMM'] = lec_with_weather_no_occ.groupby(['Meter Type'])['precipMM'].ffill()\n",
    "lec_with_weather_no_occ['previous_pressure'] = lec_with_weather_no_occ.groupby(['Meter Type'])['pressure'].ffill()\n",
    "lec_with_weather_no_occ['previous_tempC'] = lec_with_weather_no_occ.groupby(['Meter Type'])['tempC'].ffill()\n",
    "lec_with_weather_no_occ['previous_visibility'] = lec_with_weather_no_occ.groupby(['Meter Type'])['visibility'].ffill()\n",
    "lec_with_weather_no_occ['previous_winddirDegree'] = lec_with_weather_no_occ.groupby(['Meter Type'])['winddirDegree'].ffill()\n",
    "lec_with_weather_no_occ['previous_mintempC'] = lec_with_weather_no_occ.groupby(['Meter Type'])['mintempC'].ffill()\n",
    "lec_with_weather_no_occ['previous_windspeedKmph'] = lec_with_weather_no_occ.groupby(['Meter Type'])['windspeedKmph'].ffill()\n",
    "\n",
    "lec_with_weather=lec_with_weather.sort_values(by='timestamp')\n",
    "lec_with_weather.reset_index(drop=True)\n",
    "\n",
    "lec_with_weather_no_occ=lec_with_weather_no_occ.sort_values(by='timestamp')\n",
    "lec_with_weather_no_occ.reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_data_bow=bow_tow_with_weather\n",
    "train_data_bow_no_occ=bow_tow_with_weather_no_occ\n",
    "\n",
    "train_data_lec=lec_with_weather\n",
    "train_data_lec_no_occ=lec_with_weather_no_occ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_features=['reading','previous_maxtempC','previous_mintempC','previous_totalSnow_cm',\n",
    "          'previous_sunHour','previous_uvIndex','previous_moon_illumination','previous_sunrise_hour','previous_sunrise_minute',\n",
    "          'previous_sunset_hour','previous_sunset_minute','previous_DewPointC','previous_FeelsLikeC','previous_HeatIndexC','previous_WindChillC',\n",
    "          'previous_WindGustKmph','previous_cloudcover','previous_humidity','previous_precipMM','previous_pressure',\n",
    "          'previous_tempC','previous_visibility','previous_winddirDegree','previous_windspeedKmph',\n",
    "          'previous_Associated Client Count','previous_Authenticated Client Count', 'Day_type_as_int', 'Year',\n",
    "          'Month', 'Day','hour','minute', 'Term_as_int']\n",
    "train_data_bow=train_data_bow[train_features]\n",
    "\n",
    "bow_day_avg_reading=[]\n",
    "bow_day_avg_maxtemp=[]\n",
    "bow_day_avg_mintemp=[]\n",
    "bow_day_avg_snow=[]\n",
    "bow_day_avg_sunhour=[]\n",
    "bow_day_avg_uvindex=[]\n",
    "bow_day_avg_moonillumination=[]\n",
    "bow_day_avg_sunrise_hr=[]\n",
    "bow_day_avg_sunrise_min=[]\n",
    "bow_day_avg_sunset_hr=[]\n",
    "bow_day_avg_sunset_min=[]\n",
    "bow_day_avg_dewpoint=[]\n",
    "bow_day_avg_feelslike=[]\n",
    "bow_day_avg_heatindex=[]\n",
    "bow_day_avg_windchill=[]\n",
    "bow_day_avg_windgust=[]\n",
    "bow_day_avg_cloud=[]\n",
    "bow_day_avg_humidity=[]\n",
    "bow_day_avg_precip=[]\n",
    "bow_day_avg_pressure=[]\n",
    "bow_day_avg_temp=[]\n",
    "bow_day_avg_visibility=[]\n",
    "bow_day_avg_winddir=[]\n",
    "bow_day_avg_windspeed=[]\n",
    "bow_day_avg_as_client=[]\n",
    "bow_day_avg_auth_client=[]\n",
    "for  i in range(train_data_bow.index.min(), (train_data_bow.index.max()+1)):\n",
    "    if i-144 < 0:\n",
    "        bow_day_avg_reading.append(train_data_bow.reading[i])\n",
    "        bow_day_avg_maxtemp.append(train_data_bow.previous_maxtempC[i])\n",
    "        bow_day_avg_mintemp.append(train_data_bow.previous_mintempC[i])\n",
    "        bow_day_avg_snow.append(train_data_bow.previous_totalSnow_cm[i])\n",
    "        bow_day_avg_sunhour.append(train_data_bow.previous_sunHour[i])\n",
    "        bow_day_avg_uvindex.append(train_data_bow.previous_uvIndex[i])\n",
    "        bow_day_avg_moonillumination.append(train_data_bow.previous_moon_illumination[i])\n",
    "        bow_day_avg_sunrise_hr.append(train_data_bow.previous_sunrise_hour[i])\n",
    "        bow_day_avg_sunrise_min.append(train_data_bow.previous_sunrise_minute[i])\n",
    "        bow_day_avg_sunset_hr.append(train_data_bow.previous_sunset_hour[i])\n",
    "        bow_day_avg_sunset_min.append(train_data_bow.previous_sunset_minute[i])\n",
    "        bow_day_avg_dewpoint.append(train_data_bow.previous_DewPointC[i])\n",
    "        bow_day_avg_feelslike.append(train_data_bow.previous_FeelsLikeC[i])\n",
    "        bow_day_avg_heatindex.append(train_data_bow.previous_HeatIndexC[i])\n",
    "        bow_day_avg_windchill.append(train_data_bow.previous_WindChillC[i])\n",
    "        bow_day_avg_windgust.append(train_data_bow.previous_WindGustKmph[i])\n",
    "        bow_day_avg_cloud.append(train_data_bow.previous_cloudcover[i])\n",
    "        bow_day_avg_humidity.append(train_data_bow.previous_humidity[i])\n",
    "        bow_day_avg_precip.append(train_data_bow.previous_precipMM[i])\n",
    "        bow_day_avg_pressure.append(train_data_bow.previous_pressure[i])\n",
    "        bow_day_avg_temp.append(train_data_bow.previous_tempC[i])\n",
    "        bow_day_avg_visibility.append(train_data_bow.previous_visibility[i])\n",
    "        bow_day_avg_winddir.append(train_data_bow.previous_winddirDegree[i])\n",
    "        bow_day_avg_windspeed.append(train_data_bow.previous_windspeedKmph[i])\n",
    "        bow_day_avg_as_client.append(train_data_bow['previous_Associated Client Count'][i])\n",
    "        bow_day_avg_auth_client.append(train_data_bow['previous_Authenticated Client Count'][i])\n",
    "    else:\n",
    "        bow_day_avg_reading.append(statistics.mean(train_data_bow.reading[(i-144):(i-1)]))\n",
    "        bow_day_avg_maxtemp.append(statistics.mean(train_data_bow.previous_maxtempC[(i-144):(i-1)]))\n",
    "        bow_day_avg_mintemp.append(statistics.mean(train_data_bow.previous_mintempC[(i-144):(i-1)]))\n",
    "        bow_day_avg_snow.append(statistics.mean(train_data_bow.previous_totalSnow_cm[(i-144):(i-1)]))\n",
    "        bow_day_avg_sunhour.append(statistics.mean(train_data_bow.previous_sunHour[(i-144):(i-1)]))\n",
    "        bow_day_avg_uvindex.append(statistics.mean(train_data_bow.previous_uvIndex[(i-144):(i-1)]))\n",
    "        bow_day_avg_moonillumination.append(statistics.mean(train_data_bow.previous_moon_illumination[(i-144):(i-1)]))\n",
    "        bow_day_avg_sunrise_hr.append(statistics.mean(train_data_bow.previous_sunrise_hour[(i-144):(i-1)]))\n",
    "        bow_day_avg_sunrise_min.append(statistics.mean(train_data_bow.previous_sunrise_minute[(i-144):(i-1)]))\n",
    "        bow_day_avg_sunset_hr.append(statistics.mean(train_data_bow.previous_sunset_hour[(i-144):(i-1)]))\n",
    "        bow_day_avg_sunset_min.append(statistics.mean(train_data_bow.previous_sunset_minute[(i-144):(i-1)]))\n",
    "        bow_day_avg_dewpoint.append(statistics.mean(train_data_bow.previous_DewPointC[(i-144):(i-1)]))\n",
    "        bow_day_avg_feelslike.append(statistics.mean(train_data_bow.previous_FeelsLikeC[(i-144):(i-1)]))\n",
    "        bow_day_avg_heatindex.append(statistics.mean(train_data_bow.previous_HeatIndexC[(i-144):(i-1)]))\n",
    "        bow_day_avg_windchill.append(statistics.mean(train_data_bow.previous_WindChillC[(i-144):(i-1)]))\n",
    "        bow_day_avg_windgust.append(statistics.mean(train_data_bow.previous_WindGustKmph[(i-144):(i-1)]))\n",
    "        bow_day_avg_cloud.append(statistics.mean(train_data_bow.previous_cloudcover[(i-144):(i-1)]))\n",
    "        bow_day_avg_humidity.append(statistics.mean(train_data_bow.previous_humidity[(i-144):(i-1)]))\n",
    "        bow_day_avg_precip.append(statistics.mean(train_data_bow.previous_precipMM[(i-144):(i-1)]))\n",
    "        bow_day_avg_pressure.append(statistics.mean(train_data_bow.previous_pressure[(i-144):(i-1)]))\n",
    "        bow_day_avg_temp.append(statistics.mean(train_data_bow.previous_tempC[(i-144):(i-1)]))\n",
    "        bow_day_avg_visibility.append(statistics.mean(train_data_bow.previous_visibility[(i-144):(i-1)]))\n",
    "        bow_day_avg_winddir.append(statistics.mean(train_data_bow.previous_winddirDegree[(i-144):(i-1)]))\n",
    "        bow_day_avg_windspeed.append(statistics.mean(train_data_bow.previous_windspeedKmph[(i-144):(i-1)]))\n",
    "        bow_day_avg_as_client.append(statistics.mean(train_data_bow['previous_Associated Client Count'][(i-144):(i-1)]))\n",
    "        bow_day_avg_auth_client.append(statistics.mean(train_data_bow['previous_Authenticated Client Count'][(i-144):(i-1)]))\n",
    "\n",
    "train_data_bow['day_avg_reading']=bow_day_avg_reading\n",
    "train_data_bow['day_avg_maxtemp']=bow_day_avg_maxtemp\n",
    "train_data_bow['day_avg_mintemp']=bow_day_avg_mintemp\n",
    "train_data_bow['day_avg_snow']=bow_day_avg_snow\n",
    "train_data_bow['day_avg_sunhour']=bow_day_avg_sunhour\n",
    "train_data_bow['day_avg_uvindex']=bow_day_avg_uvindex\n",
    "train_data_bow['day_avg_moonillumination']=bow_day_avg_moonillumination\n",
    "train_data_bow['day_avg_sunrise_hr']=bow_day_avg_sunrise_hr\n",
    "train_data_bow['day_avg_sunrise_min']=bow_day_avg_sunrise_min\n",
    "train_data_bow['day_avg_sunset_hr']=bow_day_avg_sunset_hr\n",
    "train_data_bow['day_avg_sunset_min']=bow_day_avg_sunset_min\n",
    "train_data_bow['day_avg_dewpoint']=bow_day_avg_dewpoint\n",
    "train_data_bow['day_avg_feelslike']=bow_day_avg_feelslike\n",
    "train_data_bow['day_avg_heatindex']=bow_day_avg_heatindex\n",
    "train_data_bow['day_avg_windchill']=bow_day_avg_windchill\n",
    "train_data_bow['day_avg_windgust']=bow_day_avg_windgust\n",
    "train_data_bow['day_avg_cloud']=bow_day_avg_cloud\n",
    "train_data_bow['day_avg_humidity']=bow_day_avg_humidity\n",
    "train_data_bow['day_avg_precip']=bow_day_avg_precip\n",
    "train_data_bow['day_avg_pressure']=bow_day_avg_pressure\n",
    "train_data_bow['day_avg_temp']=bow_day_avg_temp\n",
    "train_data_bow['day_avg_visibility']=bow_day_avg_visibility\n",
    "train_data_bow['day_avg_winddir']=bow_day_avg_winddir\n",
    "train_data_bow['day_avg_windspeed']=bow_day_avg_windspeed\n",
    "train_data_bow['day_avg_as_client']=bow_day_avg_as_client\n",
    "train_data_bow['day_avg_auth_client']=bow_day_avg_auth_client\n",
    "\n",
    "train_data_lec=train_data_lec[train_features]\n",
    "\n",
    "l_day_avg_reading=[]\n",
    "l_day_avg_maxtemp=[]\n",
    "l_day_avg_mintemp=[]\n",
    "l_day_avg_snow=[]\n",
    "l_day_avg_sunhour=[]\n",
    "l_day_avg_uvindex=[]\n",
    "l_day_avg_moonillumination=[]\n",
    "l_day_avg_sunrise_hr=[]\n",
    "l_day_avg_sunrise_min=[]\n",
    "l_day_avg_sunset_hr=[]\n",
    "l_day_avg_sunset_min=[]\n",
    "l_day_avg_dewpoint=[]\n",
    "l_day_avg_feelslike=[]\n",
    "l_day_avg_heatindex=[]\n",
    "l_day_avg_windchill=[]\n",
    "l_day_avg_windgust=[]\n",
    "l_day_avg_cloud=[]\n",
    "l_day_avg_humidity=[]\n",
    "l_day_avg_precip=[]\n",
    "l_day_avg_pressure=[]\n",
    "l_day_avg_temp=[]\n",
    "l_day_avg_visibility=[]\n",
    "l_day_avg_winddir=[]\n",
    "l_day_avg_windspeed=[]\n",
    "l_day_avg_as_client=[]\n",
    "l_day_avg_auth_client=[]\n",
    "for  i in range(train_data_lec.index.min(), (train_data_lec.index.max()+1)):\n",
    "    if i-144 < 0:\n",
    "        l_day_avg_reading.append(train_data_lec.reading[i])\n",
    "        l_day_avg_maxtemp.append(train_data_lec.previous_maxtempC[i])\n",
    "        l_day_avg_mintemp.append(train_data_lec.previous_mintempC[i])\n",
    "        l_day_avg_snow.append(train_data_lec.previous_totalSnow_cm[i])\n",
    "        l_day_avg_sunhour.append(train_data_lec.previous_sunHour[i])\n",
    "        l_day_avg_uvindex.append(train_data_lec.previous_uvIndex[i])\n",
    "        l_day_avg_moonillumination.append(train_data_lec.previous_moon_illumination[i])\n",
    "        l_day_avg_sunrise_hr.append(train_data_lec.previous_sunrise_hour[i])\n",
    "        l_day_avg_sunrise_min.append(train_data_lec.previous_sunrise_minute[i])\n",
    "        l_day_avg_sunset_hr.append(train_data_lec.previous_sunset_hour[i])\n",
    "        l_day_avg_sunset_min.append(train_data_lec.previous_sunset_minute[i])\n",
    "        l_day_avg_dewpoint.append(train_data_lec.previous_DewPointC[i])\n",
    "        l_day_avg_feelslike.append(train_data_lec.previous_FeelsLikeC[i])\n",
    "        l_day_avg_heatindex.append(train_data_lec.previous_HeatIndexC[i])\n",
    "        l_day_avg_windchill.append(train_data_lec.previous_WindChillC[i])\n",
    "        l_day_avg_windgust.append(train_data_lec.previous_WindGustKmph[i])\n",
    "        l_day_avg_cloud.append(train_data_lec.previous_cloudcover[i])\n",
    "        l_day_avg_humidity.append(train_data_lec.previous_humidity[i])\n",
    "        l_day_avg_precip.append(train_data_lec.previous_precipMM[i])\n",
    "        l_day_avg_pressure.append(train_data_lec.previous_pressure[i])\n",
    "        l_day_avg_temp.append(train_data_lec.previous_tempC[i])\n",
    "        l_day_avg_visibility.append(train_data_lec.previous_visibility[i])\n",
    "        l_day_avg_winddir.append(train_data_lec.previous_winddirDegree[i])\n",
    "        l_day_avg_windspeed.append(train_data_lec.previous_windspeedKmph[i])\n",
    "        l_day_avg_as_client.append(train_data_lec['previous_Associated Client Count'][i])\n",
    "        l_day_avg_auth_client.append(train_data_lec['previous_Authenticated Client Count'][i])\n",
    "    else:\n",
    "        l_day_avg_reading.append(statistics.mean(train_data_lec.reading[(i-144):(i-1)]))\n",
    "        l_day_avg_maxtemp.append(statistics.mean(train_data_lec.previous_maxtempC[(i-144):(i-1)]))\n",
    "        l_day_avg_mintemp.append(statistics.mean(train_data_lec.previous_mintempC[(i-144):(i-1)]))\n",
    "        l_day_avg_snow.append(statistics.mean(train_data_lec.previous_totalSnow_cm[(i-144):(i-1)]))\n",
    "        l_day_avg_sunhour.append(statistics.mean(train_data_lec.previous_sunHour[(i-144):(i-1)]))\n",
    "        l_day_avg_uvindex.append(statistics.mean(train_data_lec.previous_uvIndex[(i-144):(i-1)]))\n",
    "        l_day_avg_moonillumination.append(statistics.mean(train_data_lec.previous_moon_illumination[(i-144):(i-1)]))\n",
    "        l_day_avg_sunrise_hr.append(statistics.mean(train_data_lec.previous_sunrise_hour[(i-144):(i-1)]))\n",
    "        l_day_avg_sunrise_min.append(statistics.mean(train_data_lec.previous_sunrise_minute[(i-144):(i-1)]))\n",
    "        l_day_avg_sunset_hr.append(statistics.mean(train_data_lec.previous_sunset_hour[(i-144):(i-1)]))\n",
    "        l_day_avg_sunset_min.append(statistics.mean(train_data_lec.previous_sunset_minute[(i-144):(i-1)]))\n",
    "        l_day_avg_dewpoint.append(statistics.mean(train_data_lec.previous_DewPointC[(i-144):(i-1)]))\n",
    "        l_day_avg_feelslike.append(statistics.mean(train_data_lec.previous_FeelsLikeC[(i-144):(i-1)]))\n",
    "        l_day_avg_heatindex.append(statistics.mean(train_data_lec.previous_HeatIndexC[(i-144):(i-1)]))\n",
    "        l_day_avg_windchill.append(statistics.mean(train_data_lec.previous_WindChillC[(i-144):(i-1)]))\n",
    "        l_day_avg_windgust.append(statistics.mean(train_data_lec.previous_WindGustKmph[(i-144):(i-1)]))\n",
    "        l_day_avg_cloud.append(statistics.mean(train_data_lec.previous_cloudcover[(i-144):(i-1)]))\n",
    "        l_day_avg_humidity.append(statistics.mean(train_data_lec.previous_humidity[(i-144):(i-1)]))\n",
    "        l_day_avg_precip.append(statistics.mean(train_data_lec.previous_precipMM[(i-144):(i-1)]))\n",
    "        l_day_avg_pressure.append(statistics.mean(train_data_lec.previous_pressure[(i-144):(i-1)]))\n",
    "        l_day_avg_temp.append(statistics.mean(train_data_lec.previous_tempC[(i-144):(i-1)]))\n",
    "        l_day_avg_visibility.append(statistics.mean(train_data_lec.previous_visibility[(i-144):(i-1)]))\n",
    "        l_day_avg_winddir.append(statistics.mean(train_data_lec.previous_winddirDegree[(i-144):(i-1)]))\n",
    "        l_day_avg_windspeed.append(statistics.mean(train_data_lec.previous_windspeedKmph[(i-144):(i-1)]))\n",
    "        l_day_avg_as_client.append(statistics.mean(train_data_lec['previous_Associated Client Count'][(i-144):(i-1)]))\n",
    "        l_day_avg_auth_client.append(statistics.mean(train_data_lec['previous_Authenticated Client Count'][(i-144):(i-1)]))\n",
    "\n",
    "train_data_lec['day_avg_reading']=l_day_avg_reading\n",
    "train_data_lec['day_avg_maxtemp']=l_day_avg_maxtemp\n",
    "train_data_lec['day_avg_mintemp']=l_day_avg_mintemp\n",
    "train_data_lec['day_avg_snow']=l_day_avg_snow\n",
    "train_data_lec['day_avg_sunhour']=l_day_avg_sunhour\n",
    "train_data_lec['day_avg_uvindex']=l_day_avg_uvindex\n",
    "train_data_lec['day_avg_moonillumination']=l_day_avg_moonillumination\n",
    "train_data_lec['day_avg_sunrise_hr']=l_day_avg_sunrise_hr\n",
    "train_data_lec['day_avg_sunrise_min']=l_day_avg_sunrise_min\n",
    "train_data_lec['day_avg_sunset_hr']=l_day_avg_sunset_hr\n",
    "train_data_lec['day_avg_sunset_min']=l_day_avg_sunset_min\n",
    "train_data_lec['day_avg_dewpoint']=l_day_avg_dewpoint\n",
    "train_data_lec['day_avg_feelslike']=l_day_avg_feelslike\n",
    "train_data_lec['day_avg_heatindex']=l_day_avg_heatindex\n",
    "train_data_lec['day_avg_windchill']=l_day_avg_windchill\n",
    "train_data_lec['day_avg_windgust']=l_day_avg_windgust\n",
    "train_data_lec['day_avg_cloud']=l_day_avg_cloud\n",
    "train_data_lec['day_avg_humidity']=l_day_avg_humidity\n",
    "train_data_lec['day_avg_precip']=l_day_avg_precip\n",
    "train_data_lec['day_avg_pressure']=l_day_avg_pressure\n",
    "train_data_lec['day_avg_temp']=l_day_avg_temp\n",
    "train_data_lec['day_avg_visibility']=l_day_avg_visibility\n",
    "train_data_lec['day_avg_winddir']=l_day_avg_winddir\n",
    "train_data_lec['day_avg_windspeed']=l_day_avg_windspeed\n",
    "train_data_lec['day_avg_as_client']=l_day_avg_as_client\n",
    "train_data_lec['day_avg_auth_client']=l_day_avg_auth_client\n",
    "\n",
    "train_features_no_occ=['reading','previous_maxtempC','previous_mintempC','previous_totalSnow_cm',\n",
    "          'previous_sunHour','previous_uvIndex','previous_moon_illumination','previous_sunrise_hour','previous_sunrise_minute',\n",
    "          'previous_sunset_hour','previous_sunset_minute','previous_DewPointC','previous_FeelsLikeC','previous_HeatIndexC','previous_WindChillC',\n",
    "          'previous_WindGustKmph','previous_cloudcover','previous_humidity','previous_precipMM','previous_pressure',\n",
    "          'previous_tempC','previous_visibility','previous_winddirDegree','previous_windspeedKmph', 'Day_type_as_int', 'Year',\n",
    "          'Month', 'Day','hour','minute', 'Term_as_int']\n",
    "train_data_no_occ=train_data_bow_no_occ[train_features_no_occ]\n",
    "\n",
    "day_avg_reading_no_occ=[]\n",
    "day_avg_maxtemp_no_occ=[]\n",
    "day_avg_mintemp_no_occ=[]\n",
    "day_avg_snow_no_occ=[]\n",
    "day_avg_sunhour_no_occ=[]\n",
    "day_avg_uvindex_no_occ=[]\n",
    "day_avg_moonillumination_no_occ=[]\n",
    "day_avg_sunrise_hr_no_occ=[]\n",
    "day_avg_sunrise_min_no_occ=[]\n",
    "day_avg_sunset_hr_no_occ=[]\n",
    "day_avg_sunset_min_no_occ=[]\n",
    "day_avg_dewpoint_no_occ=[]\n",
    "day_avg_feelslike_no_occ=[]\n",
    "day_avg_heatindex_no_occ=[]\n",
    "day_avg_windchill_no_occ=[]\n",
    "day_avg_windgust_no_occ=[]\n",
    "day_avg_cloud_no_occ=[]\n",
    "day_avg_humidity_no_occ=[]\n",
    "day_avg_precip_no_occ=[]\n",
    "day_avg_pressure_no_occ=[]\n",
    "day_avg_temp_no_occ=[]\n",
    "day_avg_visibility_no_occ=[]\n",
    "day_avg_winddir_no_occ=[]\n",
    "day_avg_windspeed_no_occ=[]\n",
    "\n",
    "for  i in range(train_data_no_occ.index.min(), (train_data_no_occ.index.max()+1)):\n",
    "    if i-144 < 0:\n",
    "        day_avg_reading_no_occ.append(train_data_no_occ.reading[i])\n",
    "        day_avg_maxtemp_no_occ.append(train_data_no_occ.previous_maxtempC[i])\n",
    "        day_avg_mintemp_no_occ.append(train_data_no_occ.previous_mintempC[i])\n",
    "        day_avg_snow_no_occ.append(train_data_no_occ.previous_totalSnow_cm[i])\n",
    "        day_avg_sunhour_no_occ.append(train_data_no_occ.previous_sunHour[i])\n",
    "        day_avg_uvindex_no_occ.append(train_data_no_occ.previous_uvIndex[i])\n",
    "        day_avg_moonillumination_no_occ.append(train_data_no_occ.previous_moon_illumination[i])\n",
    "        day_avg_sunrise_hr_no_occ.append(train_data_no_occ.previous_sunrise_hour[i])\n",
    "        day_avg_sunrise_min_no_occ.append(train_data_no_occ.previous_sunrise_minute[i])\n",
    "        day_avg_sunset_hr_no_occ.append(train_data_no_occ.previous_sunset_hour[i])\n",
    "        day_avg_sunset_min_no_occ.append(train_data_no_occ.previous_sunset_minute[i])\n",
    "        day_avg_dewpoint_no_occ.append(train_data_no_occ.previous_DewPointC[i])\n",
    "        day_avg_feelslike_no_occ.append(train_data_no_occ.previous_FeelsLikeC[i])\n",
    "        day_avg_heatindex_no_occ.append(train_data_no_occ.previous_HeatIndexC[i])\n",
    "        day_avg_windchill_no_occ.append(train_data_no_occ.previous_WindChillC[i])\n",
    "        day_avg_windgust_no_occ.append(train_data_no_occ.previous_WindGustKmph[i])\n",
    "        day_avg_cloud_no_occ.append(train_data_no_occ.previous_cloudcover[i])\n",
    "        day_avg_humidity_no_occ.append(train_data_no_occ.previous_humidity[i])\n",
    "        day_avg_precip_no_occ.append(train_data_no_occ.previous_precipMM[i])\n",
    "        day_avg_pressure_no_occ.append(train_data_no_occ.previous_pressure[i])\n",
    "        day_avg_temp_no_occ.append(train_data_no_occ.previous_tempC[i])\n",
    "        day_avg_visibility_no_occ.append(train_data_no_occ.previous_visibility[i])\n",
    "        day_avg_winddir_no_occ.append(train_data_no_occ.previous_winddirDegree[i])\n",
    "        day_avg_windspeed_no_occ.append(train_data_no_occ.previous_windspeedKmph[i])\n",
    "       \n",
    "    else:\n",
    "        day_avg_reading_no_occ.append(statistics.mean(train_data_no_occ.reading[(i-144):(i-1)]))\n",
    "        day_avg_maxtemp_no_occ.append(statistics.mean(train_data_no_occ.previous_maxtempC[(i-144):(i-1)]))\n",
    "        day_avg_mintemp_no_occ.append(statistics.mean(train_data_no_occ.previous_mintempC[(i-144):(i-1)]))\n",
    "        day_avg_snow_no_occ.append(statistics.mean(train_data_no_occ.previous_totalSnow_cm[(i-144):(i-1)]))\n",
    "        day_avg_sunhour_no_occ.append(statistics.mean(train_data_no_occ.previous_sunHour[(i-144):(i-1)]))\n",
    "        day_avg_uvindex_no_occ.append(statistics.mean(train_data_no_occ.previous_uvIndex[(i-144):(i-1)]))\n",
    "        day_avg_moonillumination_no_occ.append(statistics.mean(train_data_no_occ.previous_moon_illumination[(i-144):(i-1)]))\n",
    "        day_avg_sunrise_hr_no_occ.append(statistics.mean(train_data_no_occ.previous_sunrise_hour[(i-144):(i-1)]))\n",
    "        day_avg_sunrise_min_no_occ.append(statistics.mean(train_data_no_occ.previous_sunrise_minute[(i-144):(i-1)]))\n",
    "        day_avg_sunset_hr_no_occ.append(statistics.mean(train_data_no_occ.previous_sunset_hour[(i-144):(i-1)]))\n",
    "        day_avg_sunset_min_no_occ.append(statistics.mean(train_data_no_occ.previous_sunset_minute[(i-144):(i-1)]))\n",
    "        day_avg_dewpoint_no_occ.append(statistics.mean(train_data_no_occ.previous_DewPointC[(i-144):(i-1)]))\n",
    "        day_avg_feelslike_no_occ.append(statistics.mean(train_data_no_occ.previous_FeelsLikeC[(i-144):(i-1)]))\n",
    "        day_avg_heatindex_no_occ.append(statistics.mean(train_data_no_occ.previous_HeatIndexC[(i-144):(i-1)]))\n",
    "        day_avg_windchill_no_occ.append(statistics.mean(train_data_no_occ.previous_WindChillC[(i-144):(i-1)]))\n",
    "        day_avg_windgust_no_occ.append(statistics.mean(train_data_no_occ.previous_WindGustKmph[(i-144):(i-1)]))\n",
    "        day_avg_cloud_no_occ.append(statistics.mean(train_data_no_occ.previous_cloudcover[(i-144):(i-1)]))\n",
    "        day_avg_humidity_no_occ.append(statistics.mean(train_data_no_occ.previous_humidity[(i-144):(i-1)]))\n",
    "        day_avg_precip_no_occ.append(statistics.mean(train_data_no_occ.previous_precipMM[(i-144):(i-1)]))\n",
    "        day_avg_pressure_no_occ.append(statistics.mean(train_data_no_occ.previous_pressure[(i-144):(i-1)]))\n",
    "        day_avg_temp_no_occ.append(statistics.mean(train_data_no_occ.previous_tempC[(i-144):(i-1)]))\n",
    "        day_avg_visibility_no_occ.append(statistics.mean(train_data_no_occ.previous_visibility[(i-144):(i-1)]))\n",
    "        day_avg_winddir_no_occ.append(statistics.mean(train_data_no_occ.previous_winddirDegree[(i-144):(i-1)]))\n",
    "        day_avg_windspeed_no_occ.append(statistics.mean(train_data_no_occ.previous_windspeedKmph[(i-144):(i-1)]))\n",
    "        \n",
    "\n",
    "train_data_no_occ['day_avg_reading']=day_avg_reading_no_occ\n",
    "train_data_no_occ['day_avg_maxtemp']=day_avg_maxtemp_no_occ\n",
    "train_data_no_occ['day_avg_mintemp']=day_avg_mintemp_no_occ\n",
    "train_data_no_occ['day_avg_snow']=day_avg_snow_no_occ\n",
    "train_data_no_occ['day_avg_sunhour']=day_avg_sunhour_no_occ\n",
    "train_data_no_occ['day_avg_uvindex']=day_avg_uvindex_no_occ\n",
    "train_data_no_occ['day_avg_moonillumination']=day_avg_moonillumination_no_occ\n",
    "train_data_no_occ['day_avg_sunrise_hr']=day_avg_sunrise_hr_no_occ\n",
    "train_data_no_occ['day_avg_sunrise_min']=day_avg_sunrise_min_no_occ\n",
    "train_data_no_occ['day_avg_sunset_hr']=day_avg_sunset_hr_no_occ\n",
    "train_data_no_occ['day_avg_sunset_min']=day_avg_sunset_min_no_occ\n",
    "train_data_no_occ['day_avg_dewpoint']=day_avg_dewpoint_no_occ\n",
    "train_data_no_occ['day_avg_feelslike']=day_avg_feelslike_no_occ\n",
    "train_data_no_occ['day_avg_heatindex']=day_avg_heatindex_no_occ\n",
    "train_data_no_occ['day_avg_windchill']=day_avg_windchill_no_occ\n",
    "train_data_no_occ['day_avg_windgust']=day_avg_windgust_no_occ\n",
    "train_data_no_occ['day_avg_cloud']=day_avg_cloud_no_occ\n",
    "train_data_no_occ['day_avg_humidity']=day_avg_humidity_no_occ\n",
    "train_data_no_occ['day_avg_precip']=day_avg_precip_no_occ\n",
    "train_data_no_occ['day_avg_pressure']=day_avg_pressure_no_occ\n",
    "train_data_no_occ['day_avg_temp']=day_avg_temp_no_occ\n",
    "train_data_no_occ['day_avg_visibility']=day_avg_visibility_no_occ\n",
    "train_data_no_occ['day_avg_winddir']=day_avg_winddir_no_occ\n",
    "train_data_no_occ['day_avg_windspeed']=day_avg_windspeed_no_occ\n",
    "\n",
    "ltrain_data_no_occ=train_data_lec_no_occ[train_features_no_occ]\n",
    "\n",
    "lday_avg_reading_no_occ=[]\n",
    "lday_avg_maxtemp_no_occ=[]\n",
    "lday_avg_mintemp_no_occ=[]\n",
    "lday_avg_snow_no_occ=[]\n",
    "lday_avg_sunhour_no_occ=[]\n",
    "lday_avg_uvindex_no_occ=[]\n",
    "lday_avg_moonillumination_no_occ=[]\n",
    "lday_avg_sunrise_hr_no_occ=[]\n",
    "lday_avg_sunrise_min_no_occ=[]\n",
    "lday_avg_sunset_hr_no_occ=[]\n",
    "lday_avg_sunset_min_no_occ=[]\n",
    "lday_avg_dewpoint_no_occ=[]\n",
    "lday_avg_feelslike_no_occ=[]\n",
    "lday_avg_heatindex_no_occ=[]\n",
    "lday_avg_windchill_no_occ=[]\n",
    "lday_avg_windgust_no_occ=[]\n",
    "lday_avg_cloud_no_occ=[]\n",
    "lday_avg_humidity_no_occ=[]\n",
    "lday_avg_precip_no_occ=[]\n",
    "lday_avg_pressure_no_occ=[]\n",
    "lday_avg_temp_no_occ=[]\n",
    "lday_avg_visibility_no_occ=[]\n",
    "lday_avg_winddir_no_occ=[]\n",
    "lday_avg_windspeed_no_occ=[]\n",
    "\n",
    "for  i in range(ltrain_data_no_occ.index.min(), (ltrain_data_no_occ.index.max()+1)):\n",
    "    if i-144 < 0:\n",
    "        lday_avg_reading_no_occ.append(ltrain_data_no_occ.reading[i])\n",
    "        lday_avg_maxtemp_no_occ.append(ltrain_data_no_occ.previous_maxtempC[i])\n",
    "        lday_avg_mintemp_no_occ.append(ltrain_data_no_occ.previous_mintempC[i])\n",
    "        lday_avg_snow_no_occ.append(ltrain_data_no_occ.previous_totalSnow_cm[i])\n",
    "        lday_avg_sunhour_no_occ.append(ltrain_data_no_occ.previous_sunHour[i])\n",
    "        lday_avg_uvindex_no_occ.append(ltrain_data_no_occ.previous_uvIndex[i])\n",
    "        lday_avg_moonillumination_no_occ.append(ltrain_data_no_occ.previous_moon_illumination[i])\n",
    "        lday_avg_sunrise_hr_no_occ.append(ltrain_data_no_occ.previous_sunrise_hour[i])\n",
    "        lday_avg_sunrise_min_no_occ.append(ltrain_data_no_occ.previous_sunrise_minute[i])\n",
    "        lday_avg_sunset_hr_no_occ.append(ltrain_data_no_occ.previous_sunset_hour[i])\n",
    "        lday_avg_sunset_min_no_occ.append(ltrain_data_no_occ.previous_sunset_minute[i])\n",
    "        lday_avg_dewpoint_no_occ.append(ltrain_data_no_occ.previous_DewPointC[i])\n",
    "        lday_avg_feelslike_no_occ.append(ltrain_data_no_occ.previous_FeelsLikeC[i])\n",
    "        lday_avg_heatindex_no_occ.append(ltrain_data_no_occ.previous_HeatIndexC[i])\n",
    "        lday_avg_windchill_no_occ.append(ltrain_data_no_occ.previous_WindChillC[i])\n",
    "        lday_avg_windgust_no_occ.append(ltrain_data_no_occ.previous_WindGustKmph[i])\n",
    "        lday_avg_cloud_no_occ.append(ltrain_data_no_occ.previous_cloudcover[i])\n",
    "        lday_avg_humidity_no_occ.append(ltrain_data_no_occ.previous_humidity[i])\n",
    "        lday_avg_precip_no_occ.append(ltrain_data_no_occ.previous_precipMM[i])\n",
    "        lday_avg_pressure_no_occ.append(ltrain_data_no_occ.previous_pressure[i])\n",
    "        lday_avg_temp_no_occ.append(ltrain_data_no_occ.previous_tempC[i])\n",
    "        lday_avg_visibility_no_occ.append(ltrain_data_no_occ.previous_visibility[i])\n",
    "        lday_avg_winddir_no_occ.append(ltrain_data_no_occ.previous_winddirDegree[i])\n",
    "        lday_avg_windspeed_no_occ.append(ltrain_data_no_occ.previous_windspeedKmph[i])\n",
    "       \n",
    "    else:\n",
    "        lday_avg_reading_no_occ.append(statistics.mean(ltrain_data_no_occ.reading[(i-144):(i-1)]))\n",
    "        lday_avg_maxtemp_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_maxtempC[(i-144):(i-1)]))\n",
    "        lday_avg_mintemp_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_mintempC[(i-144):(i-1)]))\n",
    "        lday_avg_snow_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_totalSnow_cm[(i-144):(i-1)]))\n",
    "        lday_avg_sunhour_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_sunHour[(i-144):(i-1)]))\n",
    "        lday_avg_uvindex_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_uvIndex[(i-144):(i-1)]))\n",
    "        lday_avg_moonillumination_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_moon_illumination[(i-144):(i-1)]))\n",
    "        lday_avg_sunrise_hr_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_sunrise_hour[(i-144):(i-1)]))\n",
    "        lday_avg_sunrise_min_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_sunrise_minute[(i-144):(i-1)]))\n",
    "        lday_avg_sunset_hr_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_sunset_hour[(i-144):(i-1)]))\n",
    "        lday_avg_sunset_min_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_sunset_minute[(i-144):(i-1)]))\n",
    "        lday_avg_dewpoint_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_DewPointC[(i-144):(i-1)]))\n",
    "        lday_avg_feelslike_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_FeelsLikeC[(i-144):(i-1)]))\n",
    "        lday_avg_heatindex_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_HeatIndexC[(i-144):(i-1)]))\n",
    "        lday_avg_windchill_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_WindChillC[(i-144):(i-1)]))\n",
    "        lday_avg_windgust_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_WindGustKmph[(i-144):(i-1)]))\n",
    "        lday_avg_cloud_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_cloudcover[(i-144):(i-1)]))\n",
    "        lday_avg_humidity_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_humidity[(i-144):(i-1)]))\n",
    "        lday_avg_precip_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_precipMM[(i-144):(i-1)]))\n",
    "        lday_avg_pressure_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_pressure[(i-144):(i-1)]))\n",
    "        lday_avg_temp_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_tempC[(i-144):(i-1)]))\n",
    "        lday_avg_visibility_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_visibility[(i-144):(i-1)]))\n",
    "        lday_avg_winddir_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_winddirDegree[(i-144):(i-1)]))\n",
    "        lday_avg_windspeed_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_windspeedKmph[(i-144):(i-1)]))\n",
    "        \n",
    "\n",
    "ltrain_data_no_occ['day_avg_reading']=lday_avg_reading_no_occ\n",
    "ltrain_data_no_occ['day_avg_maxtemp']=lday_avg_maxtemp_no_occ\n",
    "ltrain_data_no_occ['day_avg_mintemp']=lday_avg_mintemp_no_occ\n",
    "ltrain_data_no_occ['day_avg_snow']=lday_avg_snow_no_occ\n",
    "ltrain_data_no_occ['day_avg_sunhour']=lday_avg_sunhour_no_occ\n",
    "ltrain_data_no_occ['day_avg_uvindex']=lday_avg_uvindex_no_occ\n",
    "ltrain_data_no_occ['day_avg_moonillumination']=lday_avg_moonillumination_no_occ\n",
    "ltrain_data_no_occ['day_avg_sunrise_hr']=lday_avg_sunrise_hr_no_occ\n",
    "ltrain_data_no_occ['day_avg_sunrise_min']=lday_avg_sunrise_min_no_occ\n",
    "ltrain_data_no_occ['day_avg_sunset_hr']=lday_avg_sunset_hr_no_occ\n",
    "ltrain_data_no_occ['day_avg_sunset_min']=lday_avg_sunset_min_no_occ\n",
    "ltrain_data_no_occ['day_avg_dewpoint']=lday_avg_dewpoint_no_occ\n",
    "ltrain_data_no_occ['day_avg_feelslike']=lday_avg_feelslike_no_occ\n",
    "ltrain_data_no_occ['day_avg_heatindex']=lday_avg_heatindex_no_occ\n",
    "ltrain_data_no_occ['day_avg_windchill']=lday_avg_windchill_no_occ\n",
    "ltrain_data_no_occ['day_avg_windgust']=lday_avg_windgust_no_occ\n",
    "ltrain_data_no_occ['day_avg_cloud']=lday_avg_cloud_no_occ\n",
    "ltrain_data_no_occ['day_avg_humidity']=lday_avg_humidity_no_occ\n",
    "ltrain_data_no_occ['day_avg_precip']=lday_avg_precip_no_occ\n",
    "ltrain_data_no_occ['day_avg_pressure']=lday_avg_pressure_no_occ\n",
    "ltrain_data_no_occ['day_avg_temp']=lday_avg_temp_no_occ\n",
    "ltrain_data_no_occ['day_avg_visibility']=lday_avg_visibility_no_occ\n",
    "ltrain_data_no_occ['day_avg_winddir']=lday_avg_winddir_no_occ\n",
    "ltrain_data_no_occ['day_avg_windspeed']=lday_avg_windspeed_no_occ\n",
    "\n",
    "week_avg_reading=[]\n",
    "week_avg_maxtemp=[]\n",
    "week_avg_mintemp=[]\n",
    "week_avg_snow=[]\n",
    "week_avg_sunhour=[]\n",
    "week_avg_uvindex=[]\n",
    "week_avg_moonillumination=[]\n",
    "week_avg_sunrise_hr=[]\n",
    "week_avg_sunrise_min=[]\n",
    "week_avg_sunset_hr=[]\n",
    "week_avg_sunset_min=[]\n",
    "week_avg_dewpoint=[]\n",
    "week_avg_feelslike=[]\n",
    "week_avg_heatindex=[]\n",
    "week_avg_windchill=[]\n",
    "week_avg_windgust=[]\n",
    "week_avg_cloud=[]\n",
    "week_avg_humidity=[]\n",
    "week_avg_precip=[]\n",
    "week_avg_pressure=[]\n",
    "week_avg_temp=[]\n",
    "week_avg_visibility=[]\n",
    "week_avg_winddir=[]\n",
    "week_avg_windspeed=[]\n",
    "week_avg_as_client=[]\n",
    "week_avg_auth_client=[]\n",
    "for  i in range(train_data_bow.index.min(), (train_data_bow.index.max()+1)):\n",
    "    if i-1008 < 0:\n",
    "        week_avg_reading.append(train_data_bow.reading[i])\n",
    "        week_avg_maxtemp.append(train_data_bow.previous_maxtempC[i])\n",
    "        week_avg_mintemp.append(train_data_bow.previous_mintempC[i])\n",
    "        week_avg_snow.append(train_data_bow.previous_totalSnow_cm[i])\n",
    "        week_avg_sunhour.append(train_data_bow.previous_sunHour[i])\n",
    "        week_avg_uvindex.append(train_data_bow.previous_uvIndex[i])\n",
    "        week_avg_moonillumination.append(train_data_bow.previous_moon_illumination[i])\n",
    "        week_avg_sunrise_hr.append(train_data_bow.previous_sunrise_hour[i])\n",
    "        week_avg_sunrise_min.append(train_data_bow.previous_sunrise_minute[i])\n",
    "        week_avg_sunset_hr.append(train_data_bow.previous_sunset_hour[i])\n",
    "        week_avg_sunset_min.append(train_data_bow.previous_sunset_minute[i])\n",
    "        week_avg_dewpoint.append(train_data_bow.previous_DewPointC[i])\n",
    "        week_avg_feelslike.append(train_data_bow.previous_FeelsLikeC[i])\n",
    "        week_avg_heatindex.append(train_data_bow.previous_HeatIndexC[i])\n",
    "        week_avg_windchill.append(train_data_bow.previous_WindChillC[i])\n",
    "        week_avg_windgust.append(train_data_bow.previous_WindGustKmph[i])\n",
    "        week_avg_cloud.append(train_data_bow.previous_cloudcover[i])\n",
    "        week_avg_humidity.append(train_data_bow.previous_humidity[i])\n",
    "        week_avg_precip.append(train_data_bow.previous_precipMM[i])\n",
    "        week_avg_pressure.append(train_data_bow.previous_pressure[i])\n",
    "        week_avg_temp.append(train_data_bow.previous_tempC[i])\n",
    "        week_avg_visibility.append(train_data_bow.previous_visibility[i])\n",
    "        week_avg_winddir.append(train_data_bow.previous_winddirDegree[i])\n",
    "        week_avg_windspeed.append(train_data_bow.previous_windspeedKmph[i])\n",
    "        week_avg_as_client.append(train_data_bow['previous_Associated Client Count'][i])\n",
    "        week_avg_auth_client.append(train_data_bow['previous_Authenticated Client Count'][i])\n",
    "    else:\n",
    "        week_avg_reading.append(statistics.mean(train_data_bow.reading[(i-1008):(i-1)]))\n",
    "        week_avg_maxtemp.append(statistics.mean(train_data_bow.previous_maxtempC[(i-1008):(i-1)]))\n",
    "        week_avg_mintemp.append(statistics.mean(train_data_bow.previous_mintempC[(i-1008):(i-1)]))\n",
    "        week_avg_snow.append(statistics.mean(train_data_bow.previous_totalSnow_cm[(i-1008):(i-1)]))\n",
    "        week_avg_sunhour.append(statistics.mean(train_data_bow.previous_sunHour[(i-1008):(i-1)]))\n",
    "        week_avg_uvindex.append(statistics.mean(train_data_bow.previous_uvIndex[(i-1008):(i-1)]))\n",
    "        week_avg_moonillumination.append(statistics.mean(train_data_bow.previous_moon_illumination[(i-1008):(i-1)]))\n",
    "        week_avg_sunrise_hr.append(statistics.mean(train_data_bow.previous_sunrise_hour[(i-1008):(i-1)]))\n",
    "        week_avg_sunrise_min.append(statistics.mean(train_data_bow.previous_sunrise_minute[(i-1008):(i-1)]))\n",
    "        week_avg_sunset_hr.append(statistics.mean(train_data_bow.previous_sunset_hour[(i-1008):(i-1)]))\n",
    "        week_avg_sunset_min.append(statistics.mean(train_data_bow.previous_sunset_minute[(i-1008):(i-1)]))\n",
    "        week_avg_dewpoint.append(statistics.mean(train_data_bow.previous_DewPointC[(i-1008):(i-1)]))\n",
    "        week_avg_feelslike.append(statistics.mean(train_data_bow.previous_FeelsLikeC[(i-1008):(i-1)]))\n",
    "        week_avg_heatindex.append(statistics.mean(train_data_bow.previous_HeatIndexC[(i-1008):(i-1)]))\n",
    "        week_avg_windchill.append(statistics.mean(train_data_bow.previous_WindChillC[(i-1008):(i-1)]))\n",
    "        week_avg_windgust.append(statistics.mean(train_data_bow.previous_WindGustKmph[(i-1008):(i-1)]))\n",
    "        week_avg_cloud.append(statistics.mean(train_data_bow.previous_cloudcover[(i-1008):(i-1)]))\n",
    "        week_avg_humidity.append(statistics.mean(train_data_bow.previous_humidity[(i-1008):(i-1)]))\n",
    "        week_avg_precip.append(statistics.mean(train_data_bow.previous_precipMM[(i-1008):(i-1)]))\n",
    "        week_avg_pressure.append(statistics.mean(train_data_bow.previous_pressure[(i-1008):(i-1)]))\n",
    "        week_avg_temp.append(statistics.mean(train_data_bow.previous_tempC[(i-1008):(i-1)]))\n",
    "        week_avg_visibility.append(statistics.mean(train_data_bow.previous_visibility[(i-1008):(i-1)]))\n",
    "        week_avg_winddir.append(statistics.mean(train_data_bow.previous_winddirDegree[(i-1008):(i-1)]))\n",
    "        week_avg_windspeed.append(statistics.mean(train_data_bow.previous_windspeedKmph[(i-1008):(i-1)]))\n",
    "        week_avg_as_client.append(statistics.mean(train_data_bow['previous_Associated Client Count'][(i-1008):(i-1)]))\n",
    "        week_avg_auth_client.append(statistics.mean(train_data_bow['previous_Authenticated Client Count'][(i-1008):(i-1)]))\n",
    "\n",
    "train_data_bow['week_avg_reading']=week_avg_reading\n",
    "train_data_bow['week_avg_maxtemp']=week_avg_maxtemp\n",
    "train_data_bow['week_avg_mintemp']=week_avg_mintemp\n",
    "train_data_bow['week_avg_snow']=week_avg_snow\n",
    "train_data_bow['week_avg_sunhour']=week_avg_sunhour\n",
    "train_data_bow['week_avg_uvindex']=week_avg_uvindex\n",
    "train_data_bow['week_avg_moonillumination']=week_avg_moonillumination\n",
    "train_data_bow['week_avg_sunrise_hr']=week_avg_sunrise_hr\n",
    "train_data_bow['week_avg_sunrise_min']=week_avg_sunrise_min\n",
    "train_data_bow['week_avg_sunset_hr']=week_avg_sunset_hr\n",
    "train_data_bow['week_avg_sunset_min']=week_avg_sunset_min\n",
    "train_data_bow['week_avg_dewpoint']=week_avg_dewpoint\n",
    "train_data_bow['week_avg_feelslike']=week_avg_feelslike\n",
    "train_data_bow['week_avg_heatindex']=week_avg_heatindex\n",
    "train_data_bow['week_avg_windchill']=week_avg_windchill\n",
    "train_data_bow['week_avg_windgust']=week_avg_windgust\n",
    "train_data_bow['week_avg_cloud']=week_avg_cloud\n",
    "train_data_bow['week_avg_humidity']=week_avg_humidity\n",
    "train_data_bow['week_avg_precip']=week_avg_precip\n",
    "train_data_bow['week_avg_pressure']=week_avg_pressure\n",
    "train_data_bow['week_avg_temp']=week_avg_temp\n",
    "train_data_bow['week_avg_visibility']=week_avg_visibility\n",
    "train_data_bow['week_avg_winddir']=week_avg_winddir\n",
    "train_data_bow['week_avg_windspeed']=week_avg_windspeed\n",
    "train_data_bow['week_avg_as_client']=week_avg_as_client\n",
    "train_data_bow['week_avg_auth_client']=week_avg_auth_client\n",
    "\n",
    "lweek_avg_reading=[]\n",
    "lweek_avg_maxtemp=[]\n",
    "lweek_avg_mintemp=[]\n",
    "lweek_avg_snow=[]\n",
    "lweek_avg_sunhour=[]\n",
    "lweek_avg_uvindex=[]\n",
    "lweek_avg_moonillumination=[]\n",
    "lweek_avg_sunrise_hr=[]\n",
    "lweek_avg_sunrise_min=[]\n",
    "lweek_avg_sunset_hr=[]\n",
    "lweek_avg_sunset_min=[]\n",
    "lweek_avg_dewpoint=[]\n",
    "lweek_avg_feelslike=[]\n",
    "lweek_avg_heatindex=[]\n",
    "lweek_avg_windchill=[]\n",
    "lweek_avg_windgust=[]\n",
    "lweek_avg_cloud=[]\n",
    "lweek_avg_humidity=[]\n",
    "lweek_avg_precip=[]\n",
    "lweek_avg_pressure=[]\n",
    "lweek_avg_temp=[]\n",
    "lweek_avg_visibility=[]\n",
    "lweek_avg_winddir=[]\n",
    "lweek_avg_windspeed=[]\n",
    "lweek_avg_as_client=[]\n",
    "lweek_avg_auth_client=[]\n",
    "for  i in range(train_data_lec.index.min(), (train_data_lec.index.max()+1)):\n",
    "    if i-1008 < 0:\n",
    "        lweek_avg_reading.append(train_data_lec.reading[i])\n",
    "        lweek_avg_maxtemp.append(train_data_lec.previous_maxtempC[i])\n",
    "        lweek_avg_mintemp.append(train_data_lec.previous_mintempC[i])\n",
    "        lweek_avg_snow.append(train_data_lec.previous_totalSnow_cm[i])\n",
    "        lweek_avg_sunhour.append(train_data_lec.previous_sunHour[i])\n",
    "        lweek_avg_uvindex.append(train_data_lec.previous_uvIndex[i])\n",
    "        lweek_avg_moonillumination.append(train_data_lec.previous_moon_illumination[i])\n",
    "        lweek_avg_sunrise_hr.append(train_data_lec.previous_sunrise_hour[i])\n",
    "        lweek_avg_sunrise_min.append(train_data_lec.previous_sunrise_minute[i])\n",
    "        lweek_avg_sunset_hr.append(train_data_lec.previous_sunset_hour[i])\n",
    "        lweek_avg_sunset_min.append(train_data_lec.previous_sunset_minute[i])\n",
    "        lweek_avg_dewpoint.append(train_data_lec.previous_DewPointC[i])\n",
    "        lweek_avg_feelslike.append(train_data_lec.previous_FeelsLikeC[i])\n",
    "        lweek_avg_heatindex.append(train_data_lec.previous_HeatIndexC[i])\n",
    "        lweek_avg_windchill.append(train_data_lec.previous_WindChillC[i])\n",
    "        lweek_avg_windgust.append(train_data_lec.previous_WindGustKmph[i])\n",
    "        lweek_avg_cloud.append(train_data_lec.previous_cloudcover[i])\n",
    "        lweek_avg_humidity.append(train_data_lec.previous_humidity[i])\n",
    "        lweek_avg_precip.append(train_data_lec.previous_precipMM[i])\n",
    "        lweek_avg_pressure.append(train_data_lec.previous_pressure[i])\n",
    "        lweek_avg_temp.append(train_data_lec.previous_tempC[i])\n",
    "        lweek_avg_visibility.append(train_data_lec.previous_visibility[i])\n",
    "        lweek_avg_winddir.append(train_data_lec.previous_winddirDegree[i])\n",
    "        lweek_avg_windspeed.append(train_data_lec.previous_windspeedKmph[i])\n",
    "        lweek_avg_as_client.append(train_data_lec['previous_Associated Client Count'][i])\n",
    "        lweek_avg_auth_client.append(train_data_lec['previous_Authenticated Client Count'][i])\n",
    "    else:\n",
    "        lweek_avg_reading.append(statistics.mean(train_data_lec.reading[(i-1008):(i-1)]))\n",
    "        lweek_avg_maxtemp.append(statistics.mean(train_data_lec.previous_maxtempC[(i-1008):(i-1)]))\n",
    "        lweek_avg_mintemp.append(statistics.mean(train_data_lec.previous_mintempC[(i-1008):(i-1)]))\n",
    "        lweek_avg_snow.append(statistics.mean(train_data_lec.previous_totalSnow_cm[(i-1008):(i-1)]))\n",
    "        lweek_avg_sunhour.append(statistics.mean(train_data_lec.previous_sunHour[(i-1008):(i-1)]))\n",
    "        lweek_avg_uvindex.append(statistics.mean(train_data_lec.previous_uvIndex[(i-1008):(i-1)]))\n",
    "        lweek_avg_moonillumination.append(statistics.mean(train_data_lec.previous_moon_illumination[(i-1008):(i-1)]))\n",
    "        lweek_avg_sunrise_hr.append(statistics.mean(train_data_lec.previous_sunrise_hour[(i-1008):(i-1)]))\n",
    "        lweek_avg_sunrise_min.append(statistics.mean(train_data_lec.previous_sunrise_minute[(i-1008):(i-1)]))\n",
    "        lweek_avg_sunset_hr.append(statistics.mean(train_data_lec.previous_sunset_hour[(i-1008):(i-1)]))\n",
    "        lweek_avg_sunset_min.append(statistics.mean(train_data_lec.previous_sunset_minute[(i-1008):(i-1)]))\n",
    "        lweek_avg_dewpoint.append(statistics.mean(train_data_lec.previous_DewPointC[(i-1008):(i-1)]))\n",
    "        lweek_avg_feelslike.append(statistics.mean(train_data_lec.previous_FeelsLikeC[(i-1008):(i-1)]))\n",
    "        lweek_avg_heatindex.append(statistics.mean(train_data_lec.previous_HeatIndexC[(i-1008):(i-1)]))\n",
    "        lweek_avg_windchill.append(statistics.mean(train_data_lec.previous_WindChillC[(i-1008):(i-1)]))\n",
    "        lweek_avg_windgust.append(statistics.mean(train_data_lec.previous_WindGustKmph[(i-1008):(i-1)]))\n",
    "        lweek_avg_cloud.append(statistics.mean(train_data_lec.previous_cloudcover[(i-1008):(i-1)]))\n",
    "        lweek_avg_humidity.append(statistics.mean(train_data_lec.previous_humidity[(i-1008):(i-1)]))\n",
    "        lweek_avg_precip.append(statistics.mean(train_data_lec.previous_precipMM[(i-1008):(i-1)]))\n",
    "        lweek_avg_pressure.append(statistics.mean(train_data_lec.previous_pressure[(i-1008):(i-1)]))\n",
    "        lweek_avg_temp.append(statistics.mean(train_data_lec.previous_tempC[(i-1008):(i-1)]))\n",
    "        lweek_avg_visibility.append(statistics.mean(train_data_lec.previous_visibility[(i-1008):(i-1)]))\n",
    "        lweek_avg_winddir.append(statistics.mean(train_data_lec.previous_winddirDegree[(i-1008):(i-1)]))\n",
    "        lweek_avg_windspeed.append(statistics.mean(train_data_lec.previous_windspeedKmph[(i-1008):(i-1)]))\n",
    "        lweek_avg_as_client.append(statistics.mean(train_data_lec['previous_Associated Client Count'][(i-1008):(i-1)]))\n",
    "        lweek_avg_auth_client.append(statistics.mean(train_data_lec['previous_Authenticated Client Count'][(i-1008):(i-1)]))\n",
    "\n",
    "train_data_lec['week_avg_reading']=lweek_avg_reading\n",
    "train_data_lec['week_avg_maxtemp']=lweek_avg_maxtemp\n",
    "train_data_lec['week_avg_mintemp']=lweek_avg_mintemp\n",
    "train_data_lec['week_avg_snow']=lweek_avg_snow\n",
    "train_data_lec['week_avg_sunhour']=lweek_avg_sunhour\n",
    "train_data_lec['week_avg_uvindex']=lweek_avg_uvindex\n",
    "train_data_lec['week_avg_moonillumination']=lweek_avg_moonillumination\n",
    "train_data_lec['week_avg_sunrise_hr']=lweek_avg_sunrise_hr\n",
    "train_data_lec['week_avg_sunrise_min']=lweek_avg_sunrise_min\n",
    "train_data_lec['week_avg_sunset_hr']=lweek_avg_sunset_hr\n",
    "train_data_lec['week_avg_sunset_min']=lweek_avg_sunset_min\n",
    "train_data_lec['week_avg_dewpoint']=lweek_avg_dewpoint\n",
    "train_data_lec['week_avg_feelslike']=lweek_avg_feelslike\n",
    "train_data_lec['week_avg_heatindex']=lweek_avg_heatindex\n",
    "train_data_lec['week_avg_windchill']=lweek_avg_windchill\n",
    "train_data_lec['week_avg_windgust']=lweek_avg_windgust\n",
    "train_data_lec['week_avg_cloud']=lweek_avg_cloud\n",
    "train_data_lec['week_avg_humidity']=lweek_avg_humidity\n",
    "train_data_lec['week_avg_precip']=lweek_avg_precip\n",
    "train_data_lec['week_avg_pressure']=lweek_avg_pressure\n",
    "train_data_lec['week_avg_temp']=lweek_avg_temp\n",
    "train_data_lec['week_avg_visibility']=lweek_avg_visibility\n",
    "train_data_lec['week_avg_winddir']=lweek_avg_winddir\n",
    "train_data_lec['week_avg_windspeed']=lweek_avg_windspeed\n",
    "train_data_lec['week_avg_as_client']=lweek_avg_as_client\n",
    "train_data_lec['week_avg_auth_client']=lweek_avg_auth_client\n",
    "\n",
    "week_avg_reading_no_occ=[]\n",
    "week_avg_maxtemp_no_occ=[]\n",
    "week_avg_mintemp_no_occ=[]\n",
    "week_avg_snow_no_occ=[]\n",
    "week_avg_sunhour_no_occ=[]\n",
    "week_avg_uvindex_no_occ=[]\n",
    "week_avg_moonillumination_no_occ=[]\n",
    "week_avg_sunrise_hr_no_occ=[]\n",
    "week_avg_sunrise_min_no_occ=[]\n",
    "week_avg_sunset_hr_no_occ=[]\n",
    "week_avg_sunset_min_no_occ=[]\n",
    "week_avg_dewpoint_no_occ=[]\n",
    "week_avg_feelslike_no_occ=[]\n",
    "week_avg_heatindex_no_occ=[]\n",
    "week_avg_windchill_no_occ=[]\n",
    "week_avg_windgust_no_occ=[]\n",
    "week_avg_cloud_no_occ=[]\n",
    "week_avg_humidity_no_occ=[]\n",
    "week_avg_precip_no_occ=[]\n",
    "week_avg_pressure_no_occ=[]\n",
    "week_avg_temp_no_occ=[]\n",
    "week_avg_visibility_no_occ=[]\n",
    "week_avg_winddir_no_occ=[]\n",
    "week_avg_windspeed_no_occ=[]\n",
    "\n",
    "for  i in range(train_data_no_occ.index.min(), (train_data_no_occ.index.max()+1)):\n",
    "    if i-1008 < 0:\n",
    "        week_avg_reading_no_occ.append(train_data_no_occ.reading[i])\n",
    "        week_avg_maxtemp_no_occ.append(train_data_no_occ.previous_maxtempC[i])\n",
    "        week_avg_mintemp_no_occ.append(train_data_no_occ.previous_mintempC[i])\n",
    "        week_avg_snow_no_occ.append(train_data_no_occ.previous_totalSnow_cm[i])\n",
    "        week_avg_sunhour_no_occ.append(train_data_no_occ.previous_sunHour[i])\n",
    "        week_avg_uvindex_no_occ.append(train_data_no_occ.previous_uvIndex[i])\n",
    "        week_avg_moonillumination_no_occ.append(train_data_no_occ.previous_moon_illumination[i])\n",
    "        week_avg_sunrise_hr_no_occ.append(train_data_no_occ.previous_sunrise_hour[i])\n",
    "        week_avg_sunrise_min_no_occ.append(train_data_no_occ.previous_sunrise_minute[i])\n",
    "        week_avg_sunset_hr_no_occ.append(train_data_no_occ.previous_sunset_hour[i])\n",
    "        week_avg_sunset_min_no_occ.append(train_data_no_occ.previous_sunset_minute[i])\n",
    "        week_avg_dewpoint_no_occ.append(train_data_no_occ.previous_DewPointC[i])\n",
    "        week_avg_feelslike_no_occ.append(train_data_no_occ.previous_FeelsLikeC[i])\n",
    "        week_avg_heatindex_no_occ.append(train_data_no_occ.previous_HeatIndexC[i])\n",
    "        week_avg_windchill_no_occ.append(train_data_no_occ.previous_WindChillC[i])\n",
    "        week_avg_windgust_no_occ.append(train_data_no_occ.previous_WindGustKmph[i])\n",
    "        week_avg_cloud_no_occ.append(train_data_no_occ.previous_cloudcover[i])\n",
    "        week_avg_humidity_no_occ.append(train_data_no_occ.previous_humidity[i])\n",
    "        week_avg_precip_no_occ.append(train_data_no_occ.previous_precipMM[i])\n",
    "        week_avg_pressure_no_occ.append(train_data_no_occ.previous_pressure[i])\n",
    "        week_avg_temp_no_occ.append(train_data_no_occ.previous_tempC[i])\n",
    "        week_avg_visibility_no_occ.append(train_data_no_occ.previous_visibility[i])\n",
    "        week_avg_winddir_no_occ.append(train_data_no_occ.previous_winddirDegree[i])\n",
    "        week_avg_windspeed_no_occ.append(train_data_no_occ.previous_windspeedKmph[i])\n",
    "\n",
    "    else:\n",
    "        week_avg_reading_no_occ.append(statistics.mean(train_data_no_occ.reading[(i-1008):(i-1)]))\n",
    "        week_avg_maxtemp_no_occ.append(statistics.mean(train_data_no_occ.previous_maxtempC[(i-1008):(i-1)]))\n",
    "        week_avg_mintemp_no_occ.append(statistics.mean(train_data_no_occ.previous_mintempC[(i-1008):(i-1)]))\n",
    "        week_avg_snow_no_occ.append(statistics.mean(train_data_no_occ.previous_totalSnow_cm[(i-1008):(i-1)]))\n",
    "        week_avg_sunhour_no_occ.append(statistics.mean(train_data_no_occ.previous_sunHour[(i-1008):(i-1)]))\n",
    "        week_avg_uvindex_no_occ.append(statistics.mean(train_data_no_occ.previous_uvIndex[(i-1008):(i-1)]))\n",
    "        week_avg_moonillumination_no_occ.append(statistics.mean(train_data_no_occ.previous_moon_illumination[(i-1008):(i-1)]))\n",
    "        week_avg_sunrise_hr_no_occ.append(statistics.mean(train_data_no_occ.previous_sunrise_hour[(i-1008):(i-1)]))\n",
    "        week_avg_sunrise_min_no_occ.append(statistics.mean(train_data_no_occ.previous_sunrise_minute[(i-1008):(i-1)]))\n",
    "        week_avg_sunset_hr_no_occ.append(statistics.mean(train_data_no_occ.previous_sunset_hour[(i-1008):(i-1)]))\n",
    "        week_avg_sunset_min_no_occ.append(statistics.mean(train_data_no_occ.previous_sunset_minute[(i-1008):(i-1)]))\n",
    "        week_avg_dewpoint_no_occ.append(statistics.mean(train_data_no_occ.previous_DewPointC[(i-1008):(i-1)]))\n",
    "        week_avg_feelslike_no_occ.append(statistics.mean(train_data_no_occ.previous_FeelsLikeC[(i-1008):(i-1)]))\n",
    "        week_avg_heatindex_no_occ.append(statistics.mean(train_data_no_occ.previous_HeatIndexC[(i-1008):(i-1)]))\n",
    "        week_avg_windchill_no_occ.append(statistics.mean(train_data_no_occ.previous_WindChillC[(i-1008):(i-1)]))\n",
    "        week_avg_windgust_no_occ.append(statistics.mean(train_data_no_occ.previous_WindGustKmph[(i-1008):(i-1)]))\n",
    "        week_avg_cloud_no_occ.append(statistics.mean(train_data_no_occ.previous_cloudcover[(i-1008):(i-1)]))\n",
    "        week_avg_humidity_no_occ.append(statistics.mean(train_data_no_occ.previous_humidity[(i-1008):(i-1)]))\n",
    "        week_avg_precip_no_occ.append(statistics.mean(train_data_no_occ.previous_precipMM[(i-1008):(i-1)]))\n",
    "        week_avg_pressure_no_occ.append(statistics.mean(train_data_no_occ.previous_pressure[(i-1008):(i-1)]))\n",
    "        week_avg_temp_no_occ.append(statistics.mean(train_data_no_occ.previous_tempC[(i-1008):(i-1)]))\n",
    "        week_avg_visibility_no_occ.append(statistics.mean(train_data_no_occ.previous_visibility[(i-1008):(i-1)]))\n",
    "        week_avg_winddir_no_occ.append(statistics.mean(train_data_no_occ.previous_winddirDegree[(i-1008):(i-1)]))\n",
    "        week_avg_windspeed_no_occ.append(statistics.mean(train_data_no_occ.previous_windspeedKmph[(i-1008):(i-1)]))\n",
    "        \n",
    "\n",
    "train_data_no_occ['week_avg_reading']=week_avg_reading_no_occ\n",
    "train_data_no_occ['week_avg_maxtemp']=week_avg_maxtemp_no_occ\n",
    "train_data_no_occ['week_avg_mintemp']=week_avg_mintemp_no_occ\n",
    "train_data_no_occ['week_avg_snow']=week_avg_snow_no_occ\n",
    "train_data_no_occ['week_avg_sunhour']=week_avg_sunhour_no_occ\n",
    "train_data_no_occ['week_avg_uvindex']=week_avg_uvindex_no_occ\n",
    "train_data_no_occ['week_avg_moonillumination']=week_avg_moonillumination_no_occ\n",
    "train_data_no_occ['week_avg_sunrise_hr']=week_avg_sunrise_hr_no_occ\n",
    "train_data_no_occ['week_avg_sunrise_min']=week_avg_sunrise_min_no_occ\n",
    "train_data_no_occ['week_avg_sunset_hr']=week_avg_sunset_hr_no_occ\n",
    "train_data_no_occ['week_avg_sunset_min']=week_avg_sunset_min_no_occ\n",
    "train_data_no_occ['week_avg_dewpoint']=week_avg_dewpoint_no_occ\n",
    "train_data_no_occ['week_avg_feelslike']=week_avg_feelslike_no_occ\n",
    "train_data_no_occ['week_avg_heatindex']=week_avg_heatindex_no_occ\n",
    "train_data_no_occ['week_avg_windchill']=week_avg_windchill_no_occ\n",
    "train_data_no_occ['week_avg_windgust']=week_avg_windgust_no_occ\n",
    "train_data_no_occ['week_avg_cloud']=week_avg_cloud_no_occ\n",
    "train_data_no_occ['week_avg_humidity']=week_avg_humidity_no_occ\n",
    "train_data_no_occ['week_avg_precip']=week_avg_precip_no_occ\n",
    "train_data_no_occ['week_avg_pressure']=week_avg_pressure_no_occ\n",
    "train_data_no_occ['week_avg_temp']=week_avg_temp_no_occ\n",
    "train_data_no_occ['week_avg_visibility']=week_avg_visibility_no_occ\n",
    "train_data_no_occ['week_avg_winddir']=week_avg_winddir_no_occ\n",
    "train_data_no_occ['week_avg_windspeed']=week_avg_windspeed_no_occ\n",
    "\n",
    "lweek_avg_reading_no_occ=[]\n",
    "lweek_avg_maxtemp_no_occ=[]\n",
    "lweek_avg_mintemp_no_occ=[]\n",
    "lweek_avg_snow_no_occ=[]\n",
    "lweek_avg_sunhour_no_occ=[]\n",
    "lweek_avg_uvindex_no_occ=[]\n",
    "lweek_avg_moonillumination_no_occ=[]\n",
    "lweek_avg_sunrise_hr_no_occ=[]\n",
    "lweek_avg_sunrise_min_no_occ=[]\n",
    "lweek_avg_sunset_hr_no_occ=[]\n",
    "lweek_avg_sunset_min_no_occ=[]\n",
    "lweek_avg_dewpoint_no_occ=[]\n",
    "lweek_avg_feelslike_no_occ=[]\n",
    "lweek_avg_heatindex_no_occ=[]\n",
    "lweek_avg_windchill_no_occ=[]\n",
    "lweek_avg_windgust_no_occ=[]\n",
    "lweek_avg_cloud_no_occ=[]\n",
    "lweek_avg_humidity_no_occ=[]\n",
    "lweek_avg_precip_no_occ=[]\n",
    "lweek_avg_pressure_no_occ=[]\n",
    "lweek_avg_temp_no_occ=[]\n",
    "lweek_avg_visibility_no_occ=[]\n",
    "lweek_avg_winddir_no_occ=[]\n",
    "lweek_avg_windspeed_no_occ=[]\n",
    "\n",
    "for  i in range(ltrain_data_no_occ.index.min(), (ltrain_data_no_occ.index.max()+1)):\n",
    "    if i-1008 < 0:\n",
    "        lweek_avg_reading_no_occ.append(ltrain_data_no_occ.reading[i])\n",
    "        lweek_avg_maxtemp_no_occ.append(ltrain_data_no_occ.previous_maxtempC[i])\n",
    "        lweek_avg_mintemp_no_occ.append(ltrain_data_no_occ.previous_mintempC[i])\n",
    "        lweek_avg_snow_no_occ.append(ltrain_data_no_occ.previous_totalSnow_cm[i])\n",
    "        lweek_avg_sunhour_no_occ.append(ltrain_data_no_occ.previous_sunHour[i])\n",
    "        lweek_avg_uvindex_no_occ.append(ltrain_data_no_occ.previous_uvIndex[i])\n",
    "        lweek_avg_moonillumination_no_occ.append(ltrain_data_no_occ.previous_moon_illumination[i])\n",
    "        lweek_avg_sunrise_hr_no_occ.append(ltrain_data_no_occ.previous_sunrise_hour[i])\n",
    "        lweek_avg_sunrise_min_no_occ.append(ltrain_data_no_occ.previous_sunrise_minute[i])\n",
    "        lweek_avg_sunset_hr_no_occ.append(ltrain_data_no_occ.previous_sunset_hour[i])\n",
    "        lweek_avg_sunset_min_no_occ.append(ltrain_data_no_occ.previous_sunset_minute[i])\n",
    "        lweek_avg_dewpoint_no_occ.append(ltrain_data_no_occ.previous_DewPointC[i])\n",
    "        lweek_avg_feelslike_no_occ.append(ltrain_data_no_occ.previous_FeelsLikeC[i])\n",
    "        lweek_avg_heatindex_no_occ.append(ltrain_data_no_occ.previous_HeatIndexC[i])\n",
    "        lweek_avg_windchill_no_occ.append(ltrain_data_no_occ.previous_WindChillC[i])\n",
    "        lweek_avg_windgust_no_occ.append(ltrain_data_no_occ.previous_WindGustKmph[i])\n",
    "        lweek_avg_cloud_no_occ.append(ltrain_data_no_occ.previous_cloudcover[i])\n",
    "        lweek_avg_humidity_no_occ.append(ltrain_data_no_occ.previous_humidity[i])\n",
    "        lweek_avg_precip_no_occ.append(ltrain_data_no_occ.previous_precipMM[i])\n",
    "        lweek_avg_pressure_no_occ.append(ltrain_data_no_occ.previous_pressure[i])\n",
    "        lweek_avg_temp_no_occ.append(ltrain_data_no_occ.previous_tempC[i])\n",
    "        lweek_avg_visibility_no_occ.append(ltrain_data_no_occ.previous_visibility[i])\n",
    "        lweek_avg_winddir_no_occ.append(ltrain_data_no_occ.previous_winddirDegree[i])\n",
    "        lweek_avg_windspeed_no_occ.append(ltrain_data_no_occ.previous_windspeedKmph[i])\n",
    "\n",
    "    else:\n",
    "        lweek_avg_reading_no_occ.append(statistics.mean(ltrain_data_no_occ.reading[(i-1008):(i-1)]))\n",
    "        lweek_avg_maxtemp_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_maxtempC[(i-1008):(i-1)]))\n",
    "        lweek_avg_mintemp_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_mintempC[(i-1008):(i-1)]))\n",
    "        lweek_avg_snow_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_totalSnow_cm[(i-1008):(i-1)]))\n",
    "        lweek_avg_sunhour_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_sunHour[(i-1008):(i-1)]))\n",
    "        lweek_avg_uvindex_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_uvIndex[(i-1008):(i-1)]))\n",
    "        lweek_avg_moonillumination_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_moon_illumination[(i-1008):(i-1)]))\n",
    "        lweek_avg_sunrise_hr_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_sunrise_hour[(i-1008):(i-1)]))\n",
    "        lweek_avg_sunrise_min_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_sunrise_minute[(i-1008):(i-1)]))\n",
    "        lweek_avg_sunset_hr_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_sunset_hour[(i-1008):(i-1)]))\n",
    "        lweek_avg_sunset_min_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_sunset_minute[(i-1008):(i-1)]))\n",
    "        lweek_avg_dewpoint_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_DewPointC[(i-1008):(i-1)]))\n",
    "        lweek_avg_feelslike_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_FeelsLikeC[(i-1008):(i-1)]))\n",
    "        lweek_avg_heatindex_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_HeatIndexC[(i-1008):(i-1)]))\n",
    "        lweek_avg_windchill_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_WindChillC[(i-1008):(i-1)]))\n",
    "        lweek_avg_windgust_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_WindGustKmph[(i-1008):(i-1)]))\n",
    "        lweek_avg_cloud_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_cloudcover[(i-1008):(i-1)]))\n",
    "        lweek_avg_humidity_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_humidity[(i-1008):(i-1)]))\n",
    "        lweek_avg_precip_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_precipMM[(i-1008):(i-1)]))\n",
    "        lweek_avg_pressure_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_pressure[(i-1008):(i-1)]))\n",
    "        lweek_avg_temp_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_tempC[(i-1008):(i-1)]))\n",
    "        lweek_avg_visibility_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_visibility[(i-1008):(i-1)]))\n",
    "        lweek_avg_winddir_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_winddirDegree[(i-1008):(i-1)]))\n",
    "        lweek_avg_windspeed_no_occ.append(statistics.mean(ltrain_data_no_occ.previous_windspeedKmph[(i-1008):(i-1)]))\n",
    "        \n",
    "\n",
    "ltrain_data_no_occ['week_avg_reading']=lweek_avg_reading_no_occ\n",
    "ltrain_data_no_occ['week_avg_maxtemp']=lweek_avg_maxtemp_no_occ\n",
    "ltrain_data_no_occ['week_avg_mintemp']=lweek_avg_mintemp_no_occ\n",
    "ltrain_data_no_occ['week_avg_snow']=lweek_avg_snow_no_occ\n",
    "ltrain_data_no_occ['week_avg_sunhour']=lweek_avg_sunhour_no_occ\n",
    "ltrain_data_no_occ['week_avg_uvindex']=lweek_avg_uvindex_no_occ\n",
    "ltrain_data_no_occ['week_avg_moonillumination']=lweek_avg_moonillumination_no_occ\n",
    "ltrain_data_no_occ['week_avg_sunrise_hr']=lweek_avg_sunrise_hr_no_occ\n",
    "ltrain_data_no_occ['week_avg_sunrise_min']=lweek_avg_sunrise_min_no_occ\n",
    "ltrain_data_no_occ['week_avg_sunset_hr']=lweek_avg_sunset_hr_no_occ\n",
    "ltrain_data_no_occ['week_avg_sunset_min']=lweek_avg_sunset_min_no_occ\n",
    "ltrain_data_no_occ['week_avg_dewpoint']=lweek_avg_dewpoint_no_occ\n",
    "ltrain_data_no_occ['week_avg_feelslike']=lweek_avg_feelslike_no_occ\n",
    "ltrain_data_no_occ['week_avg_heatindex']=lweek_avg_heatindex_no_occ\n",
    "ltrain_data_no_occ['week_avg_windchill']=lweek_avg_windchill_no_occ\n",
    "ltrain_data_no_occ['week_avg_windgust']=lweek_avg_windgust_no_occ\n",
    "ltrain_data_no_occ['week_avg_cloud']=lweek_avg_cloud_no_occ\n",
    "ltrain_data_no_occ['week_avg_humidity']=lweek_avg_humidity_no_occ\n",
    "ltrain_data_no_occ['week_avg_precip']=lweek_avg_precip_no_occ\n",
    "ltrain_data_no_occ['week_avg_pressure']=lweek_avg_pressure_no_occ\n",
    "ltrain_data_no_occ['week_avg_temp']=lweek_avg_temp_no_occ\n",
    "ltrain_data_no_occ['week_avg_visibility']=lweek_avg_visibility_no_occ\n",
    "ltrain_data_no_occ['week_avg_winddir']=lweek_avg_winddir_no_occ\n",
    "ltrain_data_no_occ['week_avg_windspeed']=lweek_avg_windspeed_no_occ\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_9749f_row0_col0,#T_9749f_row1_col1,#T_9749f_row2_col2,#T_9749f_row3_col3,#T_9749f_row4_col4,#T_9749f_row5_col5,#T_9749f_row6_col6,#T_9749f_row7_col7,#T_9749f_row8_col8,#T_9749f_row9_col9,#T_9749f_row10_col10,#T_9749f_row11_col11,#T_9749f_row12_col12,#T_9749f_row13_col13,#T_9749f_row14_col14,#T_9749f_row15_col15,#T_9749f_row15_col17,#T_9749f_row16_col16,#T_9749f_row16_col18,#T_9749f_row17_col15,#T_9749f_row17_col17,#T_9749f_row18_col16,#T_9749f_row18_col18,#T_9749f_row19_col19,#T_9749f_row20_col20,#T_9749f_row21_col21,#T_9749f_row22_col22,#T_9749f_row23_col23,#T_9749f_row24_col24,#T_9749f_row25_col25,#T_9749f_row25_col29,#T_9749f_row26_col26,#T_9749f_row26_col30,#T_9749f_row27_col27,#T_9749f_row27_col41,#T_9749f_row28_col28,#T_9749f_row28_col42,#T_9749f_row29_col25,#T_9749f_row29_col29,#T_9749f_row30_col26,#T_9749f_row30_col30,#T_9749f_row31_col31,#T_9749f_row32_col32,#T_9749f_row33_col33,#T_9749f_row34_col34,#T_9749f_row35_col35,#T_9749f_row36_col36,#T_9749f_row37_col37,#T_9749f_row38_col38,#T_9749f_row39_col39,#T_9749f_row40_col40,#T_9749f_row41_col27,#T_9749f_row41_col41,#T_9749f_row42_col28,#T_9749f_row42_col42,#T_9749f_row43_col43,#T_9749f_row44_col44,#T_9749f_row45_col45,#T_9749f_row46_col46,#T_9749f_row47_col47,#T_9749f_row48_col48,#T_9749f_row49_col49,#T_9749f_row49_col51,#T_9749f_row50_col50,#T_9749f_row50_col52,#T_9749f_row51_col49,#T_9749f_row51_col51,#T_9749f_row52_col50,#T_9749f_row52_col52,#T_9749f_row53_col53,#T_9749f_row54_col54,#T_9749f_row55_col55,#T_9749f_row56_col56,#T_9749f_row57_col57,#T_9749f_row58_col58,#T_9749f_row59_col59{\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row0_col1,#T_9749f_row9_col42,#T_9749f_row19_col23,#T_9749f_row35_col33{\n",
       "            background-color:  #f7a889;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col2,#T_9749f_row10_col24,#T_9749f_row12_col59,#T_9749f_row19_col6,#T_9749f_row20_col5,#T_9749f_row32_col16,#T_9749f_row32_col18,#T_9749f_row47_col48,#T_9749f_row48_col34{\n",
       "            background-color:  #f7ad90;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col3,#T_9749f_row8_col50,#T_9749f_row8_col52,#T_9749f_row31_col51,#T_9749f_row33_col16,#T_9749f_row33_col18,#T_9749f_row36_col26,#T_9749f_row36_col30,#T_9749f_row36_col42,#T_9749f_row37_col20,#T_9749f_row54_col26,#T_9749f_row54_col30,#T_9749f_row55_col5{\n",
       "            background-color:  #e8d6cc;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col4,#T_9749f_row7_col8,#T_9749f_row9_col5,#T_9749f_row38_col19,#T_9749f_row39_col10,#T_9749f_row43_col51,#T_9749f_row54_col38{\n",
       "            background-color:  #ecd3c5;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col5,#T_9749f_row0_col23,#T_9749f_row15_col31,#T_9749f_row17_col31,#T_9749f_row25_col54,#T_9749f_row29_col54,#T_9749f_row32_col33,#T_9749f_row34_col49,#T_9749f_row34_col51,#T_9749f_row35_col6,#T_9749f_row35_col26,#T_9749f_row35_col30,#T_9749f_row36_col25,#T_9749f_row36_col27,#T_9749f_row36_col29,#T_9749f_row36_col41,#T_9749f_row38_col4,#T_9749f_row40_col4,#T_9749f_row56_col9,#T_9749f_row56_col40{\n",
       "            background-color:  #dddcdc;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col6,#T_9749f_row6_col36,#T_9749f_row35_col24,#T_9749f_row38_col24,#T_9749f_row38_col28,#T_9749f_row38_col47,#T_9749f_row40_col11,#T_9749f_row56_col20{\n",
       "            background-color:  #e2dad5;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col7,#T_9749f_row0_col21,#T_9749f_row1_col7,#T_9749f_row7_col35,#T_9749f_row14_col46,#T_9749f_row15_col45,#T_9749f_row17_col45,#T_9749f_row20_col35,#T_9749f_row20_col47,#T_9749f_row21_col7,#T_9749f_row24_col51,#T_9749f_row25_col47,#T_9749f_row28_col49,#T_9749f_row28_col51,#T_9749f_row29_col47,#T_9749f_row35_col8,#T_9749f_row42_col49,#T_9749f_row42_col51,#T_9749f_row44_col47,#T_9749f_row46_col55,#T_9749f_row48_col7,#T_9749f_row54_col32,#T_9749f_row57_col22,#T_9749f_row58_col22,#T_9749f_row58_col45,#T_9749f_row58_col56{\n",
       "            background-color:  #7396f5;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col8,#T_9749f_row0_col46,#T_9749f_row2_col8,#T_9749f_row31_col25,#T_9749f_row31_col29,#T_9749f_row36_col45,#T_9749f_row37_col0,#T_9749f_row43_col55,#T_9749f_row48_col28,#T_9749f_row48_col42,#T_9749f_row53_col2,#T_9749f_row53_col36,#T_9749f_row56_col35{\n",
       "            background-color:  #96b7ff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col9,#T_9749f_row0_col42,#T_9749f_row11_col1,#T_9749f_row33_col15,#T_9749f_row33_col17,#T_9749f_row35_col25,#T_9749f_row38_col33,#T_9749f_row39_col59,#T_9749f_row40_col19,#T_9749f_row40_col20,#T_9749f_row43_col50,#T_9749f_row43_col52{\n",
       "            background-color:  #ead5c9;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col10,#T_9749f_row4_col1,#T_9749f_row20_col44,#T_9749f_row33_col38,#T_9749f_row48_col50,#T_9749f_row48_col52,#T_9749f_row59_col5,#T_9749f_row59_col40{\n",
       "            background-color:  #efcfbf;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col11,#T_9749f_row6_col38,#T_9749f_row7_col49,#T_9749f_row7_col51,#T_9749f_row24_col38,#T_9749f_row33_col48,#T_9749f_row34_col47,#T_9749f_row38_col42,#T_9749f_row45_col20,#T_9749f_row46_col19,#T_9749f_row46_col20,#T_9749f_row49_col32,#T_9749f_row51_col32,#T_9749f_row54_col28,#T_9749f_row54_col42,#T_9749f_row55_col16,#T_9749f_row55_col18,#T_9749f_row55_col25,#T_9749f_row55_col29{\n",
       "            background-color:  #e1dad6;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col12,#T_9749f_row0_col28,#T_9749f_row8_col49,#T_9749f_row8_col51,#T_9749f_row9_col39,#T_9749f_row10_col1,#T_9749f_row24_col55,#T_9749f_row31_col38,#T_9749f_row35_col5,#T_9749f_row35_col29,#T_9749f_row36_col33,#T_9749f_row38_col54{\n",
       "            background-color:  #ead4c8;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col13,#T_9749f_row0_col56,#T_9749f_row5_col21,#T_9749f_row6_col52,#T_9749f_row11_col16,#T_9749f_row11_col18,#T_9749f_row20_col31,#T_9749f_row21_col56,#T_9749f_row24_col21,#T_9749f_row37_col44,#T_9749f_row39_col8{\n",
       "            background-color:  #6a8bef;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col14,#T_9749f_row1_col56,#T_9749f_row2_col14,#T_9749f_row7_col21,#T_9749f_row10_col45,#T_9749f_row12_col22,#T_9749f_row13_col45,#T_9749f_row23_col21,#T_9749f_row25_col16,#T_9749f_row25_col18,#T_9749f_row26_col21,#T_9749f_row30_col21,#T_9749f_row31_col13,#T_9749f_row31_col21,#T_9749f_row39_col32,#T_9749f_row40_col33,#T_9749f_row42_col15,#T_9749f_row42_col17,#T_9749f_row47_col13,#T_9749f_row50_col4,#T_9749f_row50_col12,#T_9749f_row50_col45,#T_9749f_row52_col4,#T_9749f_row52_col45,#T_9749f_row54_col35{\n",
       "            background-color:  #6687ed;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col15,#T_9749f_row0_col17,#T_9749f_row2_col36,#T_9749f_row2_col43,#T_9749f_row7_col26,#T_9749f_row7_col30,#T_9749f_row7_col47,#T_9749f_row21_col8,#T_9749f_row21_col38,#T_9749f_row24_col39,#T_9749f_row31_col5,#T_9749f_row35_col40,#T_9749f_row38_col55,#T_9749f_row46_col11,#T_9749f_row47_col28,#T_9749f_row47_col42,#T_9749f_row48_col59,#T_9749f_row54_col8,#T_9749f_row55_col9,#T_9749f_row58_col2{\n",
       "            background-color:  #adc9fd;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col16,#T_9749f_row0_col18,#T_9749f_row7_col28,#T_9749f_row7_col42,#T_9749f_row14_col54,#T_9749f_row15_col59,#T_9749f_row16_col40,#T_9749f_row17_col59,#T_9749f_row18_col40,#T_9749f_row22_col44,#T_9749f_row26_col33,#T_9749f_row28_col34,#T_9749f_row30_col33,#T_9749f_row31_col4,#T_9749f_row31_col28,#T_9749f_row32_col8,#T_9749f_row36_col39,#T_9749f_row36_col40,#T_9749f_row40_col56,#T_9749f_row42_col34,#T_9749f_row43_col15,#T_9749f_row43_col17,#T_9749f_row47_col12,#T_9749f_row47_col23,#T_9749f_row54_col0,#T_9749f_row58_col1,#T_9749f_row58_col47{\n",
       "            background-color:  #aac7fd;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col19,#T_9749f_row5_col9,#T_9749f_row26_col2,#T_9749f_row30_col2,#T_9749f_row35_col36,#T_9749f_row40_col10,#T_9749f_row47_col33{\n",
       "            background-color:  #f5c2aa;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col20,#T_9749f_row9_col54,#T_9749f_row15_col49,#T_9749f_row15_col51,#T_9749f_row16_col50,#T_9749f_row16_col52,#T_9749f_row17_col49,#T_9749f_row17_col51,#T_9749f_row18_col50,#T_9749f_row18_col52,#T_9749f_row19_col1,#T_9749f_row59_col41{\n",
       "            background-color:  #f5c0a7;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col22,#T_9749f_row1_col21,#T_9749f_row3_col53,#T_9749f_row9_col50,#T_9749f_row9_col52,#T_9749f_row20_col56,#T_9749f_row21_col53,#T_9749f_row22_col53,#T_9749f_row27_col53,#T_9749f_row34_col11,#T_9749f_row41_col53,#T_9749f_row48_col3,#T_9749f_row48_col12,#T_9749f_row50_col9,#T_9749f_row52_col9,#T_9749f_row55_col14,#T_9749f_row58_col0{\n",
       "            background-color:  #85a8fc;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col24,#T_9749f_row7_col15,#T_9749f_row7_col16,#T_9749f_row7_col17,#T_9749f_row7_col18,#T_9749f_row9_col1,#T_9749f_row28_col55,#T_9749f_row31_col49,#T_9749f_row31_col50,#T_9749f_row31_col52,#T_9749f_row36_col28,#T_9749f_row39_col19,#T_9749f_row40_col12,#T_9749f_row42_col55,#T_9749f_row54_col59,#T_9749f_row55_col15,#T_9749f_row55_col17{\n",
       "            background-color:  #e7d7ce;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col25,#T_9749f_row37_col34,#T_9749f_row47_col34,#T_9749f_row55_col27,#T_9749f_row55_col41{\n",
       "            background-color:  #e5d8d1;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col26,#T_9749f_row0_col30,#T_9749f_row3_col1,#T_9749f_row5_col55,#T_9749f_row9_col40,#T_9749f_row43_col49,#T_9749f_row47_col38{\n",
       "            background-color:  #ebd3c6;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col27,#T_9749f_row0_col41,#T_9749f_row9_col43,#T_9749f_row12_col55,#T_9749f_row23_col55,#T_9749f_row31_col34,#T_9749f_row34_col37,#T_9749f_row35_col16,#T_9749f_row35_col18,#T_9749f_row39_col11,#T_9749f_row55_col4{\n",
       "            background-color:  #e4d9d2;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col29,#T_9749f_row3_col54,#T_9749f_row24_col36,#T_9749f_row35_col15,#T_9749f_row35_col17,#T_9749f_row37_col19,#T_9749f_row39_col20,#T_9749f_row47_col49,#T_9749f_row47_col50,#T_9749f_row47_col51,#T_9749f_row47_col52{\n",
       "            background-color:  #e6d7cf;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col31,#T_9749f_row2_col32,#T_9749f_row4_col56,#T_9749f_row7_col6,#T_9749f_row7_col55,#T_9749f_row12_col35,#T_9749f_row14_col43,#T_9749f_row19_col46,#T_9749f_row20_col46,#T_9749f_row21_col0,#T_9749f_row22_col0,#T_9749f_row22_col46,#T_9749f_row23_col44,#T_9749f_row25_col34,#T_9749f_row27_col56,#T_9749f_row29_col34,#T_9749f_row32_col20,#T_9749f_row35_col54,#T_9749f_row36_col0,#T_9749f_row37_col45,#T_9749f_row39_col55,#T_9749f_row41_col56,#T_9749f_row47_col1,#T_9749f_row47_col46,#T_9749f_row56_col32,#T_9749f_row56_col38,#T_9749f_row56_col43,#T_9749f_row56_col48,#T_9749f_row59_col53{\n",
       "            background-color:  #98b9ff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col32,#T_9749f_row1_col39,#T_9749f_row3_col33,#T_9749f_row4_col43,#T_9749f_row23_col47,#T_9749f_row25_col56,#T_9749f_row28_col46,#T_9749f_row29_col56,#T_9749f_row34_col8,#T_9749f_row35_col46,#T_9749f_row47_col36,#T_9749f_row48_col19,#T_9749f_row56_col34,#T_9749f_row59_col2{\n",
       "            background-color:  #9dbdff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col33,#T_9749f_row0_col57,#T_9749f_row3_col35,#T_9749f_row7_col2,#T_9749f_row11_col43,#T_9749f_row13_col2,#T_9749f_row21_col48,#T_9749f_row22_col38,#T_9749f_row27_col39,#T_9749f_row33_col54,#T_9749f_row34_col25,#T_9749f_row34_col29,#T_9749f_row37_col55,#T_9749f_row39_col23,#T_9749f_row40_col50,#T_9749f_row40_col52,#T_9749f_row41_col39,#T_9749f_row42_col39,#T_9749f_row43_col16,#T_9749f_row43_col18,#T_9749f_row43_col38,#T_9749f_row50_col38,#T_9749f_row52_col38,#T_9749f_row53_col5,#T_9749f_row57_col1,#T_9749f_row57_col33,#T_9749f_row57_col37,#T_9749f_row58_col33,#T_9749f_row58_col39,#T_9749f_row59_col37{\n",
       "            background-color:  #aec9fc;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col34,#T_9749f_row12_col38,#T_9749f_row21_col5,#T_9749f_row21_col40,#T_9749f_row26_col39,#T_9749f_row34_col26,#T_9749f_row34_col30,#T_9749f_row36_col11,#T_9749f_row36_col46,#T_9749f_row36_col48,#T_9749f_row38_col8,#T_9749f_row46_col47,#T_9749f_row53_col34,#T_9749f_row53_col48,#T_9749f_row55_col35,#T_9749f_row57_col6,#T_9749f_row57_col23,#T_9749f_row58_col6,#T_9749f_row58_col23{\n",
       "            background-color:  #b7cff9;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col35,#T_9749f_row1_col46,#T_9749f_row1_col47,#T_9749f_row1_col48,#T_9749f_row2_col31,#T_9749f_row3_col36,#T_9749f_row6_col46,#T_9749f_row7_col11,#T_9749f_row11_col56,#T_9749f_row13_col43,#T_9749f_row21_col39,#T_9749f_row22_col31,#T_9749f_row23_col31,#T_9749f_row26_col56,#T_9749f_row27_col47,#T_9749f_row28_col56,#T_9749f_row30_col46,#T_9749f_row30_col56,#T_9749f_row32_col13,#T_9749f_row32_col36,#T_9749f_row36_col10,#T_9749f_row39_col13,#T_9749f_row41_col47,#T_9749f_row42_col46,#T_9749f_row42_col56,#T_9749f_row43_col5,#T_9749f_row43_col23,#T_9749f_row48_col2,#T_9749f_row49_col55,#T_9749f_row51_col55,#T_9749f_row56_col44{\n",
       "            background-color:  #9abbff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col36,#T_9749f_row2_col35,#T_9749f_row2_col40,#T_9749f_row2_col48,#T_9749f_row7_col24,#T_9749f_row16_col39,#T_9749f_row18_col39,#T_9749f_row21_col35,#T_9749f_row22_col47,#T_9749f_row26_col44,#T_9749f_row27_col34,#T_9749f_row30_col44,#T_9749f_row41_col44,#T_9749f_row44_col6,#T_9749f_row49_col19,#T_9749f_row49_col37,#T_9749f_row50_col2,#T_9749f_row51_col19,#T_9749f_row51_col20,#T_9749f_row51_col37,#T_9749f_row52_col2,#T_9749f_row52_col19,#T_9749f_row54_col50,#T_9749f_row54_col52,#T_9749f_row57_col44,#T_9749f_row58_col44{\n",
       "            background-color:  #a1c0ff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col37,#T_9749f_row6_col33,#T_9749f_row11_col0,#T_9749f_row14_col5,#T_9749f_row16_col36,#T_9749f_row18_col36,#T_9749f_row21_col11,#T_9749f_row27_col36,#T_9749f_row33_col3,#T_9749f_row34_col20,#T_9749f_row35_col10,#T_9749f_row36_col19,#T_9749f_row41_col36,#T_9749f_row43_col59,#T_9749f_row50_col34,#T_9749f_row51_col8,#T_9749f_row52_col34,#T_9749f_row53_col55,#T_9749f_row55_col10{\n",
       "            background-color:  #bad0f8;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col38,#T_9749f_row1_col50,#T_9749f_row1_col52,#T_9749f_row5_col33,#T_9749f_row5_col37,#T_9749f_row13_col39,#T_9749f_row13_col40,#T_9749f_row33_col59,#T_9749f_row34_col24,#T_9749f_row34_col55,#T_9749f_row36_col12,#T_9749f_row37_col35,#T_9749f_row40_col15,#T_9749f_row40_col17,#T_9749f_row43_col3,#T_9749f_row43_col54,#T_9749f_row45_col25,#T_9749f_row45_col40,#T_9749f_row46_col40,#T_9749f_row50_col47,#T_9749f_row52_col47,#T_9749f_row53_col3,#T_9749f_row58_col4{\n",
       "            background-color:  #ccd9ed;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col39,#T_9749f_row5_col47,#T_9749f_row7_col40,#T_9749f_row9_col38,#T_9749f_row13_col33,#T_9749f_row14_col2,#T_9749f_row14_col32,#T_9749f_row15_col35,#T_9749f_row17_col35,#T_9749f_row21_col32,#T_9749f_row22_col32,#T_9749f_row24_col46,#T_9749f_row34_col3,#T_9749f_row39_col5,#T_9749f_row39_col14,#T_9749f_row40_col14,#T_9749f_row43_col32,#T_9749f_row44_col0,#T_9749f_row47_col2,#T_9749f_row47_col6,#T_9749f_row47_col26,#T_9749f_row47_col30,#T_9749f_row50_col1,#T_9749f_row52_col1,#T_9749f_row55_col1,#T_9749f_row59_col33{\n",
       "            background-color:  #a5c3fe;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col40,#T_9749f_row1_col36,#T_9749f_row4_col44,#T_9749f_row13_col24,#T_9749f_row22_col5,#T_9749f_row23_col34,#T_9749f_row29_col33,#T_9749f_row32_col46,#T_9749f_row33_col46,#T_9749f_row34_col5,#T_9749f_row34_col41,#T_9749f_row34_col54,#T_9749f_row37_col11,#T_9749f_row39_col50,#T_9749f_row39_col52,#T_9749f_row40_col49,#T_9749f_row40_col51,#T_9749f_row43_col24,#T_9749f_row44_col24,#T_9749f_row46_col31,#T_9749f_row47_col41,#T_9749f_row53_col31,#T_9749f_row53_col47,#T_9749f_row53_col54,#T_9749f_row57_col2,#T_9749f_row57_col32{\n",
       "            background-color:  #b2ccfb;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col43,#T_9749f_row4_col36,#T_9749f_row6_col39,#T_9749f_row10_col38,#T_9749f_row14_col44,#T_9749f_row16_col38,#T_9749f_row18_col38,#T_9749f_row22_col36,#T_9749f_row23_col39,#T_9749f_row31_col24,#T_9749f_row35_col31,#T_9749f_row43_col6,#T_9749f_row47_col3,#T_9749f_row47_col8,#T_9749f_row47_col10,#T_9749f_row59_col38{\n",
       "            background-color:  #a6c4fe;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col44,#T_9749f_row1_col34,#T_9749f_row6_col40,#T_9749f_row7_col34,#T_9749f_row12_col44,#T_9749f_row13_col26,#T_9749f_row13_col30,#T_9749f_row13_col34,#T_9749f_row14_col24,#T_9749f_row21_col23,#T_9749f_row34_col2,#T_9749f_row35_col1,#T_9749f_row36_col49,#T_9749f_row36_col51,#T_9749f_row38_col9,#T_9749f_row39_col54,#T_9749f_row40_col5,#T_9749f_row46_col12,#T_9749f_row49_col8,#T_9749f_row50_col8,#T_9749f_row52_col8,#T_9749f_row53_col33,#T_9749f_row53_col38,#T_9749f_row53_col49,#T_9749f_row59_col55{\n",
       "            background-color:  #bbd1f8;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col45,#T_9749f_row2_col56,#T_9749f_row5_col22,#T_9749f_row6_col49,#T_9749f_row6_col51,#T_9749f_row9_col8,#T_9749f_row10_col46,#T_9749f_row12_col46,#T_9749f_row13_col46,#T_9749f_row23_col50,#T_9749f_row23_col52,#T_9749f_row24_col49,#T_9749f_row25_col49,#T_9749f_row25_col51,#T_9749f_row29_col49,#T_9749f_row29_col51,#T_9749f_row34_col39,#T_9749f_row41_col32,#T_9749f_row49_col35,#T_9749f_row51_col35,#T_9749f_row54_col48,#T_9749f_row54_col53{\n",
       "            background-color:  #7597f6;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col47,#T_9749f_row4_col33,#T_9749f_row4_col35,#T_9749f_row7_col41,#T_9749f_row11_col37,#T_9749f_row13_col31,#T_9749f_row14_col34,#T_9749f_row16_col37,#T_9749f_row18_col37,#T_9749f_row21_col46,#T_9749f_row26_col34,#T_9749f_row30_col34,#T_9749f_row38_col0,#T_9749f_row40_col43,#T_9749f_row48_col20{\n",
       "            background-color:  #9ebeff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col48,#T_9749f_row22_col54,#T_9749f_row31_col30,#T_9749f_row34_col45,#T_9749f_row37_col46,#T_9749f_row44_col5,#T_9749f_row50_col37,#T_9749f_row50_col55,#T_9749f_row52_col37,#T_9749f_row52_col55,#T_9749f_row55_col22,#T_9749f_row55_col37{\n",
       "            background-color:  #a3c2fe;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col49,#T_9749f_row0_col51,#T_9749f_row1_col49,#T_9749f_row10_col39,#T_9749f_row11_col54,#T_9749f_row13_col48,#T_9749f_row14_col39,#T_9749f_row19_col40,#T_9749f_row20_col40,#T_9749f_row20_col43,#T_9749f_row21_col2,#T_9749f_row21_col49,#T_9749f_row21_col50,#T_9749f_row21_col51,#T_9749f_row21_col52,#T_9749f_row24_col54,#T_9749f_row33_col50,#T_9749f_row33_col52,#T_9749f_row37_col25,#T_9749f_row37_col29,#T_9749f_row37_col59,#T_9749f_row38_col25,#T_9749f_row38_col29,#T_9749f_row41_col38,#T_9749f_row43_col4,#T_9749f_row44_col2,#T_9749f_row44_col11,#T_9749f_row46_col48,#T_9749f_row56_col24,#T_9749f_row57_col49,#T_9749f_row57_col51,#T_9749f_row57_col59,#T_9749f_row58_col49,#T_9749f_row58_col51,#T_9749f_row58_col59{\n",
       "            background-color:  #d3dbe7;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col50,#T_9749f_row0_col52,#T_9749f_row13_col10,#T_9749f_row14_col25,#T_9749f_row14_col50,#T_9749f_row14_col52,#T_9749f_row25_col38,#T_9749f_row27_col40,#T_9749f_row29_col38,#T_9749f_row33_col5,#T_9749f_row35_col20,#T_9749f_row37_col2,#T_9749f_row37_col5,#T_9749f_row38_col15,#T_9749f_row38_col17,#T_9749f_row38_col49,#T_9749f_row38_col51,#T_9749f_row40_col16,#T_9749f_row40_col18,#T_9749f_row40_col28,#T_9749f_row40_col42,#T_9749f_row41_col37,#T_9749f_row45_col29,#T_9749f_row45_col41,#T_9749f_row45_col49,#T_9749f_row45_col51,#T_9749f_row53_col9,#T_9749f_row54_col23,#T_9749f_row57_col4{\n",
       "            background-color:  #cdd9ec;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col53,#T_9749f_row16_col43,#T_9749f_row18_col43,#T_9749f_row50_col24,#T_9749f_row52_col24{\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row0_col54,#T_9749f_row1_col51,#T_9749f_row6_col37,#T_9749f_row7_col19,#T_9749f_row13_col49,#T_9749f_row13_col51,#T_9749f_row13_col59,#T_9749f_row14_col19,#T_9749f_row21_col15,#T_9749f_row21_col16,#T_9749f_row21_col17,#T_9749f_row21_col18,#T_9749f_row22_col15,#T_9749f_row22_col17,#T_9749f_row22_col20,#T_9749f_row24_col37,#T_9749f_row30_col40,#T_9749f_row35_col12,#T_9749f_row39_col4,#T_9749f_row39_col16,#T_9749f_row39_col18,#T_9749f_row39_col25,#T_9749f_row39_col29,#T_9749f_row40_col41,#T_9749f_row45_col4,#T_9749f_row45_col28,#T_9749f_row45_col34,#T_9749f_row46_col26,#T_9749f_row46_col30,#T_9749f_row59_col39{\n",
       "            background-color:  #d2dbe8;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col55,#T_9749f_row3_col44,#T_9749f_row7_col4,#T_9749f_row7_col32,#T_9749f_row8_col1,#T_9749f_row11_col38,#T_9749f_row22_col23,#T_9749f_row31_col27,#T_9749f_row31_col41,#T_9749f_row33_col2,#T_9749f_row33_col12,#T_9749f_row34_col1,#T_9749f_row34_col59,#T_9749f_row36_col31,#T_9749f_row36_col47,#T_9749f_row36_col50,#T_9749f_row36_col52,#T_9749f_row40_col6,#T_9749f_row49_col38,#T_9749f_row50_col33,#T_9749f_row51_col38,#T_9749f_row52_col33,#T_9749f_row53_col32,#T_9749f_row53_col37,#T_9749f_row55_col20,#T_9749f_row57_col48{\n",
       "            background-color:  #b5cdfa;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row0_col58,#T_9749f_row1_col53,#T_9749f_row9_col33,#T_9749f_row9_col35,#T_9749f_row10_col36,#T_9749f_row11_col7,#T_9749f_row15_col9,#T_9749f_row15_col10,#T_9749f_row15_col19,#T_9749f_row15_col20,#T_9749f_row15_col44,#T_9749f_row16_col0,#T_9749f_row16_col1,#T_9749f_row16_col2,#T_9749f_row16_col3,#T_9749f_row16_col4,#T_9749f_row16_col5,#T_9749f_row16_col6,#T_9749f_row16_col10,#T_9749f_row16_col11,#T_9749f_row16_col12,#T_9749f_row16_col19,#T_9749f_row16_col20,#T_9749f_row16_col23,#T_9749f_row16_col24,#T_9749f_row16_col25,#T_9749f_row16_col26,#T_9749f_row16_col27,#T_9749f_row16_col28,#T_9749f_row16_col29,#T_9749f_row16_col30,#T_9749f_row16_col41,#T_9749f_row16_col42,#T_9749f_row17_col9,#T_9749f_row17_col10,#T_9749f_row17_col19,#T_9749f_row17_col20,#T_9749f_row17_col44,#T_9749f_row18_col0,#T_9749f_row18_col1,#T_9749f_row18_col2,#T_9749f_row18_col3,#T_9749f_row18_col4,#T_9749f_row18_col5,#T_9749f_row18_col6,#T_9749f_row18_col10,#T_9749f_row18_col11,#T_9749f_row18_col12,#T_9749f_row18_col19,#T_9749f_row18_col20,#T_9749f_row18_col23,#T_9749f_row18_col24,#T_9749f_row18_col25,#T_9749f_row18_col26,#T_9749f_row18_col27,#T_9749f_row18_col28,#T_9749f_row18_col29,#T_9749f_row18_col30,#T_9749f_row18_col41,#T_9749f_row18_col42,#T_9749f_row20_col15,#T_9749f_row20_col16,#T_9749f_row20_col17,#T_9749f_row20_col18,#T_9749f_row22_col13,#T_9749f_row22_col56,#T_9749f_row24_col8,#T_9749f_row33_col43,#T_9749f_row36_col57,#T_9749f_row37_col39,#T_9749f_row38_col14,#T_9749f_row38_col40,#T_9749f_row39_col31,#T_9749f_row39_col37,#T_9749f_row39_col47,#T_9749f_row40_col32,#T_9749f_row40_col34,#T_9749f_row40_col38,#T_9749f_row40_col48,#T_9749f_row49_col59,#T_9749f_row51_col59,#T_9749f_row54_col21,#T_9749f_row54_col55,#T_9749f_row55_col45,#T_9749f_row55_col46,#T_9749f_row55_col54,#T_9749f_row56_col22,#T_9749f_row59_col49,#T_9749f_row59_col50,#T_9749f_row59_col51,#T_9749f_row59_col52{\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row0_col59,#T_9749f_row2_col50,#T_9749f_row2_col52,#T_9749f_row8_col37,#T_9749f_row13_col3,#T_9749f_row14_col12,#T_9749f_row14_col26,#T_9749f_row14_col30,#T_9749f_row14_col55,#T_9749f_row16_col33,#T_9749f_row18_col33,#T_9749f_row21_col12,#T_9749f_row24_col0,#T_9749f_row28_col36,#T_9749f_row33_col28,#T_9749f_row33_col42,#T_9749f_row36_col1,#T_9749f_row40_col44,#T_9749f_row42_col36,#T_9749f_row44_col26,#T_9749f_row46_col25,#T_9749f_row46_col29,#T_9749f_row46_col50,#T_9749f_row46_col52,#T_9749f_row53_col25,#T_9749f_row53_col27,#T_9749f_row53_col29,#T_9749f_row57_col28,#T_9749f_row57_col42,#T_9749f_row58_col26,#T_9749f_row58_col30{\n",
       "            background-color:  #c6d6f1;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col0,#T_9749f_row14_col56,#T_9749f_row20_col2,#T_9749f_row24_col59,#T_9749f_row33_col35,#T_9749f_row49_col16,#T_9749f_row49_col18,#T_9749f_row51_col16,#T_9749f_row51_col18,#T_9749f_row59_col26,#T_9749f_row59_col30{\n",
       "            background-color:  #f7b79b;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col2,#T_9749f_row3_col26,#T_9749f_row3_col30,#T_9749f_row24_col25,#T_9749f_row24_col27,#T_9749f_row24_col29,#T_9749f_row24_col41,#T_9749f_row25_col24,#T_9749f_row26_col3,#T_9749f_row27_col24,#T_9749f_row29_col24,#T_9749f_row30_col3{\n",
       "            background-color:  #d1493f;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row1_col3,#T_9749f_row1_col6,#T_9749f_row1_col9,#T_9749f_row2_col9,#T_9749f_row31_col16,#T_9749f_row31_col18,#T_9749f_row31_col37,#T_9749f_row43_col10,#T_9749f_row47_col37{\n",
       "            background-color:  #f4c6af;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col4,#T_9749f_row1_col26,#T_9749f_row1_col30,#T_9749f_row2_col0,#T_9749f_row6_col2,#T_9749f_row43_col9{\n",
       "            background-color:  #f6bea4;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col5,#T_9749f_row1_col11,#T_9749f_row24_col1,#T_9749f_row32_col49,#T_9749f_row32_col51{\n",
       "            background-color:  #f2cbb7;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col8,#T_9749f_row3_col56,#T_9749f_row14_col1,#T_9749f_row21_col54,#T_9749f_row26_col46,#T_9749f_row28_col44,#T_9749f_row38_col45,#T_9749f_row42_col44,#T_9749f_row43_col0,#T_9749f_row59_col35{\n",
       "            background-color:  #9bbcff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col10,#T_9749f_row2_col25,#T_9749f_row2_col27,#T_9749f_row2_col29,#T_9749f_row2_col41,#T_9749f_row5_col59,#T_9749f_row9_col24,#T_9749f_row10_col54,#T_9749f_row16_col49,#T_9749f_row16_col51,#T_9749f_row18_col49,#T_9749f_row18_col51,#T_9749f_row20_col1,#T_9749f_row34_col33{\n",
       "            background-color:  #f6bda2;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col12,#T_9749f_row1_col24,#T_9749f_row2_col5,#T_9749f_row23_col9,#T_9749f_row24_col2,#T_9749f_row28_col2,#T_9749f_row40_col59,#T_9749f_row42_col2,#T_9749f_row59_col19,#T_9749f_row59_col20{\n",
       "            background-color:  #f5c1a9;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col13,#T_9749f_row3_col48,#T_9749f_row4_col22,#T_9749f_row16_col56,#T_9749f_row18_col56,#T_9749f_row19_col22,#T_9749f_row19_col31,#T_9749f_row20_col14,#T_9749f_row24_col50,#T_9749f_row24_col52,#T_9749f_row26_col48,#T_9749f_row28_col15,#T_9749f_row28_col17,#T_9749f_row28_col50,#T_9749f_row28_col52,#T_9749f_row29_col48,#T_9749f_row30_col48,#T_9749f_row42_col50,#T_9749f_row42_col52,#T_9749f_row43_col37,#T_9749f_row45_col56,#T_9749f_row49_col12,#T_9749f_row49_col14,#T_9749f_row50_col21,#T_9749f_row50_col36,#T_9749f_row51_col12,#T_9749f_row51_col14,#T_9749f_row52_col21,#T_9749f_row52_col36,#T_9749f_row56_col45{\n",
       "            background-color:  #6788ee;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col14,#T_9749f_row10_col31,#T_9749f_row10_col35,#T_9749f_row20_col36,#T_9749f_row24_col13,#T_9749f_row26_col16,#T_9749f_row26_col18,#T_9749f_row27_col21,#T_9749f_row30_col16,#T_9749f_row30_col18,#T_9749f_row31_col43,#T_9749f_row38_col13,#T_9749f_row38_col22,#T_9749f_row40_col31,#T_9749f_row40_col37,#T_9749f_row49_col21,#T_9749f_row51_col21,#T_9749f_row54_col13,#T_9749f_row58_col21{\n",
       "            background-color:  #5f7fe8;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col15,#T_9749f_row1_col17,#T_9749f_row7_col44,#T_9749f_row7_col56,#T_9749f_row8_col11,#T_9749f_row8_col40,#T_9749f_row9_col37,#T_9749f_row9_col49,#T_9749f_row9_col51,#T_9749f_row16_col7,#T_9749f_row18_col7,#T_9749f_row22_col43,#T_9749f_row31_col53,#T_9749f_row32_col1,#T_9749f_row32_col41,#T_9749f_row39_col36,#T_9749f_row45_col7,#T_9749f_row45_col55,#T_9749f_row47_col11,#T_9749f_row47_col35,#T_9749f_row48_col35,#T_9749f_row48_col41,#T_9749f_row49_col7,#T_9749f_row49_col54,#T_9749f_row51_col54,#T_9749f_row57_col46{\n",
       "            background-color:  #8badfd;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col16,#T_9749f_row1_col18,#T_9749f_row2_col15,#T_9749f_row2_col17,#T_9749f_row4_col34,#T_9749f_row5_col32,#T_9749f_row8_col45,#T_9749f_row11_col49,#T_9749f_row11_col51,#T_9749f_row21_col45,#T_9749f_row25_col43,#T_9749f_row27_col45,#T_9749f_row28_col45,#T_9749f_row29_col43,#T_9749f_row31_col9,#T_9749f_row32_col5,#T_9749f_row33_col11,#T_9749f_row40_col55,#T_9749f_row41_col45,#T_9749f_row47_col53,#T_9749f_row48_col43,#T_9749f_row53_col46,#T_9749f_row55_col13,#T_9749f_row56_col31,#T_9749f_row56_col53{\n",
       "            background-color:  #88abfd;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col19,#T_9749f_row20_col54{\n",
       "            background-color:  #f6a586;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col20,#T_9749f_row19_col54{\n",
       "            background-color:  #f5a081;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col22,#T_9749f_row1_col32,#T_9749f_row2_col39,#T_9749f_row8_col3,#T_9749f_row10_col55,#T_9749f_row12_col36,#T_9749f_row14_col35,#T_9749f_row20_col33,#T_9749f_row20_col49,#T_9749f_row20_col51,#T_9749f_row36_col9,#T_9749f_row46_col0,#T_9749f_row46_col44,#T_9749f_row48_col6,#T_9749f_row49_col40,#T_9749f_row51_col40,#T_9749f_row52_col40,#T_9749f_row54_col16,#T_9749f_row54_col18,#T_9749f_row59_col47{\n",
       "            background-color:  #93b5fe;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col23,#T_9749f_row26_col1,#T_9749f_row28_col1,#T_9749f_row30_col1,#T_9749f_row42_col1,#T_9749f_row55_col6{\n",
       "            background-color:  #f1cdba;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col25,#T_9749f_row1_col29,#T_9749f_row2_col23,#T_9749f_row15_col32,#T_9749f_row17_col32,#T_9749f_row31_col15,#T_9749f_row31_col17,#T_9749f_row33_col47,#T_9749f_row36_col24,#T_9749f_row36_col35,#T_9749f_row39_col9{\n",
       "            background-color:  #f4c5ad;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col27,#T_9749f_row1_col41,#T_9749f_row16_col32,#T_9749f_row18_col32,#T_9749f_row19_col59,#T_9749f_row20_col59,#T_9749f_row27_col2,#T_9749f_row31_col33,#T_9749f_row41_col2,#T_9749f_row59_col11{\n",
       "            background-color:  #f3c7b1;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col28,#T_9749f_row1_col42,#T_9749f_row2_col3,#T_9749f_row10_col5,#T_9749f_row59_col27{\n",
       "            background-color:  #f6bfa6;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col31,#T_9749f_row6_col31,#T_9749f_row7_col45,#T_9749f_row19_col33,#T_9749f_row31_col54,#T_9749f_row32_col24,#T_9749f_row48_col24,#T_9749f_row53_col35,#T_9749f_row54_col15,#T_9749f_row54_col17,#T_9749f_row55_col21,#T_9749f_row57_col8,#T_9749f_row57_col43,#T_9749f_row58_col36{\n",
       "            background-color:  #90b2fe;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col33,#T_9749f_row1_col43,#T_9749f_row5_col34,#T_9749f_row25_col33,#T_9749f_row26_col35,#T_9749f_row28_col35,#T_9749f_row30_col35,#T_9749f_row35_col32,#T_9749f_row35_col48,#T_9749f_row42_col35,#T_9749f_row49_col33,#T_9749f_row51_col33,#T_9749f_row54_col39,#T_9749f_row54_col46,#T_9749f_row55_col38,#T_9749f_row57_col5,#T_9749f_row58_col5,#T_9749f_row58_col32,#T_9749f_row58_col34{\n",
       "            background-color:  #b1cbfc;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col35,#T_9749f_row2_col22,#T_9749f_row2_col47,#T_9749f_row5_col31,#T_9749f_row5_col39,#T_9749f_row7_col25,#T_9749f_row7_col29,#T_9749f_row12_col43,#T_9749f_row13_col1,#T_9749f_row13_col47,#T_9749f_row16_col35,#T_9749f_row18_col35,#T_9749f_row22_col39,#T_9749f_row31_col2,#T_9749f_row31_col6,#T_9749f_row31_col10,#T_9749f_row31_col26,#T_9749f_row45_col8,#T_9749f_row53_col44,#T_9749f_row54_col33{\n",
       "            background-color:  #a2c1ff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col37,#T_9749f_row5_col40,#T_9749f_row14_col42,#T_9749f_row19_col39,#T_9749f_row20_col37,#T_9749f_row21_col1,#T_9749f_row22_col4,#T_9749f_row26_col0,#T_9749f_row26_col36,#T_9749f_row28_col0,#T_9749f_row28_col40,#T_9749f_row30_col0,#T_9749f_row30_col36,#T_9749f_row33_col19,#T_9749f_row33_col25,#T_9749f_row33_col29,#T_9749f_row36_col2,#T_9749f_row38_col10,#T_9749f_row38_col12,#T_9749f_row39_col28,#T_9749f_row39_col42,#T_9749f_row42_col0,#T_9749f_row42_col40,#T_9749f_row43_col1,#T_9749f_row43_col40,#T_9749f_row45_col3,#T_9749f_row53_col26,#T_9749f_row53_col30,#T_9749f_row53_col41,#T_9749f_row53_col42,#T_9749f_row55_col34,#T_9749f_row58_col28,#T_9749f_row58_col42{\n",
       "            background-color:  #c5d6f2;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col38,#T_9749f_row5_col35,#T_9749f_row8_col38,#T_9749f_row11_col55,#T_9749f_row13_col20,#T_9749f_row16_col47,#T_9749f_row18_col47,#T_9749f_row20_col38,#T_9749f_row23_col38,#T_9749f_row38_col27,#T_9749f_row53_col19,#T_9749f_row53_col20,#T_9749f_row54_col11,#T_9749f_row56_col11,#T_9749f_row56_col15,#T_9749f_row56_col17{\n",
       "            background-color:  #d8dce2;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col40,#T_9749f_row15_col38,#T_9749f_row15_col40,#T_9749f_row17_col38,#T_9749f_row17_col40,#T_9749f_row21_col36,#T_9749f_row21_col37,#T_9749f_row22_col37,#T_9749f_row31_col3,#T_9749f_row33_col10,#T_9749f_row35_col47,#T_9749f_row38_col35,#T_9749f_row45_col1,#T_9749f_row45_col39,#T_9749f_row47_col24,#T_9749f_row49_col1,#T_9749f_row51_col1,#T_9749f_row54_col34{\n",
       "            background-color:  #a9c6fd;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col44,#T_9749f_row2_col44,#T_9749f_row3_col38,#T_9749f_row7_col10,#T_9749f_row7_col59,#T_9749f_row8_col48,#T_9749f_row14_col4,#T_9749f_row21_col4,#T_9749f_row21_col26,#T_9749f_row21_col30,#T_9749f_row26_col37,#T_9749f_row30_col37,#T_9749f_row33_col20,#T_9749f_row33_col24,#T_9749f_row37_col49,#T_9749f_row37_col51,#T_9749f_row45_col12,#T_9749f_row45_col37,#T_9749f_row46_col9,#T_9749f_row57_col12,#T_9749f_row58_col12{\n",
       "            background-color:  #cad8ef;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col45,#T_9749f_row3_col50,#T_9749f_row3_col52,#T_9749f_row7_col14,#T_9749f_row8_col5,#T_9749f_row8_col35,#T_9749f_row10_col33,#T_9749f_row12_col45,#T_9749f_row13_col36,#T_9749f_row21_col14,#T_9749f_row22_col45,#T_9749f_row24_col15,#T_9749f_row24_col17,#T_9749f_row24_col22,#T_9749f_row25_col13,#T_9749f_row25_col31,#T_9749f_row29_col13,#T_9749f_row29_col31,#T_9749f_row31_col7,#T_9749f_row32_col7,#T_9749f_row37_col40,#T_9749f_row41_col13,#T_9749f_row44_col34,#T_9749f_row45_col22,#T_9749f_row48_col0,#T_9749f_row50_col13,#T_9749f_row52_col13,#T_9749f_row53_col45,#T_9749f_row55_col44,#T_9749f_row57_col45,#T_9749f_row57_col56,#T_9749f_row59_col0{\n",
       "            background-color:  #7295f4;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col54,#T_9749f_row2_col38,#T_9749f_row8_col7,#T_9749f_row11_col40,#T_9749f_row14_col15,#T_9749f_row14_col16,#T_9749f_row14_col17,#T_9749f_row14_col18,#T_9749f_row15_col34,#T_9749f_row17_col34,#T_9749f_row26_col54,#T_9749f_row30_col54,#T_9749f_row34_col31,#T_9749f_row37_col23,#T_9749f_row38_col31,#T_9749f_row40_col3,#T_9749f_row45_col19,#T_9749f_row45_col59,#T_9749f_row49_col48,#T_9749f_row51_col48,#T_9749f_row54_col12,#T_9749f_row56_col4{\n",
       "            background-color:  #dfdbd9;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col55,#T_9749f_row8_col2,#T_9749f_row8_col33,#T_9749f_row21_col47,#T_9749f_row22_col33,#T_9749f_row31_col20,#T_9749f_row34_col27,#T_9749f_row37_col9,#T_9749f_row37_col36,#T_9749f_row43_col27,#T_9749f_row43_col41,#T_9749f_row47_col19,#T_9749f_row47_col27,#T_9749f_row48_col46,#T_9749f_row55_col2,#T_9749f_row58_col48,#T_9749f_row59_col16,#T_9749f_row59_col18{\n",
       "            background-color:  #b3cdfb;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row1_col57,#T_9749f_row10_col32,#T_9749f_row19_col21,#T_9749f_row25_col8,#T_9749f_row29_col8,#T_9749f_row31_col39,#T_9749f_row41_col8,#T_9749f_row50_col6,#T_9749f_row55_col8{\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row1_col58,#T_9749f_row2_col58,#T_9749f_row3_col58,#T_9749f_row4_col58,#T_9749f_row5_col58,#T_9749f_row6_col58,#T_9749f_row7_col58,#T_9749f_row8_col58,#T_9749f_row9_col58,#T_9749f_row10_col58,#T_9749f_row11_col58,#T_9749f_row12_col8,#T_9749f_row12_col58,#T_9749f_row13_col58,#T_9749f_row14_col58,#T_9749f_row15_col58,#T_9749f_row16_col9,#T_9749f_row16_col58,#T_9749f_row17_col58,#T_9749f_row18_col9,#T_9749f_row18_col58,#T_9749f_row19_col15,#T_9749f_row19_col16,#T_9749f_row19_col17,#T_9749f_row19_col18,#T_9749f_row19_col58,#T_9749f_row20_col58,#T_9749f_row21_col58,#T_9749f_row22_col58,#T_9749f_row23_col58,#T_9749f_row24_col58,#T_9749f_row25_col58,#T_9749f_row26_col58,#T_9749f_row27_col58,#T_9749f_row28_col58,#T_9749f_row29_col58,#T_9749f_row30_col58,#T_9749f_row31_col58,#T_9749f_row32_col58,#T_9749f_row33_col58,#T_9749f_row34_col58,#T_9749f_row35_col58,#T_9749f_row36_col58,#T_9749f_row37_col14,#T_9749f_row37_col58,#T_9749f_row38_col58,#T_9749f_row39_col58,#T_9749f_row40_col58,#T_9749f_row41_col58,#T_9749f_row42_col58,#T_9749f_row43_col58,#T_9749f_row44_col58,#T_9749f_row45_col58,#T_9749f_row46_col58,#T_9749f_row47_col58,#T_9749f_row48_col58,#T_9749f_row49_col58,#T_9749f_row50_col58,#T_9749f_row51_col58,#T_9749f_row52_col58,#T_9749f_row53_col58,#T_9749f_row54_col58,#T_9749f_row55_col58,#T_9749f_row56_col58,#T_9749f_row57_col58,#T_9749f_row59_col58{\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row1_col59,#T_9749f_row3_col39,#T_9749f_row12_col0,#T_9749f_row13_col4,#T_9749f_row15_col36,#T_9749f_row17_col36,#T_9749f_row21_col33,#T_9749f_row21_col34,#T_9749f_row22_col25,#T_9749f_row22_col29,#T_9749f_row24_col40,#T_9749f_row25_col39,#T_9749f_row27_col33,#T_9749f_row29_col39,#T_9749f_row39_col27,#T_9749f_row39_col41,#T_9749f_row39_col43,#T_9749f_row39_col49,#T_9749f_row39_col51,#T_9749f_row41_col33,#T_9749f_row44_col27,#T_9749f_row44_col28,#T_9749f_row44_col41,#T_9749f_row45_col9,#T_9749f_row45_col48,#T_9749f_row46_col39,#T_9749f_row49_col43,#T_9749f_row51_col34,#T_9749f_row51_col43,#T_9749f_row53_col11,#T_9749f_row54_col6,#T_9749f_row58_col11,#T_9749f_row58_col27,#T_9749f_row58_col41{\n",
       "            background-color:  #c0d4f5;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col1,#T_9749f_row3_col5,#T_9749f_row3_col12,#T_9749f_row3_col42,#T_9749f_row6_col12,#T_9749f_row9_col19,#T_9749f_row12_col3,#T_9749f_row25_col12,#T_9749f_row28_col3,#T_9749f_row29_col12,#T_9749f_row41_col24,#T_9749f_row42_col3{\n",
       "            background-color:  #d24b40;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row2_col4,#T_9749f_row2_col24,#T_9749f_row6_col59,#T_9749f_row9_col59,#T_9749f_row38_col48,#T_9749f_row50_col16,#T_9749f_row50_col18,#T_9749f_row52_col16,#T_9749f_row52_col18,#T_9749f_row56_col14{\n",
       "            background-color:  #f7b89c;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col6,#T_9749f_row23_col59,#T_9749f_row38_col32{\n",
       "            background-color:  #f7b99e;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col7,#T_9749f_row3_col13,#T_9749f_row4_col14,#T_9749f_row6_col21,#T_9749f_row10_col8,#T_9749f_row11_col13,#T_9749f_row11_col15,#T_9749f_row11_col17,#T_9749f_row11_col31,#T_9749f_row20_col8,#T_9749f_row20_col13,#T_9749f_row24_col14,#T_9749f_row24_col16,#T_9749f_row24_col18,#T_9749f_row27_col15,#T_9749f_row27_col17,#T_9749f_row28_col22,#T_9749f_row36_col56,#T_9749f_row37_col22,#T_9749f_row41_col15,#T_9749f_row41_col17,#T_9749f_row48_col22,#T_9749f_row50_col56,#T_9749f_row52_col56,#T_9749f_row53_col1,#T_9749f_row57_col7,#T_9749f_row58_col7{\n",
       "            background-color:  #6c8ff1;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col10,#T_9749f_row6_col9,#T_9749f_row10_col6,#T_9749f_row46_col45,#T_9749f_row49_col15,#T_9749f_row49_col17,#T_9749f_row51_col15,#T_9749f_row51_col17,#T_9749f_row59_col3,#T_9749f_row59_col9{\n",
       "            background-color:  #f7ba9f;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col11,#T_9749f_row4_col2,#T_9749f_row9_col6,#T_9749f_row23_col35,#T_9749f_row25_col2,#T_9749f_row29_col2,#T_9749f_row34_col15,#T_9749f_row34_col17,#T_9749f_row37_col47,#T_9749f_row47_col15,#T_9749f_row47_col17,#T_9749f_row59_col6{\n",
       "            background-color:  #f3c8b2;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col12,#T_9749f_row11_col59,#T_9749f_row19_col2,#T_9749f_row33_col34,#T_9749f_row33_col37,#T_9749f_row37_col33,#T_9749f_row50_col15,#T_9749f_row50_col17,#T_9749f_row52_col15,#T_9749f_row52_col17,#T_9749f_row59_col25,#T_9749f_row59_col28,#T_9749f_row59_col29,#T_9749f_row59_col42{\n",
       "            background-color:  #f7bca1;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col13,#T_9749f_row9_col13,#T_9749f_row19_col47,#T_9749f_row26_col14,#T_9749f_row26_col49,#T_9749f_row26_col51,#T_9749f_row27_col13,#T_9749f_row30_col14,#T_9749f_row30_col49,#T_9749f_row30_col51,#T_9749f_row41_col50,#T_9749f_row41_col52,#T_9749f_row42_col14,#T_9749f_row44_col35,#T_9749f_row47_col7,#T_9749f_row57_col13,#T_9749f_row57_col14,#T_9749f_row58_col13,#T_9749f_row58_col14{\n",
       "            background-color:  #7093f3;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col16,#T_9749f_row2_col18,#T_9749f_row5_col15,#T_9749f_row5_col17,#T_9749f_row8_col27,#T_9749f_row8_col28,#T_9749f_row8_col41,#T_9749f_row8_col42,#T_9749f_row11_col36,#T_9749f_row20_col55,#T_9749f_row24_col48,#T_9749f_row25_col53,#T_9749f_row29_col53,#T_9749f_row32_col3,#T_9749f_row32_col12,#T_9749f_row32_col23,#T_9749f_row32_col43,#T_9749f_row32_col45,#T_9749f_row32_col53,#T_9749f_row36_col53,#T_9749f_row46_col22,#T_9749f_row48_col9,#T_9749f_row48_col10,#T_9749f_row48_col23,#T_9749f_row48_col45,#T_9749f_row48_col53,#T_9749f_row49_col9,#T_9749f_row50_col0,#T_9749f_row50_col10,#T_9749f_row51_col9,#T_9749f_row52_col0,#T_9749f_row52_col10,#T_9749f_row56_col7{\n",
       "            background-color:  #84a7fc;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col19,#T_9749f_row9_col26,#T_9749f_row9_col30,#T_9749f_row23_col10,#T_9749f_row28_col9,#T_9749f_row42_col9{\n",
       "            background-color:  #f6a283;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col20,#T_9749f_row19_col24,#T_9749f_row26_col9,#T_9749f_row30_col9{\n",
       "            background-color:  #f59c7d;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col21,#T_9749f_row3_col43,#T_9749f_row6_col47,#T_9749f_row7_col39,#T_9749f_row21_col43,#T_9749f_row27_col31,#T_9749f_row31_col46,#T_9749f_row32_col19,#T_9749f_row39_col1,#T_9749f_row41_col31,#T_9749f_row49_col2,#T_9749f_row51_col2,#T_9749f_row56_col37,#T_9749f_row59_col46{\n",
       "            background-color:  #97b8ff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col26,#T_9749f_row2_col28,#T_9749f_row2_col30,#T_9749f_row2_col42,#T_9749f_row19_col5,#T_9749f_row34_col36,#T_9749f_row35_col23,#T_9749f_row44_col9,#T_9749f_row48_col31{\n",
       "            background-color:  #f7b599;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col33,#T_9749f_row4_col39,#T_9749f_row13_col6,#T_9749f_row13_col23,#T_9749f_row15_col8,#T_9749f_row17_col8,#T_9749f_row44_col59,#T_9749f_row46_col2,#T_9749f_row47_col20,#T_9749f_row53_col6,#T_9749f_row59_col15,#T_9749f_row59_col17{\n",
       "            background-color:  #b6cefa;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col34,#T_9749f_row3_col37,#T_9749f_row5_col54,#T_9749f_row8_col59,#T_9749f_row16_col8,#T_9749f_row18_col8,#T_9749f_row21_col6,#T_9749f_row25_col0,#T_9749f_row27_col0,#T_9749f_row29_col0,#T_9749f_row33_col4,#T_9749f_row34_col28,#T_9749f_row34_col42,#T_9749f_row36_col20,#T_9749f_row38_col46,#T_9749f_row40_col54,#T_9749f_row41_col0,#T_9749f_row46_col3,#T_9749f_row46_col23,#T_9749f_row49_col34,#T_9749f_row55_col50,#T_9749f_row55_col52,#T_9749f_row56_col55,#T_9749f_row57_col24{\n",
       "            background-color:  #bfd3f6;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col37,#T_9749f_row3_col55,#T_9749f_row13_col32,#T_9749f_row14_col29,#T_9749f_row14_col49,#T_9749f_row14_col51,#T_9749f_row19_col0,#T_9749f_row23_col54,#T_9749f_row27_col37,#T_9749f_row28_col37,#T_9749f_row36_col3,#T_9749f_row39_col26,#T_9749f_row39_col30,#T_9749f_row41_col40,#T_9749f_row42_col37,#T_9749f_row44_col39,#T_9749f_row45_col10,#T_9749f_row45_col24,#T_9749f_row45_col27,#T_9749f_row45_col31,#T_9749f_row46_col33,#T_9749f_row46_col49,#T_9749f_row46_col51,#T_9749f_row47_col55,#T_9749f_row49_col44,#T_9749f_row51_col44,#T_9749f_row55_col32,#T_9749f_row56_col23,#T_9749f_row56_col49,#T_9749f_row56_col51,#T_9749f_row57_col9,#T_9749f_row58_col9{\n",
       "            background-color:  #cedaeb;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col45,#T_9749f_row5_col43,#T_9749f_row6_col22,#T_9749f_row8_col24,#T_9749f_row16_col45,#T_9749f_row18_col45,#T_9749f_row23_col16,#T_9749f_row23_col18,#T_9749f_row27_col32,#T_9749f_row31_col0,#T_9749f_row34_col21,#T_9749f_row35_col21,#T_9749f_row44_col32,#T_9749f_row45_col21,#T_9749f_row50_col35,#T_9749f_row52_col35,#T_9749f_row53_col13,#T_9749f_row56_col8,#T_9749f_row59_col14,#T_9749f_row59_col44{\n",
       "            background-color:  #7699f6;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col46,#T_9749f_row5_col46,#T_9749f_row5_col56,#T_9749f_row12_col33,#T_9749f_row12_col56,#T_9749f_row19_col49,#T_9749f_row19_col51,#T_9749f_row23_col46,#T_9749f_row23_col56,#T_9749f_row24_col56,#T_9749f_row31_col1,#T_9749f_row32_col2,#T_9749f_row32_col28,#T_9749f_row32_col42,#T_9749f_row33_col8,#T_9749f_row35_col0,#T_9749f_row40_col1,#T_9749f_row44_col16,#T_9749f_row44_col18,#T_9749f_row47_col25,#T_9749f_row47_col29,#T_9749f_row48_col36,#T_9749f_row49_col39,#T_9749f_row50_col40,#T_9749f_row51_col39,#T_9749f_row59_col36{\n",
       "            background-color:  #94b6ff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col49,#T_9749f_row2_col51,#T_9749f_row5_col0,#T_9749f_row21_col29,#T_9749f_row22_col1,#T_9749f_row22_col3,#T_9749f_row22_col42,#T_9749f_row24_col35,#T_9749f_row25_col37,#T_9749f_row29_col37,#T_9749f_row31_col59,#T_9749f_row35_col11,#T_9749f_row40_col23,#T_9749f_row40_col24,#T_9749f_row45_col6,#T_9749f_row46_col41,#T_9749f_row47_col59,#T_9749f_row55_col33,#T_9749f_row57_col25,#T_9749f_row58_col25,#T_9749f_row58_col29{\n",
       "            background-color:  #c3d5f4;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col53,#T_9749f_row3_col15,#T_9749f_row3_col17,#T_9749f_row10_col13,#T_9749f_row14_col21,#T_9749f_row16_col22,#T_9749f_row18_col22,#T_9749f_row19_col48,#T_9749f_row20_col48,#T_9749f_row32_col14,#T_9749f_row40_col47,#T_9749f_row41_col21,#T_9749f_row44_col45,#T_9749f_row45_col14,#T_9749f_row48_col14,#T_9749f_row57_col21{\n",
       "            background-color:  #6180e9;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col54,#T_9749f_row7_col50,#T_9749f_row7_col52,#T_9749f_row13_col56,#T_9749f_row14_col40,#T_9749f_row28_col38,#T_9749f_row33_col36,#T_9749f_row35_col3,#T_9749f_row37_col24,#T_9749f_row37_col26,#T_9749f_row37_col32,#T_9749f_row37_col48,#T_9749f_row45_col16,#T_9749f_row45_col18,#T_9749f_row46_col16,#T_9749f_row46_col18,#T_9749f_row54_col27,#T_9749f_row56_col26,#T_9749f_row56_col30{\n",
       "            background-color:  #dcdddd;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col55,#T_9749f_row3_col0,#T_9749f_row6_col34,#T_9749f_row8_col9,#T_9749f_row8_col47,#T_9749f_row10_col0,#T_9749f_row13_col11,#T_9749f_row13_col42,#T_9749f_row14_col6,#T_9749f_row14_col23,#T_9749f_row22_col11,#T_9749f_row22_col24,#T_9749f_row22_col27,#T_9749f_row22_col41,#T_9749f_row23_col0,#T_9749f_row35_col2,#T_9749f_row45_col32,#T_9749f_row53_col23,#T_9749f_row53_col24,#T_9749f_row53_col40,#T_9749f_row58_col24{\n",
       "            background-color:  #bed2f6;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row2_col57,#T_9749f_row6_col7,#T_9749f_row10_col15,#T_9749f_row10_col16,#T_9749f_row10_col17,#T_9749f_row10_col18,#T_9749f_row10_col34,#T_9749f_row24_col7,#T_9749f_row27_col8,#T_9749f_row37_col43,#T_9749f_row38_col56,#T_9749f_row43_col35{\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row2_col59,#T_9749f_row4_col37,#T_9749f_row8_col20,#T_9749f_row8_col32,#T_9749f_row14_col11,#T_9749f_row14_col27,#T_9749f_row14_col41,#T_9749f_row21_col28,#T_9749f_row23_col40,#T_9749f_row37_col50,#T_9749f_row37_col52,#T_9749f_row44_col30,#T_9749f_row45_col23,#T_9749f_row45_col50,#T_9749f_row45_col52,#T_9749f_row49_col31,#T_9749f_row51_col31,#T_9749f_row53_col12,#T_9749f_row53_col50,#T_9749f_row53_col52,#T_9749f_row55_col36,#T_9749f_row57_col26,#T_9749f_row57_col30,#T_9749f_row58_col3{\n",
       "            background-color:  #c7d7f0;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col2,#T_9749f_row6_col1,#T_9749f_row6_col55,#T_9749f_row16_col48,#T_9749f_row18_col48,#T_9749f_row34_col16,#T_9749f_row34_col18,#T_9749f_row36_col6,#T_9749f_row54_col4{\n",
       "            background-color:  #f1ccb8;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col4,#T_9749f_row3_col23,#T_9749f_row4_col3,#T_9749f_row25_col26,#T_9749f_row25_col30,#T_9749f_row26_col25,#T_9749f_row26_col29,#T_9749f_row29_col4,#T_9749f_row29_col26,#T_9749f_row29_col30,#T_9749f_row30_col25,#T_9749f_row30_col29{\n",
       "            background-color:  #cb3e38;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row3_col6,#T_9749f_row12_col20{\n",
       "            background-color:  #e16751;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col7,#T_9749f_row6_col8,#T_9749f_row13_col22,#T_9749f_row15_col0,#T_9749f_row15_col3,#T_9749f_row15_col4,#T_9749f_row15_col11,#T_9749f_row15_col12,#T_9749f_row16_col44,#T_9749f_row17_col0,#T_9749f_row17_col3,#T_9749f_row17_col4,#T_9749f_row17_col11,#T_9749f_row17_col12,#T_9749f_row18_col44,#T_9749f_row23_col7,#T_9749f_row28_col8,#T_9749f_row34_col57,#T_9749f_row35_col57,#T_9749f_row37_col57,#T_9749f_row42_col8,#T_9749f_row43_col57,#T_9749f_row47_col14{\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row3_col8,#T_9749f_row5_col8,#T_9749f_row8_col13{\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row3_col9,#T_9749f_row9_col12,#T_9749f_row10_col26,#T_9749f_row10_col30,#T_9749f_row24_col19,#T_9749f_row28_col10,#T_9749f_row41_col10{\n",
       "            background-color:  #f08b6e;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col10,#T_9749f_row11_col23,#T_9749f_row12_col5,#T_9749f_row19_col3{\n",
       "            background-color:  #e67259;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col11,#T_9749f_row4_col27,#T_9749f_row24_col12,#T_9749f_row26_col41,#T_9749f_row28_col41,#T_9749f_row30_col41,#T_9749f_row42_col41{\n",
       "            background-color:  #cf453c;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row3_col14,#T_9749f_row3_col46,#T_9749f_row4_col53,#T_9749f_row5_col14,#T_9749f_row6_col15,#T_9749f_row6_col17,#T_9749f_row6_col43,#T_9749f_row7_col43,#T_9749f_row11_col14,#T_9749f_row11_col52,#T_9749f_row14_col0,#T_9749f_row14_col31,#T_9749f_row14_col47,#T_9749f_row19_col56,#T_9749f_row23_col49,#T_9749f_row23_col51,#T_9749f_row24_col53,#T_9749f_row28_col53,#T_9749f_row32_col25,#T_9749f_row32_col29,#T_9749f_row35_col56,#T_9749f_row36_col21,#T_9749f_row42_col53,#T_9749f_row43_col53,#T_9749f_row45_col53,#T_9749f_row46_col53,#T_9749f_row54_col7,#T_9749f_row54_col47{\n",
       "            background-color:  #7da0f9;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col16,#T_9749f_row3_col18,#T_9749f_row4_col21,#T_9749f_row12_col15,#T_9749f_row12_col17,#T_9749f_row34_col44,#T_9749f_row40_col22,#T_9749f_row43_col33,#T_9749f_row43_col36{\n",
       "            background-color:  #5d7ce6;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col19,#T_9749f_row11_col26,#T_9749f_row11_col30{\n",
       "            background-color:  #e36b54;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col20,#T_9749f_row4_col11,#T_9749f_row4_col19,#T_9749f_row23_col12{\n",
       "            background-color:  #df634e;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col21,#T_9749f_row8_col36,#T_9749f_row9_col45,#T_9749f_row9_col48,#T_9749f_row12_col16,#T_9749f_row12_col18,#T_9749f_row34_col14,#T_9749f_row34_col56,#T_9749f_row46_col13,#T_9749f_row46_col14,#T_9749f_row49_col26,#T_9749f_row49_col42,#T_9749f_row51_col26,#T_9749f_row51_col28,#T_9749f_row51_col30,#T_9749f_row51_col42{\n",
       "            background-color:  #5a78e4;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col22,#T_9749f_row4_col50,#T_9749f_row4_col52,#T_9749f_row6_col50,#T_9749f_row10_col21,#T_9749f_row12_col14,#T_9749f_row25_col50,#T_9749f_row25_col52,#T_9749f_row29_col50,#T_9749f_row29_col52,#T_9749f_row33_col9,#T_9749f_row39_col35,#T_9749f_row39_col45,#T_9749f_row43_col22,#T_9749f_row44_col31,#T_9749f_row44_col56,#T_9749f_row47_col21,#T_9749f_row49_col4,#T_9749f_row49_col36,#T_9749f_row49_col56,#T_9749f_row51_col4,#T_9749f_row51_col36,#T_9749f_row51_col56,#T_9749f_row59_col43{\n",
       "            background-color:  #6b8df0;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col24,#T_9749f_row4_col20,#T_9749f_row6_col23,#T_9749f_row23_col6,#T_9749f_row24_col5,#T_9749f_row28_col5,#T_9749f_row42_col5{\n",
       "            background-color:  #da5a49;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col25,#T_9749f_row3_col27,#T_9749f_row3_col29,#T_9749f_row3_col41,#T_9749f_row6_col28,#T_9749f_row23_col27,#T_9749f_row23_col41,#T_9749f_row25_col3,#T_9749f_row27_col3,#T_9749f_row27_col23,#T_9749f_row28_col6,#T_9749f_row29_col3,#T_9749f_row41_col3,#T_9749f_row41_col23,#T_9749f_row42_col6{\n",
       "            background-color:  #bb1b2c;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row3_col28,#T_9749f_row9_col20,#T_9749f_row12_col25,#T_9749f_row12_col29,#T_9749f_row27_col12{\n",
       "            background-color:  #d44e41;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col31,#T_9749f_row3_col47,#T_9749f_row4_col47,#T_9749f_row5_col49,#T_9749f_row5_col51,#T_9749f_row7_col36,#T_9749f_row10_col22,#T_9749f_row19_col34,#T_9749f_row19_col45,#T_9749f_row23_col48,#T_9749f_row27_col43,#T_9749f_row34_col10,#T_9749f_row40_col53,#T_9749f_row41_col43,#T_9749f_row44_col21,#T_9749f_row44_col48,#T_9749f_row44_col53,#T_9749f_row48_col11,#T_9749f_row50_col54,#T_9749f_row52_col54,#T_9749f_row55_col53{\n",
       "            background-color:  #80a3fa;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col32,#T_9749f_row4_col32,#T_9749f_row12_col48,#T_9749f_row13_col7,#T_9749f_row14_col45,#T_9749f_row15_col22,#T_9749f_row17_col22,#T_9749f_row25_col32,#T_9749f_row26_col15,#T_9749f_row26_col17,#T_9749f_row26_col52,#T_9749f_row28_col13,#T_9749f_row28_col21,#T_9749f_row29_col32,#T_9749f_row30_col15,#T_9749f_row30_col17,#T_9749f_row31_col22,#T_9749f_row32_col39,#T_9749f_row33_col13,#T_9749f_row44_col8,#T_9749f_row45_col13{\n",
       "            background-color:  #6384eb;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col34,#T_9749f_row4_col46,#T_9749f_row6_col44,#T_9749f_row8_col25,#T_9749f_row8_col26,#T_9749f_row8_col29,#T_9749f_row8_col30,#T_9749f_row10_col56,#T_9749f_row13_col35,#T_9749f_row23_col53,#T_9749f_row28_col31,#T_9749f_row33_col0,#T_9749f_row34_col9,#T_9749f_row34_col53,#T_9749f_row35_col44,#T_9749f_row37_col7,#T_9749f_row37_col53,#T_9749f_row42_col31,#T_9749f_row42_col45,#T_9749f_row43_col46,#T_9749f_row49_col0,#T_9749f_row50_col7,#T_9749f_row51_col0,#T_9749f_row52_col7,#T_9749f_row56_col47,#T_9749f_row59_col34{\n",
       "            background-color:  #86a9fc;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col40,#T_9749f_row5_col38,#T_9749f_row19_col38,#T_9749f_row22_col9,#T_9749f_row22_col55,#T_9749f_row27_col54,#T_9749f_row35_col55,#T_9749f_row37_col6,#T_9749f_row38_col41,#T_9749f_row44_col4,#T_9749f_row50_col44,#T_9749f_row52_col44,#T_9749f_row54_col24,#T_9749f_row55_col48,#T_9749f_row56_col27,#T_9749f_row56_col41{\n",
       "            background-color:  #d7dce3;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col45,#T_9749f_row7_col53,#T_9749f_row11_col47,#T_9749f_row11_col48,#T_9749f_row14_col7,#T_9749f_row23_col13,#T_9749f_row23_col43,#T_9749f_row27_col22,#T_9749f_row36_col44,#T_9749f_row50_col14,#T_9749f_row52_col14,#T_9749f_row59_col8{\n",
       "            background-color:  #6e90f2;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col49,#T_9749f_row3_col51,#T_9749f_row4_col45,#T_9749f_row6_col53,#T_9749f_row9_col53,#T_9749f_row15_col14,#T_9749f_row16_col14,#T_9749f_row17_col14,#T_9749f_row18_col14,#T_9749f_row19_col53,#T_9749f_row23_col15,#T_9749f_row23_col17,#T_9749f_row26_col53,#T_9749f_row30_col53,#T_9749f_row31_col40,#T_9749f_row38_col53,#T_9749f_row39_col0,#T_9749f_row44_col37,#T_9749f_row48_col54,#T_9749f_row50_col46,#T_9749f_row55_col56,#T_9749f_row56_col46{\n",
       "            background-color:  #7b9ff9;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row3_col57,#T_9749f_row4_col8,#T_9749f_row4_col57,#T_9749f_row6_col57,#T_9749f_row8_col57,#T_9749f_row9_col36,#T_9749f_row10_col57,#T_9749f_row11_col57,#T_9749f_row12_col7,#T_9749f_row12_col57,#T_9749f_row15_col5,#T_9749f_row15_col23,#T_9749f_row15_col24,#T_9749f_row17_col5,#T_9749f_row17_col23,#T_9749f_row17_col24,#T_9749f_row19_col57,#T_9749f_row20_col57,#T_9749f_row22_col57,#T_9749f_row24_col57,#T_9749f_row25_col57,#T_9749f_row27_col57,#T_9749f_row29_col57,#T_9749f_row31_col57,#T_9749f_row38_col57,#T_9749f_row39_col57,#T_9749f_row41_col57,#T_9749f_row46_col57,#T_9749f_row47_col39,#T_9749f_row50_col57,#T_9749f_row52_col57,#T_9749f_row59_col57{\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row3_col59,#T_9749f_row9_col27,#T_9749f_row9_col41,#T_9749f_row24_col9,#T_9749f_row28_col59,#T_9749f_row32_col31,#T_9749f_row32_col34,#T_9749f_row32_col38,#T_9749f_row34_col32,#T_9749f_row48_col38,#T_9749f_row59_col12{\n",
       "            background-color:  #f7b396;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col0,#T_9749f_row6_col35,#T_9749f_row6_col54,#T_9749f_row7_col37,#T_9749f_row8_col10,#T_9749f_row13_col27,#T_9749f_row13_col41,#T_9749f_row20_col39,#T_9749f_row21_col25,#T_9749f_row21_col27,#T_9749f_row21_col41,#T_9749f_row22_col12,#T_9749f_row22_col28,#T_9749f_row24_col34,#T_9749f_row33_col6,#T_9749f_row35_col50,#T_9749f_row35_col52,#T_9749f_row37_col1,#T_9749f_row38_col59,#T_9749f_row43_col28,#T_9749f_row43_col42,#T_9749f_row44_col42,#T_9749f_row50_col43,#T_9749f_row52_col43,#T_9749f_row54_col40,#T_9749f_row57_col11,#T_9749f_row57_col27,#T_9749f_row57_col41{\n",
       "            background-color:  #c1d4f4;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col5,#T_9749f_row5_col12,#T_9749f_row12_col10,#T_9749f_row12_col23,#T_9749f_row19_col4{\n",
       "            background-color:  #e26952;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col6,#T_9749f_row25_col5,#T_9749f_row29_col5{\n",
       "            background-color:  #ca3b37;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row4_col7,#T_9749f_row15_col43,#T_9749f_row17_col43,#T_9749f_row23_col8,#T_9749f_row28_col7,#T_9749f_row39_col21,#T_9749f_row42_col7,#T_9749f_row48_col40{\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row4_col9,#T_9749f_row9_col4,#T_9749f_row23_col20,#T_9749f_row42_col10{\n",
       "            background-color:  #f08a6c;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col10,#T_9749f_row11_col28,#T_9749f_row11_col42,#T_9749f_row20_col3,#T_9749f_row26_col11,#T_9749f_row26_col20,#T_9749f_row30_col11,#T_9749f_row30_col20{\n",
       "            background-color:  #e36c55;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col12,#T_9749f_row6_col26,#T_9749f_row6_col30,#T_9749f_row12_col4,#T_9749f_row23_col25,#T_9749f_row23_col29,#T_9749f_row25_col23,#T_9749f_row29_col23{\n",
       "            background-color:  #be242e;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row4_col13,#T_9749f_row12_col13,#T_9749f_row12_col21,#T_9749f_row16_col54,#T_9749f_row18_col54,#T_9749f_row19_col7,#T_9749f_row19_col36,#T_9749f_row36_col7,#T_9749f_row44_col36,#T_9749f_row49_col28,#T_9749f_row49_col30,#T_9749f_row53_col7,#T_9749f_row54_col56,#T_9749f_row59_col7,#T_9749f_row59_col21{\n",
       "            background-color:  #5b7ae5;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col15,#T_9749f_row4_col17,#T_9749f_row8_col14,#T_9749f_row8_col56,#T_9749f_row9_col7,#T_9749f_row9_col34,#T_9749f_row20_col7,#T_9749f_row36_col8,#T_9749f_row37_col21,#T_9749f_row40_col21,#T_9749f_row49_col22,#T_9749f_row49_col25,#T_9749f_row49_col27,#T_9749f_row49_col29,#T_9749f_row49_col41,#T_9749f_row51_col22,#T_9749f_row51_col25,#T_9749f_row51_col27,#T_9749f_row51_col29,#T_9749f_row51_col41{\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col16,#T_9749f_row4_col18,#T_9749f_row32_col56,#T_9749f_row50_col26,#T_9749f_row50_col28,#T_9749f_row50_col30,#T_9749f_row50_col42,#T_9749f_row52_col26,#T_9749f_row52_col28,#T_9749f_row52_col30,#T_9749f_row52_col42,#T_9749f_row53_col0,#T_9749f_row56_col21{\n",
       "            background-color:  #5572df;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col23{\n",
       "            background-color:  #dc5d4a;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col24,#T_9749f_row5_col27,#T_9749f_row41_col5{\n",
       "            background-color:  #c32e31;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row4_col25,#T_9749f_row4_col29,#T_9749f_row25_col4,#T_9749f_row29_col42{\n",
       "            background-color:  #cc403a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row4_col26,#T_9749f_row4_col30,#T_9749f_row6_col24,#T_9749f_row24_col26,#T_9749f_row24_col30,#T_9749f_row26_col4,#T_9749f_row26_col24,#T_9749f_row30_col4,#T_9749f_row30_col24,#T_9749f_row42_col4{\n",
       "            background-color:  #b8122a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row4_col28,#T_9749f_row4_col42,#T_9749f_row6_col42,#T_9749f_row24_col6,#T_9749f_row28_col4{\n",
       "            background-color:  #ba162b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row4_col31,#T_9749f_row5_col13,#T_9749f_row5_col53,#T_9749f_row6_col14,#T_9749f_row10_col50,#T_9749f_row10_col52,#T_9749f_row12_col31,#T_9749f_row12_col53,#T_9749f_row15_col13,#T_9749f_row17_col13,#T_9749f_row19_col55,#T_9749f_row20_col53,#T_9749f_row23_col32,#T_9749f_row26_col31,#T_9749f_row27_col14,#T_9749f_row27_col48,#T_9749f_row30_col31,#T_9749f_row34_col7,#T_9749f_row39_col53,#T_9749f_row41_col14,#T_9749f_row43_col56,#T_9749f_row44_col46,#T_9749f_row52_col46,#T_9749f_row53_col22,#T_9749f_row54_col31,#T_9749f_row59_col32{\n",
       "            background-color:  #7a9df8;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col38,#T_9749f_row4_col40,#T_9749f_row5_col36,#T_9749f_row7_col20,#T_9749f_row13_col50,#T_9749f_row13_col52,#T_9749f_row20_col0,#T_9749f_row21_col9,#T_9749f_row21_col59,#T_9749f_row22_col16,#T_9749f_row22_col18,#T_9749f_row26_col40,#T_9749f_row35_col38,#T_9749f_row37_col10,#T_9749f_row37_col12,#T_9749f_row37_col15,#T_9749f_row37_col17,#T_9749f_row39_col15,#T_9749f_row39_col17,#T_9749f_row40_col27,#T_9749f_row45_col42,#T_9749f_row46_col24,#T_9749f_row46_col28{\n",
       "            background-color:  #d1dae9;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col41,#T_9749f_row5_col3,#T_9749f_row12_col24{\n",
       "            background-color:  #d0473d;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row4_col48,#T_9749f_row7_col13,#T_9749f_row10_col47,#T_9749f_row11_col32,#T_9749f_row12_col34,#T_9749f_row13_col8,#T_9749f_row19_col13,#T_9749f_row25_col15,#T_9749f_row25_col17,#T_9749f_row25_col48,#T_9749f_row27_col16,#T_9749f_row27_col18,#T_9749f_row29_col15,#T_9749f_row29_col17,#T_9749f_row34_col43,#T_9749f_row35_col13,#T_9749f_row38_col44,#T_9749f_row39_col48,#T_9749f_row41_col16,#T_9749f_row41_col18,#T_9749f_row47_col22,#T_9749f_row47_col44,#T_9749f_row48_col44,#T_9749f_row49_col3,#T_9749f_row49_col11,#T_9749f_row49_col45,#T_9749f_row50_col22,#T_9749f_row51_col3,#T_9749f_row51_col11,#T_9749f_row51_col45,#T_9749f_row52_col22,#T_9749f_row53_col21,#T_9749f_row55_col43{\n",
       "            background-color:  #688aef;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col49,#T_9749f_row4_col51,#T_9749f_row6_col16,#T_9749f_row6_col18,#T_9749f_row8_col44,#T_9749f_row12_col51,#T_9749f_row22_col7,#T_9749f_row35_col14,#T_9749f_row35_col45,#T_9749f_row39_col34,#T_9749f_row43_col14,#T_9749f_row44_col14,#T_9749f_row46_col21{\n",
       "            background-color:  #779af7;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col54,#T_9749f_row9_col2,#T_9749f_row35_col27,#T_9749f_row35_col41,#T_9749f_row36_col23,#T_9749f_row55_col26,#T_9749f_row55_col30{\n",
       "            background-color:  #e9d5cb;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col55,#T_9749f_row13_col19,#T_9749f_row14_col9,#T_9749f_row14_col20,#T_9749f_row14_col59,#T_9749f_row21_col20,#T_9749f_row21_col55,#T_9749f_row25_col40,#T_9749f_row29_col40,#T_9749f_row34_col50,#T_9749f_row34_col52,#T_9749f_row35_col4,#T_9749f_row38_col2,#T_9749f_row39_col3,#T_9749f_row41_col54,#T_9749f_row45_col38,#T_9749f_row54_col1{\n",
       "            background-color:  #d6dce4;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row4_col59{\n",
       "            background-color:  #f7b093;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col1,#T_9749f_row9_col44,#T_9749f_row32_col50,#T_9749f_row32_col52,#T_9749f_row36_col15,#T_9749f_row36_col17,#T_9749f_row44_col50,#T_9749f_row44_col52,#T_9749f_row48_col49,#T_9749f_row48_col51{\n",
       "            background-color:  #f0cdbb;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col2,#T_9749f_row15_col50,#T_9749f_row15_col52,#T_9749f_row17_col50,#T_9749f_row17_col52,#T_9749f_row43_col19,#T_9749f_row43_col20,#T_9749f_row59_col24{\n",
       "            background-color:  #f5c4ac;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col4,#T_9749f_row11_col4,#T_9749f_row26_col5,#T_9749f_row30_col5{\n",
       "            background-color:  #dd5f4b;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col6,#T_9749f_row5_col42,#T_9749f_row6_col5,#T_9749f_row11_col12,#T_9749f_row25_col6,#T_9749f_row26_col23,#T_9749f_row28_col23,#T_9749f_row29_col6,#T_9749f_row30_col23,#T_9749f_row42_col23{\n",
       "            background-color:  #d75445;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col7,#T_9749f_row15_col6,#T_9749f_row17_col6,#T_9749f_row26_col57,#T_9749f_row28_col57,#T_9749f_row30_col57,#T_9749f_row31_col14,#T_9749f_row32_col57,#T_9749f_row42_col57,#T_9749f_row47_col57,#T_9749f_row48_col57{\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row5_col10,#T_9749f_row10_col59,#T_9749f_row32_col15,#T_9749f_row32_col17{\n",
       "            background-color:  #f7aa8c;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col11,#T_9749f_row10_col4,#T_9749f_row25_col20,#T_9749f_row28_col20,#T_9749f_row29_col20,#T_9749f_row42_col20{\n",
       "            background-color:  #e57058;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col16,#T_9749f_row5_col18,#T_9749f_row7_col22,#T_9749f_row9_col14,#T_9749f_row10_col49,#T_9749f_row10_col51,#T_9749f_row10_col53,#T_9749f_row11_col50,#T_9749f_row11_col53,#T_9749f_row24_col32,#T_9749f_row28_col48,#T_9749f_row32_col9,#T_9749f_row32_col10,#T_9749f_row32_col11,#T_9749f_row32_col54,#T_9749f_row34_col13,#T_9749f_row38_col7,#T_9749f_row42_col48,#T_9749f_row43_col8,#T_9749f_row43_col47,#T_9749f_row44_col22,#T_9749f_row48_col25,#T_9749f_row48_col29,#T_9749f_row53_col56,#T_9749f_row56_col0,#T_9749f_row57_col53,#T_9749f_row58_col53{\n",
       "            background-color:  #7ea1fa;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col19,#T_9749f_row38_col37,#T_9749f_row43_col44{\n",
       "            background-color:  #f59d7e;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col20,#T_9749f_row10_col28{\n",
       "            background-color:  #f39577;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col23,#T_9749f_row6_col4,#T_9749f_row9_col10,#T_9749f_row10_col19,#T_9749f_row10_col20,#T_9749f_row20_col10,#T_9749f_row23_col5{\n",
       "            background-color:  #c73635;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row5_col24,#T_9749f_row5_col28,#T_9749f_row11_col27,#T_9749f_row11_col41,#T_9749f_row12_col11,#T_9749f_row23_col4,#T_9749f_row27_col11,#T_9749f_row41_col11{\n",
       "            background-color:  #d85646;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col25,#T_9749f_row5_col29,#T_9749f_row10_col9,#T_9749f_row19_col10,#T_9749f_row23_col3{\n",
       "            background-color:  #c83836;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row5_col26,#T_9749f_row5_col30,#T_9749f_row24_col3{\n",
       "            background-color:  #d95847;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col41,#T_9749f_row24_col4{\n",
       "            background-color:  #c12b30;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row5_col44,#T_9749f_row7_col23,#T_9749f_row8_col4,#T_9749f_row11_col35,#T_9749f_row14_col33,#T_9749f_row14_col38,#T_9749f_row22_col35,#T_9749f_row24_col44,#T_9749f_row24_col47,#T_9749f_row32_col6,#T_9749f_row35_col9,#T_9749f_row35_col39,#T_9749f_row39_col2,#T_9749f_row44_col15,#T_9749f_row44_col17,#T_9749f_row45_col35,#T_9749f_row45_col44,#T_9749f_row53_col43,#T_9749f_row58_col43{\n",
       "            background-color:  #92b4fe;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col45,#T_9749f_row5_col48,#T_9749f_row15_col46,#T_9749f_row17_col46,#T_9749f_row20_col50,#T_9749f_row20_col52,#T_9749f_row24_col31,#T_9749f_row28_col43,#T_9749f_row31_col35,#T_9749f_row32_col4,#T_9749f_row32_col27,#T_9749f_row34_col12,#T_9749f_row36_col22,#T_9749f_row40_col45,#T_9749f_row41_col46,#T_9749f_row42_col43,#T_9749f_row44_col38,#T_9749f_row48_col27,#T_9749f_row55_col39,#T_9749f_row55_col40,#T_9749f_row57_col35,#T_9749f_row57_col36,#T_9749f_row59_col45{\n",
       "            background-color:  #8caffe;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col50,#T_9749f_row5_col52,#T_9749f_row8_col23,#T_9749f_row8_col53,#T_9749f_row8_col55,#T_9749f_row12_col49,#T_9749f_row14_col8,#T_9749f_row16_col13,#T_9749f_row18_col13,#T_9749f_row23_col14,#T_9749f_row27_col49,#T_9749f_row27_col51,#T_9749f_row28_col32,#T_9749f_row33_col7,#T_9749f_row33_col21,#T_9749f_row33_col22,#T_9749f_row33_col40,#T_9749f_row33_col44,#T_9749f_row35_col22,#T_9749f_row40_col0,#T_9749f_row40_col35,#T_9749f_row40_col36,#T_9749f_row41_col48,#T_9749f_row41_col49,#T_9749f_row41_col51,#T_9749f_row42_col32,#T_9749f_row43_col13,#T_9749f_row43_col31,#T_9749f_row47_col0,#T_9749f_row47_col40{\n",
       "            background-color:  #799cf8;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row5_col57,#T_9749f_row7_col57,#T_9749f_row9_col57,#T_9749f_row13_col57,#T_9749f_row14_col57,#T_9749f_row15_col1,#T_9749f_row15_col2,#T_9749f_row15_col25,#T_9749f_row15_col26,#T_9749f_row15_col27,#T_9749f_row15_col28,#T_9749f_row15_col29,#T_9749f_row15_col30,#T_9749f_row15_col41,#T_9749f_row15_col42,#T_9749f_row15_col57,#T_9749f_row16_col57,#T_9749f_row17_col1,#T_9749f_row17_col2,#T_9749f_row17_col25,#T_9749f_row17_col26,#T_9749f_row17_col27,#T_9749f_row17_col28,#T_9749f_row17_col29,#T_9749f_row17_col30,#T_9749f_row17_col41,#T_9749f_row17_col42,#T_9749f_row17_col57,#T_9749f_row18_col57,#T_9749f_row21_col57,#T_9749f_row23_col57,#T_9749f_row25_col7,#T_9749f_row26_col8,#T_9749f_row27_col7,#T_9749f_row29_col7,#T_9749f_row30_col8,#T_9749f_row33_col57,#T_9749f_row40_col57,#T_9749f_row41_col7,#T_9749f_row44_col57,#T_9749f_row45_col57,#T_9749f_row49_col57,#T_9749f_row51_col57,#T_9749f_row53_col57,#T_9749f_row54_col57,#T_9749f_row55_col57,#T_9749f_row56_col57,#T_9749f_row58_col57{\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row6_col0,#T_9749f_row7_col9,#T_9749f_row7_col54,#T_9749f_row13_col25,#T_9749f_row13_col29,#T_9749f_row14_col28,#T_9749f_row16_col55,#T_9749f_row18_col55,#T_9749f_row19_col37,#T_9749f_row21_col3,#T_9749f_row21_col24,#T_9749f_row22_col26,#T_9749f_row22_col30,#T_9749f_row22_col34,#T_9749f_row22_col49,#T_9749f_row22_col51,#T_9749f_row33_col26,#T_9749f_row33_col30,#T_9749f_row34_col6,#T_9749f_row35_col49,#T_9749f_row35_col51,#T_9749f_row38_col50,#T_9749f_row38_col52,#T_9749f_row39_col44,#T_9749f_row43_col2,#T_9749f_row43_col26,#T_9749f_row43_col30,#T_9749f_row45_col5,#T_9749f_row46_col6,#T_9749f_row46_col27,#T_9749f_row46_col37,#T_9749f_row53_col28,#T_9749f_row55_col47,#T_9749f_row57_col29{\n",
       "            background-color:  #c4d5f3;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col3,#T_9749f_row20_col4{\n",
       "            background-color:  #de614d;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col10,#T_9749f_row9_col28,#T_9749f_row27_col9,#T_9749f_row38_col34,#T_9749f_row41_col9,#T_9749f_row59_col10{\n",
       "            background-color:  #f7a98b;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col11,#T_9749f_row13_col14,#T_9749f_row14_col13,#T_9749f_row24_col20{\n",
       "            background-color:  #ec8165;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col13,#T_9749f_row8_col6,#T_9749f_row10_col14,#T_9749f_row11_col22,#T_9749f_row11_col33,#T_9749f_row11_col34,#T_9749f_row11_col46,#T_9749f_row12_col50,#T_9749f_row12_col52,#T_9749f_row15_col56,#T_9749f_row17_col56,#T_9749f_row19_col8,#T_9749f_row19_col35,#T_9749f_row23_col22,#T_9749f_row25_col22,#T_9749f_row26_col22,#T_9749f_row27_col50,#T_9749f_row27_col52,#T_9749f_row28_col14,#T_9749f_row29_col22,#T_9749f_row30_col22,#T_9749f_row32_col0,#T_9749f_row41_col22,#T_9749f_row42_col22,#T_9749f_row43_col45,#T_9749f_row44_col13,#T_9749f_row49_col13,#T_9749f_row50_col53,#T_9749f_row51_col13,#T_9749f_row52_col53,#T_9749f_row59_col13{\n",
       "            background-color:  #6f92f3;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col19,#T_9749f_row10_col27,#T_9749f_row10_col41{\n",
       "            background-color:  #f4987a;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col20,#T_9749f_row9_col3,#T_9749f_row9_col11,#T_9749f_row10_col25,#T_9749f_row10_col29{\n",
       "            background-color:  #f18f71;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col25,#T_9749f_row6_col27,#T_9749f_row6_col29,#T_9749f_row6_col41,#T_9749f_row11_col25,#T_9749f_row11_col29,#T_9749f_row12_col6,#T_9749f_row19_col9,#T_9749f_row20_col9,#T_9749f_row23_col24,#T_9749f_row23_col26,#T_9749f_row23_col28,#T_9749f_row23_col30,#T_9749f_row23_col42,#T_9749f_row25_col11,#T_9749f_row29_col11,#T_9749f_row41_col12{\n",
       "            background-color:  #d55042;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col32,#T_9749f_row8_col12,#T_9749f_row15_col7,#T_9749f_row17_col7,#T_9749f_row23_col45,#T_9749f_row26_col45,#T_9749f_row30_col45,#T_9749f_row40_col13,#T_9749f_row44_col33,#T_9749f_row45_col0,#T_9749f_row47_col9,#T_9749f_row48_col5,#T_9749f_row50_col39,#T_9749f_row51_col7,#T_9749f_row52_col39,#T_9749f_row53_col8,#T_9749f_row54_col45,#T_9749f_row56_col33,#T_9749f_row56_col36,#T_9749f_row58_col46,#T_9749f_row59_col56{\n",
       "            background-color:  #89acfd;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col45,#T_9749f_row8_col21,#T_9749f_row9_col22,#T_9749f_row12_col47,#T_9749f_row13_col53,#T_9749f_row14_col36,#T_9749f_row20_col45,#T_9749f_row24_col43,#T_9749f_row25_col14,#T_9749f_row25_col45,#T_9749f_row29_col14,#T_9749f_row29_col45,#T_9749f_row32_col26,#T_9749f_row32_col30,#T_9749f_row48_col26,#T_9749f_row48_col30,#T_9749f_row49_col10,#T_9749f_row51_col10,#T_9749f_row53_col14,#T_9749f_row55_col0,#T_9749f_row59_col22{\n",
       "            background-color:  #82a6fb;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col48,#T_9749f_row8_col0,#T_9749f_row8_col22,#T_9749f_row8_col39,#T_9749f_row9_col55,#T_9749f_row9_col56,#T_9749f_row13_col37,#T_9749f_row14_col53,#T_9749f_row16_col46,#T_9749f_row18_col46,#T_9749f_row19_col50,#T_9749f_row19_col52,#T_9749f_row34_col0,#T_9749f_row34_col22,#T_9749f_row36_col54,#T_9749f_row40_col2,#T_9749f_row44_col55,#T_9749f_row45_col43,#T_9749f_row46_col43,#T_9749f_row47_col54,#T_9749f_row48_col1,#T_9749f_row58_col8{\n",
       "            background-color:  #8fb1fe;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row6_col56,#T_9749f_row7_col27,#T_9749f_row13_col44,#T_9749f_row15_col37,#T_9749f_row15_col39,#T_9749f_row17_col37,#T_9749f_row17_col39,#T_9749f_row27_col44,#T_9749f_row31_col36,#T_9749f_row39_col46,#T_9749f_row40_col46,#T_9749f_row41_col34,#T_9749f_row46_col35,#T_9749f_row48_col13,#T_9749f_row49_col20,#T_9749f_row50_col19,#T_9749f_row50_col20,#T_9749f_row52_col20,#T_9749f_row56_col1{\n",
       "            background-color:  #9fbfff;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row7_col0,#T_9749f_row7_col5,#T_9749f_row24_col45,#T_9749f_row25_col46,#T_9749f_row26_col43,#T_9749f_row27_col46,#T_9749f_row28_col47,#T_9749f_row29_col46,#T_9749f_row30_col43,#T_9749f_row31_col11,#T_9749f_row32_col35,#T_9749f_row33_col53,#T_9749f_row42_col47,#T_9749f_row43_col34,#T_9749f_row46_col7,#T_9749f_row48_col4,#T_9749f_row58_col35,#T_9749f_row59_col1,#T_9749f_row59_col31{\n",
       "            background-color:  #8db0fe;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row7_col1,#T_9749f_row13_col38,#T_9749f_row22_col48,#T_9749f_row28_col33,#T_9749f_row28_col39,#T_9749f_row31_col19,#T_9749f_row39_col6,#T_9749f_row42_col33,#T_9749f_row44_col23,#T_9749f_row45_col2,#T_9749f_row45_col36,#T_9749f_row54_col49,#T_9749f_row54_col51,#T_9749f_row56_col2,#T_9749f_row57_col34,#T_9749f_row57_col39,#T_9749f_row58_col37{\n",
       "            background-color:  #afcafc;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row7_col3,#T_9749f_row7_col46,#T_9749f_row10_col37,#T_9749f_row14_col48,#T_9749f_row16_col59,#T_9749f_row18_col59,#T_9749f_row22_col8,#T_9749f_row25_col44,#T_9749f_row29_col44,#T_9749f_row31_col8,#T_9749f_row31_col12,#T_9749f_row31_col45,#T_9749f_row56_col54,#T_9749f_row57_col31,#T_9749f_row58_col31{\n",
       "            background-color:  #a7c5fe;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row7_col12,#T_9749f_row7_col31,#T_9749f_row13_col54,#T_9749f_row21_col31,#T_9749f_row22_col40,#T_9749f_row31_col23,#T_9749f_row31_col42,#T_9749f_row32_col59,#T_9749f_row33_col1,#T_9749f_row34_col4,#T_9749f_row37_col8,#T_9749f_row39_col56,#T_9749f_row43_col48,#T_9749f_row45_col11,#T_9749f_row47_col4,#T_9749f_row47_col5,#T_9749f_row47_col45,#T_9749f_row48_col8,#T_9749f_row53_col39,#T_9749f_row54_col43,#T_9749f_row55_col19,#T_9749f_row57_col47{\n",
       "            background-color:  #abc8fd;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row7_col33,#T_9749f_row7_col48,#T_9749f_row8_col46,#T_9749f_row9_col0,#T_9749f_row11_col44,#T_9749f_row12_col37,#T_9749f_row13_col5,#T_9749f_row21_col44,#T_9749f_row22_col6,#T_9749f_row25_col36,#T_9749f_row29_col36,#T_9749f_row30_col39,#T_9749f_row33_col45,#T_9749f_row34_col19,#T_9749f_row34_col23,#T_9749f_row36_col32,#T_9749f_row38_col11,#T_9749f_row46_col1,#T_9749f_row46_col5,#T_9749f_row54_col5,#T_9749f_row57_col54,#T_9749f_row57_col55,#T_9749f_row58_col54,#T_9749f_row58_col55{\n",
       "            background-color:  #b9d0f9;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row7_col38,#T_9749f_row8_col19,#T_9749f_row13_col55,#T_9749f_row15_col33,#T_9749f_row17_col33,#T_9749f_row21_col42,#T_9749f_row22_col50,#T_9749f_row22_col52,#T_9749f_row35_col19,#T_9749f_row44_col25,#T_9749f_row44_col29,#T_9749f_row45_col54,#T_9749f_row46_col10,#T_9749f_row49_col47,#T_9749f_row51_col47,#T_9749f_row56_col5,#T_9749f_row57_col3{\n",
       "            background-color:  #c9d7f0;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row8_col15,#T_9749f_row8_col17,#T_9749f_row23_col1,#T_9749f_row38_col20,#T_9749f_row46_col34,#T_9749f_row55_col12,#T_9749f_row55_col24,#T_9749f_row55_col28,#T_9749f_row55_col42{\n",
       "            background-color:  #edd2c3;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row8_col16,#T_9749f_row8_col18,#T_9749f_row9_col23,#T_9749f_row19_col44{\n",
       "            background-color:  #efcebd;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row8_col31,#T_9749f_row8_col34,#T_9749f_row12_col39,#T_9749f_row13_col12,#T_9749f_row13_col28,#T_9749f_row24_col33,#T_9749f_row38_col36,#T_9749f_row39_col24,#T_9749f_row43_col25,#T_9749f_row43_col29,#T_9749f_row46_col8,#T_9749f_row46_col36,#T_9749f_row53_col51,#T_9749f_row54_col44,#T_9749f_row55_col31,#T_9749f_row55_col49,#T_9749f_row55_col51,#T_9749f_row57_col38,#T_9749f_row57_col40,#T_9749f_row58_col38,#T_9749f_row58_col40{\n",
       "            background-color:  #bcd2f7;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row8_col43,#T_9749f_row9_col46,#T_9749f_row13_col0,#T_9749f_row14_col37,#T_9749f_row15_col53,#T_9749f_row16_col53,#T_9749f_row17_col53,#T_9749f_row18_col53,#T_9749f_row20_col34,#T_9749f_row26_col47,#T_9749f_row30_col47,#T_9749f_row35_col53,#T_9749f_row38_col43,#T_9749f_row49_col46,#T_9749f_row51_col46,#T_9749f_row59_col48{\n",
       "            background-color:  #81a4fb;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row8_col54,#T_9749f_row13_col9,#T_9749f_row14_col3,#T_9749f_row22_col2,#T_9749f_row33_col27,#T_9749f_row33_col41,#T_9749f_row37_col16,#T_9749f_row37_col18,#T_9749f_row38_col5,#T_9749f_row44_col1,#T_9749f_row44_col54,#T_9749f_row46_col32,#T_9749f_row46_col42,#T_9749f_row57_col50,#T_9749f_row57_col52,#T_9749f_row58_col50,#T_9749f_row58_col52{\n",
       "            background-color:  #cfdaea;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row9_col15,#T_9749f_row9_col17,#T_9749f_row14_col22,#T_9749f_row32_col21,#T_9749f_row36_col13,#T_9749f_row48_col56,#T_9749f_row49_col24{\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row9_col16,#T_9749f_row9_col18,#T_9749f_row40_col8,#T_9749f_row44_col7{\n",
       "            background-color:  #536edd;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row9_col21,#T_9749f_row19_col14,#T_9749f_row20_col22,#T_9749f_row26_col32,#T_9749f_row28_col16,#T_9749f_row28_col18,#T_9749f_row30_col32,#T_9749f_row32_col44,#T_9749f_row36_col14,#T_9749f_row39_col38,#T_9749f_row42_col16,#T_9749f_row42_col18,#T_9749f_row47_col43,#T_9749f_row48_col39{\n",
       "            background-color:  #6282ea;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row9_col25,#T_9749f_row9_col29,#T_9749f_row36_col34{\n",
       "            background-color:  #f7a688;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row9_col31,#T_9749f_row11_col8{\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row9_col32,#T_9749f_row35_col7,#T_9749f_row39_col7,#T_9749f_row51_col24{\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row9_col47,#T_9749f_row21_col13{\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row10_col2,#T_9749f_row10_col40,#T_9749f_row11_col2,#T_9749f_row12_col1,#T_9749f_row25_col1,#T_9749f_row27_col1,#T_9749f_row36_col16,#T_9749f_row36_col18,#T_9749f_row41_col1,#T_9749f_row44_col49,#T_9749f_row44_col51,#T_9749f_row54_col3{\n",
       "            background-color:  #edd1c2;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row10_col3,#T_9749f_row11_col10,#T_9749f_row11_col20,#T_9749f_row25_col19{\n",
       "            background-color:  #e97a5f;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row10_col7,#T_9749f_row11_col21,#T_9749f_row11_col45,#T_9749f_row19_col32,#T_9749f_row20_col32,#T_9749f_row37_col56,#T_9749f_row43_col7,#T_9749f_row49_col53,#T_9749f_row50_col25,#T_9749f_row50_col29,#T_9749f_row52_col25,#T_9749f_row52_col29{\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row10_col11,#T_9749f_row19_col25,#T_9749f_row19_col29,#T_9749f_row20_col27,#T_9749f_row20_col41,#T_9749f_row25_col10,#T_9749f_row29_col10{\n",
       "            background-color:  #ee8468;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row10_col12,#T_9749f_row12_col19,#T_9749f_row20_col12,#T_9749f_row23_col11,#T_9749f_row28_col11,#T_9749f_row42_col11{\n",
       "            background-color:  #e46e56;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row10_col23,#T_9749f_row27_col59,#T_9749f_row41_col59,#T_9749f_row48_col16,#T_9749f_row48_col18,#T_9749f_row54_col9,#T_9749f_row59_col4{\n",
       "            background-color:  #f7b497;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row10_col42,#T_9749f_row21_col22,#T_9749f_row40_col39{\n",
       "            background-color:  #f39475;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row10_col43,#T_9749f_row14_col10,#T_9749f_row23_col36,#T_9749f_row33_col49,#T_9749f_row33_col51,#T_9749f_row36_col59,#T_9749f_row37_col3,#T_9749f_row38_col23,#T_9749f_row43_col39,#T_9749f_row44_col3,#T_9749f_row46_col54,#T_9749f_row53_col10,#T_9749f_row54_col2,#T_9749f_row55_col59,#T_9749f_row56_col39,#T_9749f_row57_col10,#T_9749f_row58_col10{\n",
       "            background-color:  #d5dbe5;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row10_col44,#T_9749f_row23_col2,#T_9749f_row59_col23{\n",
       "            background-color:  #f2c9b4;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row10_col48,#T_9749f_row15_col21,#T_9749f_row16_col21,#T_9749f_row17_col21,#T_9749f_row18_col21,#T_9749f_row33_col14,#T_9749f_row40_col7,#T_9749f_row50_col23,#T_9749f_row52_col23{\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row11_col3,#T_9749f_row25_col28,#T_9749f_row25_col42,#T_9749f_row26_col27,#T_9749f_row27_col4,#T_9749f_row27_col26,#T_9749f_row27_col28,#T_9749f_row27_col30,#T_9749f_row27_col42,#T_9749f_row28_col25,#T_9749f_row28_col27,#T_9749f_row28_col29,#T_9749f_row29_col28,#T_9749f_row30_col27,#T_9749f_row41_col4,#T_9749f_row41_col26,#T_9749f_row41_col28,#T_9749f_row41_col30,#T_9749f_row41_col42,#T_9749f_row42_col25,#T_9749f_row42_col27,#T_9749f_row42_col29{\n",
       "            background-color:  #cd423b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row11_col5,#T_9749f_row20_col26,#T_9749f_row20_col30,#T_9749f_row26_col19,#T_9749f_row27_col20,#T_9749f_row30_col19{\n",
       "            background-color:  #e8765c;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row11_col6,#T_9749f_row19_col28,#T_9749f_row19_col42{\n",
       "            background-color:  #ee8669;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row11_col9,#T_9749f_row12_col9,#T_9749f_row20_col11{\n",
       "            background-color:  #ef886b;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row11_col19,#T_9749f_row19_col26,#T_9749f_row19_col30,#T_9749f_row27_col19,#T_9749f_row41_col19{\n",
       "            background-color:  #ec7f63;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row11_col24,#T_9749f_row20_col25,#T_9749f_row20_col29,#T_9749f_row24_col11{\n",
       "            background-color:  #eb7d62;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row11_col39,#T_9749f_row23_col37,#T_9749f_row28_col54,#T_9749f_row40_col26,#T_9749f_row40_col30,#T_9749f_row42_col54,#T_9749f_row44_col40,#T_9749f_row48_col37,#T_9749f_row57_col19,#T_9749f_row58_col19{\n",
       "            background-color:  #d9dce1;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row12_col2,#T_9749f_row15_col48,#T_9749f_row17_col48,#T_9749f_row33_col31,#T_9749f_row37_col31,#T_9749f_row40_col9,#T_9749f_row47_col16,#T_9749f_row47_col18{\n",
       "            background-color:  #f2cab5;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row12_col26,#T_9749f_row12_col30,#T_9749f_row26_col12,#T_9749f_row27_col5,#T_9749f_row30_col12{\n",
       "            background-color:  #c43032;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row12_col27,#T_9749f_row12_col41,#T_9749f_row24_col23,#T_9749f_row27_col6,#T_9749f_row41_col6{\n",
       "            background-color:  #d65244;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row12_col28,#T_9749f_row12_col42,#T_9749f_row28_col12,#T_9749f_row42_col12{\n",
       "            background-color:  #c53334;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row12_col32,#T_9749f_row25_col21,#T_9749f_row26_col13,#T_9749f_row29_col21,#T_9749f_row30_col13,#T_9749f_row36_col43,#T_9749f_row54_col14,#T_9749f_row54_col36{\n",
       "            background-color:  #5e7de7;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row12_col40,#T_9749f_row13_col15,#T_9749f_row13_col16,#T_9749f_row13_col17,#T_9749f_row13_col18,#T_9749f_row33_col32,#T_9749f_row37_col4,#T_9749f_row37_col28,#T_9749f_row37_col42,#T_9749f_row38_col6,#T_9749f_row45_col33,#T_9749f_row48_col33,#T_9749f_row55_col11,#T_9749f_row56_col3,#T_9749f_row56_col10,#T_9749f_row56_col19,#T_9749f_row56_col59{\n",
       "            background-color:  #dedcdb;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row12_col54,#T_9749f_row19_col43,#T_9749f_row22_col19,#T_9749f_row26_col38,#T_9749f_row27_col38,#T_9749f_row30_col38,#T_9749f_row32_col55,#T_9749f_row38_col3,#T_9749f_row39_col12,#T_9749f_row43_col11,#T_9749f_row43_col12,#T_9749f_row45_col26,#T_9749f_row45_col30,#T_9749f_row45_col47,#T_9749f_row54_col37,#T_9749f_row56_col6,#T_9749f_row56_col16,#T_9749f_row56_col18,#T_9749f_row59_col54{\n",
       "            background-color:  #d4dbe6;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row13_col21,#T_9749f_row33_col39,#T_9749f_row39_col33,#T_9749f_row52_col6,#T_9749f_row55_col7{\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row15_col16,#T_9749f_row15_col18,#T_9749f_row16_col15,#T_9749f_row16_col17,#T_9749f_row17_col16,#T_9749f_row17_col18,#T_9749f_row18_col15,#T_9749f_row18_col17,#T_9749f_row19_col20,#T_9749f_row20_col19,#T_9749f_row26_col28,#T_9749f_row26_col42,#T_9749f_row28_col26,#T_9749f_row28_col30,#T_9749f_row30_col28,#T_9749f_row30_col42,#T_9749f_row31_col47,#T_9749f_row32_col48,#T_9749f_row42_col26,#T_9749f_row42_col30,#T_9749f_row47_col31,#T_9749f_row48_col32{\n",
       "            background-color:  #b50927;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row15_col47,#T_9749f_row16_col34,#T_9749f_row17_col47,#T_9749f_row18_col34,#T_9749f_row21_col10,#T_9749f_row22_col59,#T_9749f_row25_col55,#T_9749f_row29_col55,#T_9749f_row36_col4,#T_9749f_row37_col41,#T_9749f_row37_col54,#T_9749f_row46_col59,#T_9749f_row48_col55,#T_9749f_row55_col3,#T_9749f_row56_col28,#T_9749f_row57_col0,#T_9749f_row57_col15,#T_9749f_row57_col16,#T_9749f_row57_col17,#T_9749f_row57_col18,#T_9749f_row57_col20,#T_9749f_row58_col15,#T_9749f_row58_col16,#T_9749f_row58_col17,#T_9749f_row58_col18,#T_9749f_row58_col20{\n",
       "            background-color:  #dadce0;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row15_col54,#T_9749f_row17_col54,#T_9749f_row20_col21,#T_9749f_row48_col21,#T_9749f_row50_col27,#T_9749f_row50_col41,#T_9749f_row51_col53,#T_9749f_row52_col27,#T_9749f_row52_col41,#T_9749f_row54_col22{\n",
       "            background-color:  #5875e1;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row15_col55,#T_9749f_row17_col55,#T_9749f_row21_col19,#T_9749f_row25_col35,#T_9749f_row27_col35,#T_9749f_row29_col35,#T_9749f_row31_col55,#T_9749f_row33_col55,#T_9749f_row34_col35,#T_9749f_row36_col37,#T_9749f_row38_col1,#T_9749f_row38_col16,#T_9749f_row38_col18,#T_9749f_row41_col35,#T_9749f_row46_col4,#T_9749f_row50_col31,#T_9749f_row52_col31,#T_9749f_row53_col4,#T_9749f_row56_col50,#T_9749f_row56_col52{\n",
       "            background-color:  #cbd8ee;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row16_col31,#T_9749f_row18_col31,#T_9749f_row22_col10,#T_9749f_row23_col33,#T_9749f_row32_col37,#T_9749f_row34_col46,#T_9749f_row35_col28,#T_9749f_row35_col42,#T_9749f_row35_col59,#T_9749f_row36_col38,#T_9749f_row37_col27,#T_9749f_row37_col30,#T_9749f_row38_col26,#T_9749f_row38_col30,#T_9749f_row40_col25,#T_9749f_row40_col29,#T_9749f_row42_col38,#T_9749f_row44_col12,#T_9749f_row45_col15,#T_9749f_row45_col17,#T_9749f_row46_col15,#T_9749f_row46_col17,#T_9749f_row53_col15,#T_9749f_row53_col16,#T_9749f_row53_col17,#T_9749f_row53_col18,#T_9749f_row54_col41,#T_9749f_row56_col12,#T_9749f_row56_col13,#T_9749f_row56_col25,#T_9749f_row56_col29,#T_9749f_row56_col42{\n",
       "            background-color:  #dbdcde;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row19_col11,#T_9749f_row19_col27,#T_9749f_row19_col41,#T_9749f_row27_col10,#T_9749f_row39_col40,#T_9749f_row54_col19{\n",
       "            background-color:  #f18d6f;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row19_col12,#T_9749f_row29_col19,#T_9749f_row41_col20{\n",
       "            background-color:  #e9785d;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row20_col6,#T_9749f_row34_col38,#T_9749f_row44_col43{\n",
       "            background-color:  #f6a385;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row20_col23,#T_9749f_row24_col10,#T_9749f_row25_col9,#T_9749f_row29_col9{\n",
       "            background-color:  #f59f80;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row20_col24,#T_9749f_row54_col20{\n",
       "            background-color:  #f29072;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row20_col28,#T_9749f_row20_col42,#T_9749f_row28_col19,#T_9749f_row42_col19{\n",
       "            background-color:  #ea7b60;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row22_col14,#T_9749f_row31_col56,#T_9749f_row38_col39,#T_9749f_row49_col23,#T_9749f_row51_col23{\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row22_col21{\n",
       "            background-color:  #f49a7b;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row23_col19{\n",
       "            background-color:  #f29274;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row24_col28,#T_9749f_row24_col42,#T_9749f_row25_col27,#T_9749f_row25_col41,#T_9749f_row27_col25,#T_9749f_row27_col29,#T_9749f_row28_col24,#T_9749f_row29_col27,#T_9749f_row29_col41,#T_9749f_row41_col25,#T_9749f_row41_col29,#T_9749f_row42_col24{\n",
       "            background-color:  #b70d28;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row25_col59,#T_9749f_row29_col59,#T_9749f_row32_col47,#T_9749f_row42_col59,#T_9749f_row45_col46,#T_9749f_row48_col15,#T_9749f_row48_col17,#T_9749f_row48_col47{\n",
       "            background-color:  #f7b194;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row26_col6,#T_9749f_row30_col6{\n",
       "            background-color:  #c0282f;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row26_col7,#T_9749f_row30_col7,#T_9749f_row33_col56,#T_9749f_row49_col6,#T_9749f_row51_col6{\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row26_col10,#T_9749f_row30_col10{\n",
       "            background-color:  #ed8366;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row26_col50,#T_9749f_row29_col16,#T_9749f_row29_col18,#T_9749f_row30_col50,#T_9749f_row30_col52,#T_9749f_row31_col44,#T_9749f_row32_col22,#T_9749f_row39_col22,#T_9749f_row42_col13,#T_9749f_row42_col21,#T_9749f_row43_col21,#T_9749f_row46_col56,#T_9749f_row50_col3,#T_9749f_row50_col11,#T_9749f_row52_col3,#T_9749f_row52_col11,#T_9749f_row52_col12{\n",
       "            background-color:  #6485ec;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row26_col55,#T_9749f_row27_col55,#T_9749f_row30_col55,#T_9749f_row33_col23,#T_9749f_row35_col34,#T_9749f_row35_col37,#T_9749f_row36_col55,#T_9749f_row41_col55,#T_9749f_row46_col38,#T_9749f_row50_col32,#T_9749f_row50_col48,#T_9749f_row52_col32,#T_9749f_row52_col48,#T_9749f_row53_col59{\n",
       "            background-color:  #e0dbd8;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row26_col59,#T_9749f_row30_col59,#T_9749f_row31_col32,#T_9749f_row31_col48,#T_9749f_row44_col19,#T_9749f_row44_col20,#T_9749f_row47_col32{\n",
       "            background-color:  #f7af91;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row29_col1{\n",
       "            background-color:  #eed0c0;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row32_col40,#T_9749f_row34_col40,#T_9749f_row35_col43,#T_9749f_row37_col13,#T_9749f_row38_col21,#T_9749f_row47_col56,#T_9749f_row49_col5,#T_9749f_row50_col5,#T_9749f_row51_col5,#T_9749f_row52_col5{\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row34_col48,#T_9749f_row44_col10,#T_9749f_row54_col10{\n",
       "            background-color:  #f7ac8e;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row36_col5,#T_9749f_row54_col25,#T_9749f_row54_col29,#T_9749f_row55_col23{\n",
       "            background-color:  #e3d9d3;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row37_col38{\n",
       "            background-color:  #f39778;\n",
       "            color:  #000000;\n",
       "        }#T_9749f_row49_col50,#T_9749f_row49_col52,#T_9749f_row50_col49,#T_9749f_row50_col51,#T_9749f_row51_col50,#T_9749f_row51_col52,#T_9749f_row52_col49,#T_9749f_row52_col51{\n",
       "            background-color:  #bd1f2d;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_9749f_row50_col59,#T_9749f_row52_col59{\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_9749f_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >reading</th>        <th class=\"col_heading level0 col1\" >day_avg_reading</th>        <th class=\"col_heading level0 col2\" >week_avg_reading</th>        <th class=\"col_heading level0 col3\" >day_avg_maxtemp</th>        <th class=\"col_heading level0 col4\" >week_avg_maxtemp</th>        <th class=\"col_heading level0 col5\" >day_avg_mintemp</th>        <th class=\"col_heading level0 col6\" >week_avg_mintemp</th>        <th class=\"col_heading level0 col7\" >day_avg_snow</th>        <th class=\"col_heading level0 col8\" >week_avg_snow</th>        <th class=\"col_heading level0 col9\" >day_avg_sunhour</th>        <th class=\"col_heading level0 col10\" >week_avg_sunhour</th>        <th class=\"col_heading level0 col11\" >day_avg_uvindex</th>        <th class=\"col_heading level0 col12\" >week_avg_uvindex</th>        <th class=\"col_heading level0 col13\" >day_avg_moonillumination</th>        <th class=\"col_heading level0 col14\" >week_avg_moonillumination</th>        <th class=\"col_heading level0 col15\" >day_avg_sunrise_hr</th>        <th class=\"col_heading level0 col16\" >week_avg_sunrise_hr</th>        <th class=\"col_heading level0 col17\" >day_avg_sunrise_min</th>        <th class=\"col_heading level0 col18\" >week_avg_sunrise_min</th>        <th class=\"col_heading level0 col19\" >day_avg_sunset_hr</th>        <th class=\"col_heading level0 col20\" >week_avg_sunset_hr</th>        <th class=\"col_heading level0 col21\" >day_avg_sunset_min</th>        <th class=\"col_heading level0 col22\" >week_avg_sunset_min</th>        <th class=\"col_heading level0 col23\" >day_avg_dewpoint</th>        <th class=\"col_heading level0 col24\" >week_avg_dewpoint</th>        <th class=\"col_heading level0 col25\" >day_avg_feelslike</th>        <th class=\"col_heading level0 col26\" >week_avg_feelslike</th>        <th class=\"col_heading level0 col27\" >day_avg_heatindex</th>        <th class=\"col_heading level0 col28\" >week_avg_heatindex</th>        <th class=\"col_heading level0 col29\" >day_avg_windchill</th>        <th class=\"col_heading level0 col30\" >week_avg_windchill</th>        <th class=\"col_heading level0 col31\" >day_avg_windgust</th>        <th class=\"col_heading level0 col32\" >week_avg_windgust</th>        <th class=\"col_heading level0 col33\" >day_avg_cloud</th>        <th class=\"col_heading level0 col34\" >week_avg_cloud</th>        <th class=\"col_heading level0 col35\" >day_avg_humidity</th>        <th class=\"col_heading level0 col36\" >week_avg_humidity</th>        <th class=\"col_heading level0 col37\" >day_avg_precip</th>        <th class=\"col_heading level0 col38\" >week_avg_precip</th>        <th class=\"col_heading level0 col39\" >day_avg_pressure</th>        <th class=\"col_heading level0 col40\" >week_avg_pressure</th>        <th class=\"col_heading level0 col41\" >day_avg_temp</th>        <th class=\"col_heading level0 col42\" >week_avg_temp</th>        <th class=\"col_heading level0 col43\" >day_avg_visibility</th>        <th class=\"col_heading level0 col44\" >week_avg_visibility</th>        <th class=\"col_heading level0 col45\" >day_avg_winddir</th>        <th class=\"col_heading level0 col46\" >week_avg_winddir</th>        <th class=\"col_heading level0 col47\" >day_avg_windspeed</th>        <th class=\"col_heading level0 col48\" >week_avg_windspeed</th>        <th class=\"col_heading level0 col49\" >day_avg_as_client</th>        <th class=\"col_heading level0 col50\" >week_avg_as_client</th>        <th class=\"col_heading level0 col51\" >day_avg_auth_client</th>        <th class=\"col_heading level0 col52\" >week_avg_auth_client</th>        <th class=\"col_heading level0 col53\" >Day_type_as_int</th>        <th class=\"col_heading level0 col54\" >Year</th>        <th class=\"col_heading level0 col55\" >Month</th>        <th class=\"col_heading level0 col56\" >Day</th>        <th class=\"col_heading level0 col57\" >hour</th>        <th class=\"col_heading level0 col58\" >minute</th>        <th class=\"col_heading level0 col59\" >Term_as_int</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_9749f_level0_row0\" class=\"row_heading level0 row0\" >reading</th>\n",
       "                        <td id=\"T_9749f_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row0_col1\" class=\"data row0 col1\" >0.567473</td>\n",
       "                        <td id=\"T_9749f_row0_col2\" class=\"data row0 col2\" >0.537752</td>\n",
       "                        <td id=\"T_9749f_row0_col3\" class=\"data row0 col3\" >0.204917</td>\n",
       "                        <td id=\"T_9749f_row0_col4\" class=\"data row0 col4\" >0.223379</td>\n",
       "                        <td id=\"T_9749f_row0_col5\" class=\"data row0 col5\" >0.226490</td>\n",
       "                        <td id=\"T_9749f_row0_col6\" class=\"data row0 col6\" >0.234687</td>\n",
       "                        <td id=\"T_9749f_row0_col7\" class=\"data row0 col7\" >0.023012</td>\n",
       "                        <td id=\"T_9749f_row0_col8\" class=\"data row0 col8\" >0.028832</td>\n",
       "                        <td id=\"T_9749f_row0_col9\" class=\"data row0 col9\" >0.188191</td>\n",
       "                        <td id=\"T_9749f_row0_col10\" class=\"data row0 col10\" >0.205086</td>\n",
       "                        <td id=\"T_9749f_row0_col11\" class=\"data row0 col11\" >0.193354</td>\n",
       "                        <td id=\"T_9749f_row0_col12\" class=\"data row0 col12\" >0.218208</td>\n",
       "                        <td id=\"T_9749f_row0_col13\" class=\"data row0 col13\" >-0.021305</td>\n",
       "                        <td id=\"T_9749f_row0_col14\" class=\"data row0 col14\" >-0.040266</td>\n",
       "                        <td id=\"T_9749f_row0_col15\" class=\"data row0 col15\" >-0.293742</td>\n",
       "                        <td id=\"T_9749f_row0_col16\" class=\"data row0 col16\" >-0.306035</td>\n",
       "                        <td id=\"T_9749f_row0_col17\" class=\"data row0 col17\" >-0.293742</td>\n",
       "                        <td id=\"T_9749f_row0_col18\" class=\"data row0 col18\" >-0.306035</td>\n",
       "                        <td id=\"T_9749f_row0_col19\" class=\"data row0 col19\" >0.280387</td>\n",
       "                        <td id=\"T_9749f_row0_col20\" class=\"data row0 col20\" >0.289345</td>\n",
       "                        <td id=\"T_9749f_row0_col21\" class=\"data row0 col21\" >0.064767</td>\n",
       "                        <td id=\"T_9749f_row0_col22\" class=\"data row0 col22\" >0.062920</td>\n",
       "                        <td id=\"T_9749f_row0_col23\" class=\"data row0 col23\" >0.206195</td>\n",
       "                        <td id=\"T_9749f_row0_col24\" class=\"data row0 col24\" >0.241993</td>\n",
       "                        <td id=\"T_9749f_row0_col25\" class=\"data row0 col25\" >0.212822</td>\n",
       "                        <td id=\"T_9749f_row0_col26\" class=\"data row0 col26\" >0.239393</td>\n",
       "                        <td id=\"T_9749f_row0_col27\" class=\"data row0 col27\" >0.210423</td>\n",
       "                        <td id=\"T_9749f_row0_col28\" class=\"data row0 col28\" >0.238363</td>\n",
       "                        <td id=\"T_9749f_row0_col29\" class=\"data row0 col29\" >0.213159</td>\n",
       "                        <td id=\"T_9749f_row0_col30\" class=\"data row0 col30\" >0.239797</td>\n",
       "                        <td id=\"T_9749f_row0_col31\" class=\"data row0 col31\" >-0.061662</td>\n",
       "                        <td id=\"T_9749f_row0_col32\" class=\"data row0 col32\" >-0.088989</td>\n",
       "                        <td id=\"T_9749f_row0_col33\" class=\"data row0 col33\" >-0.001699</td>\n",
       "                        <td id=\"T_9749f_row0_col34\" class=\"data row0 col34\" >0.028084</td>\n",
       "                        <td id=\"T_9749f_row0_col35\" class=\"data row0 col35\" >0.049246</td>\n",
       "                        <td id=\"T_9749f_row0_col36\" class=\"data row0 col36\" >0.063068</td>\n",
       "                        <td id=\"T_9749f_row0_col37\" class=\"data row0 col37\" >0.053676</td>\n",
       "                        <td id=\"T_9749f_row0_col38\" class=\"data row0 col38\" >0.085062</td>\n",
       "                        <td id=\"T_9749f_row0_col39\" class=\"data row0 col39\" >-0.043682</td>\n",
       "                        <td id=\"T_9749f_row0_col40\" class=\"data row0 col40\" >-0.053315</td>\n",
       "                        <td id=\"T_9749f_row0_col41\" class=\"data row0 col41\" >0.210208</td>\n",
       "                        <td id=\"T_9749f_row0_col42\" class=\"data row0 col42\" >0.236778</td>\n",
       "                        <td id=\"T_9749f_row0_col43\" class=\"data row0 col43\" >0.075453</td>\n",
       "                        <td id=\"T_9749f_row0_col44\" class=\"data row0 col44\" >0.109228</td>\n",
       "                        <td id=\"T_9749f_row0_col45\" class=\"data row0 col45\" >0.007677</td>\n",
       "                        <td id=\"T_9749f_row0_col46\" class=\"data row0 col46\" >0.045745</td>\n",
       "                        <td id=\"T_9749f_row0_col47\" class=\"data row0 col47\" >-0.051985</td>\n",
       "                        <td id=\"T_9749f_row0_col48\" class=\"data row0 col48\" >-0.076518</td>\n",
       "                        <td id=\"T_9749f_row0_col49\" class=\"data row0 col49\" >-0.001067</td>\n",
       "                        <td id=\"T_9749f_row0_col50\" class=\"data row0 col50\" >-0.010859</td>\n",
       "                        <td id=\"T_9749f_row0_col51\" class=\"data row0 col51\" >-0.002215</td>\n",
       "                        <td id=\"T_9749f_row0_col52\" class=\"data row0 col52\" >-0.011734</td>\n",
       "                        <td id=\"T_9749f_row0_col53\" class=\"data row0 col53\" >-0.189202</td>\n",
       "                        <td id=\"T_9749f_row0_col54\" class=\"data row0 col54\" >0.131888</td>\n",
       "                        <td id=\"T_9749f_row0_col55\" class=\"data row0 col55\" >-0.019445</td>\n",
       "                        <td id=\"T_9749f_row0_col56\" class=\"data row0 col56\" >-0.033681</td>\n",
       "                        <td id=\"T_9749f_row0_col57\" class=\"data row0 col57\" >0.335348</td>\n",
       "                        <td id=\"T_9749f_row0_col58\" class=\"data row0 col58\" >-0.006055</td>\n",
       "                        <td id=\"T_9749f_row0_col59\" class=\"data row0 col59\" >-0.081390</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row1\" class=\"row_heading level0 row1\" >day_avg_reading</th>\n",
       "                        <td id=\"T_9749f_row1_col0\" class=\"data row1 col0\" >0.567473</td>\n",
       "                        <td id=\"T_9749f_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row1_col2\" class=\"data row1 col2\" >0.869261</td>\n",
       "                        <td id=\"T_9749f_row1_col3\" class=\"data row1 col3\" >0.338584</td>\n",
       "                        <td id=\"T_9749f_row1_col4\" class=\"data row1 col4\" >0.367994</td>\n",
       "                        <td id=\"T_9749f_row1_col5\" class=\"data row1 col5\" >0.379066</td>\n",
       "                        <td id=\"T_9749f_row1_col6\" class=\"data row1 col6\" >0.391613</td>\n",
       "                        <td id=\"T_9749f_row1_col7\" class=\"data row1 col7\" >0.024919</td>\n",
       "                        <td id=\"T_9749f_row1_col8\" class=\"data row1 col8\" >0.049471</td>\n",
       "                        <td id=\"T_9749f_row1_col9\" class=\"data row1 col9\" >0.309826</td>\n",
       "                        <td id=\"T_9749f_row1_col10\" class=\"data row1 col10\" >0.336090</td>\n",
       "                        <td id=\"T_9749f_row1_col11\" class=\"data row1 col11\" >0.329526</td>\n",
       "                        <td id=\"T_9749f_row1_col12\" class=\"data row1 col12\" >0.360649</td>\n",
       "                        <td id=\"T_9749f_row1_col13\" class=\"data row1 col13\" >-0.032049</td>\n",
       "                        <td id=\"T_9749f_row1_col14\" class=\"data row1 col14\" >-0.063445</td>\n",
       "                        <td id=\"T_9749f_row1_col15\" class=\"data row1 col15\" >-0.480405</td>\n",
       "                        <td id=\"T_9749f_row1_col16\" class=\"data row1 col16\" >-0.501050</td>\n",
       "                        <td id=\"T_9749f_row1_col17\" class=\"data row1 col17\" >-0.480405</td>\n",
       "                        <td id=\"T_9749f_row1_col18\" class=\"data row1 col18\" >-0.501050</td>\n",
       "                        <td id=\"T_9749f_row1_col19\" class=\"data row1 col19\" >0.457473</td>\n",
       "                        <td id=\"T_9749f_row1_col20\" class=\"data row1 col20\" >0.474407</td>\n",
       "                        <td id=\"T_9749f_row1_col21\" class=\"data row1 col21\" >0.122808</td>\n",
       "                        <td id=\"T_9749f_row1_col22\" class=\"data row1 col22\" >0.110279</td>\n",
       "                        <td id=\"T_9749f_row1_col23\" class=\"data row1 col23\" >0.349859</td>\n",
       "                        <td id=\"T_9749f_row1_col24\" class=\"data row1 col24\" >0.397084</td>\n",
       "                        <td id=\"T_9749f_row1_col25\" class=\"data row1 col25\" >0.360822</td>\n",
       "                        <td id=\"T_9749f_row1_col26\" class=\"data row1 col26\" >0.387338</td>\n",
       "                        <td id=\"T_9749f_row1_col27\" class=\"data row1 col27\" >0.358737</td>\n",
       "                        <td id=\"T_9749f_row1_col28\" class=\"data row1 col28\" >0.386917</td>\n",
       "                        <td id=\"T_9749f_row1_col29\" class=\"data row1 col29\" >0.361364</td>\n",
       "                        <td id=\"T_9749f_row1_col30\" class=\"data row1 col30\" >0.387978</td>\n",
       "                        <td id=\"T_9749f_row1_col31\" class=\"data row1 col31\" >-0.093435</td>\n",
       "                        <td id=\"T_9749f_row1_col32\" class=\"data row1 col32\" >-0.135137</td>\n",
       "                        <td id=\"T_9749f_row1_col33\" class=\"data row1 col33\" >0.007287</td>\n",
       "                        <td id=\"T_9749f_row1_col34\" class=\"data row1 col34\" >0.049880</td>\n",
       "                        <td id=\"T_9749f_row1_col35\" class=\"data row1 col35\" >0.078898</td>\n",
       "                        <td id=\"T_9749f_row1_col36\" class=\"data row1 col36\" >0.129756</td>\n",
       "                        <td id=\"T_9749f_row1_col37\" class=\"data row1 col37\" >0.105743</td>\n",
       "                        <td id=\"T_9749f_row1_col38\" class=\"data row1 col38\" >0.151275</td>\n",
       "                        <td id=\"T_9749f_row1_col39\" class=\"data row1 col39\" >-0.083046</td>\n",
       "                        <td id=\"T_9749f_row1_col40\" class=\"data row1 col40\" >-0.093552</td>\n",
       "                        <td id=\"T_9749f_row1_col41\" class=\"data row1 col41\" >0.359164</td>\n",
       "                        <td id=\"T_9749f_row1_col42\" class=\"data row1 col42\" >0.385581</td>\n",
       "                        <td id=\"T_9749f_row1_col43\" class=\"data row1 col43\" >0.120612</td>\n",
       "                        <td id=\"T_9749f_row1_col44\" class=\"data row1 col44\" >0.179000</td>\n",
       "                        <td id=\"T_9749f_row1_col45\" class=\"data row1 col45\" >-0.003040</td>\n",
       "                        <td id=\"T_9749f_row1_col46\" class=\"data row1 col46\" >0.062250</td>\n",
       "                        <td id=\"T_9749f_row1_col47\" class=\"data row1 col47\" >-0.074133</td>\n",
       "                        <td id=\"T_9749f_row1_col48\" class=\"data row1 col48\" >-0.118409</td>\n",
       "                        <td id=\"T_9749f_row1_col49\" class=\"data row1 col49\" >-0.002856</td>\n",
       "                        <td id=\"T_9749f_row1_col50\" class=\"data row1 col50\" >-0.022856</td>\n",
       "                        <td id=\"T_9749f_row1_col51\" class=\"data row1 col51\" >-0.005689</td>\n",
       "                        <td id=\"T_9749f_row1_col52\" class=\"data row1 col52\" >-0.023453</td>\n",
       "                        <td id=\"T_9749f_row1_col53\" class=\"data row1 col53\" >-0.262337</td>\n",
       "                        <td id=\"T_9749f_row1_col54\" class=\"data row1 col54\" >0.212361</td>\n",
       "                        <td id=\"T_9749f_row1_col55\" class=\"data row1 col55\" >-0.024544</td>\n",
       "                        <td id=\"T_9749f_row1_col56\" class=\"data row1 col56\" >-0.048043</td>\n",
       "                        <td id=\"T_9749f_row1_col57\" class=\"data row1 col57\" >0.016805</td>\n",
       "                        <td id=\"T_9749f_row1_col58\" class=\"data row1 col58\" >-0.000519</td>\n",
       "                        <td id=\"T_9749f_row1_col59\" class=\"data row1 col59\" >-0.120569</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row2\" class=\"row_heading level0 row2\" >week_avg_reading</th>\n",
       "                        <td id=\"T_9749f_row2_col0\" class=\"data row2 col0\" >0.537752</td>\n",
       "                        <td id=\"T_9749f_row2_col1\" class=\"data row2 col1\" >0.869261</td>\n",
       "                        <td id=\"T_9749f_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row2_col3\" class=\"data row2 col3\" >0.381207</td>\n",
       "                        <td id=\"T_9749f_row2_col4\" class=\"data row2 col4\" >0.404759</td>\n",
       "                        <td id=\"T_9749f_row2_col5\" class=\"data row2 col5\" >0.432498</td>\n",
       "                        <td id=\"T_9749f_row2_col6\" class=\"data row2 col6\" >0.461932</td>\n",
       "                        <td id=\"T_9749f_row2_col7\" class=\"data row2 col7\" >0.001840</td>\n",
       "                        <td id=\"T_9749f_row2_col8\" class=\"data row2 col8\" >0.029085</td>\n",
       "                        <td id=\"T_9749f_row2_col9\" class=\"data row2 col9\" >0.311138</td>\n",
       "                        <td id=\"T_9749f_row2_col10\" class=\"data row2 col10\" >0.349772</td>\n",
       "                        <td id=\"T_9749f_row2_col11\" class=\"data row2 col11\" >0.350469</td>\n",
       "                        <td id=\"T_9749f_row2_col12\" class=\"data row2 col12\" >0.395077</td>\n",
       "                        <td id=\"T_9749f_row2_col13\" class=\"data row2 col13\" >0.000936</td>\n",
       "                        <td id=\"T_9749f_row2_col14\" class=\"data row2 col14\" >-0.037898</td>\n",
       "                        <td id=\"T_9749f_row2_col15\" class=\"data row2 col15\" >-0.501881</td>\n",
       "                        <td id=\"T_9749f_row2_col16\" class=\"data row2 col16\" >-0.524205</td>\n",
       "                        <td id=\"T_9749f_row2_col17\" class=\"data row2 col17\" >-0.501881</td>\n",
       "                        <td id=\"T_9749f_row2_col18\" class=\"data row2 col18\" >-0.524205</td>\n",
       "                        <td id=\"T_9749f_row2_col19\" class=\"data row2 col19\" >0.473132</td>\n",
       "                        <td id=\"T_9749f_row2_col20\" class=\"data row2 col20\" >0.496088</td>\n",
       "                        <td id=\"T_9749f_row2_col21\" class=\"data row2 col21\" >0.181016</td>\n",
       "                        <td id=\"T_9749f_row2_col22\" class=\"data row2 col22\" >0.161922</td>\n",
       "                        <td id=\"T_9749f_row2_col23\" class=\"data row2 col23\" >0.399792</td>\n",
       "                        <td id=\"T_9749f_row2_col24\" class=\"data row2 col24\" >0.445747</td>\n",
       "                        <td id=\"T_9749f_row2_col25\" class=\"data row2 col25\" >0.408125</td>\n",
       "                        <td id=\"T_9749f_row2_col26\" class=\"data row2 col26\" >0.436000</td>\n",
       "                        <td id=\"T_9749f_row2_col27\" class=\"data row2 col27\" >0.413228</td>\n",
       "                        <td id=\"T_9749f_row2_col28\" class=\"data row2 col28\" >0.441748</td>\n",
       "                        <td id=\"T_9749f_row2_col29\" class=\"data row2 col29\" >0.408468</td>\n",
       "                        <td id=\"T_9749f_row2_col30\" class=\"data row2 col30\" >0.436514</td>\n",
       "                        <td id=\"T_9749f_row2_col31\" class=\"data row2 col31\" >-0.053038</td>\n",
       "                        <td id=\"T_9749f_row2_col32\" class=\"data row2 col32\" >-0.109000</td>\n",
       "                        <td id=\"T_9749f_row2_col33\" class=\"data row2 col33\" >0.034025</td>\n",
       "                        <td id=\"T_9749f_row2_col34\" class=\"data row2 col34\" >0.064772</td>\n",
       "                        <td id=\"T_9749f_row2_col35\" class=\"data row2 col35\" >0.076198</td>\n",
       "                        <td id=\"T_9749f_row2_col36\" class=\"data row2 col36\" >0.110884</td>\n",
       "                        <td id=\"T_9749f_row2_col37\" class=\"data row2 col37\" >0.150654</td>\n",
       "                        <td id=\"T_9749f_row2_col38\" class=\"data row2 col38\" >0.201830</td>\n",
       "                        <td id=\"T_9749f_row2_col39\" class=\"data row2 col39\" >-0.121718</td>\n",
       "                        <td id=\"T_9749f_row2_col40\" class=\"data row2 col40\" >-0.134745</td>\n",
       "                        <td id=\"T_9749f_row2_col41\" class=\"data row2 col41\" >0.415279</td>\n",
       "                        <td id=\"T_9749f_row2_col42\" class=\"data row2 col42\" >0.442421</td>\n",
       "                        <td id=\"T_9749f_row2_col43\" class=\"data row2 col43\" >0.102404</td>\n",
       "                        <td id=\"T_9749f_row2_col44\" class=\"data row2 col44\" >0.182091</td>\n",
       "                        <td id=\"T_9749f_row2_col45\" class=\"data row2 col45\" >0.011296</td>\n",
       "                        <td id=\"T_9749f_row2_col46\" class=\"data row2 col46\" >0.038451</td>\n",
       "                        <td id=\"T_9749f_row2_col47\" class=\"data row2 col47\" >-0.037762</td>\n",
       "                        <td id=\"T_9749f_row2_col48\" class=\"data row2 col48\" >-0.085098</td>\n",
       "                        <td id=\"T_9749f_row2_col49\" class=\"data row2 col49\" >-0.099896</td>\n",
       "                        <td id=\"T_9749f_row2_col50\" class=\"data row2 col50\" >-0.056166</td>\n",
       "                        <td id=\"T_9749f_row2_col51\" class=\"data row2 col51\" >-0.101264</td>\n",
       "                        <td id=\"T_9749f_row2_col52\" class=\"data row2 col52\" >-0.058036</td>\n",
       "                        <td id=\"T_9749f_row2_col53\" class=\"data row2 col53\" >-0.106484</td>\n",
       "                        <td id=\"T_9749f_row2_col54\" class=\"data row2 col54\" >0.193533</td>\n",
       "                        <td id=\"T_9749f_row2_col55\" class=\"data row2 col55\" >0.024376</td>\n",
       "                        <td id=\"T_9749f_row2_col56\" class=\"data row2 col56\" >0.005952</td>\n",
       "                        <td id=\"T_9749f_row2_col57\" class=\"data row2 col57\" >0.020632</td>\n",
       "                        <td id=\"T_9749f_row2_col58\" class=\"data row2 col58\" >-0.000964</td>\n",
       "                        <td id=\"T_9749f_row2_col59\" class=\"data row2 col59\" >-0.073634</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row3\" class=\"row_heading level0 row3\" >day_avg_maxtemp</th>\n",
       "                        <td id=\"T_9749f_row3_col0\" class=\"data row3 col0\" >0.204917</td>\n",
       "                        <td id=\"T_9749f_row3_col1\" class=\"data row3 col1\" >0.338584</td>\n",
       "                        <td id=\"T_9749f_row3_col2\" class=\"data row3 col2\" >0.381207</td>\n",
       "                        <td id=\"T_9749f_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row3_col4\" class=\"data row3 col4\" >0.884754</td>\n",
       "                        <td id=\"T_9749f_row3_col5\" class=\"data row3 col5\" >0.861605</td>\n",
       "                        <td id=\"T_9749f_row3_col6\" class=\"data row3 col6\" >0.776365</td>\n",
       "                        <td id=\"T_9749f_row3_col7\" class=\"data row3 col7\" >-0.173640</td>\n",
       "                        <td id=\"T_9749f_row3_col8\" class=\"data row3 col8\" >-0.276800</td>\n",
       "                        <td id=\"T_9749f_row3_col9\" class=\"data row3 col9\" >0.606229</td>\n",
       "                        <td id=\"T_9749f_row3_col10\" class=\"data row3 col10\" >0.694063</td>\n",
       "                        <td id=\"T_9749f_row3_col11\" class=\"data row3 col11\" >0.874621</td>\n",
       "                        <td id=\"T_9749f_row3_col12\" class=\"data row3 col12\" >0.845870</td>\n",
       "                        <td id=\"T_9749f_row3_col13\" class=\"data row3 col13\" >-0.011558</td>\n",
       "                        <td id=\"T_9749f_row3_col14\" class=\"data row3 col14\" >0.043751</td>\n",
       "                        <td id=\"T_9749f_row3_col15\" class=\"data row3 col15\" >-0.722733</td>\n",
       "                        <td id=\"T_9749f_row3_col16\" class=\"data row3 col16\" >-0.739911</td>\n",
       "                        <td id=\"T_9749f_row3_col17\" class=\"data row3 col17\" >-0.722733</td>\n",
       "                        <td id=\"T_9749f_row3_col18\" class=\"data row3 col18\" >-0.739911</td>\n",
       "                        <td id=\"T_9749f_row3_col19\" class=\"data row3 col19\" >0.715190</td>\n",
       "                        <td id=\"T_9749f_row3_col20\" class=\"data row3 col20\" >0.740185</td>\n",
       "                        <td id=\"T_9749f_row3_col21\" class=\"data row3 col21\" >-0.020457</td>\n",
       "                        <td id=\"T_9749f_row3_col22\" class=\"data row3 col22\" >-0.028389</td>\n",
       "                        <td id=\"T_9749f_row3_col23\" class=\"data row3 col23\" >0.899765</td>\n",
       "                        <td id=\"T_9749f_row3_col24\" class=\"data row3 col24\" >0.807294</td>\n",
       "                        <td id=\"T_9749f_row3_col25\" class=\"data row3 col25\" >0.962176</td>\n",
       "                        <td id=\"T_9749f_row3_col26\" class=\"data row3 col26\" >0.855454</td>\n",
       "                        <td id=\"T_9749f_row3_col27\" class=\"data row3 col27\" >0.961054</td>\n",
       "                        <td id=\"T_9749f_row3_col28\" class=\"data row3 col28\" >0.846157</td>\n",
       "                        <td id=\"T_9749f_row3_col29\" class=\"data row3 col29\" >0.961953</td>\n",
       "                        <td id=\"T_9749f_row3_col30\" class=\"data row3 col30\" >0.855587</td>\n",
       "                        <td id=\"T_9749f_row3_col31\" class=\"data row3 col31\" >-0.165842</td>\n",
       "                        <td id=\"T_9749f_row3_col32\" class=\"data row3 col32\" >-0.346365</td>\n",
       "                        <td id=\"T_9749f_row3_col33\" class=\"data row3 col33\" >-0.079127</td>\n",
       "                        <td id=\"T_9749f_row3_col34\" class=\"data row3 col34\" >-0.187650</td>\n",
       "                        <td id=\"T_9749f_row3_col35\" class=\"data row3 col35\" >0.127885</td>\n",
       "                        <td id=\"T_9749f_row3_col36\" class=\"data row3 col36\" >0.035357</td>\n",
       "                        <td id=\"T_9749f_row3_col37\" class=\"data row3 col37\" >0.077244</td>\n",
       "                        <td id=\"T_9749f_row3_col38\" class=\"data row3 col38\" >0.072691</td>\n",
       "                        <td id=\"T_9749f_row3_col39\" class=\"data row3 col39\" >0.083486</td>\n",
       "                        <td id=\"T_9749f_row3_col40\" class=\"data row3 col40\" >0.150299</td>\n",
       "                        <td id=\"T_9749f_row3_col41\" class=\"data row3 col41\" >0.960877</td>\n",
       "                        <td id=\"T_9749f_row3_col42\" class=\"data row3 col42\" >0.847666</td>\n",
       "                        <td id=\"T_9749f_row3_col43\" class=\"data row3 col43\" >0.021373</td>\n",
       "                        <td id=\"T_9749f_row3_col44\" class=\"data row3 col44\" >0.082141</td>\n",
       "                        <td id=\"T_9749f_row3_col45\" class=\"data row3 col45\" >-0.016343</td>\n",
       "                        <td id=\"T_9749f_row3_col46\" class=\"data row3 col46\" >-0.047302</td>\n",
       "                        <td id=\"T_9749f_row3_col47\" class=\"data row3 col47\" >-0.180583</td>\n",
       "                        <td id=\"T_9749f_row3_col48\" class=\"data row3 col48\" >-0.343910</td>\n",
       "                        <td id=\"T_9749f_row3_col49\" class=\"data row3 col49\" >-0.485997</td>\n",
       "                        <td id=\"T_9749f_row3_col50\" class=\"data row3 col50\" >-0.502095</td>\n",
       "                        <td id=\"T_9749f_row3_col51\" class=\"data row3 col51\" >-0.487376</td>\n",
       "                        <td id=\"T_9749f_row3_col52\" class=\"data row3 col52\" >-0.502675</td>\n",
       "                        <td id=\"T_9749f_row3_col53\" class=\"data row3 col53\" >0.024258</td>\n",
       "                        <td id=\"T_9749f_row3_col54\" class=\"data row3 col54\" >0.258379</td>\n",
       "                        <td id=\"T_9749f_row3_col55\" class=\"data row3 col55\" >0.112700</td>\n",
       "                        <td id=\"T_9749f_row3_col56\" class=\"data row3 col56\" >0.137701</td>\n",
       "                        <td id=\"T_9749f_row3_col57\" class=\"data row3 col57\" >0.001300</td>\n",
       "                        <td id=\"T_9749f_row3_col58\" class=\"data row3 col58\" >-0.000883</td>\n",
       "                        <td id=\"T_9749f_row3_col59\" class=\"data row3 col59\" >0.402953</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row4\" class=\"row_heading level0 row4\" >week_avg_maxtemp</th>\n",
       "                        <td id=\"T_9749f_row4_col0\" class=\"data row4 col0\" >0.223379</td>\n",
       "                        <td id=\"T_9749f_row4_col1\" class=\"data row4 col1\" >0.367994</td>\n",
       "                        <td id=\"T_9749f_row4_col2\" class=\"data row4 col2\" >0.404759</td>\n",
       "                        <td id=\"T_9749f_row4_col3\" class=\"data row4 col3\" >0.884754</td>\n",
       "                        <td id=\"T_9749f_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row4_col5\" class=\"data row4 col5\" >0.781017</td>\n",
       "                        <td id=\"T_9749f_row4_col6\" class=\"data row4 col6\" >0.902945</td>\n",
       "                        <td id=\"T_9749f_row4_col7\" class=\"data row4 col7\" >-0.136741</td>\n",
       "                        <td id=\"T_9749f_row4_col8\" class=\"data row4 col8\" >-0.318507</td>\n",
       "                        <td id=\"T_9749f_row4_col9\" class=\"data row4 col9\" >0.616277</td>\n",
       "                        <td id=\"T_9749f_row4_col10\" class=\"data row4 col10\" >0.714330</td>\n",
       "                        <td id=\"T_9749f_row4_col11\" class=\"data row4 col11\" >0.781366</td>\n",
       "                        <td id=\"T_9749f_row4_col12\" class=\"data row4 col12\" >0.949715</td>\n",
       "                        <td id=\"T_9749f_row4_col13\" class=\"data row4 col13\" >-0.072718</td>\n",
       "                        <td id=\"T_9749f_row4_col14\" class=\"data row4 col14\" >-0.015772</td>\n",
       "                        <td id=\"T_9749f_row4_col15\" class=\"data row4 col15\" >-0.769977</td>\n",
       "                        <td id=\"T_9749f_row4_col16\" class=\"data row4 col16\" >-0.787543</td>\n",
       "                        <td id=\"T_9749f_row4_col17\" class=\"data row4 col17\" >-0.769977</td>\n",
       "                        <td id=\"T_9749f_row4_col18\" class=\"data row4 col18\" >-0.787543</td>\n",
       "                        <td id=\"T_9749f_row4_col19\" class=\"data row4 col19\" >0.743256</td>\n",
       "                        <td id=\"T_9749f_row4_col20\" class=\"data row4 col20\" >0.776557</td>\n",
       "                        <td id=\"T_9749f_row4_col21\" class=\"data row4 col21\" >-0.012632</td>\n",
       "                        <td id=\"T_9749f_row4_col22\" class=\"data row4 col22\" >-0.045283</td>\n",
       "                        <td id=\"T_9749f_row4_col23\" class=\"data row4 col23\" >0.807959</td>\n",
       "                        <td id=\"T_9749f_row4_col24\" class=\"data row4 col24\" >0.934835</td>\n",
       "                        <td id=\"T_9749f_row4_col25\" class=\"data row4 col25\" >0.881185</td>\n",
       "                        <td id=\"T_9749f_row4_col26\" class=\"data row4 col26\" >0.975984</td>\n",
       "                        <td id=\"T_9749f_row4_col27\" class=\"data row4 col27\" >0.872039</td>\n",
       "                        <td id=\"T_9749f_row4_col28\" class=\"data row4 col28\" >0.971681</td>\n",
       "                        <td id=\"T_9749f_row4_col29\" class=\"data row4 col29\" >0.881796</td>\n",
       "                        <td id=\"T_9749f_row4_col30\" class=\"data row4 col30\" >0.976085</td>\n",
       "                        <td id=\"T_9749f_row4_col31\" class=\"data row4 col31\" >-0.191524</td>\n",
       "                        <td id=\"T_9749f_row4_col32\" class=\"data row4 col32\" >-0.341449</td>\n",
       "                        <td id=\"T_9749f_row4_col33\" class=\"data row4 col33\" >-0.076762</td>\n",
       "                        <td id=\"T_9749f_row4_col34\" class=\"data row4 col34\" >-0.180175</td>\n",
       "                        <td id=\"T_9749f_row4_col35\" class=\"data row4 col35\" >0.062376</td>\n",
       "                        <td id=\"T_9749f_row4_col36\" class=\"data row4 col36\" >0.086222</td>\n",
       "                        <td id=\"T_9749f_row4_col37\" class=\"data row4 col37\" >0.117555</td>\n",
       "                        <td id=\"T_9749f_row4_col38\" class=\"data row4 col38\" >0.111240</td>\n",
       "                        <td id=\"T_9749f_row4_col39\" class=\"data row4 col39\" >0.033323</td>\n",
       "                        <td id=\"T_9749f_row4_col40\" class=\"data row4 col40\" >0.110985</td>\n",
       "                        <td id=\"T_9749f_row4_col41\" class=\"data row4 col41\" >0.869199</td>\n",
       "                        <td id=\"T_9749f_row4_col42\" class=\"data row4 col42\" >0.973018</td>\n",
       "                        <td id=\"T_9749f_row4_col43\" class=\"data row4 col43\" >0.041430</td>\n",
       "                        <td id=\"T_9749f_row4_col44\" class=\"data row4 col44\" >0.070536</td>\n",
       "                        <td id=\"T_9749f_row4_col45\" class=\"data row4 col45\" >0.031729</td>\n",
       "                        <td id=\"T_9749f_row4_col46\" class=\"data row4 col46\" >-0.010975</td>\n",
       "                        <td id=\"T_9749f_row4_col47\" class=\"data row4 col47\" >-0.181055</td>\n",
       "                        <td id=\"T_9749f_row4_col48\" class=\"data row4 col48\" >-0.339537</td>\n",
       "                        <td id=\"T_9749f_row4_col49\" class=\"data row4 col49\" >-0.510482</td>\n",
       "                        <td id=\"T_9749f_row4_col50\" class=\"data row4 col50\" >-0.540220</td>\n",
       "                        <td id=\"T_9749f_row4_col51\" class=\"data row4 col51\" >-0.511816</td>\n",
       "                        <td id=\"T_9749f_row4_col52\" class=\"data row4 col52\" >-0.541194</td>\n",
       "                        <td id=\"T_9749f_row4_col53\" class=\"data row4 col53\" >-0.005796</td>\n",
       "                        <td id=\"T_9749f_row4_col54\" class=\"data row4 col54\" >0.275693</td>\n",
       "                        <td id=\"T_9749f_row4_col55\" class=\"data row4 col55\" >0.155964</td>\n",
       "                        <td id=\"T_9749f_row4_col56\" class=\"data row4 col56\" >0.126849</td>\n",
       "                        <td id=\"T_9749f_row4_col57\" class=\"data row4 col57\" >0.002295</td>\n",
       "                        <td id=\"T_9749f_row4_col58\" class=\"data row4 col58\" >-0.000850</td>\n",
       "                        <td id=\"T_9749f_row4_col59\" class=\"data row4 col59\" >0.421848</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row5\" class=\"row_heading level0 row5\" >day_avg_mintemp</th>\n",
       "                        <td id=\"T_9749f_row5_col0\" class=\"data row5 col0\" >0.226490</td>\n",
       "                        <td id=\"T_9749f_row5_col1\" class=\"data row5 col1\" >0.379066</td>\n",
       "                        <td id=\"T_9749f_row5_col2\" class=\"data row5 col2\" >0.432498</td>\n",
       "                        <td id=\"T_9749f_row5_col3\" class=\"data row5 col3\" >0.861605</td>\n",
       "                        <td id=\"T_9749f_row5_col4\" class=\"data row5 col4\" >0.781017</td>\n",
       "                        <td id=\"T_9749f_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row5_col6\" class=\"data row5 col6\" >0.837436</td>\n",
       "                        <td id=\"T_9749f_row5_col7\" class=\"data row5 col7\" >-0.160403</td>\n",
       "                        <td id=\"T_9749f_row5_col8\" class=\"data row5 col8\" >-0.279830</td>\n",
       "                        <td id=\"T_9749f_row5_col9\" class=\"data row5 col9\" >0.328401</td>\n",
       "                        <td id=\"T_9749f_row5_col10\" class=\"data row5 col10\" >0.445027</td>\n",
       "                        <td id=\"T_9749f_row5_col11\" class=\"data row5 col11\" >0.733839</td>\n",
       "                        <td id=\"T_9749f_row5_col12\" class=\"data row5 col12\" >0.747652</td>\n",
       "                        <td id=\"T_9749f_row5_col13\" class=\"data row5 col13\" >0.035097</td>\n",
       "                        <td id=\"T_9749f_row5_col14\" class=\"data row5 col14\" >0.043197</td>\n",
       "                        <td id=\"T_9749f_row5_col15\" class=\"data row5 col15\" >-0.523234</td>\n",
       "                        <td id=\"T_9749f_row5_col16\" class=\"data row5 col16\" >-0.548903</td>\n",
       "                        <td id=\"T_9749f_row5_col17\" class=\"data row5 col17\" >-0.523234</td>\n",
       "                        <td id=\"T_9749f_row5_col18\" class=\"data row5 col18\" >-0.548903</td>\n",
       "                        <td id=\"T_9749f_row5_col19\" class=\"data row5 col19\" >0.493586</td>\n",
       "                        <td id=\"T_9749f_row5_col20\" class=\"data row5 col20\" >0.530093</td>\n",
       "                        <td id=\"T_9749f_row5_col21\" class=\"data row5 col21\" >0.031147</td>\n",
       "                        <td id=\"T_9749f_row5_col22\" class=\"data row5 col22\" >0.004150</td>\n",
       "                        <td id=\"T_9749f_row5_col23\" class=\"data row5 col23\" >0.917018</td>\n",
       "                        <td id=\"T_9749f_row5_col24\" class=\"data row5 col24\" >0.822502</td>\n",
       "                        <td id=\"T_9749f_row5_col25\" class=\"data row5 col25\" >0.905904</td>\n",
       "                        <td id=\"T_9749f_row5_col26\" class=\"data row5 col26\" >0.809178</td>\n",
       "                        <td id=\"T_9749f_row5_col27\" class=\"data row5 col27\" >0.928573</td>\n",
       "                        <td id=\"T_9749f_row5_col28\" class=\"data row5 col28\" >0.818924</td>\n",
       "                        <td id=\"T_9749f_row5_col29\" class=\"data row5 col29\" >0.905942</td>\n",
       "                        <td id=\"T_9749f_row5_col30\" class=\"data row5 col30\" >0.809055</td>\n",
       "                        <td id=\"T_9749f_row5_col31\" class=\"data row5 col31\" >-0.019270</td>\n",
       "                        <td id=\"T_9749f_row5_col32\" class=\"data row5 col32\" >-0.182769</td>\n",
       "                        <td id=\"T_9749f_row5_col33\" class=\"data row5 col33\" >0.139211</td>\n",
       "                        <td id=\"T_9749f_row5_col34\" class=\"data row5 col34\" >0.002010</td>\n",
       "                        <td id=\"T_9749f_row5_col35\" class=\"data row5 col35\" >0.311324</td>\n",
       "                        <td id=\"T_9749f_row5_col36\" class=\"data row5 col36\" >0.262858</td>\n",
       "                        <td id=\"T_9749f_row5_col37\" class=\"data row5 col37\" >0.139049</td>\n",
       "                        <td id=\"T_9749f_row5_col38\" class=\"data row5 col38\" >0.148859</td>\n",
       "                        <td id=\"T_9749f_row5_col39\" class=\"data row5 col39\" >-0.055015</td>\n",
       "                        <td id=\"T_9749f_row5_col40\" class=\"data row5 col40\" >0.044785</td>\n",
       "                        <td id=\"T_9749f_row5_col41\" class=\"data row5 col41\" >0.938649</td>\n",
       "                        <td id=\"T_9749f_row5_col42\" class=\"data row5 col42\" >0.820206</td>\n",
       "                        <td id=\"T_9749f_row5_col43\" class=\"data row5 col43\" >-0.105680</td>\n",
       "                        <td id=\"T_9749f_row5_col44\" class=\"data row5 col44\" >-0.063482</td>\n",
       "                        <td id=\"T_9749f_row5_col45\" class=\"data row5 col45\" >0.089084</td>\n",
       "                        <td id=\"T_9749f_row5_col46\" class=\"data row5 col46\" >0.037376</td>\n",
       "                        <td id=\"T_9749f_row5_col47\" class=\"data row5 col47\" >-0.024371</td>\n",
       "                        <td id=\"T_9749f_row5_col48\" class=\"data row5 col48\" >-0.178848</td>\n",
       "                        <td id=\"T_9749f_row5_col49\" class=\"data row5 col49\" >-0.464762</td>\n",
       "                        <td id=\"T_9749f_row5_col50\" class=\"data row5 col50\" >-0.468744</td>\n",
       "                        <td id=\"T_9749f_row5_col51\" class=\"data row5 col51\" >-0.466607</td>\n",
       "                        <td id=\"T_9749f_row5_col52\" class=\"data row5 col52\" >-0.470018</td>\n",
       "                        <td id=\"T_9749f_row5_col53\" class=\"data row5 col53\" >-0.011190</td>\n",
       "                        <td id=\"T_9749f_row5_col54\" class=\"data row5 col54\" >0.032750</td>\n",
       "                        <td id=\"T_9749f_row5_col55\" class=\"data row5 col55\" >0.292447</td>\n",
       "                        <td id=\"T_9749f_row5_col56\" class=\"data row5 col56\" >0.112697</td>\n",
       "                        <td id=\"T_9749f_row5_col57\" class=\"data row5 col57\" >-0.000512</td>\n",
       "                        <td id=\"T_9749f_row5_col58\" class=\"data row5 col58\" >-0.001023</td>\n",
       "                        <td id=\"T_9749f_row5_col59\" class=\"data row5 col59\" >0.349717</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row6\" class=\"row_heading level0 row6\" >week_avg_mintemp</th>\n",
       "                        <td id=\"T_9749f_row6_col0\" class=\"data row6 col0\" >0.234687</td>\n",
       "                        <td id=\"T_9749f_row6_col1\" class=\"data row6 col1\" >0.391613</td>\n",
       "                        <td id=\"T_9749f_row6_col2\" class=\"data row6 col2\" >0.461932</td>\n",
       "                        <td id=\"T_9749f_row6_col3\" class=\"data row6 col3\" >0.776365</td>\n",
       "                        <td id=\"T_9749f_row6_col4\" class=\"data row6 col4\" >0.902945</td>\n",
       "                        <td id=\"T_9749f_row6_col5\" class=\"data row6 col5\" >0.837436</td>\n",
       "                        <td id=\"T_9749f_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row6_col7\" class=\"data row6 col7\" >-0.143012</td>\n",
       "                        <td id=\"T_9749f_row6_col8\" class=\"data row6 col8\" >-0.328774</td>\n",
       "                        <td id=\"T_9749f_row6_col9\" class=\"data row6 col9\" >0.378477</td>\n",
       "                        <td id=\"T_9749f_row6_col10\" class=\"data row6 col10\" >0.452878</td>\n",
       "                        <td id=\"T_9749f_row6_col11\" class=\"data row6 col11\" >0.674645</td>\n",
       "                        <td id=\"T_9749f_row6_col12\" class=\"data row6 col12\" >0.847447</td>\n",
       "                        <td id=\"T_9749f_row6_col13\" class=\"data row6 col13\" >-0.002655</td>\n",
       "                        <td id=\"T_9749f_row6_col14\" class=\"data row6 col14\" >0.030744</td>\n",
       "                        <td id=\"T_9749f_row6_col15\" class=\"data row6 col15\" >-0.561754</td>\n",
       "                        <td id=\"T_9749f_row6_col16\" class=\"data row6 col16\" >-0.593415</td>\n",
       "                        <td id=\"T_9749f_row6_col17\" class=\"data row6 col17\" >-0.561754</td>\n",
       "                        <td id=\"T_9749f_row6_col18\" class=\"data row6 col18\" >-0.593415</td>\n",
       "                        <td id=\"T_9749f_row6_col19\" class=\"data row6 col19\" >0.517201</td>\n",
       "                        <td id=\"T_9749f_row6_col20\" class=\"data row6 col20\" >0.560914</td>\n",
       "                        <td id=\"T_9749f_row6_col21\" class=\"data row6 col21\" >0.039971</td>\n",
       "                        <td id=\"T_9749f_row6_col22\" class=\"data row6 col22\" >0.009033</td>\n",
       "                        <td id=\"T_9749f_row6_col23\" class=\"data row6 col23\" >0.816186</td>\n",
       "                        <td id=\"T_9749f_row6_col24\" class=\"data row6 col24\" >0.974610</td>\n",
       "                        <td id=\"T_9749f_row6_col25\" class=\"data row6 col25\" >0.835199</td>\n",
       "                        <td id=\"T_9749f_row6_col26\" class=\"data row6 col26\" >0.948215</td>\n",
       "                        <td id=\"T_9749f_row6_col27\" class=\"data row6 col27\" >0.840538</td>\n",
       "                        <td id=\"T_9749f_row6_col28\" class=\"data row6 col28\" >0.964164</td>\n",
       "                        <td id=\"T_9749f_row6_col29\" class=\"data row6 col29\" >0.835460</td>\n",
       "                        <td id=\"T_9749f_row6_col30\" class=\"data row6 col30\" >0.947995</td>\n",
       "                        <td id=\"T_9749f_row6_col31\" class=\"data row6 col31\" >-0.096715</td>\n",
       "                        <td id=\"T_9749f_row6_col32\" class=\"data row6 col32\" >-0.173353</td>\n",
       "                        <td id=\"T_9749f_row6_col33\" class=\"data row6 col33\" >0.053266</td>\n",
       "                        <td id=\"T_9749f_row6_col34\" class=\"data row6 col34\" >0.061058</td>\n",
       "                        <td id=\"T_9749f_row6_col35\" class=\"data row6 col35\" >0.207099</td>\n",
       "                        <td id=\"T_9749f_row6_col36\" class=\"data row6 col36\" >0.353141</td>\n",
       "                        <td id=\"T_9749f_row6_col37\" class=\"data row6 col37\" >0.169635</td>\n",
       "                        <td id=\"T_9749f_row6_col38\" class=\"data row6 col38\" >0.214386</td>\n",
       "                        <td id=\"T_9749f_row6_col39\" class=\"data row6 col39\" >-0.036129</td>\n",
       "                        <td id=\"T_9749f_row6_col40\" class=\"data row6 col40\" >-0.008474</td>\n",
       "                        <td id=\"T_9749f_row6_col41\" class=\"data row6 col41\" >0.839086</td>\n",
       "                        <td id=\"T_9749f_row6_col42\" class=\"data row6 col42\" >0.966837</td>\n",
       "                        <td id=\"T_9749f_row6_col43\" class=\"data row6 col43\" >-0.081718</td>\n",
       "                        <td id=\"T_9749f_row6_col44\" class=\"data row6 col44\" >-0.106805</td>\n",
       "                        <td id=\"T_9749f_row6_col45\" class=\"data row6 col45\" >0.054273</td>\n",
       "                        <td id=\"T_9749f_row6_col46\" class=\"data row6 col46\" >0.060154</td>\n",
       "                        <td id=\"T_9749f_row6_col47\" class=\"data row6 col47\" >-0.085869</td>\n",
       "                        <td id=\"T_9749f_row6_col48\" class=\"data row6 col48\" >-0.168713</td>\n",
       "                        <td id=\"T_9749f_row6_col49\" class=\"data row6 col49\" >-0.522276</td>\n",
       "                        <td id=\"T_9749f_row6_col50\" class=\"data row6 col50\" >-0.542480</td>\n",
       "                        <td id=\"T_9749f_row6_col51\" class=\"data row6 col51\" >-0.524206</td>\n",
       "                        <td id=\"T_9749f_row6_col52\" class=\"data row6 col52\" >-0.544106</td>\n",
       "                        <td id=\"T_9749f_row6_col53\" class=\"data row6 col53\" >-0.006473</td>\n",
       "                        <td id=\"T_9749f_row6_col54\" class=\"data row6 col54\" >0.044666</td>\n",
       "                        <td id=\"T_9749f_row6_col55\" class=\"data row6 col55\" >0.350418</td>\n",
       "                        <td id=\"T_9749f_row6_col56\" class=\"data row6 col56\" >0.150269</td>\n",
       "                        <td id=\"T_9749f_row6_col57\" class=\"data row6 col57\" >0.001658</td>\n",
       "                        <td id=\"T_9749f_row6_col58\" class=\"data row6 col58\" >-0.001132</td>\n",
       "                        <td id=\"T_9749f_row6_col59\" class=\"data row6 col59\" >0.378246</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row7\" class=\"row_heading level0 row7\" >day_avg_snow</th>\n",
       "                        <td id=\"T_9749f_row7_col0\" class=\"data row7 col0\" >0.023012</td>\n",
       "                        <td id=\"T_9749f_row7_col1\" class=\"data row7 col1\" >0.024919</td>\n",
       "                        <td id=\"T_9749f_row7_col2\" class=\"data row7 col2\" >0.001840</td>\n",
       "                        <td id=\"T_9749f_row7_col3\" class=\"data row7 col3\" >-0.173640</td>\n",
       "                        <td id=\"T_9749f_row7_col4\" class=\"data row7 col4\" >-0.136741</td>\n",
       "                        <td id=\"T_9749f_row7_col5\" class=\"data row7 col5\" >-0.160403</td>\n",
       "                        <td id=\"T_9749f_row7_col6\" class=\"data row7 col6\" >-0.143012</td>\n",
       "                        <td id=\"T_9749f_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row7_col8\" class=\"data row7 col8\" >0.416091</td>\n",
       "                        <td id=\"T_9749f_row7_col9\" class=\"data row7 col9\" >-0.066769</td>\n",
       "                        <td id=\"T_9749f_row7_col10\" class=\"data row7 col10\" >-0.077554</td>\n",
       "                        <td id=\"T_9749f_row7_col11\" class=\"data row7 col11\" >-0.187128</td>\n",
       "                        <td id=\"T_9749f_row7_col12\" class=\"data row7 col12\" >-0.166102</td>\n",
       "                        <td id=\"T_9749f_row7_col13\" class=\"data row7 col13\" >-0.030214</td>\n",
       "                        <td id=\"T_9749f_row7_col14\" class=\"data row7 col14\" >0.003476</td>\n",
       "                        <td id=\"T_9749f_row7_col15\" class=\"data row7 col15\" >0.099517</td>\n",
       "                        <td id=\"T_9749f_row7_col16\" class=\"data row7 col16\" >0.101388</td>\n",
       "                        <td id=\"T_9749f_row7_col17\" class=\"data row7 col17\" >0.099517</td>\n",
       "                        <td id=\"T_9749f_row7_col18\" class=\"data row7 col18\" >0.101388</td>\n",
       "                        <td id=\"T_9749f_row7_col19\" class=\"data row7 col19\" >-0.058424</td>\n",
       "                        <td id=\"T_9749f_row7_col20\" class=\"data row7 col20\" >-0.067602</td>\n",
       "                        <td id=\"T_9749f_row7_col21\" class=\"data row7 col21\" >0.021655</td>\n",
       "                        <td id=\"T_9749f_row7_col22\" class=\"data row7 col22\" >0.035819</td>\n",
       "                        <td id=\"T_9749f_row7_col23\" class=\"data row7 col23\" >-0.175404</td>\n",
       "                        <td id=\"T_9749f_row7_col24\" class=\"data row7 col24\" >-0.142405</td>\n",
       "                        <td id=\"T_9749f_row7_col25\" class=\"data row7 col25\" >-0.169282</td>\n",
       "                        <td id=\"T_9749f_row7_col26\" class=\"data row7 col26\" >-0.134624</td>\n",
       "                        <td id=\"T_9749f_row7_col27\" class=\"data row7 col27\" >-0.169485</td>\n",
       "                        <td id=\"T_9749f_row7_col28\" class=\"data row7 col28\" >-0.139292</td>\n",
       "                        <td id=\"T_9749f_row7_col29\" class=\"data row7 col29\" >-0.169717</td>\n",
       "                        <td id=\"T_9749f_row7_col30\" class=\"data row7 col30\" >-0.134871</td>\n",
       "                        <td id=\"T_9749f_row7_col31\" class=\"data row7 col31\" >0.017203</td>\n",
       "                        <td id=\"T_9749f_row7_col32\" class=\"data row7 col32\" >0.020589</td>\n",
       "                        <td id=\"T_9749f_row7_col33\" class=\"data row7 col33\" >0.043144</td>\n",
       "                        <td id=\"T_9749f_row7_col34\" class=\"data row7 col34\" >0.047489</td>\n",
       "                        <td id=\"T_9749f_row7_col35\" class=\"data row7 col35\" >-0.099852</td>\n",
       "                        <td id=\"T_9749f_row7_col36\" class=\"data row7 col36\" >-0.061721</td>\n",
       "                        <td id=\"T_9749f_row7_col37\" class=\"data row7 col37\" >0.089030</td>\n",
       "                        <td id=\"T_9749f_row7_col38\" class=\"data row7 col38\" >0.063152</td>\n",
       "                        <td id=\"T_9749f_row7_col39\" class=\"data row7 col39\" >-0.102566</td>\n",
       "                        <td id=\"T_9749f_row7_col40\" class=\"data row7 col40\" >-0.111542</td>\n",
       "                        <td id=\"T_9749f_row7_col41\" class=\"data row7 col41\" >-0.171503</td>\n",
       "                        <td id=\"T_9749f_row7_col42\" class=\"data row7 col42\" >-0.140540</td>\n",
       "                        <td id=\"T_9749f_row7_col43\" class=\"data row7 col43\" >-0.078801</td>\n",
       "                        <td id=\"T_9749f_row7_col44\" class=\"data row7 col44\" >-0.091325</td>\n",
       "                        <td id=\"T_9749f_row7_col45\" class=\"data row7 col45\" >0.101061</td>\n",
       "                        <td id=\"T_9749f_row7_col46\" class=\"data row7 col46\" >0.113224</td>\n",
       "                        <td id=\"T_9749f_row7_col47\" class=\"data row7 col47\" >0.013553</td>\n",
       "                        <td id=\"T_9749f_row7_col48\" class=\"data row7 col48\" >0.021794</td>\n",
       "                        <td id=\"T_9749f_row7_col49\" class=\"data row7 col49\" >0.101001</td>\n",
       "                        <td id=\"T_9749f_row7_col50\" class=\"data row7 col50\" >0.087494</td>\n",
       "                        <td id=\"T_9749f_row7_col51\" class=\"data row7 col51\" >0.100331</td>\n",
       "                        <td id=\"T_9749f_row7_col52\" class=\"data row7 col52\" >0.087062</td>\n",
       "                        <td id=\"T_9749f_row7_col53\" class=\"data row7 col53\" >-0.059621</td>\n",
       "                        <td id=\"T_9749f_row7_col54\" class=\"data row7 col54\" >0.054797</td>\n",
       "                        <td id=\"T_9749f_row7_col55\" class=\"data row7 col55\" >-0.153602</td>\n",
       "                        <td id=\"T_9749f_row7_col56\" class=\"data row7 col56\" >0.078998</td>\n",
       "                        <td id=\"T_9749f_row7_col57\" class=\"data row7 col57\" >-0.000502</td>\n",
       "                        <td id=\"T_9749f_row7_col58\" class=\"data row7 col58\" >0.000691</td>\n",
       "                        <td id=\"T_9749f_row7_col59\" class=\"data row7 col59\" >-0.060044</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row8\" class=\"row_heading level0 row8\" >week_avg_snow</th>\n",
       "                        <td id=\"T_9749f_row8_col0\" class=\"data row8 col0\" >0.028832</td>\n",
       "                        <td id=\"T_9749f_row8_col1\" class=\"data row8 col1\" >0.049471</td>\n",
       "                        <td id=\"T_9749f_row8_col2\" class=\"data row8 col2\" >0.029085</td>\n",
       "                        <td id=\"T_9749f_row8_col3\" class=\"data row8 col3\" >-0.276800</td>\n",
       "                        <td id=\"T_9749f_row8_col4\" class=\"data row8 col4\" >-0.318507</td>\n",
       "                        <td id=\"T_9749f_row8_col5\" class=\"data row8 col5\" >-0.279830</td>\n",
       "                        <td id=\"T_9749f_row8_col6\" class=\"data row8 col6\" >-0.328774</td>\n",
       "                        <td id=\"T_9749f_row8_col7\" class=\"data row8 col7\" >0.416091</td>\n",
       "                        <td id=\"T_9749f_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row8_col9\" class=\"data row8 col9\" >-0.101416</td>\n",
       "                        <td id=\"T_9749f_row8_col10\" class=\"data row8 col10\" >-0.130591</td>\n",
       "                        <td id=\"T_9749f_row8_col11\" class=\"data row8 col11\" >-0.260289</td>\n",
       "                        <td id=\"T_9749f_row8_col12\" class=\"data row8 col12\" >-0.335365</td>\n",
       "                        <td id=\"T_9749f_row8_col13\" class=\"data row8 col13\" >-0.144168</td>\n",
       "                        <td id=\"T_9749f_row8_col14\" class=\"data row8 col14\" >-0.083709</td>\n",
       "                        <td id=\"T_9749f_row8_col15\" class=\"data row8 col15\" >0.153393</td>\n",
       "                        <td id=\"T_9749f_row8_col16\" class=\"data row8 col16\" >0.187781</td>\n",
       "                        <td id=\"T_9749f_row8_col17\" class=\"data row8 col17\" >0.153393</td>\n",
       "                        <td id=\"T_9749f_row8_col18\" class=\"data row8 col18\" >0.187781</td>\n",
       "                        <td id=\"T_9749f_row8_col19\" class=\"data row8 col19\" >-0.119625</td>\n",
       "                        <td id=\"T_9749f_row8_col20\" class=\"data row8 col20\" >-0.130147</td>\n",
       "                        <td id=\"T_9749f_row8_col21\" class=\"data row8 col21\" >0.114647</td>\n",
       "                        <td id=\"T_9749f_row8_col22\" class=\"data row8 col22\" >0.092813</td>\n",
       "                        <td id=\"T_9749f_row8_col23\" class=\"data row8 col23\" >-0.289747</td>\n",
       "                        <td id=\"T_9749f_row8_col24\" class=\"data row8 col24\" >-0.343206</td>\n",
       "                        <td id=\"T_9749f_row8_col25\" class=\"data row8 col25\" >-0.297780</td>\n",
       "                        <td id=\"T_9749f_row8_col26\" class=\"data row8 col26\" >-0.323827</td>\n",
       "                        <td id=\"T_9749f_row8_col27\" class=\"data row8 col27\" >-0.295549</td>\n",
       "                        <td id=\"T_9749f_row8_col28\" class=\"data row8 col28\" >-0.327886</td>\n",
       "                        <td id=\"T_9749f_row8_col29\" class=\"data row8 col29\" >-0.298495</td>\n",
       "                        <td id=\"T_9749f_row8_col30\" class=\"data row8 col30\" >-0.324467</td>\n",
       "                        <td id=\"T_9749f_row8_col31\" class=\"data row8 col31\" >0.092737</td>\n",
       "                        <td id=\"T_9749f_row8_col32\" class=\"data row8 col32\" >0.107939</td>\n",
       "                        <td id=\"T_9749f_row8_col33\" class=\"data row8 col33\" >0.018867</td>\n",
       "                        <td id=\"T_9749f_row8_col34\" class=\"data row8 col34\" >0.051940</td>\n",
       "                        <td id=\"T_9749f_row8_col35\" class=\"data row8 col35\" >-0.102398</td>\n",
       "                        <td id=\"T_9749f_row8_col36\" class=\"data row8 col36\" >-0.209299</td>\n",
       "                        <td id=\"T_9749f_row8_col37\" class=\"data row8 col37\" >0.108632</td>\n",
       "                        <td id=\"T_9749f_row8_col38\" class=\"data row8 col38\" >0.156221</td>\n",
       "                        <td id=\"T_9749f_row8_col39\" class=\"data row8 col39\" >-0.143198</td>\n",
       "                        <td id=\"T_9749f_row8_col40\" class=\"data row8 col40\" >-0.233963</td>\n",
       "                        <td id=\"T_9749f_row8_col41\" class=\"data row8 col41\" >-0.298036</td>\n",
       "                        <td id=\"T_9749f_row8_col42\" class=\"data row8 col42\" >-0.331191</td>\n",
       "                        <td id=\"T_9749f_row8_col43\" class=\"data row8 col43\" >-0.063227</td>\n",
       "                        <td id=\"T_9749f_row8_col44\" class=\"data row8 col44\" >-0.169104</td>\n",
       "                        <td id=\"T_9749f_row8_col45\" class=\"data row8 col45\" >0.073138</td>\n",
       "                        <td id=\"T_9749f_row8_col46\" class=\"data row8 col46\" >0.180318</td>\n",
       "                        <td id=\"T_9749f_row8_col47\" class=\"data row8 col47\" >0.087761</td>\n",
       "                        <td id=\"T_9749f_row8_col48\" class=\"data row8 col48\" >0.108575</td>\n",
       "                        <td id=\"T_9749f_row8_col49\" class=\"data row8 col49\" >0.171085</td>\n",
       "                        <td id=\"T_9749f_row8_col50\" class=\"data row8 col50\" >0.172083</td>\n",
       "                        <td id=\"T_9749f_row8_col51\" class=\"data row8 col51\" >0.170157</td>\n",
       "                        <td id=\"T_9749f_row8_col52\" class=\"data row8 col52\" >0.171391</td>\n",
       "                        <td id=\"T_9749f_row8_col53\" class=\"data row8 col53\" >-0.018816</td>\n",
       "                        <td id=\"T_9749f_row8_col54\" class=\"data row8 col54\" >0.115505</td>\n",
       "                        <td id=\"T_9749f_row8_col55\" class=\"data row8 col55\" >-0.296761</td>\n",
       "                        <td id=\"T_9749f_row8_col56\" class=\"data row8 col56\" >-0.094218</td>\n",
       "                        <td id=\"T_9749f_row8_col57\" class=\"data row8 col57\" >0.003806</td>\n",
       "                        <td id=\"T_9749f_row8_col58\" class=\"data row8 col58\" >0.000865</td>\n",
       "                        <td id=\"T_9749f_row8_col59\" class=\"data row8 col59\" >-0.126563</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row9\" class=\"row_heading level0 row9\" >day_avg_sunhour</th>\n",
       "                        <td id=\"T_9749f_row9_col0\" class=\"data row9 col0\" >0.188191</td>\n",
       "                        <td id=\"T_9749f_row9_col1\" class=\"data row9 col1\" >0.309826</td>\n",
       "                        <td id=\"T_9749f_row9_col2\" class=\"data row9 col2\" >0.311138</td>\n",
       "                        <td id=\"T_9749f_row9_col3\" class=\"data row9 col3\" >0.606229</td>\n",
       "                        <td id=\"T_9749f_row9_col4\" class=\"data row9 col4\" >0.616277</td>\n",
       "                        <td id=\"T_9749f_row9_col5\" class=\"data row9 col5\" >0.328401</td>\n",
       "                        <td id=\"T_9749f_row9_col6\" class=\"data row9 col6\" >0.378477</td>\n",
       "                        <td id=\"T_9749f_row9_col7\" class=\"data row9 col7\" >-0.066769</td>\n",
       "                        <td id=\"T_9749f_row9_col8\" class=\"data row9 col8\" >-0.101416</td>\n",
       "                        <td id=\"T_9749f_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row9_col10\" class=\"data row9 col10\" >0.900249</td>\n",
       "                        <td id=\"T_9749f_row9_col11\" class=\"data row9 col11\" >0.621829</td>\n",
       "                        <td id=\"T_9749f_row9_col12\" class=\"data row9 col12\" >0.617899</td>\n",
       "                        <td id=\"T_9749f_row9_col13\" class=\"data row9 col13\" >0.000817</td>\n",
       "                        <td id=\"T_9749f_row9_col14\" class=\"data row9 col14\" >0.045993</td>\n",
       "                        <td id=\"T_9749f_row9_col15\" class=\"data row9 col15\" >-0.814917</td>\n",
       "                        <td id=\"T_9749f_row9_col16\" class=\"data row9 col16\" >-0.806576</td>\n",
       "                        <td id=\"T_9749f_row9_col17\" class=\"data row9 col17\" >-0.814917</td>\n",
       "                        <td id=\"T_9749f_row9_col18\" class=\"data row9 col18\" >-0.806576</td>\n",
       "                        <td id=\"T_9749f_row9_col19\" class=\"data row9 col19\" >0.828893</td>\n",
       "                        <td id=\"T_9749f_row9_col20\" class=\"data row9 col20\" >0.823043</td>\n",
       "                        <td id=\"T_9749f_row9_col21\" class=\"data row9 col21\" >0.007657</td>\n",
       "                        <td id=\"T_9749f_row9_col22\" class=\"data row9 col22\" >0.052959</td>\n",
       "                        <td id=\"T_9749f_row9_col23\" class=\"data row9 col23\" >0.337123</td>\n",
       "                        <td id=\"T_9749f_row9_col24\" class=\"data row9 col24\" >0.419947</td>\n",
       "                        <td id=\"T_9749f_row9_col25\" class=\"data row9 col25\" >0.518536</td>\n",
       "                        <td id=\"T_9749f_row9_col26\" class=\"data row9 col26\" >0.532105</td>\n",
       "                        <td id=\"T_9749f_row9_col27\" class=\"data row9 col27\" >0.468925</td>\n",
       "                        <td id=\"T_9749f_row9_col28\" class=\"data row9 col28\" >0.503759</td>\n",
       "                        <td id=\"T_9749f_row9_col29\" class=\"data row9 col29\" >0.518522</td>\n",
       "                        <td id=\"T_9749f_row9_col30\" class=\"data row9 col30\" >0.532424</td>\n",
       "                        <td id=\"T_9749f_row9_col31\" class=\"data row9 col31\" >-0.388742</td>\n",
       "                        <td id=\"T_9749f_row9_col32\" class=\"data row9 col32\" >-0.437007</td>\n",
       "                        <td id=\"T_9749f_row9_col33\" class=\"data row9 col33\" >-0.531756</td>\n",
       "                        <td id=\"T_9749f_row9_col34\" class=\"data row9 col34\" >-0.393922</td>\n",
       "                        <td id=\"T_9749f_row9_col35\" class=\"data row9 col35\" >-0.335275</td>\n",
       "                        <td id=\"T_9749f_row9_col36\" class=\"data row9 col36\" >-0.329134</td>\n",
       "                        <td id=\"T_9749f_row9_col37\" class=\"data row9 col37\" >-0.161127</td>\n",
       "                        <td id=\"T_9749f_row9_col38\" class=\"data row9 col38\" >-0.113745</td>\n",
       "                        <td id=\"T_9749f_row9_col39\" class=\"data row9 col39\" >0.318731</td>\n",
       "                        <td id=\"T_9749f_row9_col40\" class=\"data row9 col40\" >0.283044</td>\n",
       "                        <td id=\"T_9749f_row9_col41\" class=\"data row9 col41\" >0.469903</td>\n",
       "                        <td id=\"T_9749f_row9_col42\" class=\"data row9 col42\" >0.507836</td>\n",
       "                        <td id=\"T_9749f_row9_col43\" class=\"data row9 col43\" >0.360661</td>\n",
       "                        <td id=\"T_9749f_row9_col44\" class=\"data row9 col44\" >0.405250</td>\n",
       "                        <td id=\"T_9749f_row9_col45\" class=\"data row9 col45\" >-0.086475</td>\n",
       "                        <td id=\"T_9749f_row9_col46\" class=\"data row9 col46\" >-0.030465</td>\n",
       "                        <td id=\"T_9749f_row9_col47\" class=\"data row9 col47\" >-0.376343</td>\n",
       "                        <td id=\"T_9749f_row9_col48\" class=\"data row9 col48\" >-0.405076</td>\n",
       "                        <td id=\"T_9749f_row9_col49\" class=\"data row9 col49\" >-0.408320</td>\n",
       "                        <td id=\"T_9749f_row9_col50\" class=\"data row9 col50\" >-0.401215</td>\n",
       "                        <td id=\"T_9749f_row9_col51\" class=\"data row9 col51\" >-0.408132</td>\n",
       "                        <td id=\"T_9749f_row9_col52\" class=\"data row9 col52\" >-0.400295</td>\n",
       "                        <td id=\"T_9749f_row9_col53\" class=\"data row9 col53\" >-0.009252</td>\n",
       "                        <td id=\"T_9749f_row9_col54\" class=\"data row9 col54\" >0.417509</td>\n",
       "                        <td id=\"T_9749f_row9_col55\" class=\"data row9 col55\" >-0.197362</td>\n",
       "                        <td id=\"T_9749f_row9_col56\" class=\"data row9 col56\" >0.093434</td>\n",
       "                        <td id=\"T_9749f_row9_col57\" class=\"data row9 col57\" >0.000337</td>\n",
       "                        <td id=\"T_9749f_row9_col58\" class=\"data row9 col58\" >0.000175</td>\n",
       "                        <td id=\"T_9749f_row9_col59\" class=\"data row9 col59\" >0.380821</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row10\" class=\"row_heading level0 row10\" >week_avg_sunhour</th>\n",
       "                        <td id=\"T_9749f_row10_col0\" class=\"data row10 col0\" >0.205086</td>\n",
       "                        <td id=\"T_9749f_row10_col1\" class=\"data row10 col1\" >0.336090</td>\n",
       "                        <td id=\"T_9749f_row10_col2\" class=\"data row10 col2\" >0.349772</td>\n",
       "                        <td id=\"T_9749f_row10_col3\" class=\"data row10 col3\" >0.694063</td>\n",
       "                        <td id=\"T_9749f_row10_col4\" class=\"data row10 col4\" >0.714330</td>\n",
       "                        <td id=\"T_9749f_row10_col5\" class=\"data row10 col5\" >0.445027</td>\n",
       "                        <td id=\"T_9749f_row10_col6\" class=\"data row10 col6\" >0.452878</td>\n",
       "                        <td id=\"T_9749f_row10_col7\" class=\"data row10 col7\" >-0.077554</td>\n",
       "                        <td id=\"T_9749f_row10_col8\" class=\"data row10 col8\" >-0.130591</td>\n",
       "                        <td id=\"T_9749f_row10_col9\" class=\"data row10 col9\" >0.900249</td>\n",
       "                        <td id=\"T_9749f_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row10_col11\" class=\"data row10 col11\" >0.661551</td>\n",
       "                        <td id=\"T_9749f_row10_col12\" class=\"data row10 col12\" >0.729668</td>\n",
       "                        <td id=\"T_9749f_row10_col13\" class=\"data row10 col13\" >-0.054950</td>\n",
       "                        <td id=\"T_9749f_row10_col14\" class=\"data row10 col14\" >-0.004413</td>\n",
       "                        <td id=\"T_9749f_row10_col15\" class=\"data row10 col15\" >-0.892184</td>\n",
       "                        <td id=\"T_9749f_row10_col16\" class=\"data row10 col16\" >-0.885632</td>\n",
       "                        <td id=\"T_9749f_row10_col17\" class=\"data row10 col17\" >-0.892184</td>\n",
       "                        <td id=\"T_9749f_row10_col18\" class=\"data row10 col18\" >-0.885632</td>\n",
       "                        <td id=\"T_9749f_row10_col19\" class=\"data row10 col19\" >0.894288</td>\n",
       "                        <td id=\"T_9749f_row10_col20\" class=\"data row10 col20\" >0.897739</td>\n",
       "                        <td id=\"T_9749f_row10_col21\" class=\"data row10 col21\" >0.037669</td>\n",
       "                        <td id=\"T_9749f_row10_col22\" class=\"data row10 col22\" >0.041988</td>\n",
       "                        <td id=\"T_9749f_row10_col23\" class=\"data row10 col23\" >0.485657</td>\n",
       "                        <td id=\"T_9749f_row10_col24\" class=\"data row10 col24\" >0.497612</td>\n",
       "                        <td id=\"T_9749f_row10_col25\" class=\"data row10 col25\" >0.617685</td>\n",
       "                        <td id=\"T_9749f_row10_col26\" class=\"data row10 col26\" >0.623530</td>\n",
       "                        <td id=\"T_9749f_row10_col27\" class=\"data row10 col27\" >0.585576</td>\n",
       "                        <td id=\"T_9749f_row10_col28\" class=\"data row10 col28\" >0.590527</td>\n",
       "                        <td id=\"T_9749f_row10_col29\" class=\"data row10 col29\" >0.618431</td>\n",
       "                        <td id=\"T_9749f_row10_col30\" class=\"data row10 col30\" >0.623891</td>\n",
       "                        <td id=\"T_9749f_row10_col31\" class=\"data row10 col31\" >-0.304194</td>\n",
       "                        <td id=\"T_9749f_row10_col32\" class=\"data row10 col32\" >-0.497441</td>\n",
       "                        <td id=\"T_9749f_row10_col33\" class=\"data row10 col33\" >-0.267359</td>\n",
       "                        <td id=\"T_9749f_row10_col34\" class=\"data row10 col34\" >-0.491625</td>\n",
       "                        <td id=\"T_9749f_row10_col35\" class=\"data row10 col35\" >-0.174351</td>\n",
       "                        <td id=\"T_9749f_row10_col36\" class=\"data row10 col36\" >-0.350825</td>\n",
       "                        <td id=\"T_9749f_row10_col37\" class=\"data row10 col37\" >-0.031411</td>\n",
       "                        <td id=\"T_9749f_row10_col38\" class=\"data row10 col38\" >-0.107787</td>\n",
       "                        <td id=\"T_9749f_row10_col39\" class=\"data row10 col39\" >0.174199</td>\n",
       "                        <td id=\"T_9749f_row10_col40\" class=\"data row10 col40\" >0.299024</td>\n",
       "                        <td id=\"T_9749f_row10_col41\" class=\"data row10 col41\" >0.587275</td>\n",
       "                        <td id=\"T_9749f_row10_col42\" class=\"data row10 col42\" >0.594316</td>\n",
       "                        <td id=\"T_9749f_row10_col43\" class=\"data row10 col43\" >0.278283</td>\n",
       "                        <td id=\"T_9749f_row10_col44\" class=\"data row10 col44\" >0.431517</td>\n",
       "                        <td id=\"T_9749f_row10_col45\" class=\"data row10 col45\" >-0.045948</td>\n",
       "                        <td id=\"T_9749f_row10_col46\" class=\"data row10 col46\" >-0.079985</td>\n",
       "                        <td id=\"T_9749f_row10_col47\" class=\"data row10 col47\" >-0.282436</td>\n",
       "                        <td id=\"T_9749f_row10_col48\" class=\"data row10 col48\" >-0.466966</td>\n",
       "                        <td id=\"T_9749f_row10_col49\" class=\"data row10 col49\" >-0.474822</td>\n",
       "                        <td id=\"T_9749f_row10_col50\" class=\"data row10 col50\" >-0.464352</td>\n",
       "                        <td id=\"T_9749f_row10_col51\" class=\"data row10 col51\" >-0.474436</td>\n",
       "                        <td id=\"T_9749f_row10_col52\" class=\"data row10 col52\" >-0.463565</td>\n",
       "                        <td id=\"T_9749f_row10_col53\" class=\"data row10 col53\" >0.000403</td>\n",
       "                        <td id=\"T_9749f_row10_col54\" class=\"data row10 col54\" >0.437496</td>\n",
       "                        <td id=\"T_9749f_row10_col55\" class=\"data row10 col55\" >-0.174393</td>\n",
       "                        <td id=\"T_9749f_row10_col56\" class=\"data row10 col56\" >0.067824</td>\n",
       "                        <td id=\"T_9749f_row10_col57\" class=\"data row10 col57\" >0.000846</td>\n",
       "                        <td id=\"T_9749f_row10_col58\" class=\"data row10 col58\" >-0.000118</td>\n",
       "                        <td id=\"T_9749f_row10_col59\" class=\"data row10 col59\" >0.450651</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row11\" class=\"row_heading level0 row11\" >day_avg_uvindex</th>\n",
       "                        <td id=\"T_9749f_row11_col0\" class=\"data row11 col0\" >0.193354</td>\n",
       "                        <td id=\"T_9749f_row11_col1\" class=\"data row11 col1\" >0.329526</td>\n",
       "                        <td id=\"T_9749f_row11_col2\" class=\"data row11 col2\" >0.350469</td>\n",
       "                        <td id=\"T_9749f_row11_col3\" class=\"data row11 col3\" >0.874621</td>\n",
       "                        <td id=\"T_9749f_row11_col4\" class=\"data row11 col4\" >0.781366</td>\n",
       "                        <td id=\"T_9749f_row11_col5\" class=\"data row11 col5\" >0.733839</td>\n",
       "                        <td id=\"T_9749f_row11_col6\" class=\"data row11 col6\" >0.674645</td>\n",
       "                        <td id=\"T_9749f_row11_col7\" class=\"data row11 col7\" >-0.187128</td>\n",
       "                        <td id=\"T_9749f_row11_col8\" class=\"data row11 col8\" >-0.260289</td>\n",
       "                        <td id=\"T_9749f_row11_col9\" class=\"data row11 col9\" >0.621829</td>\n",
       "                        <td id=\"T_9749f_row11_col10\" class=\"data row11 col10\" >0.661551</td>\n",
       "                        <td id=\"T_9749f_row11_col11\" class=\"data row11 col11\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row11_col12\" class=\"data row11 col12\" >0.817387</td>\n",
       "                        <td id=\"T_9749f_row11_col13\" class=\"data row11 col13\" >-0.012424</td>\n",
       "                        <td id=\"T_9749f_row11_col14\" class=\"data row11 col14\" >0.040213</td>\n",
       "                        <td id=\"T_9749f_row11_col15\" class=\"data row11 col15\" >-0.654085</td>\n",
       "                        <td id=\"T_9749f_row11_col16\" class=\"data row11 col16\" >-0.669791</td>\n",
       "                        <td id=\"T_9749f_row11_col17\" class=\"data row11 col17\" >-0.654085</td>\n",
       "                        <td id=\"T_9749f_row11_col18\" class=\"data row11 col18\" >-0.669791</td>\n",
       "                        <td id=\"T_9749f_row11_col19\" class=\"data row11 col19\" >0.631564</td>\n",
       "                        <td id=\"T_9749f_row11_col20\" class=\"data row11 col20\" >0.650337</td>\n",
       "                        <td id=\"T_9749f_row11_col21\" class=\"data row11 col21\" >-0.035120</td>\n",
       "                        <td id=\"T_9749f_row11_col22\" class=\"data row11 col22\" >-0.015445</td>\n",
       "                        <td id=\"T_9749f_row11_col23\" class=\"data row11 col23\" >0.741697</td>\n",
       "                        <td id=\"T_9749f_row11_col24\" class=\"data row11 col24\" >0.691035</td>\n",
       "                        <td id=\"T_9749f_row11_col25\" class=\"data row11 col25\" >0.839721</td>\n",
       "                        <td id=\"T_9749f_row11_col26\" class=\"data row11 col26\" >0.746598</td>\n",
       "                        <td id=\"T_9749f_row11_col27\" class=\"data row11 col27\" >0.821105</td>\n",
       "                        <td id=\"T_9749f_row11_col28\" class=\"data row11 col28\" >0.739332</td>\n",
       "                        <td id=\"T_9749f_row11_col29\" class=\"data row11 col29\" >0.839167</td>\n",
       "                        <td id=\"T_9749f_row11_col30\" class=\"data row11 col30\" >0.746752</td>\n",
       "                        <td id=\"T_9749f_row11_col31\" class=\"data row11 col31\" >-0.248487</td>\n",
       "                        <td id=\"T_9749f_row11_col32\" class=\"data row11 col32\" >-0.321903</td>\n",
       "                        <td id=\"T_9749f_row11_col33\" class=\"data row11 col33\" >-0.277570</td>\n",
       "                        <td id=\"T_9749f_row11_col34\" class=\"data row11 col34\" >-0.290585</td>\n",
       "                        <td id=\"T_9749f_row11_col35\" class=\"data row11 col35\" >0.014442</td>\n",
       "                        <td id=\"T_9749f_row11_col36\" class=\"data row11 col36\" >-0.045763</td>\n",
       "                        <td id=\"T_9749f_row11_col37\" class=\"data row11 col37\" >-0.073706</td>\n",
       "                        <td id=\"T_9749f_row11_col38\" class=\"data row11 col38\" >-0.037779</td>\n",
       "                        <td id=\"T_9749f_row11_col39\" class=\"data row11 col39\" >0.215074</td>\n",
       "                        <td id=\"T_9749f_row11_col40\" class=\"data row11 col40\" >0.199720</td>\n",
       "                        <td id=\"T_9749f_row11_col41\" class=\"data row11 col41\" >0.821725</td>\n",
       "                        <td id=\"T_9749f_row11_col42\" class=\"data row11 col42\" >0.740950</td>\n",
       "                        <td id=\"T_9749f_row11_col43\" class=\"data row11 col43\" >0.109857</td>\n",
       "                        <td id=\"T_9749f_row11_col44\" class=\"data row11 col44\" >0.102803</td>\n",
       "                        <td id=\"T_9749f_row11_col45\" class=\"data row11 col45\" >-0.103099</td>\n",
       "                        <td id=\"T_9749f_row11_col46\" class=\"data row11 col46\" >-0.097689</td>\n",
       "                        <td id=\"T_9749f_row11_col47\" class=\"data row11 col47\" >-0.260608</td>\n",
       "                        <td id=\"T_9749f_row11_col48\" class=\"data row11 col48\" >-0.316297</td>\n",
       "                        <td id=\"T_9749f_row11_col49\" class=\"data row11 col49\" >-0.425295</td>\n",
       "                        <td id=\"T_9749f_row11_col50\" class=\"data row11 col50\" >-0.442816</td>\n",
       "                        <td id=\"T_9749f_row11_col51\" class=\"data row11 col51\" >-0.427006</td>\n",
       "                        <td id=\"T_9749f_row11_col52\" class=\"data row11 col52\" >-0.443274</td>\n",
       "                        <td id=\"T_9749f_row11_col53\" class=\"data row11 col53\" >0.001947</td>\n",
       "                        <td id=\"T_9749f_row11_col54\" class=\"data row11 col54\" >0.138374</td>\n",
       "                        <td id=\"T_9749f_row11_col55\" class=\"data row11 col55\" >0.171633</td>\n",
       "                        <td id=\"T_9749f_row11_col56\" class=\"data row11 col56\" >0.134628</td>\n",
       "                        <td id=\"T_9749f_row11_col57\" class=\"data row11 col57\" >0.002533</td>\n",
       "                        <td id=\"T_9749f_row11_col58\" class=\"data row11 col58\" >-0.000791</td>\n",
       "                        <td id=\"T_9749f_row11_col59\" class=\"data row11 col59\" >0.356827</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row12\" class=\"row_heading level0 row12\" >week_avg_uvindex</th>\n",
       "                        <td id=\"T_9749f_row12_col0\" class=\"data row12 col0\" >0.218208</td>\n",
       "                        <td id=\"T_9749f_row12_col1\" class=\"data row12 col1\" >0.360649</td>\n",
       "                        <td id=\"T_9749f_row12_col2\" class=\"data row12 col2\" >0.395077</td>\n",
       "                        <td id=\"T_9749f_row12_col3\" class=\"data row12 col3\" >0.845870</td>\n",
       "                        <td id=\"T_9749f_row12_col4\" class=\"data row12 col4\" >0.949715</td>\n",
       "                        <td id=\"T_9749f_row12_col5\" class=\"data row12 col5\" >0.747652</td>\n",
       "                        <td id=\"T_9749f_row12_col6\" class=\"data row12 col6\" >0.847447</td>\n",
       "                        <td id=\"T_9749f_row12_col7\" class=\"data row12 col7\" >-0.166102</td>\n",
       "                        <td id=\"T_9749f_row12_col8\" class=\"data row12 col8\" >-0.335365</td>\n",
       "                        <td id=\"T_9749f_row12_col9\" class=\"data row12 col9\" >0.617899</td>\n",
       "                        <td id=\"T_9749f_row12_col10\" class=\"data row12 col10\" >0.729668</td>\n",
       "                        <td id=\"T_9749f_row12_col11\" class=\"data row12 col11\" >0.817387</td>\n",
       "                        <td id=\"T_9749f_row12_col12\" class=\"data row12 col12\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row12_col13\" class=\"data row12 col13\" >-0.074713</td>\n",
       "                        <td id=\"T_9749f_row12_col14\" class=\"data row12 col14\" >-0.017838</td>\n",
       "                        <td id=\"T_9749f_row12_col15\" class=\"data row12 col15\" >-0.743217</td>\n",
       "                        <td id=\"T_9749f_row12_col16\" class=\"data row12 col16\" >-0.759207</td>\n",
       "                        <td id=\"T_9749f_row12_col17\" class=\"data row12 col17\" >-0.743217</td>\n",
       "                        <td id=\"T_9749f_row12_col18\" class=\"data row12 col18\" >-0.759207</td>\n",
       "                        <td id=\"T_9749f_row12_col19\" class=\"data row12 col19\" >0.695751</td>\n",
       "                        <td id=\"T_9749f_row12_col20\" class=\"data row12 col20\" >0.728233</td>\n",
       "                        <td id=\"T_9749f_row12_col21\" class=\"data row12 col21\" >-0.017987</td>\n",
       "                        <td id=\"T_9749f_row12_col22\" class=\"data row12 col22\" >-0.050409</td>\n",
       "                        <td id=\"T_9749f_row12_col23\" class=\"data row12 col23\" >0.769613</td>\n",
       "                        <td id=\"T_9749f_row12_col24\" class=\"data row12 col24\" >0.867535</td>\n",
       "                        <td id=\"T_9749f_row12_col25\" class=\"data row12 col25\" >0.843795</td>\n",
       "                        <td id=\"T_9749f_row12_col26\" class=\"data row12 col26\" >0.922402</td>\n",
       "                        <td id=\"T_9749f_row12_col27\" class=\"data row12 col27\" >0.835953</td>\n",
       "                        <td id=\"T_9749f_row12_col28\" class=\"data row12 col28\" >0.915889</td>\n",
       "                        <td id=\"T_9749f_row12_col29\" class=\"data row12 col29\" >0.844482</td>\n",
       "                        <td id=\"T_9749f_row12_col30\" class=\"data row12 col30\" >0.922558</td>\n",
       "                        <td id=\"T_9749f_row12_col31\" class=\"data row12 col31\" >-0.187346</td>\n",
       "                        <td id=\"T_9749f_row12_col32\" class=\"data row12 col32\" >-0.366776</td>\n",
       "                        <td id=\"T_9749f_row12_col33\" class=\"data row12 col33\" >-0.116951</td>\n",
       "                        <td id=\"T_9749f_row12_col34\" class=\"data row12 col34\" >-0.321047</td>\n",
       "                        <td id=\"T_9749f_row12_col35\" class=\"data row12 col35\" >0.045121</td>\n",
       "                        <td id=\"T_9749f_row12_col36\" class=\"data row12 col36\" >0.011464</td>\n",
       "                        <td id=\"T_9749f_row12_col37\" class=\"data row12 col37\" >0.043991</td>\n",
       "                        <td id=\"T_9749f_row12_col38\" class=\"data row12 col38\" >-0.027613</td>\n",
       "                        <td id=\"T_9749f_row12_col39\" class=\"data row12 col39\" >0.062820</td>\n",
       "                        <td id=\"T_9749f_row12_col40\" class=\"data row12 col40\" >0.194299</td>\n",
       "                        <td id=\"T_9749f_row12_col41\" class=\"data row12 col41\" >0.833228</td>\n",
       "                        <td id=\"T_9749f_row12_col42\" class=\"data row12 col42\" >0.917489</td>\n",
       "                        <td id=\"T_9749f_row12_col43\" class=\"data row12 col43\" >0.060933</td>\n",
       "                        <td id=\"T_9749f_row12_col44\" class=\"data row12 col44\" >0.110456</td>\n",
       "                        <td id=\"T_9749f_row12_col45\" class=\"data row12 col45\" >-0.000670</td>\n",
       "                        <td id=\"T_9749f_row12_col46\" class=\"data row12 col46\" >-0.079113</td>\n",
       "                        <td id=\"T_9749f_row12_col47\" class=\"data row12 col47\" >-0.172865</td>\n",
       "                        <td id=\"T_9749f_row12_col48\" class=\"data row12 col48\" >-0.360094</td>\n",
       "                        <td id=\"T_9749f_row12_col49\" class=\"data row12 col49\" >-0.506840</td>\n",
       "                        <td id=\"T_9749f_row12_col50\" class=\"data row12 col50\" >-0.518686</td>\n",
       "                        <td id=\"T_9749f_row12_col51\" class=\"data row12 col51\" >-0.508019</td>\n",
       "                        <td id=\"T_9749f_row12_col52\" class=\"data row12 col52\" >-0.519531</td>\n",
       "                        <td id=\"T_9749f_row12_col53\" class=\"data row12 col53\" >-0.014770</td>\n",
       "                        <td id=\"T_9749f_row12_col54\" class=\"data row12 col54\" >0.140796</td>\n",
       "                        <td id=\"T_9749f_row12_col55\" class=\"data row12 col55\" >0.242984</td>\n",
       "                        <td id=\"T_9749f_row12_col56\" class=\"data row12 col56\" >0.111912</td>\n",
       "                        <td id=\"T_9749f_row12_col57\" class=\"data row12 col57\" >0.002576</td>\n",
       "                        <td id=\"T_9749f_row12_col58\" class=\"data row12 col58\" >-0.000845</td>\n",
       "                        <td id=\"T_9749f_row12_col59\" class=\"data row12 col59\" >0.436885</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row13\" class=\"row_heading level0 row13\" >day_avg_moonillumination</th>\n",
       "                        <td id=\"T_9749f_row13_col0\" class=\"data row13 col0\" >-0.021305</td>\n",
       "                        <td id=\"T_9749f_row13_col1\" class=\"data row13 col1\" >-0.032049</td>\n",
       "                        <td id=\"T_9749f_row13_col2\" class=\"data row13 col2\" >0.000936</td>\n",
       "                        <td id=\"T_9749f_row13_col3\" class=\"data row13 col3\" >-0.011558</td>\n",
       "                        <td id=\"T_9749f_row13_col4\" class=\"data row13 col4\" >-0.072718</td>\n",
       "                        <td id=\"T_9749f_row13_col5\" class=\"data row13 col5\" >0.035097</td>\n",
       "                        <td id=\"T_9749f_row13_col6\" class=\"data row13 col6\" >-0.002655</td>\n",
       "                        <td id=\"T_9749f_row13_col7\" class=\"data row13 col7\" >-0.030214</td>\n",
       "                        <td id=\"T_9749f_row13_col8\" class=\"data row13 col8\" >-0.144168</td>\n",
       "                        <td id=\"T_9749f_row13_col9\" class=\"data row13 col9\" >0.000817</td>\n",
       "                        <td id=\"T_9749f_row13_col10\" class=\"data row13 col10\" >-0.054950</td>\n",
       "                        <td id=\"T_9749f_row13_col11\" class=\"data row13 col11\" >-0.012424</td>\n",
       "                        <td id=\"T_9749f_row13_col12\" class=\"data row13 col12\" >-0.074713</td>\n",
       "                        <td id=\"T_9749f_row13_col13\" class=\"data row13 col13\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row13_col14\" class=\"data row13 col14\" >0.768873</td>\n",
       "                        <td id=\"T_9749f_row13_col15\" class=\"data row13 col15\" >0.031936</td>\n",
       "                        <td id=\"T_9749f_row13_col16\" class=\"data row13 col16\" >0.028742</td>\n",
       "                        <td id=\"T_9749f_row13_col17\" class=\"data row13 col17\" >0.031936</td>\n",
       "                        <td id=\"T_9749f_row13_col18\" class=\"data row13 col18\" >0.028742</td>\n",
       "                        <td id=\"T_9749f_row13_col19\" class=\"data row13 col19\" >-0.028191</td>\n",
       "                        <td id=\"T_9749f_row13_col20\" class=\"data row13 col20\" >-0.013081</td>\n",
       "                        <td id=\"T_9749f_row13_col21\" class=\"data row13 col21\" >-0.105339</td>\n",
       "                        <td id=\"T_9749f_row13_col22\" class=\"data row13 col22\" >-0.204351</td>\n",
       "                        <td id=\"T_9749f_row13_col23\" class=\"data row13 col23\" >-0.008563</td>\n",
       "                        <td id=\"T_9749f_row13_col24\" class=\"data row13 col24\" >-0.061248</td>\n",
       "                        <td id=\"T_9749f_row13_col25\" class=\"data row13 col25\" >0.003023</td>\n",
       "                        <td id=\"T_9749f_row13_col26\" class=\"data row13 col26\" >-0.066019</td>\n",
       "                        <td id=\"T_9749f_row13_col27\" class=\"data row13 col27\" >0.002137</td>\n",
       "                        <td id=\"T_9749f_row13_col28\" class=\"data row13 col28\" >-0.044947</td>\n",
       "                        <td id=\"T_9749f_row13_col29\" class=\"data row13 col29\" >0.003355</td>\n",
       "                        <td id=\"T_9749f_row13_col30\" class=\"data row13 col30\" >-0.064837</td>\n",
       "                        <td id=\"T_9749f_row13_col31\" class=\"data row13 col31\" >-0.036909</td>\n",
       "                        <td id=\"T_9749f_row13_col32\" class=\"data row13 col32\" >0.143703</td>\n",
       "                        <td id=\"T_9749f_row13_col33\" class=\"data row13 col33\" >-0.044620</td>\n",
       "                        <td id=\"T_9749f_row13_col34\" class=\"data row13 col34\" >0.047104</td>\n",
       "                        <td id=\"T_9749f_row13_col35\" class=\"data row13 col35\" >-0.026697</td>\n",
       "                        <td id=\"T_9749f_row13_col36\" class=\"data row13 col36\" >-0.113556</td>\n",
       "                        <td id=\"T_9749f_row13_col37\" class=\"data row13 col37\" >-0.139370</td>\n",
       "                        <td id=\"T_9749f_row13_col38\" class=\"data row13 col38\" >-0.061847</td>\n",
       "                        <td id=\"T_9749f_row13_col39\" class=\"data row13 col39\" >0.140307</td>\n",
       "                        <td id=\"T_9749f_row13_col40\" class=\"data row13 col40\" >0.084360</td>\n",
       "                        <td id=\"T_9749f_row13_col41\" class=\"data row13 col41\" >0.006157</td>\n",
       "                        <td id=\"T_9749f_row13_col42\" class=\"data row13 col42\" >-0.040655</td>\n",
       "                        <td id=\"T_9749f_row13_col43\" class=\"data row13 col43\" >0.027925</td>\n",
       "                        <td id=\"T_9749f_row13_col44\" class=\"data row13 col44\" >-0.004548</td>\n",
       "                        <td id=\"T_9749f_row13_col45\" class=\"data row13 col45\" >-0.045648</td>\n",
       "                        <td id=\"T_9749f_row13_col46\" class=\"data row13 col46\" >-0.077759</td>\n",
       "                        <td id=\"T_9749f_row13_col47\" class=\"data row13 col47\" >-0.037230</td>\n",
       "                        <td id=\"T_9749f_row13_col48\" class=\"data row13 col48\" >0.160183</td>\n",
       "                        <td id=\"T_9749f_row13_col49\" class=\"data row13 col49\" >-0.005584</td>\n",
       "                        <td id=\"T_9749f_row13_col50\" class=\"data row13 col50\" >0.005652</td>\n",
       "                        <td id=\"T_9749f_row13_col51\" class=\"data row13 col51\" >-0.005551</td>\n",
       "                        <td id=\"T_9749f_row13_col52\" class=\"data row13 col52\" >0.005641</td>\n",
       "                        <td id=\"T_9749f_row13_col53\" class=\"data row13 col53\" >0.018411</td>\n",
       "                        <td id=\"T_9749f_row13_col54\" class=\"data row13 col54\" >-0.062421</td>\n",
       "                        <td id=\"T_9749f_row13_col55\" class=\"data row13 col55\" >0.080944</td>\n",
       "                        <td id=\"T_9749f_row13_col56\" class=\"data row13 col56\" >0.390340</td>\n",
       "                        <td id=\"T_9749f_row13_col57\" class=\"data row13 col57\" >-0.001658</td>\n",
       "                        <td id=\"T_9749f_row13_col58\" class=\"data row13 col58\" >0.000242</td>\n",
       "                        <td id=\"T_9749f_row13_col59\" class=\"data row13 col59\" >-0.006142</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row14\" class=\"row_heading level0 row14\" >week_avg_moonillumination</th>\n",
       "                        <td id=\"T_9749f_row14_col0\" class=\"data row14 col0\" >-0.040266</td>\n",
       "                        <td id=\"T_9749f_row14_col1\" class=\"data row14 col1\" >-0.063445</td>\n",
       "                        <td id=\"T_9749f_row14_col2\" class=\"data row14 col2\" >-0.037898</td>\n",
       "                        <td id=\"T_9749f_row14_col3\" class=\"data row14 col3\" >0.043751</td>\n",
       "                        <td id=\"T_9749f_row14_col4\" class=\"data row14 col4\" >-0.015772</td>\n",
       "                        <td id=\"T_9749f_row14_col5\" class=\"data row14 col5\" >0.043197</td>\n",
       "                        <td id=\"T_9749f_row14_col6\" class=\"data row14 col6\" >0.030744</td>\n",
       "                        <td id=\"T_9749f_row14_col7\" class=\"data row14 col7\" >0.003476</td>\n",
       "                        <td id=\"T_9749f_row14_col8\" class=\"data row14 col8\" >-0.083709</td>\n",
       "                        <td id=\"T_9749f_row14_col9\" class=\"data row14 col9\" >0.045993</td>\n",
       "                        <td id=\"T_9749f_row14_col10\" class=\"data row14 col10\" >-0.004413</td>\n",
       "                        <td id=\"T_9749f_row14_col11\" class=\"data row14 col11\" >0.040213</td>\n",
       "                        <td id=\"T_9749f_row14_col12\" class=\"data row14 col12\" >-0.017838</td>\n",
       "                        <td id=\"T_9749f_row14_col13\" class=\"data row14 col13\" >0.768873</td>\n",
       "                        <td id=\"T_9749f_row14_col14\" class=\"data row14 col14\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row14_col15\" class=\"data row14 col15\" >0.037029</td>\n",
       "                        <td id=\"T_9749f_row14_col16\" class=\"data row14 col16\" >0.034790</td>\n",
       "                        <td id=\"T_9749f_row14_col17\" class=\"data row14 col17\" >0.037029</td>\n",
       "                        <td id=\"T_9749f_row14_col18\" class=\"data row14 col18\" >0.034790</td>\n",
       "                        <td id=\"T_9749f_row14_col19\" class=\"data row14 col19\" >-0.053554</td>\n",
       "                        <td id=\"T_9749f_row14_col20\" class=\"data row14 col20\" >-0.033202</td>\n",
       "                        <td id=\"T_9749f_row14_col21\" class=\"data row14 col21\" >0.003062</td>\n",
       "                        <td id=\"T_9749f_row14_col22\" class=\"data row14 col22\" >-0.124243</td>\n",
       "                        <td id=\"T_9749f_row14_col23\" class=\"data row14 col23\" >0.029876</td>\n",
       "                        <td id=\"T_9749f_row14_col24\" class=\"data row14 col24\" >-0.016400</td>\n",
       "                        <td id=\"T_9749f_row14_col25\" class=\"data row14 col25\" >0.060915</td>\n",
       "                        <td id=\"T_9749f_row14_col26\" class=\"data row14 col26\" >-0.001810</td>\n",
       "                        <td id=\"T_9749f_row14_col27\" class=\"data row14 col27\" >0.033856</td>\n",
       "                        <td id=\"T_9749f_row14_col28\" class=\"data row14 col28\" >-0.003428</td>\n",
       "                        <td id=\"T_9749f_row14_col29\" class=\"data row14 col29\" >0.060380</td>\n",
       "                        <td id=\"T_9749f_row14_col30\" class=\"data row14 col30\" >-0.001409</td>\n",
       "                        <td id=\"T_9749f_row14_col31\" class=\"data row14 col31\" >-0.178721</td>\n",
       "                        <td id=\"T_9749f_row14_col32\" class=\"data row14 col32\" >-0.055288</td>\n",
       "                        <td id=\"T_9749f_row14_col33\" class=\"data row14 col33\" >-0.129667</td>\n",
       "                        <td id=\"T_9749f_row14_col34\" class=\"data row14 col34\" >-0.082974</td>\n",
       "                        <td id=\"T_9749f_row14_col35\" class=\"data row14 col35\" >0.022916</td>\n",
       "                        <td id=\"T_9749f_row14_col36\" class=\"data row14 col36\" >-0.051992</td>\n",
       "                        <td id=\"T_9749f_row14_col37\" class=\"data row14 col37\" >-0.199083</td>\n",
       "                        <td id=\"T_9749f_row14_col38\" class=\"data row14 col38\" >-0.205588</td>\n",
       "                        <td id=\"T_9749f_row14_col39\" class=\"data row14 col39\" >0.176687</td>\n",
       "                        <td id=\"T_9749f_row14_col40\" class=\"data row14 col40\" >0.178336</td>\n",
       "                        <td id=\"T_9749f_row14_col41\" class=\"data row14 col41\" >0.034541</td>\n",
       "                        <td id=\"T_9749f_row14_col42\" class=\"data row14 col42\" >0.000077</td>\n",
       "                        <td id=\"T_9749f_row14_col43\" class=\"data row14 col43\" >0.022773</td>\n",
       "                        <td id=\"T_9749f_row14_col44\" class=\"data row14 col44\" >0.022624</td>\n",
       "                        <td id=\"T_9749f_row14_col45\" class=\"data row14 col45\" >-0.055335</td>\n",
       "                        <td id=\"T_9749f_row14_col46\" class=\"data row14 col46\" >-0.083024</td>\n",
       "                        <td id=\"T_9749f_row14_col47\" class=\"data row14 col47\" >-0.193722</td>\n",
       "                        <td id=\"T_9749f_row14_col48\" class=\"data row14 col48\" >-0.058043</td>\n",
       "                        <td id=\"T_9749f_row14_col49\" class=\"data row14 col49\" >-0.033719</td>\n",
       "                        <td id=\"T_9749f_row14_col50\" class=\"data row14 col50\" >-0.011325</td>\n",
       "                        <td id=\"T_9749f_row14_col51\" class=\"data row14 col51\" >-0.033740</td>\n",
       "                        <td id=\"T_9749f_row14_col52\" class=\"data row14 col52\" >-0.011322</td>\n",
       "                        <td id=\"T_9749f_row14_col53\" class=\"data row14 col53\" >0.062022</td>\n",
       "                        <td id=\"T_9749f_row14_col54\" class=\"data row14 col54\" >-0.068182</td>\n",
       "                        <td id=\"T_9749f_row14_col55\" class=\"data row14 col55\" >0.069669</td>\n",
       "                        <td id=\"T_9749f_row14_col56\" class=\"data row14 col56\" >0.597306</td>\n",
       "                        <td id=\"T_9749f_row14_col57\" class=\"data row14 col57\" >-0.003034</td>\n",
       "                        <td id=\"T_9749f_row14_col58\" class=\"data row14 col58\" >-0.000047</td>\n",
       "                        <td id=\"T_9749f_row14_col59\" class=\"data row14 col59\" >0.019234</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row15\" class=\"row_heading level0 row15\" >day_avg_sunrise_hr</th>\n",
       "                        <td id=\"T_9749f_row15_col0\" class=\"data row15 col0\" >-0.293742</td>\n",
       "                        <td id=\"T_9749f_row15_col1\" class=\"data row15 col1\" >-0.480405</td>\n",
       "                        <td id=\"T_9749f_row15_col2\" class=\"data row15 col2\" >-0.501881</td>\n",
       "                        <td id=\"T_9749f_row15_col3\" class=\"data row15 col3\" >-0.722733</td>\n",
       "                        <td id=\"T_9749f_row15_col4\" class=\"data row15 col4\" >-0.769977</td>\n",
       "                        <td id=\"T_9749f_row15_col5\" class=\"data row15 col5\" >-0.523234</td>\n",
       "                        <td id=\"T_9749f_row15_col6\" class=\"data row15 col6\" >-0.561754</td>\n",
       "                        <td id=\"T_9749f_row15_col7\" class=\"data row15 col7\" >0.099517</td>\n",
       "                        <td id=\"T_9749f_row15_col8\" class=\"data row15 col8\" >0.153393</td>\n",
       "                        <td id=\"T_9749f_row15_col9\" class=\"data row15 col9\" >-0.814917</td>\n",
       "                        <td id=\"T_9749f_row15_col10\" class=\"data row15 col10\" >-0.892184</td>\n",
       "                        <td id=\"T_9749f_row15_col11\" class=\"data row15 col11\" >-0.654085</td>\n",
       "                        <td id=\"T_9749f_row15_col12\" class=\"data row15 col12\" >-0.743217</td>\n",
       "                        <td id=\"T_9749f_row15_col13\" class=\"data row15 col13\" >0.031936</td>\n",
       "                        <td id=\"T_9749f_row15_col14\" class=\"data row15 col14\" >0.037029</td>\n",
       "                        <td id=\"T_9749f_row15_col15\" class=\"data row15 col15\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row15_col16\" class=\"data row15 col16\" >0.990597</td>\n",
       "                        <td id=\"T_9749f_row15_col17\" class=\"data row15 col17\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row15_col18\" class=\"data row15 col18\" >0.990597</td>\n",
       "                        <td id=\"T_9749f_row15_col19\" class=\"data row15 col19\" >-0.952077</td>\n",
       "                        <td id=\"T_9749f_row15_col20\" class=\"data row15 col20\" >-0.963097</td>\n",
       "                        <td id=\"T_9749f_row15_col21\" class=\"data row15 col21\" >-0.064769</td>\n",
       "                        <td id=\"T_9749f_row15_col22\" class=\"data row15 col22\" >-0.059615</td>\n",
       "                        <td id=\"T_9749f_row15_col23\" class=\"data row15 col23\" >-0.570262</td>\n",
       "                        <td id=\"T_9749f_row15_col24\" class=\"data row15 col24\" >-0.620255</td>\n",
       "                        <td id=\"T_9749f_row15_col25\" class=\"data row15 col25\" >-0.672105</td>\n",
       "                        <td id=\"T_9749f_row15_col26\" class=\"data row15 col26\" >-0.705108</td>\n",
       "                        <td id=\"T_9749f_row15_col27\" class=\"data row15 col27\" >-0.649866</td>\n",
       "                        <td id=\"T_9749f_row15_col28\" class=\"data row15 col28\" >-0.685571</td>\n",
       "                        <td id=\"T_9749f_row15_col29\" class=\"data row15 col29\" >-0.673291</td>\n",
       "                        <td id=\"T_9749f_row15_col30\" class=\"data row15 col30\" >-0.706011</td>\n",
       "                        <td id=\"T_9749f_row15_col31\" class=\"data row15 col31\" >0.261753</td>\n",
       "                        <td id=\"T_9749f_row15_col32\" class=\"data row15 col32\" >0.418366</td>\n",
       "                        <td id=\"T_9749f_row15_col33\" class=\"data row15 col33\" >0.123180</td>\n",
       "                        <td id=\"T_9749f_row15_col34\" class=\"data row15 col34\" >0.239474</td>\n",
       "                        <td id=\"T_9749f_row15_col35\" class=\"data row15 col35\" >0.091333</td>\n",
       "                        <td id=\"T_9749f_row15_col36\" class=\"data row15 col36\" >0.191880</td>\n",
       "                        <td id=\"T_9749f_row15_col37\" class=\"data row15 col37\" >-0.067234</td>\n",
       "                        <td id=\"T_9749f_row15_col38\" class=\"data row15 col38\" >-0.093172</td>\n",
       "                        <td id=\"T_9749f_row15_col39\" class=\"data row15 col39\" >-0.066671</td>\n",
       "                        <td id=\"T_9749f_row15_col40\" class=\"data row15 col40\" >-0.097111</td>\n",
       "                        <td id=\"T_9749f_row15_col41\" class=\"data row15 col41\" >-0.649983</td>\n",
       "                        <td id=\"T_9749f_row15_col42\" class=\"data row15 col42\" >-0.687823</td>\n",
       "                        <td id=\"T_9749f_row15_col43\" class=\"data row15 col43\" >-0.304175</td>\n",
       "                        <td id=\"T_9749f_row15_col44\" class=\"data row15 col44\" >-0.443746</td>\n",
       "                        <td id=\"T_9749f_row15_col45\" class=\"data row15 col45\" >0.003278</td>\n",
       "                        <td id=\"T_9749f_row15_col46\" class=\"data row15 col46\" >0.009601</td>\n",
       "                        <td id=\"T_9749f_row15_col47\" class=\"data row15 col47\" >0.233342</td>\n",
       "                        <td id=\"T_9749f_row15_col48\" class=\"data row15 col48\" >0.380312</td>\n",
       "                        <td id=\"T_9749f_row15_col49\" class=\"data row15 col49\" >0.329995</td>\n",
       "                        <td id=\"T_9749f_row15_col50\" class=\"data row15 col50\" >0.321434</td>\n",
       "                        <td id=\"T_9749f_row15_col51\" class=\"data row15 col51\" >0.329282</td>\n",
       "                        <td id=\"T_9749f_row15_col52\" class=\"data row15 col52\" >0.320497</td>\n",
       "                        <td id=\"T_9749f_row15_col53\" class=\"data row15 col53\" >0.009244</td>\n",
       "                        <td id=\"T_9749f_row15_col54\" class=\"data row15 col54\" >-0.455164</td>\n",
       "                        <td id=\"T_9749f_row15_col55\" class=\"data row15 col55\" >0.095349</td>\n",
       "                        <td id=\"T_9749f_row15_col56\" class=\"data row15 col56\" >-0.016715</td>\n",
       "                        <td id=\"T_9749f_row15_col57\" class=\"data row15 col57\" >-0.000840</td>\n",
       "                        <td id=\"T_9749f_row15_col58\" class=\"data row15 col58\" >0.000031</td>\n",
       "                        <td id=\"T_9749f_row15_col59\" class=\"data row15 col59\" >-0.239723</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row16\" class=\"row_heading level0 row16\" >week_avg_sunrise_hr</th>\n",
       "                        <td id=\"T_9749f_row16_col0\" class=\"data row16 col0\" >-0.306035</td>\n",
       "                        <td id=\"T_9749f_row16_col1\" class=\"data row16 col1\" >-0.501050</td>\n",
       "                        <td id=\"T_9749f_row16_col2\" class=\"data row16 col2\" >-0.524205</td>\n",
       "                        <td id=\"T_9749f_row16_col3\" class=\"data row16 col3\" >-0.739911</td>\n",
       "                        <td id=\"T_9749f_row16_col4\" class=\"data row16 col4\" >-0.787543</td>\n",
       "                        <td id=\"T_9749f_row16_col5\" class=\"data row16 col5\" >-0.548903</td>\n",
       "                        <td id=\"T_9749f_row16_col6\" class=\"data row16 col6\" >-0.593415</td>\n",
       "                        <td id=\"T_9749f_row16_col7\" class=\"data row16 col7\" >0.101388</td>\n",
       "                        <td id=\"T_9749f_row16_col8\" class=\"data row16 col8\" >0.187781</td>\n",
       "                        <td id=\"T_9749f_row16_col9\" class=\"data row16 col9\" >-0.806576</td>\n",
       "                        <td id=\"T_9749f_row16_col10\" class=\"data row16 col10\" >-0.885632</td>\n",
       "                        <td id=\"T_9749f_row16_col11\" class=\"data row16 col11\" >-0.669791</td>\n",
       "                        <td id=\"T_9749f_row16_col12\" class=\"data row16 col12\" >-0.759207</td>\n",
       "                        <td id=\"T_9749f_row16_col13\" class=\"data row16 col13\" >0.028742</td>\n",
       "                        <td id=\"T_9749f_row16_col14\" class=\"data row16 col14\" >0.034790</td>\n",
       "                        <td id=\"T_9749f_row16_col15\" class=\"data row16 col15\" >0.990597</td>\n",
       "                        <td id=\"T_9749f_row16_col16\" class=\"data row16 col16\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row16_col17\" class=\"data row16 col17\" >0.990597</td>\n",
       "                        <td id=\"T_9749f_row16_col18\" class=\"data row16 col18\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row16_col19\" class=\"data row16 col19\" >-0.947921</td>\n",
       "                        <td id=\"T_9749f_row16_col20\" class=\"data row16 col20\" >-0.961468</td>\n",
       "                        <td id=\"T_9749f_row16_col21\" class=\"data row16 col21\" >-0.064238</td>\n",
       "                        <td id=\"T_9749f_row16_col22\" class=\"data row16 col22\" >-0.065569</td>\n",
       "                        <td id=\"T_9749f_row16_col23\" class=\"data row16 col23\" >-0.595268</td>\n",
       "                        <td id=\"T_9749f_row16_col24\" class=\"data row16 col24\" >-0.650759</td>\n",
       "                        <td id=\"T_9749f_row16_col25\" class=\"data row16 col25\" >-0.692988</td>\n",
       "                        <td id=\"T_9749f_row16_col26\" class=\"data row16 col26\" >-0.728067</td>\n",
       "                        <td id=\"T_9749f_row16_col27\" class=\"data row16 col27\" >-0.673755</td>\n",
       "                        <td id=\"T_9749f_row16_col28\" class=\"data row16 col28\" >-0.711668</td>\n",
       "                        <td id=\"T_9749f_row16_col29\" class=\"data row16 col29\" >-0.694089</td>\n",
       "                        <td id=\"T_9749f_row16_col30\" class=\"data row16 col30\" >-0.728984</td>\n",
       "                        <td id=\"T_9749f_row16_col31\" class=\"data row16 col31\" >0.253043</td>\n",
       "                        <td id=\"T_9749f_row16_col32\" class=\"data row16 col32\" >0.406900</td>\n",
       "                        <td id=\"T_9749f_row16_col33\" class=\"data row16 col33\" >0.110452</td>\n",
       "                        <td id=\"T_9749f_row16_col34\" class=\"data row16 col34\" >0.209096</td>\n",
       "                        <td id=\"T_9749f_row16_col35\" class=\"data row16 col35\" >0.078978</td>\n",
       "                        <td id=\"T_9749f_row16_col36\" class=\"data row16 col36\" >0.162840</td>\n",
       "                        <td id=\"T_9749f_row16_col37\" class=\"data row16 col37\" >-0.077334</td>\n",
       "                        <td id=\"T_9749f_row16_col38\" class=\"data row16 col38\" >-0.104700</td>\n",
       "                        <td id=\"T_9749f_row16_col39\" class=\"data row16 col39\" >-0.063610</td>\n",
       "                        <td id=\"T_9749f_row16_col40\" class=\"data row16 col40\" >-0.088216</td>\n",
       "                        <td id=\"T_9749f_row16_col41\" class=\"data row16 col41\" >-0.673082</td>\n",
       "                        <td id=\"T_9749f_row16_col42\" class=\"data row16 col42\" >-0.713628</td>\n",
       "                        <td id=\"T_9749f_row16_col43\" class=\"data row16 col43\" >-0.281719</td>\n",
       "                        <td id=\"T_9749f_row16_col44\" class=\"data row16 col44\" >-0.430739</td>\n",
       "                        <td id=\"T_9749f_row16_col45\" class=\"data row16 col45\" >0.011990</td>\n",
       "                        <td id=\"T_9749f_row16_col46\" class=\"data row16 col46\" >0.018361</td>\n",
       "                        <td id=\"T_9749f_row16_col47\" class=\"data row16 col47\" >0.224252</td>\n",
       "                        <td id=\"T_9749f_row16_col48\" class=\"data row16 col48\" >0.365754</td>\n",
       "                        <td id=\"T_9749f_row16_col49\" class=\"data row16 col49\" >0.351464</td>\n",
       "                        <td id=\"T_9749f_row16_col50\" class=\"data row16 col50\" >0.344027</td>\n",
       "                        <td id=\"T_9749f_row16_col51\" class=\"data row16 col51\" >0.350775</td>\n",
       "                        <td id=\"T_9749f_row16_col52\" class=\"data row16 col52\" >0.343062</td>\n",
       "                        <td id=\"T_9749f_row16_col53\" class=\"data row16 col53\" >0.009930</td>\n",
       "                        <td id=\"T_9749f_row16_col54\" class=\"data row16 col54\" >-0.436862</td>\n",
       "                        <td id=\"T_9749f_row16_col55\" class=\"data row16 col55\" >0.053171</td>\n",
       "                        <td id=\"T_9749f_row16_col56\" class=\"data row16 col56\" >-0.043117</td>\n",
       "                        <td id=\"T_9749f_row16_col57\" class=\"data row16 col57\" >-0.000566</td>\n",
       "                        <td id=\"T_9749f_row16_col58\" class=\"data row16 col58\" >0.000146</td>\n",
       "                        <td id=\"T_9749f_row16_col59\" class=\"data row16 col59\" >-0.253482</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row17\" class=\"row_heading level0 row17\" >day_avg_sunrise_min</th>\n",
       "                        <td id=\"T_9749f_row17_col0\" class=\"data row17 col0\" >-0.293742</td>\n",
       "                        <td id=\"T_9749f_row17_col1\" class=\"data row17 col1\" >-0.480405</td>\n",
       "                        <td id=\"T_9749f_row17_col2\" class=\"data row17 col2\" >-0.501881</td>\n",
       "                        <td id=\"T_9749f_row17_col3\" class=\"data row17 col3\" >-0.722733</td>\n",
       "                        <td id=\"T_9749f_row17_col4\" class=\"data row17 col4\" >-0.769977</td>\n",
       "                        <td id=\"T_9749f_row17_col5\" class=\"data row17 col5\" >-0.523234</td>\n",
       "                        <td id=\"T_9749f_row17_col6\" class=\"data row17 col6\" >-0.561754</td>\n",
       "                        <td id=\"T_9749f_row17_col7\" class=\"data row17 col7\" >0.099517</td>\n",
       "                        <td id=\"T_9749f_row17_col8\" class=\"data row17 col8\" >0.153393</td>\n",
       "                        <td id=\"T_9749f_row17_col9\" class=\"data row17 col9\" >-0.814917</td>\n",
       "                        <td id=\"T_9749f_row17_col10\" class=\"data row17 col10\" >-0.892184</td>\n",
       "                        <td id=\"T_9749f_row17_col11\" class=\"data row17 col11\" >-0.654085</td>\n",
       "                        <td id=\"T_9749f_row17_col12\" class=\"data row17 col12\" >-0.743217</td>\n",
       "                        <td id=\"T_9749f_row17_col13\" class=\"data row17 col13\" >0.031936</td>\n",
       "                        <td id=\"T_9749f_row17_col14\" class=\"data row17 col14\" >0.037029</td>\n",
       "                        <td id=\"T_9749f_row17_col15\" class=\"data row17 col15\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row17_col16\" class=\"data row17 col16\" >0.990597</td>\n",
       "                        <td id=\"T_9749f_row17_col17\" class=\"data row17 col17\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row17_col18\" class=\"data row17 col18\" >0.990597</td>\n",
       "                        <td id=\"T_9749f_row17_col19\" class=\"data row17 col19\" >-0.952077</td>\n",
       "                        <td id=\"T_9749f_row17_col20\" class=\"data row17 col20\" >-0.963097</td>\n",
       "                        <td id=\"T_9749f_row17_col21\" class=\"data row17 col21\" >-0.064769</td>\n",
       "                        <td id=\"T_9749f_row17_col22\" class=\"data row17 col22\" >-0.059615</td>\n",
       "                        <td id=\"T_9749f_row17_col23\" class=\"data row17 col23\" >-0.570262</td>\n",
       "                        <td id=\"T_9749f_row17_col24\" class=\"data row17 col24\" >-0.620255</td>\n",
       "                        <td id=\"T_9749f_row17_col25\" class=\"data row17 col25\" >-0.672105</td>\n",
       "                        <td id=\"T_9749f_row17_col26\" class=\"data row17 col26\" >-0.705108</td>\n",
       "                        <td id=\"T_9749f_row17_col27\" class=\"data row17 col27\" >-0.649866</td>\n",
       "                        <td id=\"T_9749f_row17_col28\" class=\"data row17 col28\" >-0.685571</td>\n",
       "                        <td id=\"T_9749f_row17_col29\" class=\"data row17 col29\" >-0.673291</td>\n",
       "                        <td id=\"T_9749f_row17_col30\" class=\"data row17 col30\" >-0.706011</td>\n",
       "                        <td id=\"T_9749f_row17_col31\" class=\"data row17 col31\" >0.261753</td>\n",
       "                        <td id=\"T_9749f_row17_col32\" class=\"data row17 col32\" >0.418366</td>\n",
       "                        <td id=\"T_9749f_row17_col33\" class=\"data row17 col33\" >0.123180</td>\n",
       "                        <td id=\"T_9749f_row17_col34\" class=\"data row17 col34\" >0.239474</td>\n",
       "                        <td id=\"T_9749f_row17_col35\" class=\"data row17 col35\" >0.091333</td>\n",
       "                        <td id=\"T_9749f_row17_col36\" class=\"data row17 col36\" >0.191880</td>\n",
       "                        <td id=\"T_9749f_row17_col37\" class=\"data row17 col37\" >-0.067234</td>\n",
       "                        <td id=\"T_9749f_row17_col38\" class=\"data row17 col38\" >-0.093172</td>\n",
       "                        <td id=\"T_9749f_row17_col39\" class=\"data row17 col39\" >-0.066671</td>\n",
       "                        <td id=\"T_9749f_row17_col40\" class=\"data row17 col40\" >-0.097111</td>\n",
       "                        <td id=\"T_9749f_row17_col41\" class=\"data row17 col41\" >-0.649983</td>\n",
       "                        <td id=\"T_9749f_row17_col42\" class=\"data row17 col42\" >-0.687823</td>\n",
       "                        <td id=\"T_9749f_row17_col43\" class=\"data row17 col43\" >-0.304175</td>\n",
       "                        <td id=\"T_9749f_row17_col44\" class=\"data row17 col44\" >-0.443746</td>\n",
       "                        <td id=\"T_9749f_row17_col45\" class=\"data row17 col45\" >0.003278</td>\n",
       "                        <td id=\"T_9749f_row17_col46\" class=\"data row17 col46\" >0.009601</td>\n",
       "                        <td id=\"T_9749f_row17_col47\" class=\"data row17 col47\" >0.233342</td>\n",
       "                        <td id=\"T_9749f_row17_col48\" class=\"data row17 col48\" >0.380312</td>\n",
       "                        <td id=\"T_9749f_row17_col49\" class=\"data row17 col49\" >0.329995</td>\n",
       "                        <td id=\"T_9749f_row17_col50\" class=\"data row17 col50\" >0.321434</td>\n",
       "                        <td id=\"T_9749f_row17_col51\" class=\"data row17 col51\" >0.329282</td>\n",
       "                        <td id=\"T_9749f_row17_col52\" class=\"data row17 col52\" >0.320497</td>\n",
       "                        <td id=\"T_9749f_row17_col53\" class=\"data row17 col53\" >0.009244</td>\n",
       "                        <td id=\"T_9749f_row17_col54\" class=\"data row17 col54\" >-0.455164</td>\n",
       "                        <td id=\"T_9749f_row17_col55\" class=\"data row17 col55\" >0.095349</td>\n",
       "                        <td id=\"T_9749f_row17_col56\" class=\"data row17 col56\" >-0.016715</td>\n",
       "                        <td id=\"T_9749f_row17_col57\" class=\"data row17 col57\" >-0.000840</td>\n",
       "                        <td id=\"T_9749f_row17_col58\" class=\"data row17 col58\" >0.000031</td>\n",
       "                        <td id=\"T_9749f_row17_col59\" class=\"data row17 col59\" >-0.239723</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row18\" class=\"row_heading level0 row18\" >week_avg_sunrise_min</th>\n",
       "                        <td id=\"T_9749f_row18_col0\" class=\"data row18 col0\" >-0.306035</td>\n",
       "                        <td id=\"T_9749f_row18_col1\" class=\"data row18 col1\" >-0.501050</td>\n",
       "                        <td id=\"T_9749f_row18_col2\" class=\"data row18 col2\" >-0.524205</td>\n",
       "                        <td id=\"T_9749f_row18_col3\" class=\"data row18 col3\" >-0.739911</td>\n",
       "                        <td id=\"T_9749f_row18_col4\" class=\"data row18 col4\" >-0.787543</td>\n",
       "                        <td id=\"T_9749f_row18_col5\" class=\"data row18 col5\" >-0.548903</td>\n",
       "                        <td id=\"T_9749f_row18_col6\" class=\"data row18 col6\" >-0.593415</td>\n",
       "                        <td id=\"T_9749f_row18_col7\" class=\"data row18 col7\" >0.101388</td>\n",
       "                        <td id=\"T_9749f_row18_col8\" class=\"data row18 col8\" >0.187781</td>\n",
       "                        <td id=\"T_9749f_row18_col9\" class=\"data row18 col9\" >-0.806576</td>\n",
       "                        <td id=\"T_9749f_row18_col10\" class=\"data row18 col10\" >-0.885632</td>\n",
       "                        <td id=\"T_9749f_row18_col11\" class=\"data row18 col11\" >-0.669791</td>\n",
       "                        <td id=\"T_9749f_row18_col12\" class=\"data row18 col12\" >-0.759207</td>\n",
       "                        <td id=\"T_9749f_row18_col13\" class=\"data row18 col13\" >0.028742</td>\n",
       "                        <td id=\"T_9749f_row18_col14\" class=\"data row18 col14\" >0.034790</td>\n",
       "                        <td id=\"T_9749f_row18_col15\" class=\"data row18 col15\" >0.990597</td>\n",
       "                        <td id=\"T_9749f_row18_col16\" class=\"data row18 col16\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row18_col17\" class=\"data row18 col17\" >0.990597</td>\n",
       "                        <td id=\"T_9749f_row18_col18\" class=\"data row18 col18\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row18_col19\" class=\"data row18 col19\" >-0.947921</td>\n",
       "                        <td id=\"T_9749f_row18_col20\" class=\"data row18 col20\" >-0.961468</td>\n",
       "                        <td id=\"T_9749f_row18_col21\" class=\"data row18 col21\" >-0.064238</td>\n",
       "                        <td id=\"T_9749f_row18_col22\" class=\"data row18 col22\" >-0.065569</td>\n",
       "                        <td id=\"T_9749f_row18_col23\" class=\"data row18 col23\" >-0.595268</td>\n",
       "                        <td id=\"T_9749f_row18_col24\" class=\"data row18 col24\" >-0.650759</td>\n",
       "                        <td id=\"T_9749f_row18_col25\" class=\"data row18 col25\" >-0.692988</td>\n",
       "                        <td id=\"T_9749f_row18_col26\" class=\"data row18 col26\" >-0.728067</td>\n",
       "                        <td id=\"T_9749f_row18_col27\" class=\"data row18 col27\" >-0.673755</td>\n",
       "                        <td id=\"T_9749f_row18_col28\" class=\"data row18 col28\" >-0.711668</td>\n",
       "                        <td id=\"T_9749f_row18_col29\" class=\"data row18 col29\" >-0.694089</td>\n",
       "                        <td id=\"T_9749f_row18_col30\" class=\"data row18 col30\" >-0.728984</td>\n",
       "                        <td id=\"T_9749f_row18_col31\" class=\"data row18 col31\" >0.253043</td>\n",
       "                        <td id=\"T_9749f_row18_col32\" class=\"data row18 col32\" >0.406900</td>\n",
       "                        <td id=\"T_9749f_row18_col33\" class=\"data row18 col33\" >0.110452</td>\n",
       "                        <td id=\"T_9749f_row18_col34\" class=\"data row18 col34\" >0.209096</td>\n",
       "                        <td id=\"T_9749f_row18_col35\" class=\"data row18 col35\" >0.078978</td>\n",
       "                        <td id=\"T_9749f_row18_col36\" class=\"data row18 col36\" >0.162840</td>\n",
       "                        <td id=\"T_9749f_row18_col37\" class=\"data row18 col37\" >-0.077334</td>\n",
       "                        <td id=\"T_9749f_row18_col38\" class=\"data row18 col38\" >-0.104700</td>\n",
       "                        <td id=\"T_9749f_row18_col39\" class=\"data row18 col39\" >-0.063610</td>\n",
       "                        <td id=\"T_9749f_row18_col40\" class=\"data row18 col40\" >-0.088216</td>\n",
       "                        <td id=\"T_9749f_row18_col41\" class=\"data row18 col41\" >-0.673082</td>\n",
       "                        <td id=\"T_9749f_row18_col42\" class=\"data row18 col42\" >-0.713628</td>\n",
       "                        <td id=\"T_9749f_row18_col43\" class=\"data row18 col43\" >-0.281719</td>\n",
       "                        <td id=\"T_9749f_row18_col44\" class=\"data row18 col44\" >-0.430739</td>\n",
       "                        <td id=\"T_9749f_row18_col45\" class=\"data row18 col45\" >0.011990</td>\n",
       "                        <td id=\"T_9749f_row18_col46\" class=\"data row18 col46\" >0.018361</td>\n",
       "                        <td id=\"T_9749f_row18_col47\" class=\"data row18 col47\" >0.224252</td>\n",
       "                        <td id=\"T_9749f_row18_col48\" class=\"data row18 col48\" >0.365754</td>\n",
       "                        <td id=\"T_9749f_row18_col49\" class=\"data row18 col49\" >0.351464</td>\n",
       "                        <td id=\"T_9749f_row18_col50\" class=\"data row18 col50\" >0.344027</td>\n",
       "                        <td id=\"T_9749f_row18_col51\" class=\"data row18 col51\" >0.350775</td>\n",
       "                        <td id=\"T_9749f_row18_col52\" class=\"data row18 col52\" >0.343062</td>\n",
       "                        <td id=\"T_9749f_row18_col53\" class=\"data row18 col53\" >0.009930</td>\n",
       "                        <td id=\"T_9749f_row18_col54\" class=\"data row18 col54\" >-0.436862</td>\n",
       "                        <td id=\"T_9749f_row18_col55\" class=\"data row18 col55\" >0.053171</td>\n",
       "                        <td id=\"T_9749f_row18_col56\" class=\"data row18 col56\" >-0.043117</td>\n",
       "                        <td id=\"T_9749f_row18_col57\" class=\"data row18 col57\" >-0.000566</td>\n",
       "                        <td id=\"T_9749f_row18_col58\" class=\"data row18 col58\" >0.000146</td>\n",
       "                        <td id=\"T_9749f_row18_col59\" class=\"data row18 col59\" >-0.253482</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row19\" class=\"row_heading level0 row19\" >day_avg_sunset_hr</th>\n",
       "                        <td id=\"T_9749f_row19_col0\" class=\"data row19 col0\" >0.280387</td>\n",
       "                        <td id=\"T_9749f_row19_col1\" class=\"data row19 col1\" >0.457473</td>\n",
       "                        <td id=\"T_9749f_row19_col2\" class=\"data row19 col2\" >0.473132</td>\n",
       "                        <td id=\"T_9749f_row19_col3\" class=\"data row19 col3\" >0.715190</td>\n",
       "                        <td id=\"T_9749f_row19_col4\" class=\"data row19 col4\" >0.743256</td>\n",
       "                        <td id=\"T_9749f_row19_col5\" class=\"data row19 col5\" >0.493586</td>\n",
       "                        <td id=\"T_9749f_row19_col6\" class=\"data row19 col6\" >0.517201</td>\n",
       "                        <td id=\"T_9749f_row19_col7\" class=\"data row19 col7\" >-0.058424</td>\n",
       "                        <td id=\"T_9749f_row19_col8\" class=\"data row19 col8\" >-0.119625</td>\n",
       "                        <td id=\"T_9749f_row19_col9\" class=\"data row19 col9\" >0.828893</td>\n",
       "                        <td id=\"T_9749f_row19_col10\" class=\"data row19 col10\" >0.894288</td>\n",
       "                        <td id=\"T_9749f_row19_col11\" class=\"data row19 col11\" >0.631564</td>\n",
       "                        <td id=\"T_9749f_row19_col12\" class=\"data row19 col12\" >0.695751</td>\n",
       "                        <td id=\"T_9749f_row19_col13\" class=\"data row19 col13\" >-0.028191</td>\n",
       "                        <td id=\"T_9749f_row19_col14\" class=\"data row19 col14\" >-0.053554</td>\n",
       "                        <td id=\"T_9749f_row19_col15\" class=\"data row19 col15\" >-0.952077</td>\n",
       "                        <td id=\"T_9749f_row19_col16\" class=\"data row19 col16\" >-0.947921</td>\n",
       "                        <td id=\"T_9749f_row19_col17\" class=\"data row19 col17\" >-0.952077</td>\n",
       "                        <td id=\"T_9749f_row19_col18\" class=\"data row19 col18\" >-0.947921</td>\n",
       "                        <td id=\"T_9749f_row19_col19\" class=\"data row19 col19\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row19_col20\" class=\"data row19 col20\" >0.990712</td>\n",
       "                        <td id=\"T_9749f_row19_col21\" class=\"data row19 col21\" >-0.100765</td>\n",
       "                        <td id=\"T_9749f_row19_col22\" class=\"data row19 col22\" >-0.044216</td>\n",
       "                        <td id=\"T_9749f_row19_col23\" class=\"data row19 col23\" >0.544449</td>\n",
       "                        <td id=\"T_9749f_row19_col24\" class=\"data row19 col24\" >0.579832</td>\n",
       "                        <td id=\"T_9749f_row19_col25\" class=\"data row19 col25\" >0.656799</td>\n",
       "                        <td id=\"T_9749f_row19_col26\" class=\"data row19 col26\" >0.669590</td>\n",
       "                        <td id=\"T_9749f_row19_col27\" class=\"data row19 col27\" >0.630287</td>\n",
       "                        <td id=\"T_9749f_row19_col28\" class=\"data row19 col28\" >0.647948</td>\n",
       "                        <td id=\"T_9749f_row19_col29\" class=\"data row19 col29\" >0.657383</td>\n",
       "                        <td id=\"T_9749f_row19_col30\" class=\"data row19 col30\" >0.669790</td>\n",
       "                        <td id=\"T_9749f_row19_col31\" class=\"data row19 col31\" >-0.269878</td>\n",
       "                        <td id=\"T_9749f_row19_col32\" class=\"data row19 col32\" >-0.405178</td>\n",
       "                        <td id=\"T_9749f_row19_col33\" class=\"data row19 col33\" >-0.136204</td>\n",
       "                        <td id=\"T_9749f_row19_col34\" class=\"data row19 col34\" >-0.218726</td>\n",
       "                        <td id=\"T_9749f_row19_col35\" class=\"data row19 col35\" >-0.114152</td>\n",
       "                        <td id=\"T_9749f_row19_col36\" class=\"data row19 col36\" >-0.207379</td>\n",
       "                        <td id=\"T_9749f_row19_col37\" class=\"data row19 col37\" >0.098560</td>\n",
       "                        <td id=\"T_9749f_row19_col38\" class=\"data row19 col38\" >0.147284</td>\n",
       "                        <td id=\"T_9749f_row19_col39\" class=\"data row19 col39\" >0.104182</td>\n",
       "                        <td id=\"T_9749f_row19_col40\" class=\"data row19 col40\" >0.123603</td>\n",
       "                        <td id=\"T_9749f_row19_col41\" class=\"data row19 col41\" >0.628933</td>\n",
       "                        <td id=\"T_9749f_row19_col42\" class=\"data row19 col42\" >0.648947</td>\n",
       "                        <td id=\"T_9749f_row19_col43\" class=\"data row19 col43\" >0.273171</td>\n",
       "                        <td id=\"T_9749f_row19_col44\" class=\"data row19 col44\" >0.401055</td>\n",
       "                        <td id=\"T_9749f_row19_col45\" class=\"data row19 col45\" >0.044090</td>\n",
       "                        <td id=\"T_9749f_row19_col46\" class=\"data row19 col46\" >0.057499</td>\n",
       "                        <td id=\"T_9749f_row19_col47\" class=\"data row19 col47\" >-0.250149</td>\n",
       "                        <td id=\"T_9749f_row19_col48\" class=\"data row19 col48\" >-0.377569</td>\n",
       "                        <td id=\"T_9749f_row19_col49\" class=\"data row19 col49\" >-0.355688</td>\n",
       "                        <td id=\"T_9749f_row19_col50\" class=\"data row19 col50\" >-0.357407</td>\n",
       "                        <td id=\"T_9749f_row19_col51\" class=\"data row19 col51\" >-0.355260</td>\n",
       "                        <td id=\"T_9749f_row19_col52\" class=\"data row19 col52\" >-0.356601</td>\n",
       "                        <td id=\"T_9749f_row19_col53\" class=\"data row19 col53\" >-0.010841</td>\n",
       "                        <td id=\"T_9749f_row19_col54\" class=\"data row19 col54\" >0.571146</td>\n",
       "                        <td id=\"T_9749f_row19_col55\" class=\"data row19 col55\" >-0.290125</td>\n",
       "                        <td id=\"T_9749f_row19_col56\" class=\"data row19 col56\" >0.033062</td>\n",
       "                        <td id=\"T_9749f_row19_col57\" class=\"data row19 col57\" >0.000705</td>\n",
       "                        <td id=\"T_9749f_row19_col58\" class=\"data row19 col58\" >0.000310</td>\n",
       "                        <td id=\"T_9749f_row19_col59\" class=\"data row19 col59\" >0.283898</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row20\" class=\"row_heading level0 row20\" >week_avg_sunset_hr</th>\n",
       "                        <td id=\"T_9749f_row20_col0\" class=\"data row20 col0\" >0.289345</td>\n",
       "                        <td id=\"T_9749f_row20_col1\" class=\"data row20 col1\" >0.474407</td>\n",
       "                        <td id=\"T_9749f_row20_col2\" class=\"data row20 col2\" >0.496088</td>\n",
       "                        <td id=\"T_9749f_row20_col3\" class=\"data row20 col3\" >0.740185</td>\n",
       "                        <td id=\"T_9749f_row20_col4\" class=\"data row20 col4\" >0.776557</td>\n",
       "                        <td id=\"T_9749f_row20_col5\" class=\"data row20 col5\" >0.530093</td>\n",
       "                        <td id=\"T_9749f_row20_col6\" class=\"data row20 col6\" >0.560914</td>\n",
       "                        <td id=\"T_9749f_row20_col7\" class=\"data row20 col7\" >-0.067602</td>\n",
       "                        <td id=\"T_9749f_row20_col8\" class=\"data row20 col8\" >-0.130147</td>\n",
       "                        <td id=\"T_9749f_row20_col9\" class=\"data row20 col9\" >0.823043</td>\n",
       "                        <td id=\"T_9749f_row20_col10\" class=\"data row20 col10\" >0.897739</td>\n",
       "                        <td id=\"T_9749f_row20_col11\" class=\"data row20 col11\" >0.650337</td>\n",
       "                        <td id=\"T_9749f_row20_col12\" class=\"data row20 col12\" >0.728233</td>\n",
       "                        <td id=\"T_9749f_row20_col13\" class=\"data row20 col13\" >-0.013081</td>\n",
       "                        <td id=\"T_9749f_row20_col14\" class=\"data row20 col14\" >-0.033202</td>\n",
       "                        <td id=\"T_9749f_row20_col15\" class=\"data row20 col15\" >-0.963097</td>\n",
       "                        <td id=\"T_9749f_row20_col16\" class=\"data row20 col16\" >-0.961468</td>\n",
       "                        <td id=\"T_9749f_row20_col17\" class=\"data row20 col17\" >-0.963097</td>\n",
       "                        <td id=\"T_9749f_row20_col18\" class=\"data row20 col18\" >-0.961468</td>\n",
       "                        <td id=\"T_9749f_row20_col19\" class=\"data row20 col19\" >0.990712</td>\n",
       "                        <td id=\"T_9749f_row20_col20\" class=\"data row20 col20\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row20_col21\" class=\"data row20 col21\" >-0.030370</td>\n",
       "                        <td id=\"T_9749f_row20_col22\" class=\"data row20 col22\" >-0.064980</td>\n",
       "                        <td id=\"T_9749f_row20_col23\" class=\"data row20 col23\" >0.579506</td>\n",
       "                        <td id=\"T_9749f_row20_col24\" class=\"data row20 col24\" >0.621953</td>\n",
       "                        <td id=\"T_9749f_row20_col25\" class=\"data row20 col25\" >0.686101</td>\n",
       "                        <td id=\"T_9749f_row20_col26\" class=\"data row20 col26\" >0.708256</td>\n",
       "                        <td id=\"T_9749f_row20_col27\" class=\"data row20 col27\" >0.662783</td>\n",
       "                        <td id=\"T_9749f_row20_col28\" class=\"data row20 col28\" >0.688189</td>\n",
       "                        <td id=\"T_9749f_row20_col29\" class=\"data row20 col29\" >0.686777</td>\n",
       "                        <td id=\"T_9749f_row20_col30\" class=\"data row20 col30\" >0.708564</td>\n",
       "                        <td id=\"T_9749f_row20_col31\" class=\"data row20 col31\" >-0.256013</td>\n",
       "                        <td id=\"T_9749f_row20_col32\" class=\"data row20 col32\" >-0.405399</td>\n",
       "                        <td id=\"T_9749f_row20_col33\" class=\"data row20 col33\" >-0.119069</td>\n",
       "                        <td id=\"T_9749f_row20_col34\" class=\"data row20 col34\" >-0.211610</td>\n",
       "                        <td id=\"T_9749f_row20_col35\" class=\"data row20 col35\" >-0.095906</td>\n",
       "                        <td id=\"T_9749f_row20_col36\" class=\"data row20 col36\" >-0.188514</td>\n",
       "                        <td id=\"T_9749f_row20_col37\" class=\"data row20 col37\" >0.103484</td>\n",
       "                        <td id=\"T_9749f_row20_col38\" class=\"data row20 col38\" >0.153751</td>\n",
       "                        <td id=\"T_9749f_row20_col39\" class=\"data row20 col39\" >0.088487</td>\n",
       "                        <td id=\"T_9749f_row20_col40\" class=\"data row20 col40\" >0.121983</td>\n",
       "                        <td id=\"T_9749f_row20_col41\" class=\"data row20 col41\" >0.661558</td>\n",
       "                        <td id=\"T_9749f_row20_col42\" class=\"data row20 col42\" >0.689217</td>\n",
       "                        <td id=\"T_9749f_row20_col43\" class=\"data row20 col43\" >0.266835</td>\n",
       "                        <td id=\"T_9749f_row20_col44\" class=\"data row20 col44\" >0.395012</td>\n",
       "                        <td id=\"T_9749f_row20_col45\" class=\"data row20 col45\" >0.052672</td>\n",
       "                        <td id=\"T_9749f_row20_col46\" class=\"data row20 col46\" >0.056783</td>\n",
       "                        <td id=\"T_9749f_row20_col47\" class=\"data row20 col47\" >-0.234632</td>\n",
       "                        <td id=\"T_9749f_row20_col48\" class=\"data row20 col48\" >-0.376438</td>\n",
       "                        <td id=\"T_9749f_row20_col49\" class=\"data row20 col49\" >-0.364999</td>\n",
       "                        <td id=\"T_9749f_row20_col50\" class=\"data row20 col50\" >-0.370882</td>\n",
       "                        <td id=\"T_9749f_row20_col51\" class=\"data row20 col51\" >-0.364725</td>\n",
       "                        <td id=\"T_9749f_row20_col52\" class=\"data row20 col52\" >-0.370186</td>\n",
       "                        <td id=\"T_9749f_row20_col53\" class=\"data row20 col53\" >-0.012323</td>\n",
       "                        <td id=\"T_9749f_row20_col54\" class=\"data row20 col54\" >0.554331</td>\n",
       "                        <td id=\"T_9749f_row20_col55\" class=\"data row20 col55\" >-0.244357</td>\n",
       "                        <td id=\"T_9749f_row20_col56\" class=\"data row20 col56\" >0.059472</td>\n",
       "                        <td id=\"T_9749f_row20_col57\" class=\"data row20 col57\" >0.000677</td>\n",
       "                        <td id=\"T_9749f_row20_col58\" class=\"data row20 col58\" >0.000230</td>\n",
       "                        <td id=\"T_9749f_row20_col59\" class=\"data row20 col59\" >0.285200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row21\" class=\"row_heading level0 row21\" >day_avg_sunset_min</th>\n",
       "                        <td id=\"T_9749f_row21_col0\" class=\"data row21 col0\" >0.064767</td>\n",
       "                        <td id=\"T_9749f_row21_col1\" class=\"data row21 col1\" >0.122808</td>\n",
       "                        <td id=\"T_9749f_row21_col2\" class=\"data row21 col2\" >0.181016</td>\n",
       "                        <td id=\"T_9749f_row21_col3\" class=\"data row21 col3\" >-0.020457</td>\n",
       "                        <td id=\"T_9749f_row21_col4\" class=\"data row21 col4\" >-0.012632</td>\n",
       "                        <td id=\"T_9749f_row21_col5\" class=\"data row21 col5\" >0.031147</td>\n",
       "                        <td id=\"T_9749f_row21_col6\" class=\"data row21 col6\" >0.039971</td>\n",
       "                        <td id=\"T_9749f_row21_col7\" class=\"data row21 col7\" >0.021655</td>\n",
       "                        <td id=\"T_9749f_row21_col8\" class=\"data row21 col8\" >0.114647</td>\n",
       "                        <td id=\"T_9749f_row21_col9\" class=\"data row21 col9\" >0.007657</td>\n",
       "                        <td id=\"T_9749f_row21_col10\" class=\"data row21 col10\" >0.037669</td>\n",
       "                        <td id=\"T_9749f_row21_col11\" class=\"data row21 col11\" >-0.035120</td>\n",
       "                        <td id=\"T_9749f_row21_col12\" class=\"data row21 col12\" >-0.017987</td>\n",
       "                        <td id=\"T_9749f_row21_col13\" class=\"data row21 col13\" >-0.105339</td>\n",
       "                        <td id=\"T_9749f_row21_col14\" class=\"data row21 col14\" >0.003062</td>\n",
       "                        <td id=\"T_9749f_row21_col15\" class=\"data row21 col15\" >-0.064769</td>\n",
       "                        <td id=\"T_9749f_row21_col16\" class=\"data row21 col16\" >-0.064238</td>\n",
       "                        <td id=\"T_9749f_row21_col17\" class=\"data row21 col17\" >-0.064769</td>\n",
       "                        <td id=\"T_9749f_row21_col18\" class=\"data row21 col18\" >-0.064238</td>\n",
       "                        <td id=\"T_9749f_row21_col19\" class=\"data row21 col19\" >-0.100765</td>\n",
       "                        <td id=\"T_9749f_row21_col20\" class=\"data row21 col20\" >-0.030370</td>\n",
       "                        <td id=\"T_9749f_row21_col21\" class=\"data row21 col21\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row21_col22\" class=\"data row21 col22\" >0.713961</td>\n",
       "                        <td id=\"T_9749f_row21_col23\" class=\"data row21 col23\" >0.019599</td>\n",
       "                        <td id=\"T_9749f_row21_col24\" class=\"data row21 col24\" >0.031541</td>\n",
       "                        <td id=\"T_9749f_row21_col25\" class=\"data row21 col25\" >-0.006042</td>\n",
       "                        <td id=\"T_9749f_row21_col26\" class=\"data row21 col26\" >0.019338</td>\n",
       "                        <td id=\"T_9749f_row21_col27\" class=\"data row21 col27\" >-0.000252</td>\n",
       "                        <td id=\"T_9749f_row21_col28\" class=\"data row21 col28\" >0.012891</td>\n",
       "                        <td id=\"T_9749f_row21_col29\" class=\"data row21 col29\" >-0.005403</td>\n",
       "                        <td id=\"T_9749f_row21_col30\" class=\"data row21 col30\" >0.020653</td>\n",
       "                        <td id=\"T_9749f_row21_col31\" class=\"data row21 col31\" >0.021215</td>\n",
       "                        <td id=\"T_9749f_row21_col32\" class=\"data row21 col32\" >-0.053121</td>\n",
       "                        <td id=\"T_9749f_row21_col33\" class=\"data row21 col33\" >0.082551</td>\n",
       "                        <td id=\"T_9749f_row21_col34\" class=\"data row21 col34\" >0.073271</td>\n",
       "                        <td id=\"T_9749f_row21_col35\" class=\"data row21 col35\" >0.071710</td>\n",
       "                        <td id=\"T_9749f_row21_col36\" class=\"data row21 col36\" >0.096163</td>\n",
       "                        <td id=\"T_9749f_row21_col37\" class=\"data row21 col37\" >-0.024810</td>\n",
       "                        <td id=\"T_9749f_row21_col38\" class=\"data row21 col38\" >-0.078382</td>\n",
       "                        <td id=\"T_9749f_row21_col39\" class=\"data row21 col39\" >-0.093042</td>\n",
       "                        <td id=\"T_9749f_row21_col40\" class=\"data row21 col40\" >-0.022828</td>\n",
       "                        <td id=\"T_9749f_row21_col41\" class=\"data row21 col41\" >0.004177</td>\n",
       "                        <td id=\"T_9749f_row21_col42\" class=\"data row21 col42\" >0.017563</td>\n",
       "                        <td id=\"T_9749f_row21_col43\" class=\"data row21 col43\" >0.017393</td>\n",
       "                        <td id=\"T_9749f_row21_col44\" class=\"data row21 col44\" >0.103275</td>\n",
       "                        <td id=\"T_9749f_row21_col45\" class=\"data row21 col45\" >0.071281</td>\n",
       "                        <td id=\"T_9749f_row21_col46\" class=\"data row21 col46\" >0.078151</td>\n",
       "                        <td id=\"T_9749f_row21_col47\" class=\"data row21 col47\" >0.039223</td>\n",
       "                        <td id=\"T_9749f_row21_col48\" class=\"data row21 col48\" >-0.029020</td>\n",
       "                        <td id=\"T_9749f_row21_col49\" class=\"data row21 col49\" >-0.004179</td>\n",
       "                        <td id=\"T_9749f_row21_col50\" class=\"data row21 col50\" >0.024046</td>\n",
       "                        <td id=\"T_9749f_row21_col51\" class=\"data row21 col51\" >-0.004099</td>\n",
       "                        <td id=\"T_9749f_row21_col52\" class=\"data row21 col52\" >0.024672</td>\n",
       "                        <td id=\"T_9749f_row21_col53\" class=\"data row21 col53\" >0.028574</td>\n",
       "                        <td id=\"T_9749f_row21_col54\" class=\"data row21 col54\" >-0.138015</td>\n",
       "                        <td id=\"T_9749f_row21_col55\" class=\"data row21 col55\" >0.158621</td>\n",
       "                        <td id=\"T_9749f_row21_col56\" class=\"data row21 col56\" >-0.036161</td>\n",
       "                        <td id=\"T_9749f_row21_col57\" class=\"data row21 col57\" >-0.000008</td>\n",
       "                        <td id=\"T_9749f_row21_col58\" class=\"data row21 col58\" >-0.000871</td>\n",
       "                        <td id=\"T_9749f_row21_col59\" class=\"data row21 col59\" >-0.017314</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row22\" class=\"row_heading level0 row22\" >week_avg_sunset_min</th>\n",
       "                        <td id=\"T_9749f_row22_col0\" class=\"data row22 col0\" >0.062920</td>\n",
       "                        <td id=\"T_9749f_row22_col1\" class=\"data row22 col1\" >0.110279</td>\n",
       "                        <td id=\"T_9749f_row22_col2\" class=\"data row22 col2\" >0.161922</td>\n",
       "                        <td id=\"T_9749f_row22_col3\" class=\"data row22 col3\" >-0.028389</td>\n",
       "                        <td id=\"T_9749f_row22_col4\" class=\"data row22 col4\" >-0.045283</td>\n",
       "                        <td id=\"T_9749f_row22_col5\" class=\"data row22 col5\" >0.004150</td>\n",
       "                        <td id=\"T_9749f_row22_col6\" class=\"data row22 col6\" >0.009033</td>\n",
       "                        <td id=\"T_9749f_row22_col7\" class=\"data row22 col7\" >0.035819</td>\n",
       "                        <td id=\"T_9749f_row22_col8\" class=\"data row22 col8\" >0.092813</td>\n",
       "                        <td id=\"T_9749f_row22_col9\" class=\"data row22 col9\" >0.052959</td>\n",
       "                        <td id=\"T_9749f_row22_col10\" class=\"data row22 col10\" >0.041988</td>\n",
       "                        <td id=\"T_9749f_row22_col11\" class=\"data row22 col11\" >-0.015445</td>\n",
       "                        <td id=\"T_9749f_row22_col12\" class=\"data row22 col12\" >-0.050409</td>\n",
       "                        <td id=\"T_9749f_row22_col13\" class=\"data row22 col13\" >-0.204351</td>\n",
       "                        <td id=\"T_9749f_row22_col14\" class=\"data row22 col14\" >-0.124243</td>\n",
       "                        <td id=\"T_9749f_row22_col15\" class=\"data row22 col15\" >-0.059615</td>\n",
       "                        <td id=\"T_9749f_row22_col16\" class=\"data row22 col16\" >-0.065569</td>\n",
       "                        <td id=\"T_9749f_row22_col17\" class=\"data row22 col17\" >-0.059615</td>\n",
       "                        <td id=\"T_9749f_row22_col18\" class=\"data row22 col18\" >-0.065569</td>\n",
       "                        <td id=\"T_9749f_row22_col19\" class=\"data row22 col19\" >-0.044216</td>\n",
       "                        <td id=\"T_9749f_row22_col20\" class=\"data row22 col20\" >-0.064980</td>\n",
       "                        <td id=\"T_9749f_row22_col21\" class=\"data row22 col21\" >0.713961</td>\n",
       "                        <td id=\"T_9749f_row22_col22\" class=\"data row22 col22\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row22_col23\" class=\"data row22 col23\" >-0.013747</td>\n",
       "                        <td id=\"T_9749f_row22_col24\" class=\"data row22 col24\" >-0.004612</td>\n",
       "                        <td id=\"T_9749f_row22_col25\" class=\"data row22 col25\" >-0.013532</td>\n",
       "                        <td id=\"T_9749f_row22_col26\" class=\"data row22 col26\" >-0.015973</td>\n",
       "                        <td id=\"T_9749f_row22_col27\" class=\"data row22 col27\" >-0.019377</td>\n",
       "                        <td id=\"T_9749f_row22_col28\" class=\"data row22 col28\" >-0.022430</td>\n",
       "                        <td id=\"T_9749f_row22_col29\" class=\"data row22 col29\" >-0.013301</td>\n",
       "                        <td id=\"T_9749f_row22_col30\" class=\"data row22 col30\" >-0.015127</td>\n",
       "                        <td id=\"T_9749f_row22_col31\" class=\"data row22 col31\" >-0.055691</td>\n",
       "                        <td id=\"T_9749f_row22_col32\" class=\"data row22 col32\" >-0.052056</td>\n",
       "                        <td id=\"T_9749f_row22_col33\" class=\"data row22 col33\" >0.018857</td>\n",
       "                        <td id=\"T_9749f_row22_col34\" class=\"data row22 col34\" >0.093184</td>\n",
       "                        <td id=\"T_9749f_row22_col35\" class=\"data row22 col35\" >0.018432</td>\n",
       "                        <td id=\"T_9749f_row22_col36\" class=\"data row22 col36\" >0.083314</td>\n",
       "                        <td id=\"T_9749f_row22_col37\" class=\"data row22 col37\" >-0.024183</td>\n",
       "                        <td id=\"T_9749f_row22_col38\" class=\"data row22 col38\" >-0.072490</td>\n",
       "                        <td id=\"T_9749f_row22_col39\" class=\"data row22 col39\" >-0.055177</td>\n",
       "                        <td id=\"T_9749f_row22_col40\" class=\"data row22 col40\" >-0.079989</td>\n",
       "                        <td id=\"T_9749f_row22_col41\" class=\"data row22 col41\" >-0.015735</td>\n",
       "                        <td id=\"T_9749f_row22_col42\" class=\"data row22 col42\" >-0.017422</td>\n",
       "                        <td id=\"T_9749f_row22_col43\" class=\"data row22 col43\" >-0.028041</td>\n",
       "                        <td id=\"T_9749f_row22_col44\" class=\"data row22 col44\" >0.036687</td>\n",
       "                        <td id=\"T_9749f_row22_col45\" class=\"data row22 col45\" >-0.004139</td>\n",
       "                        <td id=\"T_9749f_row22_col46\" class=\"data row22 col46\" >0.055806</td>\n",
       "                        <td id=\"T_9749f_row22_col47\" class=\"data row22 col47\" >-0.039219</td>\n",
       "                        <td id=\"T_9749f_row22_col48\" class=\"data row22 col48\" >-0.022615</td>\n",
       "                        <td id=\"T_9749f_row22_col49\" class=\"data row22 col49\" >-0.095600</td>\n",
       "                        <td id=\"T_9749f_row22_col50\" class=\"data row22 col50\" >-0.038860</td>\n",
       "                        <td id=\"T_9749f_row22_col51\" class=\"data row22 col51\" >-0.094965</td>\n",
       "                        <td id=\"T_9749f_row22_col52\" class=\"data row22 col52\" >-0.037868</td>\n",
       "                        <td id=\"T_9749f_row22_col53\" class=\"data row22 col53\" >0.024814</td>\n",
       "                        <td id=\"T_9749f_row22_col54\" class=\"data row22 col54\" >-0.102106</td>\n",
       "                        <td id=\"T_9749f_row22_col55\" class=\"data row22 col55\" >0.164657</td>\n",
       "                        <td id=\"T_9749f_row22_col56\" class=\"data row22 col56\" >-0.217178</td>\n",
       "                        <td id=\"T_9749f_row22_col57\" class=\"data row22 col57\" >0.000902</td>\n",
       "                        <td id=\"T_9749f_row22_col58\" class=\"data row22 col58\" >-0.001044</td>\n",
       "                        <td id=\"T_9749f_row22_col59\" class=\"data row22 col59\" >0.050116</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row23\" class=\"row_heading level0 row23\" >day_avg_dewpoint</th>\n",
       "                        <td id=\"T_9749f_row23_col0\" class=\"data row23 col0\" >0.206195</td>\n",
       "                        <td id=\"T_9749f_row23_col1\" class=\"data row23 col1\" >0.349859</td>\n",
       "                        <td id=\"T_9749f_row23_col2\" class=\"data row23 col2\" >0.399792</td>\n",
       "                        <td id=\"T_9749f_row23_col3\" class=\"data row23 col3\" >0.899765</td>\n",
       "                        <td id=\"T_9749f_row23_col4\" class=\"data row23 col4\" >0.807959</td>\n",
       "                        <td id=\"T_9749f_row23_col5\" class=\"data row23 col5\" >0.917018</td>\n",
       "                        <td id=\"T_9749f_row23_col6\" class=\"data row23 col6\" >0.816186</td>\n",
       "                        <td id=\"T_9749f_row23_col7\" class=\"data row23 col7\" >-0.175404</td>\n",
       "                        <td id=\"T_9749f_row23_col8\" class=\"data row23 col8\" >-0.289747</td>\n",
       "                        <td id=\"T_9749f_row23_col9\" class=\"data row23 col9\" >0.337123</td>\n",
       "                        <td id=\"T_9749f_row23_col10\" class=\"data row23 col10\" >0.485657</td>\n",
       "                        <td id=\"T_9749f_row23_col11\" class=\"data row23 col11\" >0.741697</td>\n",
       "                        <td id=\"T_9749f_row23_col12\" class=\"data row23 col12\" >0.769613</td>\n",
       "                        <td id=\"T_9749f_row23_col13\" class=\"data row23 col13\" >-0.008563</td>\n",
       "                        <td id=\"T_9749f_row23_col14\" class=\"data row23 col14\" >0.029876</td>\n",
       "                        <td id=\"T_9749f_row23_col15\" class=\"data row23 col15\" >-0.570262</td>\n",
       "                        <td id=\"T_9749f_row23_col16\" class=\"data row23 col16\" >-0.595268</td>\n",
       "                        <td id=\"T_9749f_row23_col17\" class=\"data row23 col17\" >-0.570262</td>\n",
       "                        <td id=\"T_9749f_row23_col18\" class=\"data row23 col18\" >-0.595268</td>\n",
       "                        <td id=\"T_9749f_row23_col19\" class=\"data row23 col19\" >0.544449</td>\n",
       "                        <td id=\"T_9749f_row23_col20\" class=\"data row23 col20\" >0.579506</td>\n",
       "                        <td id=\"T_9749f_row23_col21\" class=\"data row23 col21\" >0.019599</td>\n",
       "                        <td id=\"T_9749f_row23_col22\" class=\"data row23 col22\" >-0.013747</td>\n",
       "                        <td id=\"T_9749f_row23_col23\" class=\"data row23 col23\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row23_col24\" class=\"data row23 col24\" >0.838894</td>\n",
       "                        <td id=\"T_9749f_row23_col25\" class=\"data row23 col25\" >0.950603</td>\n",
       "                        <td id=\"T_9749f_row23_col26\" class=\"data row23 col26\" >0.832995</td>\n",
       "                        <td id=\"T_9749f_row23_col27\" class=\"data row23 col27\" >0.966743</td>\n",
       "                        <td id=\"T_9749f_row23_col28\" class=\"data row23 col28\" >0.833679</td>\n",
       "                        <td id=\"T_9749f_row23_col29\" class=\"data row23 col29\" >0.950768</td>\n",
       "                        <td id=\"T_9749f_row23_col30\" class=\"data row23 col30\" >0.832887</td>\n",
       "                        <td id=\"T_9749f_row23_col31\" class=\"data row23 col31\" >-0.054436</td>\n",
       "                        <td id=\"T_9749f_row23_col32\" class=\"data row23 col32\" >-0.238176</td>\n",
       "                        <td id=\"T_9749f_row23_col33\" class=\"data row23 col33\" >0.226580</td>\n",
       "                        <td id=\"T_9749f_row23_col34\" class=\"data row23 col34\" >0.003684</td>\n",
       "                        <td id=\"T_9749f_row23_col35\" class=\"data row23 col35\" >0.480388</td>\n",
       "                        <td id=\"T_9749f_row23_col36\" class=\"data row23 col36\" >0.282380</td>\n",
       "                        <td id=\"T_9749f_row23_col37\" class=\"data row23 col37\" >0.215508</td>\n",
       "                        <td id=\"T_9749f_row23_col38\" class=\"data row23 col38\" >0.154551</td>\n",
       "                        <td id=\"T_9749f_row23_col39\" class=\"data row23 col39\" >-0.040940</td>\n",
       "                        <td id=\"T_9749f_row23_col40\" class=\"data row23 col40\" >0.055880</td>\n",
       "                        <td id=\"T_9749f_row23_col41\" class=\"data row23 col41\" >0.963877</td>\n",
       "                        <td id=\"T_9749f_row23_col42\" class=\"data row23 col42\" >0.833204</td>\n",
       "                        <td id=\"T_9749f_row23_col43\" class=\"data row23 col43\" >-0.139103</td>\n",
       "                        <td id=\"T_9749f_row23_col44\" class=\"data row23 col44\" >-0.035035</td>\n",
       "                        <td id=\"T_9749f_row23_col45\" class=\"data row23 col45\" >0.079287</td>\n",
       "                        <td id=\"T_9749f_row23_col46\" class=\"data row23 col46\" >0.037532</td>\n",
       "                        <td id=\"T_9749f_row23_col47\" class=\"data row23 col47\" >-0.060804</td>\n",
       "                        <td id=\"T_9749f_row23_col48\" class=\"data row23 col48\" >-0.236363</td>\n",
       "                        <td id=\"T_9749f_row23_col49\" class=\"data row23 col49\" >-0.483851</td>\n",
       "                        <td id=\"T_9749f_row23_col50\" class=\"data row23 col50\" >-0.489790</td>\n",
       "                        <td id=\"T_9749f_row23_col51\" class=\"data row23 col51\" >-0.485202</td>\n",
       "                        <td id=\"T_9749f_row23_col52\" class=\"data row23 col52\" >-0.490636</td>\n",
       "                        <td id=\"T_9749f_row23_col53\" class=\"data row23 col53\" >0.028749</td>\n",
       "                        <td id=\"T_9749f_row23_col54\" class=\"data row23 col54\" >0.114187</td>\n",
       "                        <td id=\"T_9749f_row23_col55\" class=\"data row23 col55\" >0.241234</td>\n",
       "                        <td id=\"T_9749f_row23_col56\" class=\"data row23 col56\" >0.115384</td>\n",
       "                        <td id=\"T_9749f_row23_col57\" class=\"data row23 col57\" >-0.000271</td>\n",
       "                        <td id=\"T_9749f_row23_col58\" class=\"data row23 col58\" >-0.000971</td>\n",
       "                        <td id=\"T_9749f_row23_col59\" class=\"data row23 col59\" >0.373342</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row24\" class=\"row_heading level0 row24\" >week_avg_dewpoint</th>\n",
       "                        <td id=\"T_9749f_row24_col0\" class=\"data row24 col0\" >0.241993</td>\n",
       "                        <td id=\"T_9749f_row24_col1\" class=\"data row24 col1\" >0.397084</td>\n",
       "                        <td id=\"T_9749f_row24_col2\" class=\"data row24 col2\" >0.445747</td>\n",
       "                        <td id=\"T_9749f_row24_col3\" class=\"data row24 col3\" >0.807294</td>\n",
       "                        <td id=\"T_9749f_row24_col4\" class=\"data row24 col4\" >0.934835</td>\n",
       "                        <td id=\"T_9749f_row24_col5\" class=\"data row24 col5\" >0.822502</td>\n",
       "                        <td id=\"T_9749f_row24_col6\" class=\"data row24 col6\" >0.974610</td>\n",
       "                        <td id=\"T_9749f_row24_col7\" class=\"data row24 col7\" >-0.142405</td>\n",
       "                        <td id=\"T_9749f_row24_col8\" class=\"data row24 col8\" >-0.343206</td>\n",
       "                        <td id=\"T_9749f_row24_col9\" class=\"data row24 col9\" >0.419947</td>\n",
       "                        <td id=\"T_9749f_row24_col10\" class=\"data row24 col10\" >0.497612</td>\n",
       "                        <td id=\"T_9749f_row24_col11\" class=\"data row24 col11\" >0.691035</td>\n",
       "                        <td id=\"T_9749f_row24_col12\" class=\"data row24 col12\" >0.867535</td>\n",
       "                        <td id=\"T_9749f_row24_col13\" class=\"data row24 col13\" >-0.061248</td>\n",
       "                        <td id=\"T_9749f_row24_col14\" class=\"data row24 col14\" >-0.016400</td>\n",
       "                        <td id=\"T_9749f_row24_col15\" class=\"data row24 col15\" >-0.620255</td>\n",
       "                        <td id=\"T_9749f_row24_col16\" class=\"data row24 col16\" >-0.650759</td>\n",
       "                        <td id=\"T_9749f_row24_col17\" class=\"data row24 col17\" >-0.620255</td>\n",
       "                        <td id=\"T_9749f_row24_col18\" class=\"data row24 col18\" >-0.650759</td>\n",
       "                        <td id=\"T_9749f_row24_col19\" class=\"data row24 col19\" >0.579832</td>\n",
       "                        <td id=\"T_9749f_row24_col20\" class=\"data row24 col20\" >0.621953</td>\n",
       "                        <td id=\"T_9749f_row24_col21\" class=\"data row24 col21\" >0.031541</td>\n",
       "                        <td id=\"T_9749f_row24_col22\" class=\"data row24 col22\" >-0.004612</td>\n",
       "                        <td id=\"T_9749f_row24_col23\" class=\"data row24 col23\" >0.838894</td>\n",
       "                        <td id=\"T_9749f_row24_col24\" class=\"data row24 col24\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row24_col25\" class=\"data row24 col25\" >0.859995</td>\n",
       "                        <td id=\"T_9749f_row24_col26\" class=\"data row24 col26\" >0.976921</td>\n",
       "                        <td id=\"T_9749f_row24_col27\" class=\"data row24 col27\" >0.860960</td>\n",
       "                        <td id=\"T_9749f_row24_col28\" class=\"data row24 col28\" >0.985253</td>\n",
       "                        <td id=\"T_9749f_row24_col29\" class=\"data row24 col29\" >0.860361</td>\n",
       "                        <td id=\"T_9749f_row24_col30\" class=\"data row24 col30\" >0.976763</td>\n",
       "                        <td id=\"T_9749f_row24_col31\" class=\"data row24 col31\" >-0.115759</td>\n",
       "                        <td id=\"T_9749f_row24_col32\" class=\"data row24 col32\" >-0.223172</td>\n",
       "                        <td id=\"T_9749f_row24_col33\" class=\"data row24 col33\" >0.064662</td>\n",
       "                        <td id=\"T_9749f_row24_col34\" class=\"data row24 col34\" >0.076389</td>\n",
       "                        <td id=\"T_9749f_row24_col35\" class=\"data row24 col35\" >0.212387</td>\n",
       "                        <td id=\"T_9749f_row24_col36\" class=\"data row24 col36\" >0.376964</td>\n",
       "                        <td id=\"T_9749f_row24_col37\" class=\"data row24 col37\" >0.173710</td>\n",
       "                        <td id=\"T_9749f_row24_col38\" class=\"data row24 col38\" >0.209242</td>\n",
       "                        <td id=\"T_9749f_row24_col39\" class=\"data row24 col39\" >-0.007170</td>\n",
       "                        <td id=\"T_9749f_row24_col40\" class=\"data row24 col40\" >0.021643</td>\n",
       "                        <td id=\"T_9749f_row24_col41\" class=\"data row24 col41\" >0.857224</td>\n",
       "                        <td id=\"T_9749f_row24_col42\" class=\"data row24 col42\" >0.984774</td>\n",
       "                        <td id=\"T_9749f_row24_col43\" class=\"data row24 col43\" >-0.059667</td>\n",
       "                        <td id=\"T_9749f_row24_col44\" class=\"data row24 col44\" >-0.062753</td>\n",
       "                        <td id=\"T_9749f_row24_col45\" class=\"data row24 col45\" >0.090224</td>\n",
       "                        <td id=\"T_9749f_row24_col46\" class=\"data row24 col46\" >0.099943</td>\n",
       "                        <td id=\"T_9749f_row24_col47\" class=\"data row24 col47\" >-0.105575</td>\n",
       "                        <td id=\"T_9749f_row24_col48\" class=\"data row24 col48\" >-0.218882</td>\n",
       "                        <td id=\"T_9749f_row24_col49\" class=\"data row24 col49\" >-0.527675</td>\n",
       "                        <td id=\"T_9749f_row24_col50\" class=\"data row24 col50\" >-0.557556</td>\n",
       "                        <td id=\"T_9749f_row24_col51\" class=\"data row24 col51\" >-0.529398</td>\n",
       "                        <td id=\"T_9749f_row24_col52\" class=\"data row24 col52\" >-0.558937</td>\n",
       "                        <td id=\"T_9749f_row24_col53\" class=\"data row24 col53\" >-0.002401</td>\n",
       "                        <td id=\"T_9749f_row24_col54\" class=\"data row24 col54\" >0.138944</td>\n",
       "                        <td id=\"T_9749f_row24_col55\" class=\"data row24 col55\" >0.290586</td>\n",
       "                        <td id=\"T_9749f_row24_col56\" class=\"data row24 col56\" >0.111854</td>\n",
       "                        <td id=\"T_9749f_row24_col57\" class=\"data row24 col57\" >0.003419</td>\n",
       "                        <td id=\"T_9749f_row24_col58\" class=\"data row24 col58\" >-0.001107</td>\n",
       "                        <td id=\"T_9749f_row24_col59\" class=\"data row24 col59\" >0.384429</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row25\" class=\"row_heading level0 row25\" >day_avg_feelslike</th>\n",
       "                        <td id=\"T_9749f_row25_col0\" class=\"data row25 col0\" >0.212822</td>\n",
       "                        <td id=\"T_9749f_row25_col1\" class=\"data row25 col1\" >0.360822</td>\n",
       "                        <td id=\"T_9749f_row25_col2\" class=\"data row25 col2\" >0.408125</td>\n",
       "                        <td id=\"T_9749f_row25_col3\" class=\"data row25 col3\" >0.962176</td>\n",
       "                        <td id=\"T_9749f_row25_col4\" class=\"data row25 col4\" >0.881185</td>\n",
       "                        <td id=\"T_9749f_row25_col5\" class=\"data row25 col5\" >0.905904</td>\n",
       "                        <td id=\"T_9749f_row25_col6\" class=\"data row25 col6\" >0.835199</td>\n",
       "                        <td id=\"T_9749f_row25_col7\" class=\"data row25 col7\" >-0.169282</td>\n",
       "                        <td id=\"T_9749f_row25_col8\" class=\"data row25 col8\" >-0.297780</td>\n",
       "                        <td id=\"T_9749f_row25_col9\" class=\"data row25 col9\" >0.518536</td>\n",
       "                        <td id=\"T_9749f_row25_col10\" class=\"data row25 col10\" >0.617685</td>\n",
       "                        <td id=\"T_9749f_row25_col11\" class=\"data row25 col11\" >0.839721</td>\n",
       "                        <td id=\"T_9749f_row25_col12\" class=\"data row25 col12\" >0.843795</td>\n",
       "                        <td id=\"T_9749f_row25_col13\" class=\"data row25 col13\" >0.003023</td>\n",
       "                        <td id=\"T_9749f_row25_col14\" class=\"data row25 col14\" >0.060915</td>\n",
       "                        <td id=\"T_9749f_row25_col15\" class=\"data row25 col15\" >-0.672105</td>\n",
       "                        <td id=\"T_9749f_row25_col16\" class=\"data row25 col16\" >-0.692988</td>\n",
       "                        <td id=\"T_9749f_row25_col17\" class=\"data row25 col17\" >-0.672105</td>\n",
       "                        <td id=\"T_9749f_row25_col18\" class=\"data row25 col18\" >-0.692988</td>\n",
       "                        <td id=\"T_9749f_row25_col19\" class=\"data row25 col19\" >0.656799</td>\n",
       "                        <td id=\"T_9749f_row25_col20\" class=\"data row25 col20\" >0.686101</td>\n",
       "                        <td id=\"T_9749f_row25_col21\" class=\"data row25 col21\" >-0.006042</td>\n",
       "                        <td id=\"T_9749f_row25_col22\" class=\"data row25 col22\" >-0.013532</td>\n",
       "                        <td id=\"T_9749f_row25_col23\" class=\"data row25 col23\" >0.950603</td>\n",
       "                        <td id=\"T_9749f_row25_col24\" class=\"data row25 col24\" >0.859995</td>\n",
       "                        <td id=\"T_9749f_row25_col25\" class=\"data row25 col25\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row25_col26\" class=\"data row25 col26\" >0.889537</td>\n",
       "                        <td id=\"T_9749f_row25_col27\" class=\"data row25 col27\" >0.982586</td>\n",
       "                        <td id=\"T_9749f_row25_col28\" class=\"data row25 col28\" >0.878981</td>\n",
       "                        <td id=\"T_9749f_row25_col29\" class=\"data row25 col29\" >0.999923</td>\n",
       "                        <td id=\"T_9749f_row25_col30\" class=\"data row25 col30\" >0.889513</td>\n",
       "                        <td id=\"T_9749f_row25_col31\" class=\"data row25 col31\" >-0.225089</td>\n",
       "                        <td id=\"T_9749f_row25_col32\" class=\"data row25 col32\" >-0.344117</td>\n",
       "                        <td id=\"T_9749f_row25_col33\" class=\"data row25 col33\" >0.012727</td>\n",
       "                        <td id=\"T_9749f_row25_col34\" class=\"data row25 col34\" >-0.108145</td>\n",
       "                        <td id=\"T_9749f_row25_col35\" class=\"data row25 col35\" >0.245008</td>\n",
       "                        <td id=\"T_9749f_row25_col36\" class=\"data row25 col36\" >0.158403</td>\n",
       "                        <td id=\"T_9749f_row25_col37\" class=\"data row25 col37\" >0.091814</td>\n",
       "                        <td id=\"T_9749f_row25_col38\" class=\"data row25 col38\" >0.091490</td>\n",
       "                        <td id=\"T_9749f_row25_col39\" class=\"data row25 col39\" >0.080945</td>\n",
       "                        <td id=\"T_9749f_row25_col40\" class=\"data row25 col40\" >0.140283</td>\n",
       "                        <td id=\"T_9749f_row25_col41\" class=\"data row25 col41\" >0.981656</td>\n",
       "                        <td id=\"T_9749f_row25_col42\" class=\"data row25 col42\" >0.879382</td>\n",
       "                        <td id=\"T_9749f_row25_col43\" class=\"data row25 col43\" >-0.037100</td>\n",
       "                        <td id=\"T_9749f_row25_col44\" class=\"data row25 col44\" >0.028526</td>\n",
       "                        <td id=\"T_9749f_row25_col45\" class=\"data row25 col45\" >0.054128</td>\n",
       "                        <td id=\"T_9749f_row25_col46\" class=\"data row25 col46\" >0.015617</td>\n",
       "                        <td id=\"T_9749f_row25_col47\" class=\"data row25 col47\" >-0.233769</td>\n",
       "                        <td id=\"T_9749f_row25_col48\" class=\"data row25 col48\" >-0.341194</td>\n",
       "                        <td id=\"T_9749f_row25_col49\" class=\"data row25 col49\" >-0.525422</td>\n",
       "                        <td id=\"T_9749f_row25_col50\" class=\"data row25 col50\" >-0.538962</td>\n",
       "                        <td id=\"T_9749f_row25_col51\" class=\"data row25 col51\" >-0.527048</td>\n",
       "                        <td id=\"T_9749f_row25_col52\" class=\"data row25 col52\" >-0.539805</td>\n",
       "                        <td id=\"T_9749f_row25_col53\" class=\"data row25 col53\" >0.020965</td>\n",
       "                        <td id=\"T_9749f_row25_col54\" class=\"data row25 col54\" >0.197930</td>\n",
       "                        <td id=\"T_9749f_row25_col55\" class=\"data row25 col55\" >0.181440</td>\n",
       "                        <td id=\"T_9749f_row25_col56\" class=\"data row25 col56\" >0.141187</td>\n",
       "                        <td id=\"T_9749f_row25_col57\" class=\"data row25 col57\" >0.001033</td>\n",
       "                        <td id=\"T_9749f_row25_col58\" class=\"data row25 col58\" >-0.001012</td>\n",
       "                        <td id=\"T_9749f_row25_col59\" class=\"data row25 col59\" >0.415039</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row26\" class=\"row_heading level0 row26\" >week_avg_feelslike</th>\n",
       "                        <td id=\"T_9749f_row26_col0\" class=\"data row26 col0\" >0.239393</td>\n",
       "                        <td id=\"T_9749f_row26_col1\" class=\"data row26 col1\" >0.387338</td>\n",
       "                        <td id=\"T_9749f_row26_col2\" class=\"data row26 col2\" >0.436000</td>\n",
       "                        <td id=\"T_9749f_row26_col3\" class=\"data row26 col3\" >0.855454</td>\n",
       "                        <td id=\"T_9749f_row26_col4\" class=\"data row26 col4\" >0.975984</td>\n",
       "                        <td id=\"T_9749f_row26_col5\" class=\"data row26 col5\" >0.809178</td>\n",
       "                        <td id=\"T_9749f_row26_col6\" class=\"data row26 col6\" >0.948215</td>\n",
       "                        <td id=\"T_9749f_row26_col7\" class=\"data row26 col7\" >-0.134624</td>\n",
       "                        <td id=\"T_9749f_row26_col8\" class=\"data row26 col8\" >-0.323827</td>\n",
       "                        <td id=\"T_9749f_row26_col9\" class=\"data row26 col9\" >0.532105</td>\n",
       "                        <td id=\"T_9749f_row26_col10\" class=\"data row26 col10\" >0.623530</td>\n",
       "                        <td id=\"T_9749f_row26_col11\" class=\"data row26 col11\" >0.746598</td>\n",
       "                        <td id=\"T_9749f_row26_col12\" class=\"data row26 col12\" >0.922402</td>\n",
       "                        <td id=\"T_9749f_row26_col13\" class=\"data row26 col13\" >-0.066019</td>\n",
       "                        <td id=\"T_9749f_row26_col14\" class=\"data row26 col14\" >-0.001810</td>\n",
       "                        <td id=\"T_9749f_row26_col15\" class=\"data row26 col15\" >-0.705108</td>\n",
       "                        <td id=\"T_9749f_row26_col16\" class=\"data row26 col16\" >-0.728067</td>\n",
       "                        <td id=\"T_9749f_row26_col17\" class=\"data row26 col17\" >-0.705108</td>\n",
       "                        <td id=\"T_9749f_row26_col18\" class=\"data row26 col18\" >-0.728067</td>\n",
       "                        <td id=\"T_9749f_row26_col19\" class=\"data row26 col19\" >0.669590</td>\n",
       "                        <td id=\"T_9749f_row26_col20\" class=\"data row26 col20\" >0.708256</td>\n",
       "                        <td id=\"T_9749f_row26_col21\" class=\"data row26 col21\" >0.019338</td>\n",
       "                        <td id=\"T_9749f_row26_col22\" class=\"data row26 col22\" >-0.015973</td>\n",
       "                        <td id=\"T_9749f_row26_col23\" class=\"data row26 col23\" >0.832995</td>\n",
       "                        <td id=\"T_9749f_row26_col24\" class=\"data row26 col24\" >0.976921</td>\n",
       "                        <td id=\"T_9749f_row26_col25\" class=\"data row26 col25\" >0.889537</td>\n",
       "                        <td id=\"T_9749f_row26_col26\" class=\"data row26 col26\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row26_col27\" class=\"data row26 col27\" >0.877463</td>\n",
       "                        <td id=\"T_9749f_row26_col28\" class=\"data row26 col28\" >0.992363</td>\n",
       "                        <td id=\"T_9749f_row26_col29\" class=\"data row26 col29\" >0.890043</td>\n",
       "                        <td id=\"T_9749f_row26_col30\" class=\"data row26 col30\" >0.999979</td>\n",
       "                        <td id=\"T_9749f_row26_col31\" class=\"data row26 col31\" >-0.188976</td>\n",
       "                        <td id=\"T_9749f_row26_col32\" class=\"data row26 col32\" >-0.349705</td>\n",
       "                        <td id=\"T_9749f_row26_col33\" class=\"data row26 col33\" >-0.017358</td>\n",
       "                        <td id=\"T_9749f_row26_col34\" class=\"data row26 col34\" >-0.082115</td>\n",
       "                        <td id=\"T_9749f_row26_col35\" class=\"data row26 col35\" >0.136342</td>\n",
       "                        <td id=\"T_9749f_row26_col36\" class=\"data row26 col36\" >0.211160</td>\n",
       "                        <td id=\"T_9749f_row26_col37\" class=\"data row26 col37\" >0.129269</td>\n",
       "                        <td id=\"T_9749f_row26_col38\" class=\"data row26 col38\" >0.128097</td>\n",
       "                        <td id=\"T_9749f_row26_col39\" class=\"data row26 col39\" >0.042043</td>\n",
       "                        <td id=\"T_9749f_row26_col40\" class=\"data row26 col40\" >0.112280</td>\n",
       "                        <td id=\"T_9749f_row26_col41\" class=\"data row26 col41\" >0.873961</td>\n",
       "                        <td id=\"T_9749f_row26_col42\" class=\"data row26 col42\" >0.991954</td>\n",
       "                        <td id=\"T_9749f_row26_col43\" class=\"data row26 col43\" >-0.018601</td>\n",
       "                        <td id=\"T_9749f_row26_col44\" class=\"data row26 col44\" >0.000489</td>\n",
       "                        <td id=\"T_9749f_row26_col45\" class=\"data row26 col45\" >0.077477</td>\n",
       "                        <td id=\"T_9749f_row26_col46\" class=\"data row26 col46\" >0.063131</td>\n",
       "                        <td id=\"T_9749f_row26_col47\" class=\"data row26 col47\" >-0.178508</td>\n",
       "                        <td id=\"T_9749f_row26_col48\" class=\"data row26 col48\" >-0.345084</td>\n",
       "                        <td id=\"T_9749f_row26_col49\" class=\"data row26 col49\" >-0.546500</td>\n",
       "                        <td id=\"T_9749f_row26_col50\" class=\"data row26 col50\" >-0.576847</td>\n",
       "                        <td id=\"T_9749f_row26_col51\" class=\"data row26 col51\" >-0.548243</td>\n",
       "                        <td id=\"T_9749f_row26_col52\" class=\"data row26 col52\" >-0.578340</td>\n",
       "                        <td id=\"T_9749f_row26_col53\" class=\"data row26 col53\" >-0.007236</td>\n",
       "                        <td id=\"T_9749f_row26_col54\" class=\"data row26 col54\" >0.212412</td>\n",
       "                        <td id=\"T_9749f_row26_col55\" class=\"data row26 col55\" >0.219271</td>\n",
       "                        <td id=\"T_9749f_row26_col56\" class=\"data row26 col56\" >0.131433</td>\n",
       "                        <td id=\"T_9749f_row26_col57\" class=\"data row26 col57\" >0.006258</td>\n",
       "                        <td id=\"T_9749f_row26_col58\" class=\"data row26 col58\" >-0.001060</td>\n",
       "                        <td id=\"T_9749f_row26_col59\" class=\"data row26 col59\" >0.426903</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row27\" class=\"row_heading level0 row27\" >day_avg_heatindex</th>\n",
       "                        <td id=\"T_9749f_row27_col0\" class=\"data row27 col0\" >0.210423</td>\n",
       "                        <td id=\"T_9749f_row27_col1\" class=\"data row27 col1\" >0.358737</td>\n",
       "                        <td id=\"T_9749f_row27_col2\" class=\"data row27 col2\" >0.413228</td>\n",
       "                        <td id=\"T_9749f_row27_col3\" class=\"data row27 col3\" >0.961054</td>\n",
       "                        <td id=\"T_9749f_row27_col4\" class=\"data row27 col4\" >0.872039</td>\n",
       "                        <td id=\"T_9749f_row27_col5\" class=\"data row27 col5\" >0.928573</td>\n",
       "                        <td id=\"T_9749f_row27_col6\" class=\"data row27 col6\" >0.840538</td>\n",
       "                        <td id=\"T_9749f_row27_col7\" class=\"data row27 col7\" >-0.169485</td>\n",
       "                        <td id=\"T_9749f_row27_col8\" class=\"data row27 col8\" >-0.295549</td>\n",
       "                        <td id=\"T_9749f_row27_col9\" class=\"data row27 col9\" >0.468925</td>\n",
       "                        <td id=\"T_9749f_row27_col10\" class=\"data row27 col10\" >0.585576</td>\n",
       "                        <td id=\"T_9749f_row27_col11\" class=\"data row27 col11\" >0.821105</td>\n",
       "                        <td id=\"T_9749f_row27_col12\" class=\"data row27 col12\" >0.835953</td>\n",
       "                        <td id=\"T_9749f_row27_col13\" class=\"data row27 col13\" >0.002137</td>\n",
       "                        <td id=\"T_9749f_row27_col14\" class=\"data row27 col14\" >0.033856</td>\n",
       "                        <td id=\"T_9749f_row27_col15\" class=\"data row27 col15\" >-0.649866</td>\n",
       "                        <td id=\"T_9749f_row27_col16\" class=\"data row27 col16\" >-0.673755</td>\n",
       "                        <td id=\"T_9749f_row27_col17\" class=\"data row27 col17\" >-0.649866</td>\n",
       "                        <td id=\"T_9749f_row27_col18\" class=\"data row27 col18\" >-0.673755</td>\n",
       "                        <td id=\"T_9749f_row27_col19\" class=\"data row27 col19\" >0.630287</td>\n",
       "                        <td id=\"T_9749f_row27_col20\" class=\"data row27 col20\" >0.662783</td>\n",
       "                        <td id=\"T_9749f_row27_col21\" class=\"data row27 col21\" >-0.000252</td>\n",
       "                        <td id=\"T_9749f_row27_col22\" class=\"data row27 col22\" >-0.019377</td>\n",
       "                        <td id=\"T_9749f_row27_col23\" class=\"data row27 col23\" >0.966743</td>\n",
       "                        <td id=\"T_9749f_row27_col24\" class=\"data row27 col24\" >0.860960</td>\n",
       "                        <td id=\"T_9749f_row27_col25\" class=\"data row27 col25\" >0.982586</td>\n",
       "                        <td id=\"T_9749f_row27_col26\" class=\"data row27 col26\" >0.877463</td>\n",
       "                        <td id=\"T_9749f_row27_col27\" class=\"data row27 col27\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row27_col28\" class=\"data row27 col28\" >0.878252</td>\n",
       "                        <td id=\"T_9749f_row27_col29\" class=\"data row27 col29\" >0.982234</td>\n",
       "                        <td id=\"T_9749f_row27_col30\" class=\"data row27 col30\" >0.877424</td>\n",
       "                        <td id=\"T_9749f_row27_col31\" class=\"data row27 col31\" >-0.064867</td>\n",
       "                        <td id=\"T_9749f_row27_col32\" class=\"data row27 col32\" >-0.261380</td>\n",
       "                        <td id=\"T_9749f_row27_col33\" class=\"data row27 col33\" >0.082663</td>\n",
       "                        <td id=\"T_9749f_row27_col34\" class=\"data row27 col34\" >-0.072081</td>\n",
       "                        <td id=\"T_9749f_row27_col35\" class=\"data row27 col35\" >0.247750</td>\n",
       "                        <td id=\"T_9749f_row27_col36\" class=\"data row27 col36\" >0.165874</td>\n",
       "                        <td id=\"T_9749f_row27_col37\" class=\"data row27 col37\" >0.155420</td>\n",
       "                        <td id=\"T_9749f_row27_col38\" class=\"data row27 col38\" >0.130977</td>\n",
       "                        <td id=\"T_9749f_row27_col39\" class=\"data row27 col39\" >-0.003323</td>\n",
       "                        <td id=\"T_9749f_row27_col40\" class=\"data row27 col40\" >0.089640</td>\n",
       "                        <td id=\"T_9749f_row27_col41\" class=\"data row27 col41\" >0.997911</td>\n",
       "                        <td id=\"T_9749f_row27_col42\" class=\"data row27 col42\" >0.878339</td>\n",
       "                        <td id=\"T_9749f_row27_col43\" class=\"data row27 col43\" >-0.070647</td>\n",
       "                        <td id=\"T_9749f_row27_col44\" class=\"data row27 col44\" >-0.006487</td>\n",
       "                        <td id=\"T_9749f_row27_col45\" class=\"data row27 col45\" >0.074759</td>\n",
       "                        <td id=\"T_9749f_row27_col46\" class=\"data row27 col46\" >0.015256</td>\n",
       "                        <td id=\"T_9749f_row27_col47\" class=\"data row27 col47\" >-0.072148</td>\n",
       "                        <td id=\"T_9749f_row27_col48\" class=\"data row27 col48\" >-0.257144</td>\n",
       "                        <td id=\"T_9749f_row27_col49\" class=\"data row27 col49\" >-0.504862</td>\n",
       "                        <td id=\"T_9749f_row27_col50\" class=\"data row27 col50\" >-0.514488</td>\n",
       "                        <td id=\"T_9749f_row27_col51\" class=\"data row27 col51\" >-0.506393</td>\n",
       "                        <td id=\"T_9749f_row27_col52\" class=\"data row27 col52\" >-0.515382</td>\n",
       "                        <td id=\"T_9749f_row27_col53\" class=\"data row27 col53\" >0.026912</td>\n",
       "                        <td id=\"T_9749f_row27_col54\" class=\"data row27 col54\" >0.159265</td>\n",
       "                        <td id=\"T_9749f_row27_col55\" class=\"data row27 col55\" >0.215840</td>\n",
       "                        <td id=\"T_9749f_row27_col56\" class=\"data row27 col56\" >0.127536</td>\n",
       "                        <td id=\"T_9749f_row27_col57\" class=\"data row27 col57\" >0.001526</td>\n",
       "                        <td id=\"T_9749f_row27_col58\" class=\"data row27 col58\" >-0.000969</td>\n",
       "                        <td id=\"T_9749f_row27_col59\" class=\"data row27 col59\" >0.398544</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row28\" class=\"row_heading level0 row28\" >week_avg_heatindex</th>\n",
       "                        <td id=\"T_9749f_row28_col0\" class=\"data row28 col0\" >0.238363</td>\n",
       "                        <td id=\"T_9749f_row28_col1\" class=\"data row28 col1\" >0.386917</td>\n",
       "                        <td id=\"T_9749f_row28_col2\" class=\"data row28 col2\" >0.441748</td>\n",
       "                        <td id=\"T_9749f_row28_col3\" class=\"data row28 col3\" >0.846157</td>\n",
       "                        <td id=\"T_9749f_row28_col4\" class=\"data row28 col4\" >0.971681</td>\n",
       "                        <td id=\"T_9749f_row28_col5\" class=\"data row28 col5\" >0.818924</td>\n",
       "                        <td id=\"T_9749f_row28_col6\" class=\"data row28 col6\" >0.964164</td>\n",
       "                        <td id=\"T_9749f_row28_col7\" class=\"data row28 col7\" >-0.139292</td>\n",
       "                        <td id=\"T_9749f_row28_col8\" class=\"data row28 col8\" >-0.327886</td>\n",
       "                        <td id=\"T_9749f_row28_col9\" class=\"data row28 col9\" >0.503759</td>\n",
       "                        <td id=\"T_9749f_row28_col10\" class=\"data row28 col10\" >0.590527</td>\n",
       "                        <td id=\"T_9749f_row28_col11\" class=\"data row28 col11\" >0.739332</td>\n",
       "                        <td id=\"T_9749f_row28_col12\" class=\"data row28 col12\" >0.915889</td>\n",
       "                        <td id=\"T_9749f_row28_col13\" class=\"data row28 col13\" >-0.044947</td>\n",
       "                        <td id=\"T_9749f_row28_col14\" class=\"data row28 col14\" >-0.003428</td>\n",
       "                        <td id=\"T_9749f_row28_col15\" class=\"data row28 col15\" >-0.685571</td>\n",
       "                        <td id=\"T_9749f_row28_col16\" class=\"data row28 col16\" >-0.711668</td>\n",
       "                        <td id=\"T_9749f_row28_col17\" class=\"data row28 col17\" >-0.685571</td>\n",
       "                        <td id=\"T_9749f_row28_col18\" class=\"data row28 col18\" >-0.711668</td>\n",
       "                        <td id=\"T_9749f_row28_col19\" class=\"data row28 col19\" >0.647948</td>\n",
       "                        <td id=\"T_9749f_row28_col20\" class=\"data row28 col20\" >0.688189</td>\n",
       "                        <td id=\"T_9749f_row28_col21\" class=\"data row28 col21\" >0.012891</td>\n",
       "                        <td id=\"T_9749f_row28_col22\" class=\"data row28 col22\" >-0.022430</td>\n",
       "                        <td id=\"T_9749f_row28_col23\" class=\"data row28 col23\" >0.833679</td>\n",
       "                        <td id=\"T_9749f_row28_col24\" class=\"data row28 col24\" >0.985253</td>\n",
       "                        <td id=\"T_9749f_row28_col25\" class=\"data row28 col25\" >0.878981</td>\n",
       "                        <td id=\"T_9749f_row28_col26\" class=\"data row28 col26\" >0.992363</td>\n",
       "                        <td id=\"T_9749f_row28_col27\" class=\"data row28 col27\" >0.878252</td>\n",
       "                        <td id=\"T_9749f_row28_col28\" class=\"data row28 col28\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row28_col29\" class=\"data row28 col29\" >0.879350</td>\n",
       "                        <td id=\"T_9749f_row28_col30\" class=\"data row28 col30\" >0.992243</td>\n",
       "                        <td id=\"T_9749f_row28_col31\" class=\"data row28 col31\" >-0.137593</td>\n",
       "                        <td id=\"T_9749f_row28_col32\" class=\"data row28 col32\" >-0.246913</td>\n",
       "                        <td id=\"T_9749f_row28_col33\" class=\"data row28 col33\" >0.005827</td>\n",
       "                        <td id=\"T_9749f_row28_col34\" class=\"data row28 col34\" >-0.029832</td>\n",
       "                        <td id=\"T_9749f_row28_col35\" class=\"data row28 col35\" >0.136905</td>\n",
       "                        <td id=\"T_9749f_row28_col36\" class=\"data row28 col36\" >0.217221</td>\n",
       "                        <td id=\"T_9749f_row28_col37\" class=\"data row28 col37\" >0.152650</td>\n",
       "                        <td id=\"T_9749f_row28_col38\" class=\"data row28 col38\" >0.178447</td>\n",
       "                        <td id=\"T_9749f_row28_col39\" class=\"data row28 col39\" >0.000688</td>\n",
       "                        <td id=\"T_9749f_row28_col40\" class=\"data row28 col40\" >0.046161</td>\n",
       "                        <td id=\"T_9749f_row28_col41\" class=\"data row28 col41\" >0.874173</td>\n",
       "                        <td id=\"T_9749f_row28_col42\" class=\"data row28 col42\" >0.999288</td>\n",
       "                        <td id=\"T_9749f_row28_col43\" class=\"data row28 col43\" >-0.020330</td>\n",
       "                        <td id=\"T_9749f_row28_col44\" class=\"data row28 col44\" >-0.024115</td>\n",
       "                        <td id=\"T_9749f_row28_col45\" class=\"data row28 col45\" >0.073014</td>\n",
       "                        <td id=\"T_9749f_row28_col46\" class=\"data row28 col46\" >0.068207</td>\n",
       "                        <td id=\"T_9749f_row28_col47\" class=\"data row28 col47\" >-0.125130</td>\n",
       "                        <td id=\"T_9749f_row28_col48\" class=\"data row28 col48\" >-0.239669</td>\n",
       "                        <td id=\"T_9749f_row28_col49\" class=\"data row28 col49\" >-0.529737</td>\n",
       "                        <td id=\"T_9749f_row28_col50\" class=\"data row28 col50\" >-0.559063</td>\n",
       "                        <td id=\"T_9749f_row28_col51\" class=\"data row28 col51\" >-0.531371</td>\n",
       "                        <td id=\"T_9749f_row28_col52\" class=\"data row28 col52\" >-0.560527</td>\n",
       "                        <td id=\"T_9749f_row28_col53\" class=\"data row28 col53\" >-0.003697</td>\n",
       "                        <td id=\"T_9749f_row28_col54\" class=\"data row28 col54\" >0.174012</td>\n",
       "                        <td id=\"T_9749f_row28_col55\" class=\"data row28 col55\" >0.261408</td>\n",
       "                        <td id=\"T_9749f_row28_col56\" class=\"data row28 col56\" >0.130497</td>\n",
       "                        <td id=\"T_9749f_row28_col57\" class=\"data row28 col57\" >0.005948</td>\n",
       "                        <td id=\"T_9749f_row28_col58\" class=\"data row28 col58\" >-0.000991</td>\n",
       "                        <td id=\"T_9749f_row28_col59\" class=\"data row28 col59\" >0.407384</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row29\" class=\"row_heading level0 row29\" >day_avg_windchill</th>\n",
       "                        <td id=\"T_9749f_row29_col0\" class=\"data row29 col0\" >0.213159</td>\n",
       "                        <td id=\"T_9749f_row29_col1\" class=\"data row29 col1\" >0.361364</td>\n",
       "                        <td id=\"T_9749f_row29_col2\" class=\"data row29 col2\" >0.408468</td>\n",
       "                        <td id=\"T_9749f_row29_col3\" class=\"data row29 col3\" >0.961953</td>\n",
       "                        <td id=\"T_9749f_row29_col4\" class=\"data row29 col4\" >0.881796</td>\n",
       "                        <td id=\"T_9749f_row29_col5\" class=\"data row29 col5\" >0.905942</td>\n",
       "                        <td id=\"T_9749f_row29_col6\" class=\"data row29 col6\" >0.835460</td>\n",
       "                        <td id=\"T_9749f_row29_col7\" class=\"data row29 col7\" >-0.169717</td>\n",
       "                        <td id=\"T_9749f_row29_col8\" class=\"data row29 col8\" >-0.298495</td>\n",
       "                        <td id=\"T_9749f_row29_col9\" class=\"data row29 col9\" >0.518522</td>\n",
       "                        <td id=\"T_9749f_row29_col10\" class=\"data row29 col10\" >0.618431</td>\n",
       "                        <td id=\"T_9749f_row29_col11\" class=\"data row29 col11\" >0.839167</td>\n",
       "                        <td id=\"T_9749f_row29_col12\" class=\"data row29 col12\" >0.844482</td>\n",
       "                        <td id=\"T_9749f_row29_col13\" class=\"data row29 col13\" >0.003355</td>\n",
       "                        <td id=\"T_9749f_row29_col14\" class=\"data row29 col14\" >0.060380</td>\n",
       "                        <td id=\"T_9749f_row29_col15\" class=\"data row29 col15\" >-0.673291</td>\n",
       "                        <td id=\"T_9749f_row29_col16\" class=\"data row29 col16\" >-0.694089</td>\n",
       "                        <td id=\"T_9749f_row29_col17\" class=\"data row29 col17\" >-0.673291</td>\n",
       "                        <td id=\"T_9749f_row29_col18\" class=\"data row29 col18\" >-0.694089</td>\n",
       "                        <td id=\"T_9749f_row29_col19\" class=\"data row29 col19\" >0.657383</td>\n",
       "                        <td id=\"T_9749f_row29_col20\" class=\"data row29 col20\" >0.686777</td>\n",
       "                        <td id=\"T_9749f_row29_col21\" class=\"data row29 col21\" >-0.005403</td>\n",
       "                        <td id=\"T_9749f_row29_col22\" class=\"data row29 col22\" >-0.013301</td>\n",
       "                        <td id=\"T_9749f_row29_col23\" class=\"data row29 col23\" >0.950768</td>\n",
       "                        <td id=\"T_9749f_row29_col24\" class=\"data row29 col24\" >0.860361</td>\n",
       "                        <td id=\"T_9749f_row29_col25\" class=\"data row29 col25\" >0.999923</td>\n",
       "                        <td id=\"T_9749f_row29_col26\" class=\"data row29 col26\" >0.890043</td>\n",
       "                        <td id=\"T_9749f_row29_col27\" class=\"data row29 col27\" >0.982234</td>\n",
       "                        <td id=\"T_9749f_row29_col28\" class=\"data row29 col28\" >0.879350</td>\n",
       "                        <td id=\"T_9749f_row29_col29\" class=\"data row29 col29\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row29_col30\" class=\"data row29 col30\" >0.890049</td>\n",
       "                        <td id=\"T_9749f_row29_col31\" class=\"data row29 col31\" >-0.224792</td>\n",
       "                        <td id=\"T_9749f_row29_col32\" class=\"data row29 col32\" >-0.345140</td>\n",
       "                        <td id=\"T_9749f_row29_col33\" class=\"data row29 col33\" >0.013807</td>\n",
       "                        <td id=\"T_9749f_row29_col34\" class=\"data row29 col34\" >-0.108867</td>\n",
       "                        <td id=\"T_9749f_row29_col35\" class=\"data row29 col35\" >0.246088</td>\n",
       "                        <td id=\"T_9749f_row29_col36\" class=\"data row29 col36\" >0.158089</td>\n",
       "                        <td id=\"T_9749f_row29_col37\" class=\"data row29 col37\" >0.092100</td>\n",
       "                        <td id=\"T_9749f_row29_col38\" class=\"data row29 col38\" >0.091340</td>\n",
       "                        <td id=\"T_9749f_row29_col39\" class=\"data row29 col39\" >0.081171</td>\n",
       "                        <td id=\"T_9749f_row29_col40\" class=\"data row29 col40\" >0.140721</td>\n",
       "                        <td id=\"T_9749f_row29_col41\" class=\"data row29 col41\" >0.981517</td>\n",
       "                        <td id=\"T_9749f_row29_col42\" class=\"data row29 col42\" >0.879829</td>\n",
       "                        <td id=\"T_9749f_row29_col43\" class=\"data row29 col43\" >-0.036925</td>\n",
       "                        <td id=\"T_9749f_row29_col44\" class=\"data row29 col44\" >0.029165</td>\n",
       "                        <td id=\"T_9749f_row29_col45\" class=\"data row29 col45\" >0.054768</td>\n",
       "                        <td id=\"T_9749f_row29_col46\" class=\"data row29 col46\" >0.015304</td>\n",
       "                        <td id=\"T_9749f_row29_col47\" class=\"data row29 col47\" >-0.233239</td>\n",
       "                        <td id=\"T_9749f_row29_col48\" class=\"data row29 col48\" >-0.342227</td>\n",
       "                        <td id=\"T_9749f_row29_col49\" class=\"data row29 col49\" >-0.525130</td>\n",
       "                        <td id=\"T_9749f_row29_col50\" class=\"data row29 col50\" >-0.538732</td>\n",
       "                        <td id=\"T_9749f_row29_col51\" class=\"data row29 col51\" >-0.526756</td>\n",
       "                        <td id=\"T_9749f_row29_col52\" class=\"data row29 col52\" >-0.539574</td>\n",
       "                        <td id=\"T_9749f_row29_col53\" class=\"data row29 col53\" >0.020439</td>\n",
       "                        <td id=\"T_9749f_row29_col54\" class=\"data row29 col54\" >0.197939</td>\n",
       "                        <td id=\"T_9749f_row29_col55\" class=\"data row29 col55\" >0.181852</td>\n",
       "                        <td id=\"T_9749f_row29_col56\" class=\"data row29 col56\" >0.140167</td>\n",
       "                        <td id=\"T_9749f_row29_col57\" class=\"data row29 col57\" >0.001044</td>\n",
       "                        <td id=\"T_9749f_row29_col58\" class=\"data row29 col58\" >-0.001014</td>\n",
       "                        <td id=\"T_9749f_row29_col59\" class=\"data row29 col59\" >0.414733</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row30\" class=\"row_heading level0 row30\" >week_avg_windchill</th>\n",
       "                        <td id=\"T_9749f_row30_col0\" class=\"data row30 col0\" >0.239797</td>\n",
       "                        <td id=\"T_9749f_row30_col1\" class=\"data row30 col1\" >0.387978</td>\n",
       "                        <td id=\"T_9749f_row30_col2\" class=\"data row30 col2\" >0.436514</td>\n",
       "                        <td id=\"T_9749f_row30_col3\" class=\"data row30 col3\" >0.855587</td>\n",
       "                        <td id=\"T_9749f_row30_col4\" class=\"data row30 col4\" >0.976085</td>\n",
       "                        <td id=\"T_9749f_row30_col5\" class=\"data row30 col5\" >0.809055</td>\n",
       "                        <td id=\"T_9749f_row30_col6\" class=\"data row30 col6\" >0.947995</td>\n",
       "                        <td id=\"T_9749f_row30_col7\" class=\"data row30 col7\" >-0.134871</td>\n",
       "                        <td id=\"T_9749f_row30_col8\" class=\"data row30 col8\" >-0.324467</td>\n",
       "                        <td id=\"T_9749f_row30_col9\" class=\"data row30 col9\" >0.532424</td>\n",
       "                        <td id=\"T_9749f_row30_col10\" class=\"data row30 col10\" >0.623891</td>\n",
       "                        <td id=\"T_9749f_row30_col11\" class=\"data row30 col11\" >0.746752</td>\n",
       "                        <td id=\"T_9749f_row30_col12\" class=\"data row30 col12\" >0.922558</td>\n",
       "                        <td id=\"T_9749f_row30_col13\" class=\"data row30 col13\" >-0.064837</td>\n",
       "                        <td id=\"T_9749f_row30_col14\" class=\"data row30 col14\" >-0.001409</td>\n",
       "                        <td id=\"T_9749f_row30_col15\" class=\"data row30 col15\" >-0.706011</td>\n",
       "                        <td id=\"T_9749f_row30_col16\" class=\"data row30 col16\" >-0.728984</td>\n",
       "                        <td id=\"T_9749f_row30_col17\" class=\"data row30 col17\" >-0.706011</td>\n",
       "                        <td id=\"T_9749f_row30_col18\" class=\"data row30 col18\" >-0.728984</td>\n",
       "                        <td id=\"T_9749f_row30_col19\" class=\"data row30 col19\" >0.669790</td>\n",
       "                        <td id=\"T_9749f_row30_col20\" class=\"data row30 col20\" >0.708564</td>\n",
       "                        <td id=\"T_9749f_row30_col21\" class=\"data row30 col21\" >0.020653</td>\n",
       "                        <td id=\"T_9749f_row30_col22\" class=\"data row30 col22\" >-0.015127</td>\n",
       "                        <td id=\"T_9749f_row30_col23\" class=\"data row30 col23\" >0.832887</td>\n",
       "                        <td id=\"T_9749f_row30_col24\" class=\"data row30 col24\" >0.976763</td>\n",
       "                        <td id=\"T_9749f_row30_col25\" class=\"data row30 col25\" >0.889513</td>\n",
       "                        <td id=\"T_9749f_row30_col26\" class=\"data row30 col26\" >0.999979</td>\n",
       "                        <td id=\"T_9749f_row30_col27\" class=\"data row30 col27\" >0.877424</td>\n",
       "                        <td id=\"T_9749f_row30_col28\" class=\"data row30 col28\" >0.992243</td>\n",
       "                        <td id=\"T_9749f_row30_col29\" class=\"data row30 col29\" >0.890049</td>\n",
       "                        <td id=\"T_9749f_row30_col30\" class=\"data row30 col30\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row30_col31\" class=\"data row30 col31\" >-0.188497</td>\n",
       "                        <td id=\"T_9749f_row30_col32\" class=\"data row30 col32\" >-0.349688</td>\n",
       "                        <td id=\"T_9749f_row30_col33\" class=\"data row30 col33\" >-0.017626</td>\n",
       "                        <td id=\"T_9749f_row30_col34\" class=\"data row30 col34\" >-0.082539</td>\n",
       "                        <td id=\"T_9749f_row30_col35\" class=\"data row30 col35\" >0.135993</td>\n",
       "                        <td id=\"T_9749f_row30_col36\" class=\"data row30 col36\" >0.210471</td>\n",
       "                        <td id=\"T_9749f_row30_col37\" class=\"data row30 col37\" >0.128578</td>\n",
       "                        <td id=\"T_9749f_row30_col38\" class=\"data row30 col38\" >0.127740</td>\n",
       "                        <td id=\"T_9749f_row30_col39\" class=\"data row30 col39\" >0.042382</td>\n",
       "                        <td id=\"T_9749f_row30_col40\" class=\"data row30 col40\" >0.112635</td>\n",
       "                        <td id=\"T_9749f_row30_col41\" class=\"data row30 col41\" >0.873951</td>\n",
       "                        <td id=\"T_9749f_row30_col42\" class=\"data row30 col42\" >0.991901</td>\n",
       "                        <td id=\"T_9749f_row30_col43\" class=\"data row30 col43\" >-0.017954</td>\n",
       "                        <td id=\"T_9749f_row30_col44\" class=\"data row30 col44\" >0.001302</td>\n",
       "                        <td id=\"T_9749f_row30_col45\" class=\"data row30 col45\" >0.077201</td>\n",
       "                        <td id=\"T_9749f_row30_col46\" class=\"data row30 col46\" >0.062785</td>\n",
       "                        <td id=\"T_9749f_row30_col47\" class=\"data row30 col47\" >-0.177996</td>\n",
       "                        <td id=\"T_9749f_row30_col48\" class=\"data row30 col48\" >-0.345024</td>\n",
       "                        <td id=\"T_9749f_row30_col49\" class=\"data row30 col49\" >-0.545845</td>\n",
       "                        <td id=\"T_9749f_row30_col50\" class=\"data row30 col50\" >-0.576238</td>\n",
       "                        <td id=\"T_9749f_row30_col51\" class=\"data row30 col51\" >-0.547587</td>\n",
       "                        <td id=\"T_9749f_row30_col52\" class=\"data row30 col52\" >-0.577732</td>\n",
       "                        <td id=\"T_9749f_row30_col53\" class=\"data row30 col53\" >-0.007420</td>\n",
       "                        <td id=\"T_9749f_row30_col54\" class=\"data row30 col54\" >0.212323</td>\n",
       "                        <td id=\"T_9749f_row30_col55\" class=\"data row30 col55\" >0.219631</td>\n",
       "                        <td id=\"T_9749f_row30_col56\" class=\"data row30 col56\" >0.130534</td>\n",
       "                        <td id=\"T_9749f_row30_col57\" class=\"data row30 col57\" >0.006261</td>\n",
       "                        <td id=\"T_9749f_row30_col58\" class=\"data row30 col58\" >-0.001059</td>\n",
       "                        <td id=\"T_9749f_row30_col59\" class=\"data row30 col59\" >0.426308</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row31\" class=\"row_heading level0 row31\" >day_avg_windgust</th>\n",
       "                        <td id=\"T_9749f_row31_col0\" class=\"data row31 col0\" >-0.061662</td>\n",
       "                        <td id=\"T_9749f_row31_col1\" class=\"data row31 col1\" >-0.093435</td>\n",
       "                        <td id=\"T_9749f_row31_col2\" class=\"data row31 col2\" >-0.053038</td>\n",
       "                        <td id=\"T_9749f_row31_col3\" class=\"data row31 col3\" >-0.165842</td>\n",
       "                        <td id=\"T_9749f_row31_col4\" class=\"data row31 col4\" >-0.191524</td>\n",
       "                        <td id=\"T_9749f_row31_col5\" class=\"data row31 col5\" >-0.019270</td>\n",
       "                        <td id=\"T_9749f_row31_col6\" class=\"data row31 col6\" >-0.096715</td>\n",
       "                        <td id=\"T_9749f_row31_col7\" class=\"data row31 col7\" >0.017203</td>\n",
       "                        <td id=\"T_9749f_row31_col8\" class=\"data row31 col8\" >0.092737</td>\n",
       "                        <td id=\"T_9749f_row31_col9\" class=\"data row31 col9\" >-0.388742</td>\n",
       "                        <td id=\"T_9749f_row31_col10\" class=\"data row31 col10\" >-0.304194</td>\n",
       "                        <td id=\"T_9749f_row31_col11\" class=\"data row31 col11\" >-0.248487</td>\n",
       "                        <td id=\"T_9749f_row31_col12\" class=\"data row31 col12\" >-0.187346</td>\n",
       "                        <td id=\"T_9749f_row31_col13\" class=\"data row31 col13\" >-0.036909</td>\n",
       "                        <td id=\"T_9749f_row31_col14\" class=\"data row31 col14\" >-0.178721</td>\n",
       "                        <td id=\"T_9749f_row31_col15\" class=\"data row31 col15\" >0.261753</td>\n",
       "                        <td id=\"T_9749f_row31_col16\" class=\"data row31 col16\" >0.253043</td>\n",
       "                        <td id=\"T_9749f_row31_col17\" class=\"data row31 col17\" >0.261753</td>\n",
       "                        <td id=\"T_9749f_row31_col18\" class=\"data row31 col18\" >0.253043</td>\n",
       "                        <td id=\"T_9749f_row31_col19\" class=\"data row31 col19\" >-0.269878</td>\n",
       "                        <td id=\"T_9749f_row31_col20\" class=\"data row31 col20\" >-0.256013</td>\n",
       "                        <td id=\"T_9749f_row31_col21\" class=\"data row31 col21\" >0.021215</td>\n",
       "                        <td id=\"T_9749f_row31_col22\" class=\"data row31 col22\" >-0.055691</td>\n",
       "                        <td id=\"T_9749f_row31_col23\" class=\"data row31 col23\" >-0.054436</td>\n",
       "                        <td id=\"T_9749f_row31_col24\" class=\"data row31 col24\" >-0.115759</td>\n",
       "                        <td id=\"T_9749f_row31_col25\" class=\"data row31 col25\" >-0.225089</td>\n",
       "                        <td id=\"T_9749f_row31_col26\" class=\"data row31 col26\" >-0.188976</td>\n",
       "                        <td id=\"T_9749f_row31_col27\" class=\"data row31 col27\" >-0.064867</td>\n",
       "                        <td id=\"T_9749f_row31_col28\" class=\"data row31 col28\" >-0.137593</td>\n",
       "                        <td id=\"T_9749f_row31_col29\" class=\"data row31 col29\" >-0.224792</td>\n",
       "                        <td id=\"T_9749f_row31_col30\" class=\"data row31 col30\" >-0.188497</td>\n",
       "                        <td id=\"T_9749f_row31_col31\" class=\"data row31 col31\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row31_col32\" class=\"data row31 col32\" >0.528670</td>\n",
       "                        <td id=\"T_9749f_row31_col33\" class=\"data row31 col33\" >0.411756</td>\n",
       "                        <td id=\"T_9749f_row31_col34\" class=\"data row31 col34\" >0.273602</td>\n",
       "                        <td id=\"T_9749f_row31_col35\" class=\"data row31 col35\" >-0.006111</td>\n",
       "                        <td id=\"T_9749f_row31_col36\" class=\"data row31 col36\" >0.057528</td>\n",
       "                        <td id=\"T_9749f_row31_col37\" class=\"data row31 col37\" >0.414462</td>\n",
       "                        <td id=\"T_9749f_row31_col38\" class=\"data row31 col38\" >0.276516</td>\n",
       "                        <td id=\"T_9749f_row31_col39\" class=\"data row31 col39\" >-0.480995</td>\n",
       "                        <td id=\"T_9749f_row31_col40\" class=\"data row31 col40\" >-0.302535</td>\n",
       "                        <td id=\"T_9749f_row31_col41\" class=\"data row31 col41\" >-0.065198</td>\n",
       "                        <td id=\"T_9749f_row31_col42\" class=\"data row31 col42\" >-0.137480</td>\n",
       "                        <td id=\"T_9749f_row31_col43\" class=\"data row31 col43\" >-0.197123</td>\n",
       "                        <td id=\"T_9749f_row31_col44\" class=\"data row31 col44\" >-0.249901</td>\n",
       "                        <td id=\"T_9749f_row31_col45\" class=\"data row31 col45\" >0.183119</td>\n",
       "                        <td id=\"T_9749f_row31_col46\" class=\"data row31 col46\" >0.048527</td>\n",
       "                        <td id=\"T_9749f_row31_col47\" class=\"data row31 col47\" >0.990488</td>\n",
       "                        <td id=\"T_9749f_row31_col48\" class=\"data row31 col48\" >0.519489</td>\n",
       "                        <td id=\"T_9749f_row31_col49\" class=\"data row31 col49\" >0.147967</td>\n",
       "                        <td id=\"T_9749f_row31_col50\" class=\"data row31 col50\" >0.163855</td>\n",
       "                        <td id=\"T_9749f_row31_col51\" class=\"data row31 col51\" >0.148473</td>\n",
       "                        <td id=\"T_9749f_row31_col52\" class=\"data row31 col52\" >0.163480</td>\n",
       "                        <td id=\"T_9749f_row31_col53\" class=\"data row31 col53\" >0.045466</td>\n",
       "                        <td id=\"T_9749f_row31_col54\" class=\"data row31 col54\" >-0.188962</td>\n",
       "                        <td id=\"T_9749f_row31_col55\" class=\"data row31 col55\" >0.093873</td>\n",
       "                        <td id=\"T_9749f_row31_col56\" class=\"data row31 col56\" >-0.132681</td>\n",
       "                        <td id=\"T_9749f_row31_col57\" class=\"data row31 col57\" >0.001789</td>\n",
       "                        <td id=\"T_9749f_row31_col58\" class=\"data row31 col58\" >0.000479</td>\n",
       "                        <td id=\"T_9749f_row31_col59\" class=\"data row31 col59\" >-0.106361</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row32\" class=\"row_heading level0 row32\" >week_avg_windgust</th>\n",
       "                        <td id=\"T_9749f_row32_col0\" class=\"data row32 col0\" >-0.088989</td>\n",
       "                        <td id=\"T_9749f_row32_col1\" class=\"data row32 col1\" >-0.135137</td>\n",
       "                        <td id=\"T_9749f_row32_col2\" class=\"data row32 col2\" >-0.109000</td>\n",
       "                        <td id=\"T_9749f_row32_col3\" class=\"data row32 col3\" >-0.346365</td>\n",
       "                        <td id=\"T_9749f_row32_col4\" class=\"data row32 col4\" >-0.341449</td>\n",
       "                        <td id=\"T_9749f_row32_col5\" class=\"data row32 col5\" >-0.182769</td>\n",
       "                        <td id=\"T_9749f_row32_col6\" class=\"data row32 col6\" >-0.173353</td>\n",
       "                        <td id=\"T_9749f_row32_col7\" class=\"data row32 col7\" >0.020589</td>\n",
       "                        <td id=\"T_9749f_row32_col8\" class=\"data row32 col8\" >0.107939</td>\n",
       "                        <td id=\"T_9749f_row32_col9\" class=\"data row32 col9\" >-0.437007</td>\n",
       "                        <td id=\"T_9749f_row32_col10\" class=\"data row32 col10\" >-0.497441</td>\n",
       "                        <td id=\"T_9749f_row32_col11\" class=\"data row32 col11\" >-0.321903</td>\n",
       "                        <td id=\"T_9749f_row32_col12\" class=\"data row32 col12\" >-0.366776</td>\n",
       "                        <td id=\"T_9749f_row32_col13\" class=\"data row32 col13\" >0.143703</td>\n",
       "                        <td id=\"T_9749f_row32_col14\" class=\"data row32 col14\" >-0.055288</td>\n",
       "                        <td id=\"T_9749f_row32_col15\" class=\"data row32 col15\" >0.418366</td>\n",
       "                        <td id=\"T_9749f_row32_col16\" class=\"data row32 col16\" >0.406900</td>\n",
       "                        <td id=\"T_9749f_row32_col17\" class=\"data row32 col17\" >0.418366</td>\n",
       "                        <td id=\"T_9749f_row32_col18\" class=\"data row32 col18\" >0.406900</td>\n",
       "                        <td id=\"T_9749f_row32_col19\" class=\"data row32 col19\" >-0.405178</td>\n",
       "                        <td id=\"T_9749f_row32_col20\" class=\"data row32 col20\" >-0.405399</td>\n",
       "                        <td id=\"T_9749f_row32_col21\" class=\"data row32 col21\" >-0.053121</td>\n",
       "                        <td id=\"T_9749f_row32_col22\" class=\"data row32 col22\" >-0.052056</td>\n",
       "                        <td id=\"T_9749f_row32_col23\" class=\"data row32 col23\" >-0.238176</td>\n",
       "                        <td id=\"T_9749f_row32_col24\" class=\"data row32 col24\" >-0.223172</td>\n",
       "                        <td id=\"T_9749f_row32_col25\" class=\"data row32 col25\" >-0.344117</td>\n",
       "                        <td id=\"T_9749f_row32_col26\" class=\"data row32 col26\" >-0.349705</td>\n",
       "                        <td id=\"T_9749f_row32_col27\" class=\"data row32 col27\" >-0.261380</td>\n",
       "                        <td id=\"T_9749f_row32_col28\" class=\"data row32 col28\" >-0.246913</td>\n",
       "                        <td id=\"T_9749f_row32_col29\" class=\"data row32 col29\" >-0.345140</td>\n",
       "                        <td id=\"T_9749f_row32_col30\" class=\"data row32 col30\" >-0.349688</td>\n",
       "                        <td id=\"T_9749f_row32_col31\" class=\"data row32 col31\" >0.528670</td>\n",
       "                        <td id=\"T_9749f_row32_col32\" class=\"data row32 col32\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row32_col33\" class=\"data row32 col33\" >0.238346</td>\n",
       "                        <td id=\"T_9749f_row32_col34\" class=\"data row32 col34\" >0.509873</td>\n",
       "                        <td id=\"T_9749f_row32_col35\" class=\"data row32 col35\" >0.000226</td>\n",
       "                        <td id=\"T_9749f_row32_col36\" class=\"data row32 col36\" >0.039391</td>\n",
       "                        <td id=\"T_9749f_row32_col37\" class=\"data row32 col37\" >0.222538</td>\n",
       "                        <td id=\"T_9749f_row32_col38\" class=\"data row32 col38\" >0.477326</td>\n",
       "                        <td id=\"T_9749f_row32_col39\" class=\"data row32 col39\" >-0.332747</td>\n",
       "                        <td id=\"T_9749f_row32_col40\" class=\"data row32 col40\" >-0.545773</td>\n",
       "                        <td id=\"T_9749f_row32_col41\" class=\"data row32 col41\" >-0.266803</td>\n",
       "                        <td id=\"T_9749f_row32_col42\" class=\"data row32 col42\" >-0.248495</td>\n",
       "                        <td id=\"T_9749f_row32_col43\" class=\"data row32 col43\" >-0.052381</td>\n",
       "                        <td id=\"T_9749f_row32_col44\" class=\"data row32 col44\" >-0.260356</td>\n",
       "                        <td id=\"T_9749f_row32_col45\" class=\"data row32 col45\" >0.059853</td>\n",
       "                        <td id=\"T_9749f_row32_col46\" class=\"data row32 col46\" >0.151269</td>\n",
       "                        <td id=\"T_9749f_row32_col47\" class=\"data row32 col47\" >0.526551</td>\n",
       "                        <td id=\"T_9749f_row32_col48\" class=\"data row32 col48\" >0.991156</td>\n",
       "                        <td id=\"T_9749f_row32_col49\" class=\"data row32 col49\" >0.251675</td>\n",
       "                        <td id=\"T_9749f_row32_col50\" class=\"data row32 col50\" >0.248909</td>\n",
       "                        <td id=\"T_9749f_row32_col51\" class=\"data row32 col51\" >0.252405</td>\n",
       "                        <td id=\"T_9749f_row32_col52\" class=\"data row32 col52\" >0.249276</td>\n",
       "                        <td id=\"T_9749f_row32_col53\" class=\"data row32 col53\" >0.019342</td>\n",
       "                        <td id=\"T_9749f_row32_col54\" class=\"data row32 col54\" >-0.272125</td>\n",
       "                        <td id=\"T_9749f_row32_col55\" class=\"data row32 col55\" >0.143740</td>\n",
       "                        <td id=\"T_9749f_row32_col56\" class=\"data row32 col56\" >-0.109937</td>\n",
       "                        <td id=\"T_9749f_row32_col57\" class=\"data row32 col57\" >0.006503</td>\n",
       "                        <td id=\"T_9749f_row32_col58\" class=\"data row32 col58\" >0.001056</td>\n",
       "                        <td id=\"T_9749f_row32_col59\" class=\"data row32 col59\" >-0.238010</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row33\" class=\"row_heading level0 row33\" >day_avg_cloud</th>\n",
       "                        <td id=\"T_9749f_row33_col0\" class=\"data row33 col0\" >-0.001699</td>\n",
       "                        <td id=\"T_9749f_row33_col1\" class=\"data row33 col1\" >0.007287</td>\n",
       "                        <td id=\"T_9749f_row33_col2\" class=\"data row33 col2\" >0.034025</td>\n",
       "                        <td id=\"T_9749f_row33_col3\" class=\"data row33 col3\" >-0.079127</td>\n",
       "                        <td id=\"T_9749f_row33_col4\" class=\"data row33 col4\" >-0.076762</td>\n",
       "                        <td id=\"T_9749f_row33_col5\" class=\"data row33 col5\" >0.139211</td>\n",
       "                        <td id=\"T_9749f_row33_col6\" class=\"data row33 col6\" >0.053266</td>\n",
       "                        <td id=\"T_9749f_row33_col7\" class=\"data row33 col7\" >0.043144</td>\n",
       "                        <td id=\"T_9749f_row33_col8\" class=\"data row33 col8\" >0.018867</td>\n",
       "                        <td id=\"T_9749f_row33_col9\" class=\"data row33 col9\" >-0.531756</td>\n",
       "                        <td id=\"T_9749f_row33_col10\" class=\"data row33 col10\" >-0.267359</td>\n",
       "                        <td id=\"T_9749f_row33_col11\" class=\"data row33 col11\" >-0.277570</td>\n",
       "                        <td id=\"T_9749f_row33_col12\" class=\"data row33 col12\" >-0.116951</td>\n",
       "                        <td id=\"T_9749f_row33_col13\" class=\"data row33 col13\" >-0.044620</td>\n",
       "                        <td id=\"T_9749f_row33_col14\" class=\"data row33 col14\" >-0.129667</td>\n",
       "                        <td id=\"T_9749f_row33_col15\" class=\"data row33 col15\" >0.123180</td>\n",
       "                        <td id=\"T_9749f_row33_col16\" class=\"data row33 col16\" >0.110452</td>\n",
       "                        <td id=\"T_9749f_row33_col17\" class=\"data row33 col17\" >0.123180</td>\n",
       "                        <td id=\"T_9749f_row33_col18\" class=\"data row33 col18\" >0.110452</td>\n",
       "                        <td id=\"T_9749f_row33_col19\" class=\"data row33 col19\" >-0.136204</td>\n",
       "                        <td id=\"T_9749f_row33_col20\" class=\"data row33 col20\" >-0.119069</td>\n",
       "                        <td id=\"T_9749f_row33_col21\" class=\"data row33 col21\" >0.082551</td>\n",
       "                        <td id=\"T_9749f_row33_col22\" class=\"data row33 col22\" >0.018857</td>\n",
       "                        <td id=\"T_9749f_row33_col23\" class=\"data row33 col23\" >0.226580</td>\n",
       "                        <td id=\"T_9749f_row33_col24\" class=\"data row33 col24\" >0.064662</td>\n",
       "                        <td id=\"T_9749f_row33_col25\" class=\"data row33 col25\" >0.012727</td>\n",
       "                        <td id=\"T_9749f_row33_col26\" class=\"data row33 col26\" >-0.017358</td>\n",
       "                        <td id=\"T_9749f_row33_col27\" class=\"data row33 col27\" >0.082663</td>\n",
       "                        <td id=\"T_9749f_row33_col28\" class=\"data row33 col28\" >0.005827</td>\n",
       "                        <td id=\"T_9749f_row33_col29\" class=\"data row33 col29\" >0.013807</td>\n",
       "                        <td id=\"T_9749f_row33_col30\" class=\"data row33 col30\" >-0.017626</td>\n",
       "                        <td id=\"T_9749f_row33_col31\" class=\"data row33 col31\" >0.411756</td>\n",
       "                        <td id=\"T_9749f_row33_col32\" class=\"data row33 col32\" >0.238346</td>\n",
       "                        <td id=\"T_9749f_row33_col33\" class=\"data row33 col33\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row33_col34\" class=\"data row33 col34\" >0.462468</td>\n",
       "                        <td id=\"T_9749f_row33_col35\" class=\"data row33 col35\" >0.560231</td>\n",
       "                        <td id=\"T_9749f_row33_col36\" class=\"data row33 col36\" >0.320808</td>\n",
       "                        <td id=\"T_9749f_row33_col37\" class=\"data row33 col37\" >0.470748</td>\n",
       "                        <td id=\"T_9749f_row33_col38\" class=\"data row33 col38\" >0.313859</td>\n",
       "                        <td id=\"T_9749f_row33_col39\" class=\"data row33 col39\" >-0.487044</td>\n",
       "                        <td id=\"T_9749f_row33_col40\" class=\"data row33 col40\" >-0.320019</td>\n",
       "                        <td id=\"T_9749f_row33_col41\" class=\"data row33 col41\" >0.080052</td>\n",
       "                        <td id=\"T_9749f_row33_col42\" class=\"data row33 col42\" >0.002637</td>\n",
       "                        <td id=\"T_9749f_row33_col43\" class=\"data row33 col43\" >-0.360370</td>\n",
       "                        <td id=\"T_9749f_row33_col44\" class=\"data row33 col44\" >-0.166143</td>\n",
       "                        <td id=\"T_9749f_row33_col45\" class=\"data row33 col45\" >0.244252</td>\n",
       "                        <td id=\"T_9749f_row33_col46\" class=\"data row33 col46\" >0.152565</td>\n",
       "                        <td id=\"T_9749f_row33_col47\" class=\"data row33 col47\" >0.436106</td>\n",
       "                        <td id=\"T_9749f_row33_col48\" class=\"data row33 col48\" >0.246012</td>\n",
       "                        <td id=\"T_9749f_row33_col49\" class=\"data row33 col49\" >0.010810</td>\n",
       "                        <td id=\"T_9749f_row33_col50\" class=\"data row33 col50\" >0.025014</td>\n",
       "                        <td id=\"T_9749f_row33_col51\" class=\"data row33 col51\" >0.012255</td>\n",
       "                        <td id=\"T_9749f_row33_col52\" class=\"data row33 col52\" >0.025585</td>\n",
       "                        <td id=\"T_9749f_row33_col53\" class=\"data row33 col53\" >0.055944</td>\n",
       "                        <td id=\"T_9749f_row33_col54\" class=\"data row33 col54\" >-0.054146</td>\n",
       "                        <td id=\"T_9749f_row33_col55\" class=\"data row33 col55\" >0.094751</td>\n",
       "                        <td id=\"T_9749f_row33_col56\" class=\"data row33 col56\" >-0.164227</td>\n",
       "                        <td id=\"T_9749f_row33_col57\" class=\"data row33 col57\" >-0.001524</td>\n",
       "                        <td id=\"T_9749f_row33_col58\" class=\"data row33 col58\" >0.000173</td>\n",
       "                        <td id=\"T_9749f_row33_col59\" class=\"data row33 col59\" >-0.045520</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row34\" class=\"row_heading level0 row34\" >week_avg_cloud</th>\n",
       "                        <td id=\"T_9749f_row34_col0\" class=\"data row34 col0\" >0.028084</td>\n",
       "                        <td id=\"T_9749f_row34_col1\" class=\"data row34 col1\" >0.049880</td>\n",
       "                        <td id=\"T_9749f_row34_col2\" class=\"data row34 col2\" >0.064772</td>\n",
       "                        <td id=\"T_9749f_row34_col3\" class=\"data row34 col3\" >-0.187650</td>\n",
       "                        <td id=\"T_9749f_row34_col4\" class=\"data row34 col4\" >-0.180175</td>\n",
       "                        <td id=\"T_9749f_row34_col5\" class=\"data row34 col5\" >0.002010</td>\n",
       "                        <td id=\"T_9749f_row34_col6\" class=\"data row34 col6\" >0.061058</td>\n",
       "                        <td id=\"T_9749f_row34_col7\" class=\"data row34 col7\" >0.047489</td>\n",
       "                        <td id=\"T_9749f_row34_col8\" class=\"data row34 col8\" >0.051940</td>\n",
       "                        <td id=\"T_9749f_row34_col9\" class=\"data row34 col9\" >-0.393922</td>\n",
       "                        <td id=\"T_9749f_row34_col10\" class=\"data row34 col10\" >-0.491625</td>\n",
       "                        <td id=\"T_9749f_row34_col11\" class=\"data row34 col11\" >-0.290585</td>\n",
       "                        <td id=\"T_9749f_row34_col12\" class=\"data row34 col12\" >-0.321047</td>\n",
       "                        <td id=\"T_9749f_row34_col13\" class=\"data row34 col13\" >0.047104</td>\n",
       "                        <td id=\"T_9749f_row34_col14\" class=\"data row34 col14\" >-0.082974</td>\n",
       "                        <td id=\"T_9749f_row34_col15\" class=\"data row34 col15\" >0.239474</td>\n",
       "                        <td id=\"T_9749f_row34_col16\" class=\"data row34 col16\" >0.209096</td>\n",
       "                        <td id=\"T_9749f_row34_col17\" class=\"data row34 col17\" >0.239474</td>\n",
       "                        <td id=\"T_9749f_row34_col18\" class=\"data row34 col18\" >0.209096</td>\n",
       "                        <td id=\"T_9749f_row34_col19\" class=\"data row34 col19\" >-0.218726</td>\n",
       "                        <td id=\"T_9749f_row34_col20\" class=\"data row34 col20\" >-0.211610</td>\n",
       "                        <td id=\"T_9749f_row34_col21\" class=\"data row34 col21\" >0.073271</td>\n",
       "                        <td id=\"T_9749f_row34_col22\" class=\"data row34 col22\" >0.093184</td>\n",
       "                        <td id=\"T_9749f_row34_col23\" class=\"data row34 col23\" >0.003684</td>\n",
       "                        <td id=\"T_9749f_row34_col24\" class=\"data row34 col24\" >0.076389</td>\n",
       "                        <td id=\"T_9749f_row34_col25\" class=\"data row34 col25\" >-0.108145</td>\n",
       "                        <td id=\"T_9749f_row34_col26\" class=\"data row34 col26\" >-0.082115</td>\n",
       "                        <td id=\"T_9749f_row34_col27\" class=\"data row34 col27\" >-0.072081</td>\n",
       "                        <td id=\"T_9749f_row34_col28\" class=\"data row34 col28\" >-0.029832</td>\n",
       "                        <td id=\"T_9749f_row34_col29\" class=\"data row34 col29\" >-0.108867</td>\n",
       "                        <td id=\"T_9749f_row34_col30\" class=\"data row34 col30\" >-0.082539</td>\n",
       "                        <td id=\"T_9749f_row34_col31\" class=\"data row34 col31\" >0.273602</td>\n",
       "                        <td id=\"T_9749f_row34_col32\" class=\"data row34 col32\" >0.509873</td>\n",
       "                        <td id=\"T_9749f_row34_col33\" class=\"data row34 col33\" >0.462468</td>\n",
       "                        <td id=\"T_9749f_row34_col34\" class=\"data row34 col34\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row34_col35\" class=\"data row34 col35\" >0.246982</td>\n",
       "                        <td id=\"T_9749f_row34_col36\" class=\"data row34 col36\" >0.560852</td>\n",
       "                        <td id=\"T_9749f_row34_col37\" class=\"data row34 col37\" >0.276438</td>\n",
       "                        <td id=\"T_9749f_row34_col38\" class=\"data row34 col38\" >0.550556</td>\n",
       "                        <td id=\"T_9749f_row34_col39\" class=\"data row34 col39\" >-0.251668</td>\n",
       "                        <td id=\"T_9749f_row34_col40\" class=\"data row34 col40\" >-0.546340</td>\n",
       "                        <td id=\"T_9749f_row34_col41\" class=\"data row34 col41\" >-0.075814</td>\n",
       "                        <td id=\"T_9749f_row34_col42\" class=\"data row34 col42\" >-0.031666</td>\n",
       "                        <td id=\"T_9749f_row34_col43\" class=\"data row34 col43\" >-0.159412</td>\n",
       "                        <td id=\"T_9749f_row34_col44\" class=\"data row34 col44\" >-0.280466</td>\n",
       "                        <td id=\"T_9749f_row34_col45\" class=\"data row34 col45\" >0.165823</td>\n",
       "                        <td id=\"T_9749f_row34_col46\" class=\"data row34 col46\" >0.333998</td>\n",
       "                        <td id=\"T_9749f_row34_col47\" class=\"data row34 col47\" >0.276261</td>\n",
       "                        <td id=\"T_9749f_row34_col48\" class=\"data row34 col48\" >0.529928</td>\n",
       "                        <td id=\"T_9749f_row34_col49\" class=\"data row34 col49\" >0.069507</td>\n",
       "                        <td id=\"T_9749f_row34_col50\" class=\"data row34 col50\" >0.043984</td>\n",
       "                        <td id=\"T_9749f_row34_col51\" class=\"data row34 col51\" >0.070128</td>\n",
       "                        <td id=\"T_9749f_row34_col52\" class=\"data row34 col52\" >0.045199</td>\n",
       "                        <td id=\"T_9749f_row34_col53\" class=\"data row34 col53\" >0.032563</td>\n",
       "                        <td id=\"T_9749f_row34_col54\" class=\"data row34 col54\" >-0.034436</td>\n",
       "                        <td id=\"T_9749f_row34_col55\" class=\"data row34 col55\" >0.097594</td>\n",
       "                        <td id=\"T_9749f_row34_col56\" class=\"data row34 col56\" >-0.092276</td>\n",
       "                        <td id=\"T_9749f_row34_col57\" class=\"data row34 col57\" >-0.003679</td>\n",
       "                        <td id=\"T_9749f_row34_col58\" class=\"data row34 col58\" >0.000081</td>\n",
       "                        <td id=\"T_9749f_row34_col59\" class=\"data row34 col59\" >-0.186749</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row35\" class=\"row_heading level0 row35\" >day_avg_humidity</th>\n",
       "                        <td id=\"T_9749f_row35_col0\" class=\"data row35 col0\" >0.049246</td>\n",
       "                        <td id=\"T_9749f_row35_col1\" class=\"data row35 col1\" >0.078898</td>\n",
       "                        <td id=\"T_9749f_row35_col2\" class=\"data row35 col2\" >0.076198</td>\n",
       "                        <td id=\"T_9749f_row35_col3\" class=\"data row35 col3\" >0.127885</td>\n",
       "                        <td id=\"T_9749f_row35_col4\" class=\"data row35 col4\" >0.062376</td>\n",
       "                        <td id=\"T_9749f_row35_col5\" class=\"data row35 col5\" >0.311324</td>\n",
       "                        <td id=\"T_9749f_row35_col6\" class=\"data row35 col6\" >0.207099</td>\n",
       "                        <td id=\"T_9749f_row35_col7\" class=\"data row35 col7\" >-0.099852</td>\n",
       "                        <td id=\"T_9749f_row35_col8\" class=\"data row35 col8\" >-0.102398</td>\n",
       "                        <td id=\"T_9749f_row35_col9\" class=\"data row35 col9\" >-0.335275</td>\n",
       "                        <td id=\"T_9749f_row35_col10\" class=\"data row35 col10\" >-0.174351</td>\n",
       "                        <td id=\"T_9749f_row35_col11\" class=\"data row35 col11\" >0.014442</td>\n",
       "                        <td id=\"T_9749f_row35_col12\" class=\"data row35 col12\" >0.045121</td>\n",
       "                        <td id=\"T_9749f_row35_col13\" class=\"data row35 col13\" >-0.026697</td>\n",
       "                        <td id=\"T_9749f_row35_col14\" class=\"data row35 col14\" >0.022916</td>\n",
       "                        <td id=\"T_9749f_row35_col15\" class=\"data row35 col15\" >0.091333</td>\n",
       "                        <td id=\"T_9749f_row35_col16\" class=\"data row35 col16\" >0.078978</td>\n",
       "                        <td id=\"T_9749f_row35_col17\" class=\"data row35 col17\" >0.091333</td>\n",
       "                        <td id=\"T_9749f_row35_col18\" class=\"data row35 col18\" >0.078978</td>\n",
       "                        <td id=\"T_9749f_row35_col19\" class=\"data row35 col19\" >-0.114152</td>\n",
       "                        <td id=\"T_9749f_row35_col20\" class=\"data row35 col20\" >-0.095906</td>\n",
       "                        <td id=\"T_9749f_row35_col21\" class=\"data row35 col21\" >0.071710</td>\n",
       "                        <td id=\"T_9749f_row35_col22\" class=\"data row35 col22\" >0.018432</td>\n",
       "                        <td id=\"T_9749f_row35_col23\" class=\"data row35 col23\" >0.480388</td>\n",
       "                        <td id=\"T_9749f_row35_col24\" class=\"data row35 col24\" >0.212387</td>\n",
       "                        <td id=\"T_9749f_row35_col25\" class=\"data row35 col25\" >0.245008</td>\n",
       "                        <td id=\"T_9749f_row35_col26\" class=\"data row35 col26\" >0.136342</td>\n",
       "                        <td id=\"T_9749f_row35_col27\" class=\"data row35 col27\" >0.247750</td>\n",
       "                        <td id=\"T_9749f_row35_col28\" class=\"data row35 col28\" >0.136905</td>\n",
       "                        <td id=\"T_9749f_row35_col29\" class=\"data row35 col29\" >0.246088</td>\n",
       "                        <td id=\"T_9749f_row35_col30\" class=\"data row35 col30\" >0.135993</td>\n",
       "                        <td id=\"T_9749f_row35_col31\" class=\"data row35 col31\" >-0.006111</td>\n",
       "                        <td id=\"T_9749f_row35_col32\" class=\"data row35 col32\" >0.000226</td>\n",
       "                        <td id=\"T_9749f_row35_col33\" class=\"data row35 col33\" >0.560231</td>\n",
       "                        <td id=\"T_9749f_row35_col34\" class=\"data row35 col34\" >0.246982</td>\n",
       "                        <td id=\"T_9749f_row35_col35\" class=\"data row35 col35\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row35_col36\" class=\"data row35 col36\" >0.498735</td>\n",
       "                        <td id=\"T_9749f_row35_col37\" class=\"data row35 col37\" >0.253060</td>\n",
       "                        <td id=\"T_9749f_row35_col38\" class=\"data row35 col38\" >0.107709</td>\n",
       "                        <td id=\"T_9749f_row35_col39\" class=\"data row35 col39\" >-0.127051</td>\n",
       "                        <td id=\"T_9749f_row35_col40\" class=\"data row35 col40\" >-0.074705</td>\n",
       "                        <td id=\"T_9749f_row35_col41\" class=\"data row35 col41\" >0.245688</td>\n",
       "                        <td id=\"T_9749f_row35_col42\" class=\"data row35 col42\" >0.135347</td>\n",
       "                        <td id=\"T_9749f_row35_col43\" class=\"data row35 col43\" >-0.287701</td>\n",
       "                        <td id=\"T_9749f_row35_col44\" class=\"data row35 col44\" >-0.109097</td>\n",
       "                        <td id=\"T_9749f_row35_col45\" class=\"data row35 col45\" >0.016953</td>\n",
       "                        <td id=\"T_9749f_row35_col46\" class=\"data row35 col46\" >0.068710</td>\n",
       "                        <td id=\"T_9749f_row35_col47\" class=\"data row35 col47\" >-0.009165</td>\n",
       "                        <td id=\"T_9749f_row35_col48\" class=\"data row35 col48\" >-0.011432</td>\n",
       "                        <td id=\"T_9749f_row35_col49\" class=\"data row35 col49\" >-0.094477</td>\n",
       "                        <td id=\"T_9749f_row35_col50\" class=\"data row35 col50\" >-0.085544</td>\n",
       "                        <td id=\"T_9749f_row35_col51\" class=\"data row35 col51\" >-0.094425</td>\n",
       "                        <td id=\"T_9749f_row35_col52\" class=\"data row35 col52\" >-0.085603</td>\n",
       "                        <td id=\"T_9749f_row35_col53\" class=\"data row35 col53\" >0.013207</td>\n",
       "                        <td id=\"T_9749f_row35_col54\" class=\"data row35 col54\" >-0.150775</td>\n",
       "                        <td id=\"T_9749f_row35_col55\" class=\"data row35 col55\" >0.164302</td>\n",
       "                        <td id=\"T_9749f_row35_col56\" class=\"data row35 col56\" >0.034549</td>\n",
       "                        <td id=\"T_9749f_row35_col57\" class=\"data row35 col57\" >-0.005958</td>\n",
       "                        <td id=\"T_9749f_row35_col58\" class=\"data row35 col58\" >-0.000326</td>\n",
       "                        <td id=\"T_9749f_row35_col59\" class=\"data row35 col59\" >0.053890</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row36\" class=\"row_heading level0 row36\" >week_avg_humidity</th>\n",
       "                        <td id=\"T_9749f_row36_col0\" class=\"data row36 col0\" >0.063068</td>\n",
       "                        <td id=\"T_9749f_row36_col1\" class=\"data row36 col1\" >0.129756</td>\n",
       "                        <td id=\"T_9749f_row36_col2\" class=\"data row36 col2\" >0.110884</td>\n",
       "                        <td id=\"T_9749f_row36_col3\" class=\"data row36 col3\" >0.035357</td>\n",
       "                        <td id=\"T_9749f_row36_col4\" class=\"data row36 col4\" >0.086222</td>\n",
       "                        <td id=\"T_9749f_row36_col5\" class=\"data row36 col5\" >0.262858</td>\n",
       "                        <td id=\"T_9749f_row36_col6\" class=\"data row36 col6\" >0.353141</td>\n",
       "                        <td id=\"T_9749f_row36_col7\" class=\"data row36 col7\" >-0.061721</td>\n",
       "                        <td id=\"T_9749f_row36_col8\" class=\"data row36 col8\" >-0.209299</td>\n",
       "                        <td id=\"T_9749f_row36_col9\" class=\"data row36 col9\" >-0.329134</td>\n",
       "                        <td id=\"T_9749f_row36_col10\" class=\"data row36 col10\" >-0.350825</td>\n",
       "                        <td id=\"T_9749f_row36_col11\" class=\"data row36 col11\" >-0.045763</td>\n",
       "                        <td id=\"T_9749f_row36_col12\" class=\"data row36 col12\" >0.011464</td>\n",
       "                        <td id=\"T_9749f_row36_col13\" class=\"data row36 col13\" >-0.113556</td>\n",
       "                        <td id=\"T_9749f_row36_col14\" class=\"data row36 col14\" >-0.051992</td>\n",
       "                        <td id=\"T_9749f_row36_col15\" class=\"data row36 col15\" >0.191880</td>\n",
       "                        <td id=\"T_9749f_row36_col16\" class=\"data row36 col16\" >0.162840</td>\n",
       "                        <td id=\"T_9749f_row36_col17\" class=\"data row36 col17\" >0.191880</td>\n",
       "                        <td id=\"T_9749f_row36_col18\" class=\"data row36 col18\" >0.162840</td>\n",
       "                        <td id=\"T_9749f_row36_col19\" class=\"data row36 col19\" >-0.207379</td>\n",
       "                        <td id=\"T_9749f_row36_col20\" class=\"data row36 col20\" >-0.188514</td>\n",
       "                        <td id=\"T_9749f_row36_col21\" class=\"data row36 col21\" >0.096163</td>\n",
       "                        <td id=\"T_9749f_row36_col22\" class=\"data row36 col22\" >0.083314</td>\n",
       "                        <td id=\"T_9749f_row36_col23\" class=\"data row36 col23\" >0.282380</td>\n",
       "                        <td id=\"T_9749f_row36_col24\" class=\"data row36 col24\" >0.376964</td>\n",
       "                        <td id=\"T_9749f_row36_col25\" class=\"data row36 col25\" >0.158403</td>\n",
       "                        <td id=\"T_9749f_row36_col26\" class=\"data row36 col26\" >0.211160</td>\n",
       "                        <td id=\"T_9749f_row36_col27\" class=\"data row36 col27\" >0.165874</td>\n",
       "                        <td id=\"T_9749f_row36_col28\" class=\"data row36 col28\" >0.217221</td>\n",
       "                        <td id=\"T_9749f_row36_col29\" class=\"data row36 col29\" >0.158089</td>\n",
       "                        <td id=\"T_9749f_row36_col30\" class=\"data row36 col30\" >0.210471</td>\n",
       "                        <td id=\"T_9749f_row36_col31\" class=\"data row36 col31\" >0.057528</td>\n",
       "                        <td id=\"T_9749f_row36_col32\" class=\"data row36 col32\" >0.039391</td>\n",
       "                        <td id=\"T_9749f_row36_col33\" class=\"data row36 col33\" >0.320808</td>\n",
       "                        <td id=\"T_9749f_row36_col34\" class=\"data row36 col34\" >0.560852</td>\n",
       "                        <td id=\"T_9749f_row36_col35\" class=\"data row36 col35\" >0.498735</td>\n",
       "                        <td id=\"T_9749f_row36_col36\" class=\"data row36 col36\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row36_col37\" class=\"data row36 col37\" >0.136863</td>\n",
       "                        <td id=\"T_9749f_row36_col38\" class=\"data row36 col38\" >0.175488</td>\n",
       "                        <td id=\"T_9749f_row36_col39\" class=\"data row36 col39\" >-0.020173</td>\n",
       "                        <td id=\"T_9749f_row36_col40\" class=\"data row36 col40\" >-0.091252</td>\n",
       "                        <td id=\"T_9749f_row36_col41\" class=\"data row36 col41\" >0.166157</td>\n",
       "                        <td id=\"T_9749f_row36_col42\" class=\"data row36 col42\" >0.218473</td>\n",
       "                        <td id=\"T_9749f_row36_col43\" class=\"data row36 col43\" >-0.202490</td>\n",
       "                        <td id=\"T_9749f_row36_col44\" class=\"data row36 col44\" >-0.206995</td>\n",
       "                        <td id=\"T_9749f_row36_col45\" class=\"data row36 col45\" >0.122414</td>\n",
       "                        <td id=\"T_9749f_row36_col46\" class=\"data row36 col46\" >0.172251</td>\n",
       "                        <td id=\"T_9749f_row36_col47\" class=\"data row36 col47\" >0.045572</td>\n",
       "                        <td id=\"T_9749f_row36_col48\" class=\"data row36 col48\" >0.017844</td>\n",
       "                        <td id=\"T_9749f_row36_col49\" class=\"data row36 col49\" >-0.143859</td>\n",
       "                        <td id=\"T_9749f_row36_col50\" class=\"data row36 col50\" >-0.157776</td>\n",
       "                        <td id=\"T_9749f_row36_col51\" class=\"data row36 col51\" >-0.144804</td>\n",
       "                        <td id=\"T_9749f_row36_col52\" class=\"data row36 col52\" >-0.157599</td>\n",
       "                        <td id=\"T_9749f_row36_col53\" class=\"data row36 col53\" >0.019431</td>\n",
       "                        <td id=\"T_9749f_row36_col54\" class=\"data row36 col54\" >-0.194109</td>\n",
       "                        <td id=\"T_9749f_row36_col55\" class=\"data row36 col55\" >0.219572</td>\n",
       "                        <td id=\"T_9749f_row36_col56\" class=\"data row36 col56\" >-0.024028</td>\n",
       "                        <td id=\"T_9749f_row36_col57\" class=\"data row36 col57\" >-0.015468</td>\n",
       "                        <td id=\"T_9749f_row36_col58\" class=\"data row36 col58\" >-0.000985</td>\n",
       "                        <td id=\"T_9749f_row36_col59\" class=\"data row36 col59\" >0.014142</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row37\" class=\"row_heading level0 row37\" >day_avg_precip</th>\n",
       "                        <td id=\"T_9749f_row37_col0\" class=\"data row37 col0\" >0.053676</td>\n",
       "                        <td id=\"T_9749f_row37_col1\" class=\"data row37 col1\" >0.105743</td>\n",
       "                        <td id=\"T_9749f_row37_col2\" class=\"data row37 col2\" >0.150654</td>\n",
       "                        <td id=\"T_9749f_row37_col3\" class=\"data row37 col3\" >0.077244</td>\n",
       "                        <td id=\"T_9749f_row37_col4\" class=\"data row37 col4\" >0.117555</td>\n",
       "                        <td id=\"T_9749f_row37_col5\" class=\"data row37 col5\" >0.139049</td>\n",
       "                        <td id=\"T_9749f_row37_col6\" class=\"data row37 col6\" >0.169635</td>\n",
       "                        <td id=\"T_9749f_row37_col7\" class=\"data row37 col7\" >0.089030</td>\n",
       "                        <td id=\"T_9749f_row37_col8\" class=\"data row37 col8\" >0.108632</td>\n",
       "                        <td id=\"T_9749f_row37_col9\" class=\"data row37 col9\" >-0.161127</td>\n",
       "                        <td id=\"T_9749f_row37_col10\" class=\"data row37 col10\" >-0.031411</td>\n",
       "                        <td id=\"T_9749f_row37_col11\" class=\"data row37 col11\" >-0.073706</td>\n",
       "                        <td id=\"T_9749f_row37_col12\" class=\"data row37 col12\" >0.043991</td>\n",
       "                        <td id=\"T_9749f_row37_col13\" class=\"data row37 col13\" >-0.139370</td>\n",
       "                        <td id=\"T_9749f_row37_col14\" class=\"data row37 col14\" >-0.199083</td>\n",
       "                        <td id=\"T_9749f_row37_col15\" class=\"data row37 col15\" >-0.067234</td>\n",
       "                        <td id=\"T_9749f_row37_col16\" class=\"data row37 col16\" >-0.077334</td>\n",
       "                        <td id=\"T_9749f_row37_col17\" class=\"data row37 col17\" >-0.067234</td>\n",
       "                        <td id=\"T_9749f_row37_col18\" class=\"data row37 col18\" >-0.077334</td>\n",
       "                        <td id=\"T_9749f_row37_col19\" class=\"data row37 col19\" >0.098560</td>\n",
       "                        <td id=\"T_9749f_row37_col20\" class=\"data row37 col20\" >0.103484</td>\n",
       "                        <td id=\"T_9749f_row37_col21\" class=\"data row37 col21\" >-0.024810</td>\n",
       "                        <td id=\"T_9749f_row37_col22\" class=\"data row37 col22\" >-0.024183</td>\n",
       "                        <td id=\"T_9749f_row37_col23\" class=\"data row37 col23\" >0.215508</td>\n",
       "                        <td id=\"T_9749f_row37_col24\" class=\"data row37 col24\" >0.173710</td>\n",
       "                        <td id=\"T_9749f_row37_col25\" class=\"data row37 col25\" >0.091814</td>\n",
       "                        <td id=\"T_9749f_row37_col26\" class=\"data row37 col26\" >0.129269</td>\n",
       "                        <td id=\"T_9749f_row37_col27\" class=\"data row37 col27\" >0.155420</td>\n",
       "                        <td id=\"T_9749f_row37_col28\" class=\"data row37 col28\" >0.152650</td>\n",
       "                        <td id=\"T_9749f_row37_col29\" class=\"data row37 col29\" >0.092100</td>\n",
       "                        <td id=\"T_9749f_row37_col30\" class=\"data row37 col30\" >0.128578</td>\n",
       "                        <td id=\"T_9749f_row37_col31\" class=\"data row37 col31\" >0.414462</td>\n",
       "                        <td id=\"T_9749f_row37_col32\" class=\"data row37 col32\" >0.222538</td>\n",
       "                        <td id=\"T_9749f_row37_col33\" class=\"data row37 col33\" >0.470748</td>\n",
       "                        <td id=\"T_9749f_row37_col34\" class=\"data row37 col34\" >0.276438</td>\n",
       "                        <td id=\"T_9749f_row37_col35\" class=\"data row37 col35\" >0.253060</td>\n",
       "                        <td id=\"T_9749f_row37_col36\" class=\"data row37 col36\" >0.136863</td>\n",
       "                        <td id=\"T_9749f_row37_col37\" class=\"data row37 col37\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row37_col38\" class=\"data row37 col38\" >0.601591</td>\n",
       "                        <td id=\"T_9749f_row37_col39\" class=\"data row37 col39\" >-0.532497</td>\n",
       "                        <td id=\"T_9749f_row37_col40\" class=\"data row37 col40\" >-0.350352</td>\n",
       "                        <td id=\"T_9749f_row37_col41\" class=\"data row37 col41\" >0.149122</td>\n",
       "                        <td id=\"T_9749f_row37_col42\" class=\"data row37 col42\" >0.152974</td>\n",
       "                        <td id=\"T_9749f_row37_col43\" class=\"data row37 col43\" >-0.312232</td>\n",
       "                        <td id=\"T_9749f_row37_col44\" class=\"data row37 col44\" >-0.224162</td>\n",
       "                        <td id=\"T_9749f_row37_col45\" class=\"data row37 col45\" >0.127714</td>\n",
       "                        <td id=\"T_9749f_row37_col46\" class=\"data row37 col46\" >0.098100</td>\n",
       "                        <td id=\"T_9749f_row37_col47\" class=\"data row37 col47\" >0.416463</td>\n",
       "                        <td id=\"T_9749f_row37_col48\" class=\"data row37 col48\" >0.212212</td>\n",
       "                        <td id=\"T_9749f_row37_col49\" class=\"data row37 col49\" >-0.060328</td>\n",
       "                        <td id=\"T_9749f_row37_col50\" class=\"data row37 col50\" >-0.048607</td>\n",
       "                        <td id=\"T_9749f_row37_col51\" class=\"data row37 col51\" >-0.059935</td>\n",
       "                        <td id=\"T_9749f_row37_col52\" class=\"data row37 col52\" >-0.048918</td>\n",
       "                        <td id=\"T_9749f_row37_col53\" class=\"data row37 col53\" >0.029373</td>\n",
       "                        <td id=\"T_9749f_row37_col54\" class=\"data row37 col54\" >0.181255</td>\n",
       "                        <td id=\"T_9749f_row37_col55\" class=\"data row37 col55\" >-0.049851</td>\n",
       "                        <td id=\"T_9749f_row37_col56\" class=\"data row37 col56\" >-0.106381</td>\n",
       "                        <td id=\"T_9749f_row37_col57\" class=\"data row37 col57\" >-0.004918</td>\n",
       "                        <td id=\"T_9749f_row37_col58\" class=\"data row37 col58\" >0.000529</td>\n",
       "                        <td id=\"T_9749f_row37_col59\" class=\"data row37 col59\" >-0.000017</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row38\" class=\"row_heading level0 row38\" >week_avg_precip</th>\n",
       "                        <td id=\"T_9749f_row38_col0\" class=\"data row38 col0\" >0.085062</td>\n",
       "                        <td id=\"T_9749f_row38_col1\" class=\"data row38 col1\" >0.151275</td>\n",
       "                        <td id=\"T_9749f_row38_col2\" class=\"data row38 col2\" >0.201830</td>\n",
       "                        <td id=\"T_9749f_row38_col3\" class=\"data row38 col3\" >0.072691</td>\n",
       "                        <td id=\"T_9749f_row38_col4\" class=\"data row38 col4\" >0.111240</td>\n",
       "                        <td id=\"T_9749f_row38_col5\" class=\"data row38 col5\" >0.148859</td>\n",
       "                        <td id=\"T_9749f_row38_col6\" class=\"data row38 col6\" >0.214386</td>\n",
       "                        <td id=\"T_9749f_row38_col7\" class=\"data row38 col7\" >0.063152</td>\n",
       "                        <td id=\"T_9749f_row38_col8\" class=\"data row38 col8\" >0.156221</td>\n",
       "                        <td id=\"T_9749f_row38_col9\" class=\"data row38 col9\" >-0.113745</td>\n",
       "                        <td id=\"T_9749f_row38_col10\" class=\"data row38 col10\" >-0.107787</td>\n",
       "                        <td id=\"T_9749f_row38_col11\" class=\"data row38 col11\" >-0.037779</td>\n",
       "                        <td id=\"T_9749f_row38_col12\" class=\"data row38 col12\" >-0.027613</td>\n",
       "                        <td id=\"T_9749f_row38_col13\" class=\"data row38 col13\" >-0.061847</td>\n",
       "                        <td id=\"T_9749f_row38_col14\" class=\"data row38 col14\" >-0.205588</td>\n",
       "                        <td id=\"T_9749f_row38_col15\" class=\"data row38 col15\" >-0.093172</td>\n",
       "                        <td id=\"T_9749f_row38_col16\" class=\"data row38 col16\" >-0.104700</td>\n",
       "                        <td id=\"T_9749f_row38_col17\" class=\"data row38 col17\" >-0.093172</td>\n",
       "                        <td id=\"T_9749f_row38_col18\" class=\"data row38 col18\" >-0.104700</td>\n",
       "                        <td id=\"T_9749f_row38_col19\" class=\"data row38 col19\" >0.147284</td>\n",
       "                        <td id=\"T_9749f_row38_col20\" class=\"data row38 col20\" >0.153751</td>\n",
       "                        <td id=\"T_9749f_row38_col21\" class=\"data row38 col21\" >-0.078382</td>\n",
       "                        <td id=\"T_9749f_row38_col22\" class=\"data row38 col22\" >-0.072490</td>\n",
       "                        <td id=\"T_9749f_row38_col23\" class=\"data row38 col23\" >0.154551</td>\n",
       "                        <td id=\"T_9749f_row38_col24\" class=\"data row38 col24\" >0.209242</td>\n",
       "                        <td id=\"T_9749f_row38_col25\" class=\"data row38 col25\" >0.091490</td>\n",
       "                        <td id=\"T_9749f_row38_col26\" class=\"data row38 col26\" >0.128097</td>\n",
       "                        <td id=\"T_9749f_row38_col27\" class=\"data row38 col27\" >0.130977</td>\n",
       "                        <td id=\"T_9749f_row38_col28\" class=\"data row38 col28\" >0.178447</td>\n",
       "                        <td id=\"T_9749f_row38_col29\" class=\"data row38 col29\" >0.091340</td>\n",
       "                        <td id=\"T_9749f_row38_col30\" class=\"data row38 col30\" >0.127740</td>\n",
       "                        <td id=\"T_9749f_row38_col31\" class=\"data row38 col31\" >0.276516</td>\n",
       "                        <td id=\"T_9749f_row38_col32\" class=\"data row38 col32\" >0.477326</td>\n",
       "                        <td id=\"T_9749f_row38_col33\" class=\"data row38 col33\" >0.313859</td>\n",
       "                        <td id=\"T_9749f_row38_col34\" class=\"data row38 col34\" >0.550556</td>\n",
       "                        <td id=\"T_9749f_row38_col35\" class=\"data row38 col35\" >0.107709</td>\n",
       "                        <td id=\"T_9749f_row38_col36\" class=\"data row38 col36\" >0.175488</td>\n",
       "                        <td id=\"T_9749f_row38_col37\" class=\"data row38 col37\" >0.601591</td>\n",
       "                        <td id=\"T_9749f_row38_col38\" class=\"data row38 col38\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row38_col39\" class=\"data row38 col39\" >-0.428454</td>\n",
       "                        <td id=\"T_9749f_row38_col40\" class=\"data row38 col40\" >-0.634502</td>\n",
       "                        <td id=\"T_9749f_row38_col41\" class=\"data row38 col41\" >0.125194</td>\n",
       "                        <td id=\"T_9749f_row38_col42\" class=\"data row38 col42\" >0.176329</td>\n",
       "                        <td id=\"T_9749f_row38_col43\" class=\"data row38 col43\" >-0.067655</td>\n",
       "                        <td id=\"T_9749f_row38_col44\" class=\"data row38 col44\" >-0.230303</td>\n",
       "                        <td id=\"T_9749f_row38_col45\" class=\"data row38 col45\" >0.140431</td>\n",
       "                        <td id=\"T_9749f_row38_col46\" class=\"data row38 col46\" >0.205431</td>\n",
       "                        <td id=\"T_9749f_row38_col47\" class=\"data row38 col47\" >0.281748</td>\n",
       "                        <td id=\"T_9749f_row38_col48\" class=\"data row38 col48\" >0.479100</td>\n",
       "                        <td id=\"T_9749f_row38_col49\" class=\"data row38 col49\" >-0.039545</td>\n",
       "                        <td id=\"T_9749f_row38_col50\" class=\"data row38 col50\" >-0.070236</td>\n",
       "                        <td id=\"T_9749f_row38_col51\" class=\"data row38 col51\" >-0.039149</td>\n",
       "                        <td id=\"T_9749f_row38_col52\" class=\"data row38 col52\" >-0.070060</td>\n",
       "                        <td id=\"T_9749f_row38_col53\" class=\"data row38 col53\" >-0.006668</td>\n",
       "                        <td id=\"T_9749f_row38_col54\" class=\"data row38 col54\" >0.289546</td>\n",
       "                        <td id=\"T_9749f_row38_col55\" class=\"data row38 col55\" >-0.056752</td>\n",
       "                        <td id=\"T_9749f_row38_col56\" class=\"data row38 col56\" >-0.169866</td>\n",
       "                        <td id=\"T_9749f_row38_col57\" class=\"data row38 col57\" >0.002545</td>\n",
       "                        <td id=\"T_9749f_row38_col58\" class=\"data row38 col58\" >0.001036</td>\n",
       "                        <td id=\"T_9749f_row38_col59\" class=\"data row38 col59\" >-0.107742</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row39\" class=\"row_heading level0 row39\" >day_avg_pressure</th>\n",
       "                        <td id=\"T_9749f_row39_col0\" class=\"data row39 col0\" >-0.043682</td>\n",
       "                        <td id=\"T_9749f_row39_col1\" class=\"data row39 col1\" >-0.083046</td>\n",
       "                        <td id=\"T_9749f_row39_col2\" class=\"data row39 col2\" >-0.121718</td>\n",
       "                        <td id=\"T_9749f_row39_col3\" class=\"data row39 col3\" >0.083486</td>\n",
       "                        <td id=\"T_9749f_row39_col4\" class=\"data row39 col4\" >0.033323</td>\n",
       "                        <td id=\"T_9749f_row39_col5\" class=\"data row39 col5\" >-0.055015</td>\n",
       "                        <td id=\"T_9749f_row39_col6\" class=\"data row39 col6\" >-0.036129</td>\n",
       "                        <td id=\"T_9749f_row39_col7\" class=\"data row39 col7\" >-0.102566</td>\n",
       "                        <td id=\"T_9749f_row39_col8\" class=\"data row39 col8\" >-0.143198</td>\n",
       "                        <td id=\"T_9749f_row39_col9\" class=\"data row39 col9\" >0.318731</td>\n",
       "                        <td id=\"T_9749f_row39_col10\" class=\"data row39 col10\" >0.174199</td>\n",
       "                        <td id=\"T_9749f_row39_col11\" class=\"data row39 col11\" >0.215074</td>\n",
       "                        <td id=\"T_9749f_row39_col12\" class=\"data row39 col12\" >0.062820</td>\n",
       "                        <td id=\"T_9749f_row39_col13\" class=\"data row39 col13\" >0.140307</td>\n",
       "                        <td id=\"T_9749f_row39_col14\" class=\"data row39 col14\" >0.176687</td>\n",
       "                        <td id=\"T_9749f_row39_col15\" class=\"data row39 col15\" >-0.066671</td>\n",
       "                        <td id=\"T_9749f_row39_col16\" class=\"data row39 col16\" >-0.063610</td>\n",
       "                        <td id=\"T_9749f_row39_col17\" class=\"data row39 col17\" >-0.066671</td>\n",
       "                        <td id=\"T_9749f_row39_col18\" class=\"data row39 col18\" >-0.063610</td>\n",
       "                        <td id=\"T_9749f_row39_col19\" class=\"data row39 col19\" >0.104182</td>\n",
       "                        <td id=\"T_9749f_row39_col20\" class=\"data row39 col20\" >0.088487</td>\n",
       "                        <td id=\"T_9749f_row39_col21\" class=\"data row39 col21\" >-0.093042</td>\n",
       "                        <td id=\"T_9749f_row39_col22\" class=\"data row39 col22\" >-0.055177</td>\n",
       "                        <td id=\"T_9749f_row39_col23\" class=\"data row39 col23\" >-0.040940</td>\n",
       "                        <td id=\"T_9749f_row39_col24\" class=\"data row39 col24\" >-0.007170</td>\n",
       "                        <td id=\"T_9749f_row39_col25\" class=\"data row39 col25\" >0.080945</td>\n",
       "                        <td id=\"T_9749f_row39_col26\" class=\"data row39 col26\" >0.042043</td>\n",
       "                        <td id=\"T_9749f_row39_col27\" class=\"data row39 col27\" >-0.003323</td>\n",
       "                        <td id=\"T_9749f_row39_col28\" class=\"data row39 col28\" >0.000688</td>\n",
       "                        <td id=\"T_9749f_row39_col29\" class=\"data row39 col29\" >0.081171</td>\n",
       "                        <td id=\"T_9749f_row39_col30\" class=\"data row39 col30\" >0.042382</td>\n",
       "                        <td id=\"T_9749f_row39_col31\" class=\"data row39 col31\" >-0.480995</td>\n",
       "                        <td id=\"T_9749f_row39_col32\" class=\"data row39 col32\" >-0.332747</td>\n",
       "                        <td id=\"T_9749f_row39_col33\" class=\"data row39 col33\" >-0.487044</td>\n",
       "                        <td id=\"T_9749f_row39_col34\" class=\"data row39 col34\" >-0.251668</td>\n",
       "                        <td id=\"T_9749f_row39_col35\" class=\"data row39 col35\" >-0.127051</td>\n",
       "                        <td id=\"T_9749f_row39_col36\" class=\"data row39 col36\" >-0.020173</td>\n",
       "                        <td id=\"T_9749f_row39_col37\" class=\"data row39 col37\" >-0.532497</td>\n",
       "                        <td id=\"T_9749f_row39_col38\" class=\"data row39 col38\" >-0.428454</td>\n",
       "                        <td id=\"T_9749f_row39_col39\" class=\"data row39 col39\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row39_col40\" class=\"data row39 col40\" >0.636444</td>\n",
       "                        <td id=\"T_9749f_row39_col41\" class=\"data row39 col41\" >-0.002091</td>\n",
       "                        <td id=\"T_9749f_row39_col42\" class=\"data row39 col42\" >-0.000642</td>\n",
       "                        <td id=\"T_9749f_row39_col43\" class=\"data row39 col43\" >0.186351</td>\n",
       "                        <td id=\"T_9749f_row39_col44\" class=\"data row39 col44\" >0.153562</td>\n",
       "                        <td id=\"T_9749f_row39_col45\" class=\"data row39 col45\" >-0.025059</td>\n",
       "                        <td id=\"T_9749f_row39_col46\" class=\"data row39 col46\" >0.078566</td>\n",
       "                        <td id=\"T_9749f_row39_col47\" class=\"data row39 col47\" >-0.502880</td>\n",
       "                        <td id=\"T_9749f_row39_col48\" class=\"data row39 col48\" >-0.339735</td>\n",
       "                        <td id=\"T_9749f_row39_col49\" class=\"data row39 col49\" >-0.114721</td>\n",
       "                        <td id=\"T_9749f_row39_col50\" class=\"data row39 col50\" >-0.166727</td>\n",
       "                        <td id=\"T_9749f_row39_col51\" class=\"data row39 col51\" >-0.115810</td>\n",
       "                        <td id=\"T_9749f_row39_col52\" class=\"data row39 col52\" >-0.166909</td>\n",
       "                        <td id=\"T_9749f_row39_col53\" class=\"data row39 col53\" >-0.013998</td>\n",
       "                        <td id=\"T_9749f_row39_col54\" class=\"data row39 col54\" >0.008746</td>\n",
       "                        <td id=\"T_9749f_row39_col55\" class=\"data row39 col55\" >-0.152682</td>\n",
       "                        <td id=\"T_9749f_row39_col56\" class=\"data row39 col56\" >0.191781</td>\n",
       "                        <td id=\"T_9749f_row39_col57\" class=\"data row39 col57\" >0.000756</td>\n",
       "                        <td id=\"T_9749f_row39_col58\" class=\"data row39 col58\" >-0.000001</td>\n",
       "                        <td id=\"T_9749f_row39_col59\" class=\"data row39 col59\" >0.168439</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row40\" class=\"row_heading level0 row40\" >week_avg_pressure</th>\n",
       "                        <td id=\"T_9749f_row40_col0\" class=\"data row40 col0\" >-0.053315</td>\n",
       "                        <td id=\"T_9749f_row40_col1\" class=\"data row40 col1\" >-0.093552</td>\n",
       "                        <td id=\"T_9749f_row40_col2\" class=\"data row40 col2\" >-0.134745</td>\n",
       "                        <td id=\"T_9749f_row40_col3\" class=\"data row40 col3\" >0.150299</td>\n",
       "                        <td id=\"T_9749f_row40_col4\" class=\"data row40 col4\" >0.110985</td>\n",
       "                        <td id=\"T_9749f_row40_col5\" class=\"data row40 col5\" >0.044785</td>\n",
       "                        <td id=\"T_9749f_row40_col6\" class=\"data row40 col6\" >-0.008474</td>\n",
       "                        <td id=\"T_9749f_row40_col7\" class=\"data row40 col7\" >-0.111542</td>\n",
       "                        <td id=\"T_9749f_row40_col8\" class=\"data row40 col8\" >-0.233963</td>\n",
       "                        <td id=\"T_9749f_row40_col9\" class=\"data row40 col9\" >0.283044</td>\n",
       "                        <td id=\"T_9749f_row40_col10\" class=\"data row40 col10\" >0.299024</td>\n",
       "                        <td id=\"T_9749f_row40_col11\" class=\"data row40 col11\" >0.199720</td>\n",
       "                        <td id=\"T_9749f_row40_col12\" class=\"data row40 col12\" >0.194299</td>\n",
       "                        <td id=\"T_9749f_row40_col13\" class=\"data row40 col13\" >0.084360</td>\n",
       "                        <td id=\"T_9749f_row40_col14\" class=\"data row40 col14\" >0.178336</td>\n",
       "                        <td id=\"T_9749f_row40_col15\" class=\"data row40 col15\" >-0.097111</td>\n",
       "                        <td id=\"T_9749f_row40_col16\" class=\"data row40 col16\" >-0.088216</td>\n",
       "                        <td id=\"T_9749f_row40_col17\" class=\"data row40 col17\" >-0.097111</td>\n",
       "                        <td id=\"T_9749f_row40_col18\" class=\"data row40 col18\" >-0.088216</td>\n",
       "                        <td id=\"T_9749f_row40_col19\" class=\"data row40 col19\" >0.123603</td>\n",
       "                        <td id=\"T_9749f_row40_col20\" class=\"data row40 col20\" >0.121983</td>\n",
       "                        <td id=\"T_9749f_row40_col21\" class=\"data row40 col21\" >-0.022828</td>\n",
       "                        <td id=\"T_9749f_row40_col22\" class=\"data row40 col22\" >-0.079989</td>\n",
       "                        <td id=\"T_9749f_row40_col23\" class=\"data row40 col23\" >0.055880</td>\n",
       "                        <td id=\"T_9749f_row40_col24\" class=\"data row40 col24\" >0.021643</td>\n",
       "                        <td id=\"T_9749f_row40_col25\" class=\"data row40 col25\" >0.140283</td>\n",
       "                        <td id=\"T_9749f_row40_col26\" class=\"data row40 col26\" >0.112280</td>\n",
       "                        <td id=\"T_9749f_row40_col27\" class=\"data row40 col27\" >0.089640</td>\n",
       "                        <td id=\"T_9749f_row40_col28\" class=\"data row40 col28\" >0.046161</td>\n",
       "                        <td id=\"T_9749f_row40_col29\" class=\"data row40 col29\" >0.140721</td>\n",
       "                        <td id=\"T_9749f_row40_col30\" class=\"data row40 col30\" >0.112635</td>\n",
       "                        <td id=\"T_9749f_row40_col31\" class=\"data row40 col31\" >-0.302535</td>\n",
       "                        <td id=\"T_9749f_row40_col32\" class=\"data row40 col32\" >-0.545773</td>\n",
       "                        <td id=\"T_9749f_row40_col33\" class=\"data row40 col33\" >-0.320019</td>\n",
       "                        <td id=\"T_9749f_row40_col34\" class=\"data row40 col34\" >-0.546340</td>\n",
       "                        <td id=\"T_9749f_row40_col35\" class=\"data row40 col35\" >-0.074705</td>\n",
       "                        <td id=\"T_9749f_row40_col36\" class=\"data row40 col36\" >-0.091252</td>\n",
       "                        <td id=\"T_9749f_row40_col37\" class=\"data row40 col37\" >-0.350352</td>\n",
       "                        <td id=\"T_9749f_row40_col38\" class=\"data row40 col38\" >-0.634502</td>\n",
       "                        <td id=\"T_9749f_row40_col39\" class=\"data row40 col39\" >0.636444</td>\n",
       "                        <td id=\"T_9749f_row40_col40\" class=\"data row40 col40\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row40_col41\" class=\"data row40 col41\" >0.095385</td>\n",
       "                        <td id=\"T_9749f_row40_col42\" class=\"data row40 col42\" >0.048109</td>\n",
       "                        <td id=\"T_9749f_row40_col43\" class=\"data row40 col43\" >0.047451</td>\n",
       "                        <td id=\"T_9749f_row40_col44\" class=\"data row40 col44\" >0.161137</td>\n",
       "                        <td id=\"T_9749f_row40_col45\" class=\"data row40 col45\" >0.085554</td>\n",
       "                        <td id=\"T_9749f_row40_col46\" class=\"data row40 col46\" >0.081435</td>\n",
       "                        <td id=\"T_9749f_row40_col47\" class=\"data row40 col47\" >-0.315610</td>\n",
       "                        <td id=\"T_9749f_row40_col48\" class=\"data row40 col48\" >-0.568068</td>\n",
       "                        <td id=\"T_9749f_row40_col49\" class=\"data row40 col49\" >-0.195738</td>\n",
       "                        <td id=\"T_9749f_row40_col50\" class=\"data row40 col50\" >-0.192988</td>\n",
       "                        <td id=\"T_9749f_row40_col51\" class=\"data row40 col51\" >-0.197051</td>\n",
       "                        <td id=\"T_9749f_row40_col52\" class=\"data row40 col52\" >-0.193965</td>\n",
       "                        <td id=\"T_9749f_row40_col53\" class=\"data row40 col53\" >0.006343</td>\n",
       "                        <td id=\"T_9749f_row40_col54\" class=\"data row40 col54\" >0.027435</td>\n",
       "                        <td id=\"T_9749f_row40_col55\" class=\"data row40 col55\" >-0.226884</td>\n",
       "                        <td id=\"T_9749f_row40_col56\" class=\"data row40 col56\" >0.188793</td>\n",
       "                        <td id=\"T_9749f_row40_col57\" class=\"data row40 col57\" >-0.001004</td>\n",
       "                        <td id=\"T_9749f_row40_col58\" class=\"data row40 col58\" >-0.000376</td>\n",
       "                        <td id=\"T_9749f_row40_col59\" class=\"data row40 col59\" >0.316095</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row41\" class=\"row_heading level0 row41\" >day_avg_temp</th>\n",
       "                        <td id=\"T_9749f_row41_col0\" class=\"data row41 col0\" >0.210208</td>\n",
       "                        <td id=\"T_9749f_row41_col1\" class=\"data row41 col1\" >0.359164</td>\n",
       "                        <td id=\"T_9749f_row41_col2\" class=\"data row41 col2\" >0.415279</td>\n",
       "                        <td id=\"T_9749f_row41_col3\" class=\"data row41 col3\" >0.960877</td>\n",
       "                        <td id=\"T_9749f_row41_col4\" class=\"data row41 col4\" >0.869199</td>\n",
       "                        <td id=\"T_9749f_row41_col5\" class=\"data row41 col5\" >0.938649</td>\n",
       "                        <td id=\"T_9749f_row41_col6\" class=\"data row41 col6\" >0.839086</td>\n",
       "                        <td id=\"T_9749f_row41_col7\" class=\"data row41 col7\" >-0.171503</td>\n",
       "                        <td id=\"T_9749f_row41_col8\" class=\"data row41 col8\" >-0.298036</td>\n",
       "                        <td id=\"T_9749f_row41_col9\" class=\"data row41 col9\" >0.469903</td>\n",
       "                        <td id=\"T_9749f_row41_col10\" class=\"data row41 col10\" >0.587275</td>\n",
       "                        <td id=\"T_9749f_row41_col11\" class=\"data row41 col11\" >0.821725</td>\n",
       "                        <td id=\"T_9749f_row41_col12\" class=\"data row41 col12\" >0.833228</td>\n",
       "                        <td id=\"T_9749f_row41_col13\" class=\"data row41 col13\" >0.006157</td>\n",
       "                        <td id=\"T_9749f_row41_col14\" class=\"data row41 col14\" >0.034541</td>\n",
       "                        <td id=\"T_9749f_row41_col15\" class=\"data row41 col15\" >-0.649983</td>\n",
       "                        <td id=\"T_9749f_row41_col16\" class=\"data row41 col16\" >-0.673082</td>\n",
       "                        <td id=\"T_9749f_row41_col17\" class=\"data row41 col17\" >-0.649983</td>\n",
       "                        <td id=\"T_9749f_row41_col18\" class=\"data row41 col18\" >-0.673082</td>\n",
       "                        <td id=\"T_9749f_row41_col19\" class=\"data row41 col19\" >0.628933</td>\n",
       "                        <td id=\"T_9749f_row41_col20\" class=\"data row41 col20\" >0.661558</td>\n",
       "                        <td id=\"T_9749f_row41_col21\" class=\"data row41 col21\" >0.004177</td>\n",
       "                        <td id=\"T_9749f_row41_col22\" class=\"data row41 col22\" >-0.015735</td>\n",
       "                        <td id=\"T_9749f_row41_col23\" class=\"data row41 col23\" >0.963877</td>\n",
       "                        <td id=\"T_9749f_row41_col24\" class=\"data row41 col24\" >0.857224</td>\n",
       "                        <td id=\"T_9749f_row41_col25\" class=\"data row41 col25\" >0.981656</td>\n",
       "                        <td id=\"T_9749f_row41_col26\" class=\"data row41 col26\" >0.873961</td>\n",
       "                        <td id=\"T_9749f_row41_col27\" class=\"data row41 col27\" >0.997911</td>\n",
       "                        <td id=\"T_9749f_row41_col28\" class=\"data row41 col28\" >0.874173</td>\n",
       "                        <td id=\"T_9749f_row41_col29\" class=\"data row41 col29\" >0.981517</td>\n",
       "                        <td id=\"T_9749f_row41_col30\" class=\"data row41 col30\" >0.873951</td>\n",
       "                        <td id=\"T_9749f_row41_col31\" class=\"data row41 col31\" >-0.065198</td>\n",
       "                        <td id=\"T_9749f_row41_col32\" class=\"data row41 col32\" >-0.266803</td>\n",
       "                        <td id=\"T_9749f_row41_col33\" class=\"data row41 col33\" >0.080052</td>\n",
       "                        <td id=\"T_9749f_row41_col34\" class=\"data row41 col34\" >-0.075814</td>\n",
       "                        <td id=\"T_9749f_row41_col35\" class=\"data row41 col35\" >0.245688</td>\n",
       "                        <td id=\"T_9749f_row41_col36\" class=\"data row41 col36\" >0.166157</td>\n",
       "                        <td id=\"T_9749f_row41_col37\" class=\"data row41 col37\" >0.149122</td>\n",
       "                        <td id=\"T_9749f_row41_col38\" class=\"data row41 col38\" >0.125194</td>\n",
       "                        <td id=\"T_9749f_row41_col39\" class=\"data row41 col39\" >-0.002091</td>\n",
       "                        <td id=\"T_9749f_row41_col40\" class=\"data row41 col40\" >0.095385</td>\n",
       "                        <td id=\"T_9749f_row41_col41\" class=\"data row41 col41\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row41_col42\" class=\"data row41 col42\" >0.875073</td>\n",
       "                        <td id=\"T_9749f_row41_col43\" class=\"data row41 col43\" >-0.068293</td>\n",
       "                        <td id=\"T_9749f_row41_col44\" class=\"data row41 col44\" >-0.001081</td>\n",
       "                        <td id=\"T_9749f_row41_col45\" class=\"data row41 col45\" >0.070694</td>\n",
       "                        <td id=\"T_9749f_row41_col46\" class=\"data row41 col46\" >0.008620</td>\n",
       "                        <td id=\"T_9749f_row41_col47\" class=\"data row41 col47\" >-0.072436</td>\n",
       "                        <td id=\"T_9749f_row41_col48\" class=\"data row41 col48\" >-0.262648</td>\n",
       "                        <td id=\"T_9749f_row41_col49\" class=\"data row41 col49\" >-0.504222</td>\n",
       "                        <td id=\"T_9749f_row41_col50\" class=\"data row41 col50\" >-0.511592</td>\n",
       "                        <td id=\"T_9749f_row41_col51\" class=\"data row41 col51\" >-0.505765</td>\n",
       "                        <td id=\"T_9749f_row41_col52\" class=\"data row41 col52\" >-0.512474</td>\n",
       "                        <td id=\"T_9749f_row41_col53\" class=\"data row41 col53\" >0.024622</td>\n",
       "                        <td id=\"T_9749f_row41_col54\" class=\"data row41 col54\" >0.156584</td>\n",
       "                        <td id=\"T_9749f_row41_col55\" class=\"data row41 col55\" >0.216534</td>\n",
       "                        <td id=\"T_9749f_row41_col56\" class=\"data row41 col56\" >0.127857</td>\n",
       "                        <td id=\"T_9749f_row41_col57\" class=\"data row41 col57\" >0.002171</td>\n",
       "                        <td id=\"T_9749f_row41_col58\" class=\"data row41 col58\" >-0.001003</td>\n",
       "                        <td id=\"T_9749f_row41_col59\" class=\"data row41 col59\" >0.398692</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row42\" class=\"row_heading level0 row42\" >week_avg_temp</th>\n",
       "                        <td id=\"T_9749f_row42_col0\" class=\"data row42 col0\" >0.236778</td>\n",
       "                        <td id=\"T_9749f_row42_col1\" class=\"data row42 col1\" >0.385581</td>\n",
       "                        <td id=\"T_9749f_row42_col2\" class=\"data row42 col2\" >0.442421</td>\n",
       "                        <td id=\"T_9749f_row42_col3\" class=\"data row42 col3\" >0.847666</td>\n",
       "                        <td id=\"T_9749f_row42_col4\" class=\"data row42 col4\" >0.973018</td>\n",
       "                        <td id=\"T_9749f_row42_col5\" class=\"data row42 col5\" >0.820206</td>\n",
       "                        <td id=\"T_9749f_row42_col6\" class=\"data row42 col6\" >0.966837</td>\n",
       "                        <td id=\"T_9749f_row42_col7\" class=\"data row42 col7\" >-0.140540</td>\n",
       "                        <td id=\"T_9749f_row42_col8\" class=\"data row42 col8\" >-0.331191</td>\n",
       "                        <td id=\"T_9749f_row42_col9\" class=\"data row42 col9\" >0.507836</td>\n",
       "                        <td id=\"T_9749f_row42_col10\" class=\"data row42 col10\" >0.594316</td>\n",
       "                        <td id=\"T_9749f_row42_col11\" class=\"data row42 col11\" >0.740950</td>\n",
       "                        <td id=\"T_9749f_row42_col12\" class=\"data row42 col12\" >0.917489</td>\n",
       "                        <td id=\"T_9749f_row42_col13\" class=\"data row42 col13\" >-0.040655</td>\n",
       "                        <td id=\"T_9749f_row42_col14\" class=\"data row42 col14\" >0.000077</td>\n",
       "                        <td id=\"T_9749f_row42_col15\" class=\"data row42 col15\" >-0.687823</td>\n",
       "                        <td id=\"T_9749f_row42_col16\" class=\"data row42 col16\" >-0.713628</td>\n",
       "                        <td id=\"T_9749f_row42_col17\" class=\"data row42 col17\" >-0.687823</td>\n",
       "                        <td id=\"T_9749f_row42_col18\" class=\"data row42 col18\" >-0.713628</td>\n",
       "                        <td id=\"T_9749f_row42_col19\" class=\"data row42 col19\" >0.648947</td>\n",
       "                        <td id=\"T_9749f_row42_col20\" class=\"data row42 col20\" >0.689217</td>\n",
       "                        <td id=\"T_9749f_row42_col21\" class=\"data row42 col21\" >0.017563</td>\n",
       "                        <td id=\"T_9749f_row42_col22\" class=\"data row42 col22\" >-0.017422</td>\n",
       "                        <td id=\"T_9749f_row42_col23\" class=\"data row42 col23\" >0.833204</td>\n",
       "                        <td id=\"T_9749f_row42_col24\" class=\"data row42 col24\" >0.984774</td>\n",
       "                        <td id=\"T_9749f_row42_col25\" class=\"data row42 col25\" >0.879382</td>\n",
       "                        <td id=\"T_9749f_row42_col26\" class=\"data row42 col26\" >0.991954</td>\n",
       "                        <td id=\"T_9749f_row42_col27\" class=\"data row42 col27\" >0.878339</td>\n",
       "                        <td id=\"T_9749f_row42_col28\" class=\"data row42 col28\" >0.999288</td>\n",
       "                        <td id=\"T_9749f_row42_col29\" class=\"data row42 col29\" >0.879829</td>\n",
       "                        <td id=\"T_9749f_row42_col30\" class=\"data row42 col30\" >0.991901</td>\n",
       "                        <td id=\"T_9749f_row42_col31\" class=\"data row42 col31\" >-0.137480</td>\n",
       "                        <td id=\"T_9749f_row42_col32\" class=\"data row42 col32\" >-0.248495</td>\n",
       "                        <td id=\"T_9749f_row42_col33\" class=\"data row42 col33\" >0.002637</td>\n",
       "                        <td id=\"T_9749f_row42_col34\" class=\"data row42 col34\" >-0.031666</td>\n",
       "                        <td id=\"T_9749f_row42_col35\" class=\"data row42 col35\" >0.135347</td>\n",
       "                        <td id=\"T_9749f_row42_col36\" class=\"data row42 col36\" >0.218473</td>\n",
       "                        <td id=\"T_9749f_row42_col37\" class=\"data row42 col37\" >0.152974</td>\n",
       "                        <td id=\"T_9749f_row42_col38\" class=\"data row42 col38\" >0.176329</td>\n",
       "                        <td id=\"T_9749f_row42_col39\" class=\"data row42 col39\" >-0.000642</td>\n",
       "                        <td id=\"T_9749f_row42_col40\" class=\"data row42 col40\" >0.048109</td>\n",
       "                        <td id=\"T_9749f_row42_col41\" class=\"data row42 col41\" >0.875073</td>\n",
       "                        <td id=\"T_9749f_row42_col42\" class=\"data row42 col42\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row42_col43\" class=\"data row42 col43\" >-0.021262</td>\n",
       "                        <td id=\"T_9749f_row42_col44\" class=\"data row42 col44\" >-0.022401</td>\n",
       "                        <td id=\"T_9749f_row42_col45\" class=\"data row42 col45\" >0.066737</td>\n",
       "                        <td id=\"T_9749f_row42_col46\" class=\"data row42 col46\" >0.060339</td>\n",
       "                        <td id=\"T_9749f_row42_col47\" class=\"data row42 col47\" >-0.125137</td>\n",
       "                        <td id=\"T_9749f_row42_col48\" class=\"data row42 col48\" >-0.241665</td>\n",
       "                        <td id=\"T_9749f_row42_col49\" class=\"data row42 col49\" >-0.533040</td>\n",
       "                        <td id=\"T_9749f_row42_col50\" class=\"data row42 col50\" >-0.560718</td>\n",
       "                        <td id=\"T_9749f_row42_col51\" class=\"data row42 col51\" >-0.534665</td>\n",
       "                        <td id=\"T_9749f_row42_col52\" class=\"data row42 col52\" >-0.562142</td>\n",
       "                        <td id=\"T_9749f_row42_col53\" class=\"data row42 col53\" >-0.003319</td>\n",
       "                        <td id=\"T_9749f_row42_col54\" class=\"data row42 col54\" >0.173005</td>\n",
       "                        <td id=\"T_9749f_row42_col55\" class=\"data row42 col55\" >0.262671</td>\n",
       "                        <td id=\"T_9749f_row42_col56\" class=\"data row42 col56\" >0.132393</td>\n",
       "                        <td id=\"T_9749f_row42_col57\" class=\"data row42 col57\" >0.005521</td>\n",
       "                        <td id=\"T_9749f_row42_col58\" class=\"data row42 col58\" >-0.001009</td>\n",
       "                        <td id=\"T_9749f_row42_col59\" class=\"data row42 col59\" >0.410719</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row43\" class=\"row_heading level0 row43\" >day_avg_visibility</th>\n",
       "                        <td id=\"T_9749f_row43_col0\" class=\"data row43 col0\" >0.075453</td>\n",
       "                        <td id=\"T_9749f_row43_col1\" class=\"data row43 col1\" >0.120612</td>\n",
       "                        <td id=\"T_9749f_row43_col2\" class=\"data row43 col2\" >0.102404</td>\n",
       "                        <td id=\"T_9749f_row43_col3\" class=\"data row43 col3\" >0.021373</td>\n",
       "                        <td id=\"T_9749f_row43_col4\" class=\"data row43 col4\" >0.041430</td>\n",
       "                        <td id=\"T_9749f_row43_col5\" class=\"data row43 col5\" >-0.105680</td>\n",
       "                        <td id=\"T_9749f_row43_col6\" class=\"data row43 col6\" >-0.081718</td>\n",
       "                        <td id=\"T_9749f_row43_col7\" class=\"data row43 col7\" >-0.078801</td>\n",
       "                        <td id=\"T_9749f_row43_col8\" class=\"data row43 col8\" >-0.063227</td>\n",
       "                        <td id=\"T_9749f_row43_col9\" class=\"data row43 col9\" >0.360661</td>\n",
       "                        <td id=\"T_9749f_row43_col10\" class=\"data row43 col10\" >0.278283</td>\n",
       "                        <td id=\"T_9749f_row43_col11\" class=\"data row43 col11\" >0.109857</td>\n",
       "                        <td id=\"T_9749f_row43_col12\" class=\"data row43 col12\" >0.060933</td>\n",
       "                        <td id=\"T_9749f_row43_col13\" class=\"data row43 col13\" >0.027925</td>\n",
       "                        <td id=\"T_9749f_row43_col14\" class=\"data row43 col14\" >0.022773</td>\n",
       "                        <td id=\"T_9749f_row43_col15\" class=\"data row43 col15\" >-0.304175</td>\n",
       "                        <td id=\"T_9749f_row43_col16\" class=\"data row43 col16\" >-0.281719</td>\n",
       "                        <td id=\"T_9749f_row43_col17\" class=\"data row43 col17\" >-0.304175</td>\n",
       "                        <td id=\"T_9749f_row43_col18\" class=\"data row43 col18\" >-0.281719</td>\n",
       "                        <td id=\"T_9749f_row43_col19\" class=\"data row43 col19\" >0.273171</td>\n",
       "                        <td id=\"T_9749f_row43_col20\" class=\"data row43 col20\" >0.266835</td>\n",
       "                        <td id=\"T_9749f_row43_col21\" class=\"data row43 col21\" >0.017393</td>\n",
       "                        <td id=\"T_9749f_row43_col22\" class=\"data row43 col22\" >-0.028041</td>\n",
       "                        <td id=\"T_9749f_row43_col23\" class=\"data row43 col23\" >-0.139103</td>\n",
       "                        <td id=\"T_9749f_row43_col24\" class=\"data row43 col24\" >-0.059667</td>\n",
       "                        <td id=\"T_9749f_row43_col25\" class=\"data row43 col25\" >-0.037100</td>\n",
       "                        <td id=\"T_9749f_row43_col26\" class=\"data row43 col26\" >-0.018601</td>\n",
       "                        <td id=\"T_9749f_row43_col27\" class=\"data row43 col27\" >-0.070647</td>\n",
       "                        <td id=\"T_9749f_row43_col28\" class=\"data row43 col28\" >-0.020330</td>\n",
       "                        <td id=\"T_9749f_row43_col29\" class=\"data row43 col29\" >-0.036925</td>\n",
       "                        <td id=\"T_9749f_row43_col30\" class=\"data row43 col30\" >-0.017954</td>\n",
       "                        <td id=\"T_9749f_row43_col31\" class=\"data row43 col31\" >-0.197123</td>\n",
       "                        <td id=\"T_9749f_row43_col32\" class=\"data row43 col32\" >-0.052381</td>\n",
       "                        <td id=\"T_9749f_row43_col33\" class=\"data row43 col33\" >-0.360370</td>\n",
       "                        <td id=\"T_9749f_row43_col34\" class=\"data row43 col34\" >-0.159412</td>\n",
       "                        <td id=\"T_9749f_row43_col35\" class=\"data row43 col35\" >-0.287701</td>\n",
       "                        <td id=\"T_9749f_row43_col36\" class=\"data row43 col36\" >-0.202490</td>\n",
       "                        <td id=\"T_9749f_row43_col37\" class=\"data row43 col37\" >-0.312232</td>\n",
       "                        <td id=\"T_9749f_row43_col38\" class=\"data row43 col38\" >-0.067655</td>\n",
       "                        <td id=\"T_9749f_row43_col39\" class=\"data row43 col39\" >0.186351</td>\n",
       "                        <td id=\"T_9749f_row43_col40\" class=\"data row43 col40\" >0.047451</td>\n",
       "                        <td id=\"T_9749f_row43_col41\" class=\"data row43 col41\" >-0.068293</td>\n",
       "                        <td id=\"T_9749f_row43_col42\" class=\"data row43 col42\" >-0.021262</td>\n",
       "                        <td id=\"T_9749f_row43_col43\" class=\"data row43 col43\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row43_col44\" class=\"data row43 col44\" >0.624962</td>\n",
       "                        <td id=\"T_9749f_row43_col45\" class=\"data row43 col45\" >-0.012635</td>\n",
       "                        <td id=\"T_9749f_row43_col46\" class=\"data row43 col46\" >-0.013529</td>\n",
       "                        <td id=\"T_9749f_row43_col47\" class=\"data row43 col47\" >-0.187330</td>\n",
       "                        <td id=\"T_9749f_row43_col48\" class=\"data row43 col48\" >-0.039153</td>\n",
       "                        <td id=\"T_9749f_row43_col49\" class=\"data row43 col49\" >0.183606</td>\n",
       "                        <td id=\"T_9749f_row43_col50\" class=\"data row43 col50\" >0.187021</td>\n",
       "                        <td id=\"T_9749f_row43_col51\" class=\"data row43 col51\" >0.185021</td>\n",
       "                        <td id=\"T_9749f_row43_col52\" class=\"data row43 col52\" >0.188555</td>\n",
       "                        <td id=\"T_9749f_row43_col53\" class=\"data row43 col53\" >-0.002354</td>\n",
       "                        <td id=\"T_9749f_row43_col54\" class=\"data row43 col54\" >0.100944</td>\n",
       "                        <td id=\"T_9749f_row43_col55\" class=\"data row43 col55\" >-0.163317</td>\n",
       "                        <td id=\"T_9749f_row43_col56\" class=\"data row43 col56\" >0.024489</td>\n",
       "                        <td id=\"T_9749f_row43_col57\" class=\"data row43 col57\" >-0.006379</td>\n",
       "                        <td id=\"T_9749f_row43_col58\" class=\"data row43 col58\" >0.000119</td>\n",
       "                        <td id=\"T_9749f_row43_col59\" class=\"data row43 col59\" >-0.150833</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row44\" class=\"row_heading level0 row44\" >week_avg_visibility</th>\n",
       "                        <td id=\"T_9749f_row44_col0\" class=\"data row44 col0\" >0.109228</td>\n",
       "                        <td id=\"T_9749f_row44_col1\" class=\"data row44 col1\" >0.179000</td>\n",
       "                        <td id=\"T_9749f_row44_col2\" class=\"data row44 col2\" >0.182091</td>\n",
       "                        <td id=\"T_9749f_row44_col3\" class=\"data row44 col3\" >0.082141</td>\n",
       "                        <td id=\"T_9749f_row44_col4\" class=\"data row44 col4\" >0.070536</td>\n",
       "                        <td id=\"T_9749f_row44_col5\" class=\"data row44 col5\" >-0.063482</td>\n",
       "                        <td id=\"T_9749f_row44_col6\" class=\"data row44 col6\" >-0.106805</td>\n",
       "                        <td id=\"T_9749f_row44_col7\" class=\"data row44 col7\" >-0.091325</td>\n",
       "                        <td id=\"T_9749f_row44_col8\" class=\"data row44 col8\" >-0.169104</td>\n",
       "                        <td id=\"T_9749f_row44_col9\" class=\"data row44 col9\" >0.405250</td>\n",
       "                        <td id=\"T_9749f_row44_col10\" class=\"data row44 col10\" >0.431517</td>\n",
       "                        <td id=\"T_9749f_row44_col11\" class=\"data row44 col11\" >0.102803</td>\n",
       "                        <td id=\"T_9749f_row44_col12\" class=\"data row44 col12\" >0.110456</td>\n",
       "                        <td id=\"T_9749f_row44_col13\" class=\"data row44 col13\" >-0.004548</td>\n",
       "                        <td id=\"T_9749f_row44_col14\" class=\"data row44 col14\" >0.022624</td>\n",
       "                        <td id=\"T_9749f_row44_col15\" class=\"data row44 col15\" >-0.443746</td>\n",
       "                        <td id=\"T_9749f_row44_col16\" class=\"data row44 col16\" >-0.430739</td>\n",
       "                        <td id=\"T_9749f_row44_col17\" class=\"data row44 col17\" >-0.443746</td>\n",
       "                        <td id=\"T_9749f_row44_col18\" class=\"data row44 col18\" >-0.430739</td>\n",
       "                        <td id=\"T_9749f_row44_col19\" class=\"data row44 col19\" >0.401055</td>\n",
       "                        <td id=\"T_9749f_row44_col20\" class=\"data row44 col20\" >0.395012</td>\n",
       "                        <td id=\"T_9749f_row44_col21\" class=\"data row44 col21\" >0.103275</td>\n",
       "                        <td id=\"T_9749f_row44_col22\" class=\"data row44 col22\" >0.036687</td>\n",
       "                        <td id=\"T_9749f_row44_col23\" class=\"data row44 col23\" >-0.035035</td>\n",
       "                        <td id=\"T_9749f_row44_col24\" class=\"data row44 col24\" >-0.062753</td>\n",
       "                        <td id=\"T_9749f_row44_col25\" class=\"data row44 col25\" >0.028526</td>\n",
       "                        <td id=\"T_9749f_row44_col26\" class=\"data row44 col26\" >0.000489</td>\n",
       "                        <td id=\"T_9749f_row44_col27\" class=\"data row44 col27\" >-0.006487</td>\n",
       "                        <td id=\"T_9749f_row44_col28\" class=\"data row44 col28\" >-0.024115</td>\n",
       "                        <td id=\"T_9749f_row44_col29\" class=\"data row44 col29\" >0.029165</td>\n",
       "                        <td id=\"T_9749f_row44_col30\" class=\"data row44 col30\" >0.001302</td>\n",
       "                        <td id=\"T_9749f_row44_col31\" class=\"data row44 col31\" >-0.249901</td>\n",
       "                        <td id=\"T_9749f_row44_col32\" class=\"data row44 col32\" >-0.260356</td>\n",
       "                        <td id=\"T_9749f_row44_col33\" class=\"data row44 col33\" >-0.166143</td>\n",
       "                        <td id=\"T_9749f_row44_col34\" class=\"data row44 col34\" >-0.280466</td>\n",
       "                        <td id=\"T_9749f_row44_col35\" class=\"data row44 col35\" >-0.109097</td>\n",
       "                        <td id=\"T_9749f_row44_col36\" class=\"data row44 col36\" >-0.206995</td>\n",
       "                        <td id=\"T_9749f_row44_col37\" class=\"data row44 col37\" >-0.224162</td>\n",
       "                        <td id=\"T_9749f_row44_col38\" class=\"data row44 col38\" >-0.230303</td>\n",
       "                        <td id=\"T_9749f_row44_col39\" class=\"data row44 col39\" >0.153562</td>\n",
       "                        <td id=\"T_9749f_row44_col40\" class=\"data row44 col40\" >0.161137</td>\n",
       "                        <td id=\"T_9749f_row44_col41\" class=\"data row44 col41\" >-0.001081</td>\n",
       "                        <td id=\"T_9749f_row44_col42\" class=\"data row44 col42\" >-0.022401</td>\n",
       "                        <td id=\"T_9749f_row44_col43\" class=\"data row44 col43\" >0.624962</td>\n",
       "                        <td id=\"T_9749f_row44_col44\" class=\"data row44 col44\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row44_col45\" class=\"data row44 col45\" >-0.065049</td>\n",
       "                        <td id=\"T_9749f_row44_col46\" class=\"data row44 col46\" >-0.059458</td>\n",
       "                        <td id=\"T_9749f_row44_col47\" class=\"data row44 col47\" >-0.233440</td>\n",
       "                        <td id=\"T_9749f_row44_col48\" class=\"data row44 col48\" >-0.234148</td>\n",
       "                        <td id=\"T_9749f_row44_col49\" class=\"data row44 col49\" >0.200599</td>\n",
       "                        <td id=\"T_9749f_row44_col50\" class=\"data row44 col50\" >0.247908</td>\n",
       "                        <td id=\"T_9749f_row44_col51\" class=\"data row44 col51\" >0.202271</td>\n",
       "                        <td id=\"T_9749f_row44_col52\" class=\"data row44 col52\" >0.249769</td>\n",
       "                        <td id=\"T_9749f_row44_col53\" class=\"data row44 col53\" >0.004467</td>\n",
       "                        <td id=\"T_9749f_row44_col54\" class=\"data row44 col54\" >0.117943</td>\n",
       "                        <td id=\"T_9749f_row44_col55\" class=\"data row44 col55\" >-0.193857</td>\n",
       "                        <td id=\"T_9749f_row44_col56\" class=\"data row44 col56\" >-0.027205</td>\n",
       "                        <td id=\"T_9749f_row44_col57\" class=\"data row44 col57\" >-0.003036</td>\n",
       "                        <td id=\"T_9749f_row44_col58\" class=\"data row44 col58\" >-0.000356</td>\n",
       "                        <td id=\"T_9749f_row44_col59\" class=\"data row44 col59\" >-0.173895</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row45\" class=\"row_heading level0 row45\" >day_avg_winddir</th>\n",
       "                        <td id=\"T_9749f_row45_col0\" class=\"data row45 col0\" >0.007677</td>\n",
       "                        <td id=\"T_9749f_row45_col1\" class=\"data row45 col1\" >-0.003040</td>\n",
       "                        <td id=\"T_9749f_row45_col2\" class=\"data row45 col2\" >0.011296</td>\n",
       "                        <td id=\"T_9749f_row45_col3\" class=\"data row45 col3\" >-0.016343</td>\n",
       "                        <td id=\"T_9749f_row45_col4\" class=\"data row45 col4\" >0.031729</td>\n",
       "                        <td id=\"T_9749f_row45_col5\" class=\"data row45 col5\" >0.089084</td>\n",
       "                        <td id=\"T_9749f_row45_col6\" class=\"data row45 col6\" >0.054273</td>\n",
       "                        <td id=\"T_9749f_row45_col7\" class=\"data row45 col7\" >0.101061</td>\n",
       "                        <td id=\"T_9749f_row45_col8\" class=\"data row45 col8\" >0.073138</td>\n",
       "                        <td id=\"T_9749f_row45_col9\" class=\"data row45 col9\" >-0.086475</td>\n",
       "                        <td id=\"T_9749f_row45_col10\" class=\"data row45 col10\" >-0.045948</td>\n",
       "                        <td id=\"T_9749f_row45_col11\" class=\"data row45 col11\" >-0.103099</td>\n",
       "                        <td id=\"T_9749f_row45_col12\" class=\"data row45 col12\" >-0.000670</td>\n",
       "                        <td id=\"T_9749f_row45_col13\" class=\"data row45 col13\" >-0.045648</td>\n",
       "                        <td id=\"T_9749f_row45_col14\" class=\"data row45 col14\" >-0.055335</td>\n",
       "                        <td id=\"T_9749f_row45_col15\" class=\"data row45 col15\" >0.003278</td>\n",
       "                        <td id=\"T_9749f_row45_col16\" class=\"data row45 col16\" >0.011990</td>\n",
       "                        <td id=\"T_9749f_row45_col17\" class=\"data row45 col17\" >0.003278</td>\n",
       "                        <td id=\"T_9749f_row45_col18\" class=\"data row45 col18\" >0.011990</td>\n",
       "                        <td id=\"T_9749f_row45_col19\" class=\"data row45 col19\" >0.044090</td>\n",
       "                        <td id=\"T_9749f_row45_col20\" class=\"data row45 col20\" >0.052672</td>\n",
       "                        <td id=\"T_9749f_row45_col21\" class=\"data row45 col21\" >0.071281</td>\n",
       "                        <td id=\"T_9749f_row45_col22\" class=\"data row45 col22\" >-0.004139</td>\n",
       "                        <td id=\"T_9749f_row45_col23\" class=\"data row45 col23\" >0.079287</td>\n",
       "                        <td id=\"T_9749f_row45_col24\" class=\"data row45 col24\" >0.090224</td>\n",
       "                        <td id=\"T_9749f_row45_col25\" class=\"data row45 col25\" >0.054128</td>\n",
       "                        <td id=\"T_9749f_row45_col26\" class=\"data row45 col26\" >0.077477</td>\n",
       "                        <td id=\"T_9749f_row45_col27\" class=\"data row45 col27\" >0.074759</td>\n",
       "                        <td id=\"T_9749f_row45_col28\" class=\"data row45 col28\" >0.073014</td>\n",
       "                        <td id=\"T_9749f_row45_col29\" class=\"data row45 col29\" >0.054768</td>\n",
       "                        <td id=\"T_9749f_row45_col30\" class=\"data row45 col30\" >0.077201</td>\n",
       "                        <td id=\"T_9749f_row45_col31\" class=\"data row45 col31\" >0.183119</td>\n",
       "                        <td id=\"T_9749f_row45_col32\" class=\"data row45 col32\" >0.059853</td>\n",
       "                        <td id=\"T_9749f_row45_col33\" class=\"data row45 col33\" >0.244252</td>\n",
       "                        <td id=\"T_9749f_row45_col34\" class=\"data row45 col34\" >0.165823</td>\n",
       "                        <td id=\"T_9749f_row45_col35\" class=\"data row45 col35\" >0.016953</td>\n",
       "                        <td id=\"T_9749f_row45_col36\" class=\"data row45 col36\" >0.122414</td>\n",
       "                        <td id=\"T_9749f_row45_col37\" class=\"data row45 col37\" >0.127714</td>\n",
       "                        <td id=\"T_9749f_row45_col38\" class=\"data row45 col38\" >0.140431</td>\n",
       "                        <td id=\"T_9749f_row45_col39\" class=\"data row45 col39\" >-0.025059</td>\n",
       "                        <td id=\"T_9749f_row45_col40\" class=\"data row45 col40\" >0.085554</td>\n",
       "                        <td id=\"T_9749f_row45_col41\" class=\"data row45 col41\" >0.070694</td>\n",
       "                        <td id=\"T_9749f_row45_col42\" class=\"data row45 col42\" >0.066737</td>\n",
       "                        <td id=\"T_9749f_row45_col43\" class=\"data row45 col43\" >-0.012635</td>\n",
       "                        <td id=\"T_9749f_row45_col44\" class=\"data row45 col44\" >-0.065049</td>\n",
       "                        <td id=\"T_9749f_row45_col45\" class=\"data row45 col45\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row45_col46\" class=\"data row45 col46\" >0.586878</td>\n",
       "                        <td id=\"T_9749f_row45_col47\" class=\"data row45 col47\" >0.196618</td>\n",
       "                        <td id=\"T_9749f_row45_col48\" class=\"data row45 col48\" >0.057402</td>\n",
       "                        <td id=\"T_9749f_row45_col49\" class=\"data row45 col49\" >-0.035649</td>\n",
       "                        <td id=\"T_9749f_row45_col50\" class=\"data row45 col50\" >-0.046555</td>\n",
       "                        <td id=\"T_9749f_row45_col51\" class=\"data row45 col51\" >-0.035793</td>\n",
       "                        <td id=\"T_9749f_row45_col52\" class=\"data row45 col52\" >-0.047326</td>\n",
       "                        <td id=\"T_9749f_row45_col53\" class=\"data row45 col53\" >-0.004017</td>\n",
       "                        <td id=\"T_9749f_row45_col54\" class=\"data row45 col54\" >0.078389</td>\n",
       "                        <td id=\"T_9749f_row45_col55\" class=\"data row45 col55\" >-0.213797</td>\n",
       "                        <td id=\"T_9749f_row45_col56\" class=\"data row45 col56\" >-0.041662</td>\n",
       "                        <td id=\"T_9749f_row45_col57\" class=\"data row45 col57\" >-0.001757</td>\n",
       "                        <td id=\"T_9749f_row45_col58\" class=\"data row45 col58\" >0.000922</td>\n",
       "                        <td id=\"T_9749f_row45_col59\" class=\"data row45 col59\" >0.086045</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row46\" class=\"row_heading level0 row46\" >week_avg_winddir</th>\n",
       "                        <td id=\"T_9749f_row46_col0\" class=\"data row46 col0\" >0.045745</td>\n",
       "                        <td id=\"T_9749f_row46_col1\" class=\"data row46 col1\" >0.062250</td>\n",
       "                        <td id=\"T_9749f_row46_col2\" class=\"data row46 col2\" >0.038451</td>\n",
       "                        <td id=\"T_9749f_row46_col3\" class=\"data row46 col3\" >-0.047302</td>\n",
       "                        <td id=\"T_9749f_row46_col4\" class=\"data row46 col4\" >-0.010975</td>\n",
       "                        <td id=\"T_9749f_row46_col5\" class=\"data row46 col5\" >0.037376</td>\n",
       "                        <td id=\"T_9749f_row46_col6\" class=\"data row46 col6\" >0.060154</td>\n",
       "                        <td id=\"T_9749f_row46_col7\" class=\"data row46 col7\" >0.113224</td>\n",
       "                        <td id=\"T_9749f_row46_col8\" class=\"data row46 col8\" >0.180318</td>\n",
       "                        <td id=\"T_9749f_row46_col9\" class=\"data row46 col9\" >-0.030465</td>\n",
       "                        <td id=\"T_9749f_row46_col10\" class=\"data row46 col10\" >-0.079985</td>\n",
       "                        <td id=\"T_9749f_row46_col11\" class=\"data row46 col11\" >-0.097689</td>\n",
       "                        <td id=\"T_9749f_row46_col12\" class=\"data row46 col12\" >-0.079113</td>\n",
       "                        <td id=\"T_9749f_row46_col13\" class=\"data row46 col13\" >-0.077759</td>\n",
       "                        <td id=\"T_9749f_row46_col14\" class=\"data row46 col14\" >-0.083024</td>\n",
       "                        <td id=\"T_9749f_row46_col15\" class=\"data row46 col15\" >0.009601</td>\n",
       "                        <td id=\"T_9749f_row46_col16\" class=\"data row46 col16\" >0.018361</td>\n",
       "                        <td id=\"T_9749f_row46_col17\" class=\"data row46 col17\" >0.009601</td>\n",
       "                        <td id=\"T_9749f_row46_col18\" class=\"data row46 col18\" >0.018361</td>\n",
       "                        <td id=\"T_9749f_row46_col19\" class=\"data row46 col19\" >0.057499</td>\n",
       "                        <td id=\"T_9749f_row46_col20\" class=\"data row46 col20\" >0.056783</td>\n",
       "                        <td id=\"T_9749f_row46_col21\" class=\"data row46 col21\" >0.078151</td>\n",
       "                        <td id=\"T_9749f_row46_col22\" class=\"data row46 col22\" >0.055806</td>\n",
       "                        <td id=\"T_9749f_row46_col23\" class=\"data row46 col23\" >0.037532</td>\n",
       "                        <td id=\"T_9749f_row46_col24\" class=\"data row46 col24\" >0.099943</td>\n",
       "                        <td id=\"T_9749f_row46_col25\" class=\"data row46 col25\" >0.015617</td>\n",
       "                        <td id=\"T_9749f_row46_col26\" class=\"data row46 col26\" >0.063131</td>\n",
       "                        <td id=\"T_9749f_row46_col27\" class=\"data row46 col27\" >0.015256</td>\n",
       "                        <td id=\"T_9749f_row46_col28\" class=\"data row46 col28\" >0.068207</td>\n",
       "                        <td id=\"T_9749f_row46_col29\" class=\"data row46 col29\" >0.015304</td>\n",
       "                        <td id=\"T_9749f_row46_col30\" class=\"data row46 col30\" >0.062785</td>\n",
       "                        <td id=\"T_9749f_row46_col31\" class=\"data row46 col31\" >0.048527</td>\n",
       "                        <td id=\"T_9749f_row46_col32\" class=\"data row46 col32\" >0.151269</td>\n",
       "                        <td id=\"T_9749f_row46_col33\" class=\"data row46 col33\" >0.152565</td>\n",
       "                        <td id=\"T_9749f_row46_col34\" class=\"data row46 col34\" >0.333998</td>\n",
       "                        <td id=\"T_9749f_row46_col35\" class=\"data row46 col35\" >0.068710</td>\n",
       "                        <td id=\"T_9749f_row46_col36\" class=\"data row46 col36\" >0.172251</td>\n",
       "                        <td id=\"T_9749f_row46_col37\" class=\"data row46 col37\" >0.098100</td>\n",
       "                        <td id=\"T_9749f_row46_col38\" class=\"data row46 col38\" >0.205431</td>\n",
       "                        <td id=\"T_9749f_row46_col39\" class=\"data row46 col39\" >0.078566</td>\n",
       "                        <td id=\"T_9749f_row46_col40\" class=\"data row46 col40\" >0.081435</td>\n",
       "                        <td id=\"T_9749f_row46_col41\" class=\"data row46 col41\" >0.008620</td>\n",
       "                        <td id=\"T_9749f_row46_col42\" class=\"data row46 col42\" >0.060339</td>\n",
       "                        <td id=\"T_9749f_row46_col43\" class=\"data row46 col43\" >-0.013529</td>\n",
       "                        <td id=\"T_9749f_row46_col44\" class=\"data row46 col44\" >-0.059458</td>\n",
       "                        <td id=\"T_9749f_row46_col45\" class=\"data row46 col45\" >0.586878</td>\n",
       "                        <td id=\"T_9749f_row46_col46\" class=\"data row46 col46\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row46_col47\" class=\"data row46 col47\" >0.056560</td>\n",
       "                        <td id=\"T_9749f_row46_col48\" class=\"data row46 col48\" >0.158208</td>\n",
       "                        <td id=\"T_9749f_row46_col49\" class=\"data row46 col49\" >-0.033285</td>\n",
       "                        <td id=\"T_9749f_row46_col50\" class=\"data row46 col50\" >-0.055327</td>\n",
       "                        <td id=\"T_9749f_row46_col51\" class=\"data row46 col51\" >-0.034140</td>\n",
       "                        <td id=\"T_9749f_row46_col52\" class=\"data row46 col52\" >-0.055907</td>\n",
       "                        <td id=\"T_9749f_row46_col53\" class=\"data row46 col53\" >-0.004299</td>\n",
       "                        <td id=\"T_9749f_row46_col54\" class=\"data row46 col54\" >0.147352</td>\n",
       "                        <td id=\"T_9749f_row46_col55\" class=\"data row46 col55\" >-0.318086</td>\n",
       "                        <td id=\"T_9749f_row46_col56\" class=\"data row46 col56\" >-0.051446</td>\n",
       "                        <td id=\"T_9749f_row46_col57\" class=\"data row46 col57\" >0.003388</td>\n",
       "                        <td id=\"T_9749f_row46_col58\" class=\"data row46 col58\" >0.001108</td>\n",
       "                        <td id=\"T_9749f_row46_col59\" class=\"data row46 col59\" >0.052434</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row47\" class=\"row_heading level0 row47\" >day_avg_windspeed</th>\n",
       "                        <td id=\"T_9749f_row47_col0\" class=\"data row47 col0\" >-0.051985</td>\n",
       "                        <td id=\"T_9749f_row47_col1\" class=\"data row47 col1\" >-0.074133</td>\n",
       "                        <td id=\"T_9749f_row47_col2\" class=\"data row47 col2\" >-0.037762</td>\n",
       "                        <td id=\"T_9749f_row47_col3\" class=\"data row47 col3\" >-0.180583</td>\n",
       "                        <td id=\"T_9749f_row47_col4\" class=\"data row47 col4\" >-0.181055</td>\n",
       "                        <td id=\"T_9749f_row47_col5\" class=\"data row47 col5\" >-0.024371</td>\n",
       "                        <td id=\"T_9749f_row47_col6\" class=\"data row47 col6\" >-0.085869</td>\n",
       "                        <td id=\"T_9749f_row47_col7\" class=\"data row47 col7\" >0.013553</td>\n",
       "                        <td id=\"T_9749f_row47_col8\" class=\"data row47 col8\" >0.087761</td>\n",
       "                        <td id=\"T_9749f_row47_col9\" class=\"data row47 col9\" >-0.376343</td>\n",
       "                        <td id=\"T_9749f_row47_col10\" class=\"data row47 col10\" >-0.282436</td>\n",
       "                        <td id=\"T_9749f_row47_col11\" class=\"data row47 col11\" >-0.260608</td>\n",
       "                        <td id=\"T_9749f_row47_col12\" class=\"data row47 col12\" >-0.172865</td>\n",
       "                        <td id=\"T_9749f_row47_col13\" class=\"data row47 col13\" >-0.037230</td>\n",
       "                        <td id=\"T_9749f_row47_col14\" class=\"data row47 col14\" >-0.193722</td>\n",
       "                        <td id=\"T_9749f_row47_col15\" class=\"data row47 col15\" >0.233342</td>\n",
       "                        <td id=\"T_9749f_row47_col16\" class=\"data row47 col16\" >0.224252</td>\n",
       "                        <td id=\"T_9749f_row47_col17\" class=\"data row47 col17\" >0.233342</td>\n",
       "                        <td id=\"T_9749f_row47_col18\" class=\"data row47 col18\" >0.224252</td>\n",
       "                        <td id=\"T_9749f_row47_col19\" class=\"data row47 col19\" >-0.250149</td>\n",
       "                        <td id=\"T_9749f_row47_col20\" class=\"data row47 col20\" >-0.234632</td>\n",
       "                        <td id=\"T_9749f_row47_col21\" class=\"data row47 col21\" >0.039223</td>\n",
       "                        <td id=\"T_9749f_row47_col22\" class=\"data row47 col22\" >-0.039219</td>\n",
       "                        <td id=\"T_9749f_row47_col23\" class=\"data row47 col23\" >-0.060804</td>\n",
       "                        <td id=\"T_9749f_row47_col24\" class=\"data row47 col24\" >-0.105575</td>\n",
       "                        <td id=\"T_9749f_row47_col25\" class=\"data row47 col25\" >-0.233769</td>\n",
       "                        <td id=\"T_9749f_row47_col26\" class=\"data row47 col26\" >-0.178508</td>\n",
       "                        <td id=\"T_9749f_row47_col27\" class=\"data row47 col27\" >-0.072148</td>\n",
       "                        <td id=\"T_9749f_row47_col28\" class=\"data row47 col28\" >-0.125130</td>\n",
       "                        <td id=\"T_9749f_row47_col29\" class=\"data row47 col29\" >-0.233239</td>\n",
       "                        <td id=\"T_9749f_row47_col30\" class=\"data row47 col30\" >-0.177996</td>\n",
       "                        <td id=\"T_9749f_row47_col31\" class=\"data row47 col31\" >0.990488</td>\n",
       "                        <td id=\"T_9749f_row47_col32\" class=\"data row47 col32\" >0.526551</td>\n",
       "                        <td id=\"T_9749f_row47_col33\" class=\"data row47 col33\" >0.436106</td>\n",
       "                        <td id=\"T_9749f_row47_col34\" class=\"data row47 col34\" >0.276261</td>\n",
       "                        <td id=\"T_9749f_row47_col35\" class=\"data row47 col35\" >-0.009165</td>\n",
       "                        <td id=\"T_9749f_row47_col36\" class=\"data row47 col36\" >0.045572</td>\n",
       "                        <td id=\"T_9749f_row47_col37\" class=\"data row47 col37\" >0.416463</td>\n",
       "                        <td id=\"T_9749f_row47_col38\" class=\"data row47 col38\" >0.281748</td>\n",
       "                        <td id=\"T_9749f_row47_col39\" class=\"data row47 col39\" >-0.502880</td>\n",
       "                        <td id=\"T_9749f_row47_col40\" class=\"data row47 col40\" >-0.315610</td>\n",
       "                        <td id=\"T_9749f_row47_col41\" class=\"data row47 col41\" >-0.072436</td>\n",
       "                        <td id=\"T_9749f_row47_col42\" class=\"data row47 col42\" >-0.125137</td>\n",
       "                        <td id=\"T_9749f_row47_col43\" class=\"data row47 col43\" >-0.187330</td>\n",
       "                        <td id=\"T_9749f_row47_col44\" class=\"data row47 col44\" >-0.233440</td>\n",
       "                        <td id=\"T_9749f_row47_col45\" class=\"data row47 col45\" >0.196618</td>\n",
       "                        <td id=\"T_9749f_row47_col46\" class=\"data row47 col46\" >0.056560</td>\n",
       "                        <td id=\"T_9749f_row47_col47\" class=\"data row47 col47\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row47_col48\" class=\"data row47 col48\" >0.526811</td>\n",
       "                        <td id=\"T_9749f_row47_col49\" class=\"data row47 col49\" >0.138623</td>\n",
       "                        <td id=\"T_9749f_row47_col50\" class=\"data row47 col50\" >0.157568</td>\n",
       "                        <td id=\"T_9749f_row47_col51\" class=\"data row47 col51\" >0.139179</td>\n",
       "                        <td id=\"T_9749f_row47_col52\" class=\"data row47 col52\" >0.157237</td>\n",
       "                        <td id=\"T_9749f_row47_col53\" class=\"data row47 col53\" >0.035315</td>\n",
       "                        <td id=\"T_9749f_row47_col54\" class=\"data row47 col54\" >-0.193082</td>\n",
       "                        <td id=\"T_9749f_row47_col55\" class=\"data row47 col55\" >0.115026</td>\n",
       "                        <td id=\"T_9749f_row47_col56\" class=\"data row47 col56\" >-0.152393</td>\n",
       "                        <td id=\"T_9749f_row47_col57\" class=\"data row47 col57\" >0.004520</td>\n",
       "                        <td id=\"T_9749f_row47_col58\" class=\"data row47 col58\" >0.000537</td>\n",
       "                        <td id=\"T_9749f_row47_col59\" class=\"data row47 col59\" >-0.100429</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row48\" class=\"row_heading level0 row48\" >week_avg_windspeed</th>\n",
       "                        <td id=\"T_9749f_row48_col0\" class=\"data row48 col0\" >-0.076518</td>\n",
       "                        <td id=\"T_9749f_row48_col1\" class=\"data row48 col1\" >-0.118409</td>\n",
       "                        <td id=\"T_9749f_row48_col2\" class=\"data row48 col2\" >-0.085098</td>\n",
       "                        <td id=\"T_9749f_row48_col3\" class=\"data row48 col3\" >-0.343910</td>\n",
       "                        <td id=\"T_9749f_row48_col4\" class=\"data row48 col4\" >-0.339537</td>\n",
       "                        <td id=\"T_9749f_row48_col5\" class=\"data row48 col5\" >-0.178848</td>\n",
       "                        <td id=\"T_9749f_row48_col6\" class=\"data row48 col6\" >-0.168713</td>\n",
       "                        <td id=\"T_9749f_row48_col7\" class=\"data row48 col7\" >0.021794</td>\n",
       "                        <td id=\"T_9749f_row48_col8\" class=\"data row48 col8\" >0.108575</td>\n",
       "                        <td id=\"T_9749f_row48_col9\" class=\"data row48 col9\" >-0.405076</td>\n",
       "                        <td id=\"T_9749f_row48_col10\" class=\"data row48 col10\" >-0.466966</td>\n",
       "                        <td id=\"T_9749f_row48_col11\" class=\"data row48 col11\" >-0.316297</td>\n",
       "                        <td id=\"T_9749f_row48_col12\" class=\"data row48 col12\" >-0.360094</td>\n",
       "                        <td id=\"T_9749f_row48_col13\" class=\"data row48 col13\" >0.160183</td>\n",
       "                        <td id=\"T_9749f_row48_col14\" class=\"data row48 col14\" >-0.058043</td>\n",
       "                        <td id=\"T_9749f_row48_col15\" class=\"data row48 col15\" >0.380312</td>\n",
       "                        <td id=\"T_9749f_row48_col16\" class=\"data row48 col16\" >0.365754</td>\n",
       "                        <td id=\"T_9749f_row48_col17\" class=\"data row48 col17\" >0.380312</td>\n",
       "                        <td id=\"T_9749f_row48_col18\" class=\"data row48 col18\" >0.365754</td>\n",
       "                        <td id=\"T_9749f_row48_col19\" class=\"data row48 col19\" >-0.377569</td>\n",
       "                        <td id=\"T_9749f_row48_col20\" class=\"data row48 col20\" >-0.376438</td>\n",
       "                        <td id=\"T_9749f_row48_col21\" class=\"data row48 col21\" >-0.029020</td>\n",
       "                        <td id=\"T_9749f_row48_col22\" class=\"data row48 col22\" >-0.022615</td>\n",
       "                        <td id=\"T_9749f_row48_col23\" class=\"data row48 col23\" >-0.236363</td>\n",
       "                        <td id=\"T_9749f_row48_col24\" class=\"data row48 col24\" >-0.218882</td>\n",
       "                        <td id=\"T_9749f_row48_col25\" class=\"data row48 col25\" >-0.341194</td>\n",
       "                        <td id=\"T_9749f_row48_col26\" class=\"data row48 col26\" >-0.345084</td>\n",
       "                        <td id=\"T_9749f_row48_col27\" class=\"data row48 col27\" >-0.257144</td>\n",
       "                        <td id=\"T_9749f_row48_col28\" class=\"data row48 col28\" >-0.239669</td>\n",
       "                        <td id=\"T_9749f_row48_col29\" class=\"data row48 col29\" >-0.342227</td>\n",
       "                        <td id=\"T_9749f_row48_col30\" class=\"data row48 col30\" >-0.345024</td>\n",
       "                        <td id=\"T_9749f_row48_col31\" class=\"data row48 col31\" >0.519489</td>\n",
       "                        <td id=\"T_9749f_row48_col32\" class=\"data row48 col32\" >0.991156</td>\n",
       "                        <td id=\"T_9749f_row48_col33\" class=\"data row48 col33\" >0.246012</td>\n",
       "                        <td id=\"T_9749f_row48_col34\" class=\"data row48 col34\" >0.529928</td>\n",
       "                        <td id=\"T_9749f_row48_col35\" class=\"data row48 col35\" >-0.011432</td>\n",
       "                        <td id=\"T_9749f_row48_col36\" class=\"data row48 col36\" >0.017844</td>\n",
       "                        <td id=\"T_9749f_row48_col37\" class=\"data row48 col37\" >0.212212</td>\n",
       "                        <td id=\"T_9749f_row48_col38\" class=\"data row48 col38\" >0.479100</td>\n",
       "                        <td id=\"T_9749f_row48_col39\" class=\"data row48 col39\" >-0.339735</td>\n",
       "                        <td id=\"T_9749f_row48_col40\" class=\"data row48 col40\" >-0.568068</td>\n",
       "                        <td id=\"T_9749f_row48_col41\" class=\"data row48 col41\" >-0.262648</td>\n",
       "                        <td id=\"T_9749f_row48_col42\" class=\"data row48 col42\" >-0.241665</td>\n",
       "                        <td id=\"T_9749f_row48_col43\" class=\"data row48 col43\" >-0.039153</td>\n",
       "                        <td id=\"T_9749f_row48_col44\" class=\"data row48 col44\" >-0.234148</td>\n",
       "                        <td id=\"T_9749f_row48_col45\" class=\"data row48 col45\" >0.057402</td>\n",
       "                        <td id=\"T_9749f_row48_col46\" class=\"data row48 col46\" >0.158208</td>\n",
       "                        <td id=\"T_9749f_row48_col47\" class=\"data row48 col47\" >0.526811</td>\n",
       "                        <td id=\"T_9749f_row48_col48\" class=\"data row48 col48\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row48_col49\" class=\"data row48 col49\" >0.231237</td>\n",
       "                        <td id=\"T_9749f_row48_col50\" class=\"data row48 col50\" >0.234434</td>\n",
       "                        <td id=\"T_9749f_row48_col51\" class=\"data row48 col51\" >0.232205</td>\n",
       "                        <td id=\"T_9749f_row48_col52\" class=\"data row48 col52\" >0.234859</td>\n",
       "                        <td id=\"T_9749f_row48_col53\" class=\"data row48 col53\" >0.018918</td>\n",
       "                        <td id=\"T_9749f_row48_col54\" class=\"data row48 col54\" >-0.283310</td>\n",
       "                        <td id=\"T_9749f_row48_col55\" class=\"data row48 col55\" >0.180551</td>\n",
       "                        <td id=\"T_9749f_row48_col56\" class=\"data row48 col56\" >-0.122697</td>\n",
       "                        <td id=\"T_9749f_row48_col57\" class=\"data row48 col57\" >0.006402</td>\n",
       "                        <td id=\"T_9749f_row48_col58\" class=\"data row48 col58\" >0.001073</td>\n",
       "                        <td id=\"T_9749f_row48_col59\" class=\"data row48 col59\" >-0.225991</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row49\" class=\"row_heading level0 row49\" >day_avg_as_client</th>\n",
       "                        <td id=\"T_9749f_row49_col0\" class=\"data row49 col0\" >-0.001067</td>\n",
       "                        <td id=\"T_9749f_row49_col1\" class=\"data row49 col1\" >-0.002856</td>\n",
       "                        <td id=\"T_9749f_row49_col2\" class=\"data row49 col2\" >-0.099896</td>\n",
       "                        <td id=\"T_9749f_row49_col3\" class=\"data row49 col3\" >-0.485997</td>\n",
       "                        <td id=\"T_9749f_row49_col4\" class=\"data row49 col4\" >-0.510482</td>\n",
       "                        <td id=\"T_9749f_row49_col5\" class=\"data row49 col5\" >-0.464762</td>\n",
       "                        <td id=\"T_9749f_row49_col6\" class=\"data row49 col6\" >-0.522276</td>\n",
       "                        <td id=\"T_9749f_row49_col7\" class=\"data row49 col7\" >0.101001</td>\n",
       "                        <td id=\"T_9749f_row49_col8\" class=\"data row49 col8\" >0.171085</td>\n",
       "                        <td id=\"T_9749f_row49_col9\" class=\"data row49 col9\" >-0.408320</td>\n",
       "                        <td id=\"T_9749f_row49_col10\" class=\"data row49 col10\" >-0.474822</td>\n",
       "                        <td id=\"T_9749f_row49_col11\" class=\"data row49 col11\" >-0.425295</td>\n",
       "                        <td id=\"T_9749f_row49_col12\" class=\"data row49 col12\" >-0.506840</td>\n",
       "                        <td id=\"T_9749f_row49_col13\" class=\"data row49 col13\" >-0.005584</td>\n",
       "                        <td id=\"T_9749f_row49_col14\" class=\"data row49 col14\" >-0.033719</td>\n",
       "                        <td id=\"T_9749f_row49_col15\" class=\"data row49 col15\" >0.329995</td>\n",
       "                        <td id=\"T_9749f_row49_col16\" class=\"data row49 col16\" >0.351464</td>\n",
       "                        <td id=\"T_9749f_row49_col17\" class=\"data row49 col17\" >0.329995</td>\n",
       "                        <td id=\"T_9749f_row49_col18\" class=\"data row49 col18\" >0.351464</td>\n",
       "                        <td id=\"T_9749f_row49_col19\" class=\"data row49 col19\" >-0.355688</td>\n",
       "                        <td id=\"T_9749f_row49_col20\" class=\"data row49 col20\" >-0.364999</td>\n",
       "                        <td id=\"T_9749f_row49_col21\" class=\"data row49 col21\" >-0.004179</td>\n",
       "                        <td id=\"T_9749f_row49_col22\" class=\"data row49 col22\" >-0.095600</td>\n",
       "                        <td id=\"T_9749f_row49_col23\" class=\"data row49 col23\" >-0.483851</td>\n",
       "                        <td id=\"T_9749f_row49_col24\" class=\"data row49 col24\" >-0.527675</td>\n",
       "                        <td id=\"T_9749f_row49_col25\" class=\"data row49 col25\" >-0.525422</td>\n",
       "                        <td id=\"T_9749f_row49_col26\" class=\"data row49 col26\" >-0.546500</td>\n",
       "                        <td id=\"T_9749f_row49_col27\" class=\"data row49 col27\" >-0.504862</td>\n",
       "                        <td id=\"T_9749f_row49_col28\" class=\"data row49 col28\" >-0.529737</td>\n",
       "                        <td id=\"T_9749f_row49_col29\" class=\"data row49 col29\" >-0.525130</td>\n",
       "                        <td id=\"T_9749f_row49_col30\" class=\"data row49 col30\" >-0.545845</td>\n",
       "                        <td id=\"T_9749f_row49_col31\" class=\"data row49 col31\" >0.147967</td>\n",
       "                        <td id=\"T_9749f_row49_col32\" class=\"data row49 col32\" >0.251675</td>\n",
       "                        <td id=\"T_9749f_row49_col33\" class=\"data row49 col33\" >0.010810</td>\n",
       "                        <td id=\"T_9749f_row49_col34\" class=\"data row49 col34\" >0.069507</td>\n",
       "                        <td id=\"T_9749f_row49_col35\" class=\"data row49 col35\" >-0.094477</td>\n",
       "                        <td id=\"T_9749f_row49_col36\" class=\"data row49 col36\" >-0.143859</td>\n",
       "                        <td id=\"T_9749f_row49_col37\" class=\"data row49 col37\" >-0.060328</td>\n",
       "                        <td id=\"T_9749f_row49_col38\" class=\"data row49 col38\" >-0.039545</td>\n",
       "                        <td id=\"T_9749f_row49_col39\" class=\"data row49 col39\" >-0.114721</td>\n",
       "                        <td id=\"T_9749f_row49_col40\" class=\"data row49 col40\" >-0.195738</td>\n",
       "                        <td id=\"T_9749f_row49_col41\" class=\"data row49 col41\" >-0.504222</td>\n",
       "                        <td id=\"T_9749f_row49_col42\" class=\"data row49 col42\" >-0.533040</td>\n",
       "                        <td id=\"T_9749f_row49_col43\" class=\"data row49 col43\" >0.183606</td>\n",
       "                        <td id=\"T_9749f_row49_col44\" class=\"data row49 col44\" >0.200599</td>\n",
       "                        <td id=\"T_9749f_row49_col45\" class=\"data row49 col45\" >-0.035649</td>\n",
       "                        <td id=\"T_9749f_row49_col46\" class=\"data row49 col46\" >-0.033285</td>\n",
       "                        <td id=\"T_9749f_row49_col47\" class=\"data row49 col47\" >0.138623</td>\n",
       "                        <td id=\"T_9749f_row49_col48\" class=\"data row49 col48\" >0.231237</td>\n",
       "                        <td id=\"T_9749f_row49_col49\" class=\"data row49 col49\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row49_col50\" class=\"data row49 col50\" >0.951030</td>\n",
       "                        <td id=\"T_9749f_row49_col51\" class=\"data row49 col51\" >0.999942</td>\n",
       "                        <td id=\"T_9749f_row49_col52\" class=\"data row49 col52\" >0.950912</td>\n",
       "                        <td id=\"T_9749f_row49_col53\" class=\"data row49 col53\" >-0.144606</td>\n",
       "                        <td id=\"T_9749f_row49_col54\" class=\"data row49 col54\" >-0.215905</td>\n",
       "                        <td id=\"T_9749f_row49_col55\" class=\"data row49 col55\" >-0.142987</td>\n",
       "                        <td id=\"T_9749f_row49_col56\" class=\"data row49 col56\" >-0.027157</td>\n",
       "                        <td id=\"T_9749f_row49_col57\" class=\"data row49 col57\" >-0.001227</td>\n",
       "                        <td id=\"T_9749f_row49_col58\" class=\"data row49 col58\" >0.000923</td>\n",
       "                        <td id=\"T_9749f_row49_col59\" class=\"data row49 col59\" >-0.864264</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row50\" class=\"row_heading level0 row50\" >week_avg_as_client</th>\n",
       "                        <td id=\"T_9749f_row50_col0\" class=\"data row50 col0\" >-0.010859</td>\n",
       "                        <td id=\"T_9749f_row50_col1\" class=\"data row50 col1\" >-0.022856</td>\n",
       "                        <td id=\"T_9749f_row50_col2\" class=\"data row50 col2\" >-0.056166</td>\n",
       "                        <td id=\"T_9749f_row50_col3\" class=\"data row50 col3\" >-0.502095</td>\n",
       "                        <td id=\"T_9749f_row50_col4\" class=\"data row50 col4\" >-0.540220</td>\n",
       "                        <td id=\"T_9749f_row50_col5\" class=\"data row50 col5\" >-0.468744</td>\n",
       "                        <td id=\"T_9749f_row50_col6\" class=\"data row50 col6\" >-0.542480</td>\n",
       "                        <td id=\"T_9749f_row50_col7\" class=\"data row50 col7\" >0.087494</td>\n",
       "                        <td id=\"T_9749f_row50_col8\" class=\"data row50 col8\" >0.172083</td>\n",
       "                        <td id=\"T_9749f_row50_col9\" class=\"data row50 col9\" >-0.401215</td>\n",
       "                        <td id=\"T_9749f_row50_col10\" class=\"data row50 col10\" >-0.464352</td>\n",
       "                        <td id=\"T_9749f_row50_col11\" class=\"data row50 col11\" >-0.442816</td>\n",
       "                        <td id=\"T_9749f_row50_col12\" class=\"data row50 col12\" >-0.518686</td>\n",
       "                        <td id=\"T_9749f_row50_col13\" class=\"data row50 col13\" >0.005652</td>\n",
       "                        <td id=\"T_9749f_row50_col14\" class=\"data row50 col14\" >-0.011325</td>\n",
       "                        <td id=\"T_9749f_row50_col15\" class=\"data row50 col15\" >0.321434</td>\n",
       "                        <td id=\"T_9749f_row50_col16\" class=\"data row50 col16\" >0.344027</td>\n",
       "                        <td id=\"T_9749f_row50_col17\" class=\"data row50 col17\" >0.321434</td>\n",
       "                        <td id=\"T_9749f_row50_col18\" class=\"data row50 col18\" >0.344027</td>\n",
       "                        <td id=\"T_9749f_row50_col19\" class=\"data row50 col19\" >-0.357407</td>\n",
       "                        <td id=\"T_9749f_row50_col20\" class=\"data row50 col20\" >-0.370882</td>\n",
       "                        <td id=\"T_9749f_row50_col21\" class=\"data row50 col21\" >0.024046</td>\n",
       "                        <td id=\"T_9749f_row50_col22\" class=\"data row50 col22\" >-0.038860</td>\n",
       "                        <td id=\"T_9749f_row50_col23\" class=\"data row50 col23\" >-0.489790</td>\n",
       "                        <td id=\"T_9749f_row50_col24\" class=\"data row50 col24\" >-0.557556</td>\n",
       "                        <td id=\"T_9749f_row50_col25\" class=\"data row50 col25\" >-0.538962</td>\n",
       "                        <td id=\"T_9749f_row50_col26\" class=\"data row50 col26\" >-0.576847</td>\n",
       "                        <td id=\"T_9749f_row50_col27\" class=\"data row50 col27\" >-0.514488</td>\n",
       "                        <td id=\"T_9749f_row50_col28\" class=\"data row50 col28\" >-0.559063</td>\n",
       "                        <td id=\"T_9749f_row50_col29\" class=\"data row50 col29\" >-0.538732</td>\n",
       "                        <td id=\"T_9749f_row50_col30\" class=\"data row50 col30\" >-0.576238</td>\n",
       "                        <td id=\"T_9749f_row50_col31\" class=\"data row50 col31\" >0.163855</td>\n",
       "                        <td id=\"T_9749f_row50_col32\" class=\"data row50 col32\" >0.248909</td>\n",
       "                        <td id=\"T_9749f_row50_col33\" class=\"data row50 col33\" >0.025014</td>\n",
       "                        <td id=\"T_9749f_row50_col34\" class=\"data row50 col34\" >0.043984</td>\n",
       "                        <td id=\"T_9749f_row50_col35\" class=\"data row50 col35\" >-0.085544</td>\n",
       "                        <td id=\"T_9749f_row50_col36\" class=\"data row50 col36\" >-0.157776</td>\n",
       "                        <td id=\"T_9749f_row50_col37\" class=\"data row50 col37\" >-0.048607</td>\n",
       "                        <td id=\"T_9749f_row50_col38\" class=\"data row50 col38\" >-0.070236</td>\n",
       "                        <td id=\"T_9749f_row50_col39\" class=\"data row50 col39\" >-0.166727</td>\n",
       "                        <td id=\"T_9749f_row50_col40\" class=\"data row50 col40\" >-0.192988</td>\n",
       "                        <td id=\"T_9749f_row50_col41\" class=\"data row50 col41\" >-0.511592</td>\n",
       "                        <td id=\"T_9749f_row50_col42\" class=\"data row50 col42\" >-0.560718</td>\n",
       "                        <td id=\"T_9749f_row50_col43\" class=\"data row50 col43\" >0.187021</td>\n",
       "                        <td id=\"T_9749f_row50_col44\" class=\"data row50 col44\" >0.247908</td>\n",
       "                        <td id=\"T_9749f_row50_col45\" class=\"data row50 col45\" >-0.046555</td>\n",
       "                        <td id=\"T_9749f_row50_col46\" class=\"data row50 col46\" >-0.055327</td>\n",
       "                        <td id=\"T_9749f_row50_col47\" class=\"data row50 col47\" >0.157568</td>\n",
       "                        <td id=\"T_9749f_row50_col48\" class=\"data row50 col48\" >0.234434</td>\n",
       "                        <td id=\"T_9749f_row50_col49\" class=\"data row50 col49\" >0.951030</td>\n",
       "                        <td id=\"T_9749f_row50_col50\" class=\"data row50 col50\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row50_col51\" class=\"data row50 col51\" >0.952131</td>\n",
       "                        <td id=\"T_9749f_row50_col52\" class=\"data row50 col52\" >0.999936</td>\n",
       "                        <td id=\"T_9749f_row50_col53\" class=\"data row50 col53\" >-0.051715</td>\n",
       "                        <td id=\"T_9749f_row50_col54\" class=\"data row50 col54\" >-0.264805</td>\n",
       "                        <td id=\"T_9749f_row50_col55\" class=\"data row50 col55\" >-0.101139</td>\n",
       "                        <td id=\"T_9749f_row50_col56\" class=\"data row50 col56\" >-0.023755</td>\n",
       "                        <td id=\"T_9749f_row50_col57\" class=\"data row50 col57\" >0.001408</td>\n",
       "                        <td id=\"T_9749f_row50_col58\" class=\"data row50 col58\" >0.000889</td>\n",
       "                        <td id=\"T_9749f_row50_col59\" class=\"data row50 col59\" >-0.819902</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row51\" class=\"row_heading level0 row51\" >day_avg_auth_client</th>\n",
       "                        <td id=\"T_9749f_row51_col0\" class=\"data row51 col0\" >-0.002215</td>\n",
       "                        <td id=\"T_9749f_row51_col1\" class=\"data row51 col1\" >-0.005689</td>\n",
       "                        <td id=\"T_9749f_row51_col2\" class=\"data row51 col2\" >-0.101264</td>\n",
       "                        <td id=\"T_9749f_row51_col3\" class=\"data row51 col3\" >-0.487376</td>\n",
       "                        <td id=\"T_9749f_row51_col4\" class=\"data row51 col4\" >-0.511816</td>\n",
       "                        <td id=\"T_9749f_row51_col5\" class=\"data row51 col5\" >-0.466607</td>\n",
       "                        <td id=\"T_9749f_row51_col6\" class=\"data row51 col6\" >-0.524206</td>\n",
       "                        <td id=\"T_9749f_row51_col7\" class=\"data row51 col7\" >0.100331</td>\n",
       "                        <td id=\"T_9749f_row51_col8\" class=\"data row51 col8\" >0.170157</td>\n",
       "                        <td id=\"T_9749f_row51_col9\" class=\"data row51 col9\" >-0.408132</td>\n",
       "                        <td id=\"T_9749f_row51_col10\" class=\"data row51 col10\" >-0.474436</td>\n",
       "                        <td id=\"T_9749f_row51_col11\" class=\"data row51 col11\" >-0.427006</td>\n",
       "                        <td id=\"T_9749f_row51_col12\" class=\"data row51 col12\" >-0.508019</td>\n",
       "                        <td id=\"T_9749f_row51_col13\" class=\"data row51 col13\" >-0.005551</td>\n",
       "                        <td id=\"T_9749f_row51_col14\" class=\"data row51 col14\" >-0.033740</td>\n",
       "                        <td id=\"T_9749f_row51_col15\" class=\"data row51 col15\" >0.329282</td>\n",
       "                        <td id=\"T_9749f_row51_col16\" class=\"data row51 col16\" >0.350775</td>\n",
       "                        <td id=\"T_9749f_row51_col17\" class=\"data row51 col17\" >0.329282</td>\n",
       "                        <td id=\"T_9749f_row51_col18\" class=\"data row51 col18\" >0.350775</td>\n",
       "                        <td id=\"T_9749f_row51_col19\" class=\"data row51 col19\" >-0.355260</td>\n",
       "                        <td id=\"T_9749f_row51_col20\" class=\"data row51 col20\" >-0.364725</td>\n",
       "                        <td id=\"T_9749f_row51_col21\" class=\"data row51 col21\" >-0.004099</td>\n",
       "                        <td id=\"T_9749f_row51_col22\" class=\"data row51 col22\" >-0.094965</td>\n",
       "                        <td id=\"T_9749f_row51_col23\" class=\"data row51 col23\" >-0.485202</td>\n",
       "                        <td id=\"T_9749f_row51_col24\" class=\"data row51 col24\" >-0.529398</td>\n",
       "                        <td id=\"T_9749f_row51_col25\" class=\"data row51 col25\" >-0.527048</td>\n",
       "                        <td id=\"T_9749f_row51_col26\" class=\"data row51 col26\" >-0.548243</td>\n",
       "                        <td id=\"T_9749f_row51_col27\" class=\"data row51 col27\" >-0.506393</td>\n",
       "                        <td id=\"T_9749f_row51_col28\" class=\"data row51 col28\" >-0.531371</td>\n",
       "                        <td id=\"T_9749f_row51_col29\" class=\"data row51 col29\" >-0.526756</td>\n",
       "                        <td id=\"T_9749f_row51_col30\" class=\"data row51 col30\" >-0.547587</td>\n",
       "                        <td id=\"T_9749f_row51_col31\" class=\"data row51 col31\" >0.148473</td>\n",
       "                        <td id=\"T_9749f_row51_col32\" class=\"data row51 col32\" >0.252405</td>\n",
       "                        <td id=\"T_9749f_row51_col33\" class=\"data row51 col33\" >0.012255</td>\n",
       "                        <td id=\"T_9749f_row51_col34\" class=\"data row51 col34\" >0.070128</td>\n",
       "                        <td id=\"T_9749f_row51_col35\" class=\"data row51 col35\" >-0.094425</td>\n",
       "                        <td id=\"T_9749f_row51_col36\" class=\"data row51 col36\" >-0.144804</td>\n",
       "                        <td id=\"T_9749f_row51_col37\" class=\"data row51 col37\" >-0.059935</td>\n",
       "                        <td id=\"T_9749f_row51_col38\" class=\"data row51 col38\" >-0.039149</td>\n",
       "                        <td id=\"T_9749f_row51_col39\" class=\"data row51 col39\" >-0.115810</td>\n",
       "                        <td id=\"T_9749f_row51_col40\" class=\"data row51 col40\" >-0.197051</td>\n",
       "                        <td id=\"T_9749f_row51_col41\" class=\"data row51 col41\" >-0.505765</td>\n",
       "                        <td id=\"T_9749f_row51_col42\" class=\"data row51 col42\" >-0.534665</td>\n",
       "                        <td id=\"T_9749f_row51_col43\" class=\"data row51 col43\" >0.185021</td>\n",
       "                        <td id=\"T_9749f_row51_col44\" class=\"data row51 col44\" >0.202271</td>\n",
       "                        <td id=\"T_9749f_row51_col45\" class=\"data row51 col45\" >-0.035793</td>\n",
       "                        <td id=\"T_9749f_row51_col46\" class=\"data row51 col46\" >-0.034140</td>\n",
       "                        <td id=\"T_9749f_row51_col47\" class=\"data row51 col47\" >0.139179</td>\n",
       "                        <td id=\"T_9749f_row51_col48\" class=\"data row51 col48\" >0.232205</td>\n",
       "                        <td id=\"T_9749f_row51_col49\" class=\"data row51 col49\" >0.999942</td>\n",
       "                        <td id=\"T_9749f_row51_col50\" class=\"data row51 col50\" >0.952131</td>\n",
       "                        <td id=\"T_9749f_row51_col51\" class=\"data row51 col51\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row51_col52\" class=\"data row51 col52\" >0.952061</td>\n",
       "                        <td id=\"T_9749f_row51_col53\" class=\"data row51 col53\" >-0.140686</td>\n",
       "                        <td id=\"T_9749f_row51_col54\" class=\"data row51 col54\" >-0.215071</td>\n",
       "                        <td id=\"T_9749f_row51_col55\" class=\"data row51 col55\" >-0.142826</td>\n",
       "                        <td id=\"T_9749f_row51_col56\" class=\"data row51 col56\" >-0.027630</td>\n",
       "                        <td id=\"T_9749f_row51_col57\" class=\"data row51 col57\" >-0.001594</td>\n",
       "                        <td id=\"T_9749f_row51_col58\" class=\"data row51 col58\" >0.000912</td>\n",
       "                        <td id=\"T_9749f_row51_col59\" class=\"data row51 col59\" >-0.864373</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row52\" class=\"row_heading level0 row52\" >week_avg_auth_client</th>\n",
       "                        <td id=\"T_9749f_row52_col0\" class=\"data row52 col0\" >-0.011734</td>\n",
       "                        <td id=\"T_9749f_row52_col1\" class=\"data row52 col1\" >-0.023453</td>\n",
       "                        <td id=\"T_9749f_row52_col2\" class=\"data row52 col2\" >-0.058036</td>\n",
       "                        <td id=\"T_9749f_row52_col3\" class=\"data row52 col3\" >-0.502675</td>\n",
       "                        <td id=\"T_9749f_row52_col4\" class=\"data row52 col4\" >-0.541194</td>\n",
       "                        <td id=\"T_9749f_row52_col5\" class=\"data row52 col5\" >-0.470018</td>\n",
       "                        <td id=\"T_9749f_row52_col6\" class=\"data row52 col6\" >-0.544106</td>\n",
       "                        <td id=\"T_9749f_row52_col7\" class=\"data row52 col7\" >0.087062</td>\n",
       "                        <td id=\"T_9749f_row52_col8\" class=\"data row52 col8\" >0.171391</td>\n",
       "                        <td id=\"T_9749f_row52_col9\" class=\"data row52 col9\" >-0.400295</td>\n",
       "                        <td id=\"T_9749f_row52_col10\" class=\"data row52 col10\" >-0.463565</td>\n",
       "                        <td id=\"T_9749f_row52_col11\" class=\"data row52 col11\" >-0.443274</td>\n",
       "                        <td id=\"T_9749f_row52_col12\" class=\"data row52 col12\" >-0.519531</td>\n",
       "                        <td id=\"T_9749f_row52_col13\" class=\"data row52 col13\" >0.005641</td>\n",
       "                        <td id=\"T_9749f_row52_col14\" class=\"data row52 col14\" >-0.011322</td>\n",
       "                        <td id=\"T_9749f_row52_col15\" class=\"data row52 col15\" >0.320497</td>\n",
       "                        <td id=\"T_9749f_row52_col16\" class=\"data row52 col16\" >0.343062</td>\n",
       "                        <td id=\"T_9749f_row52_col17\" class=\"data row52 col17\" >0.320497</td>\n",
       "                        <td id=\"T_9749f_row52_col18\" class=\"data row52 col18\" >0.343062</td>\n",
       "                        <td id=\"T_9749f_row52_col19\" class=\"data row52 col19\" >-0.356601</td>\n",
       "                        <td id=\"T_9749f_row52_col20\" class=\"data row52 col20\" >-0.370186</td>\n",
       "                        <td id=\"T_9749f_row52_col21\" class=\"data row52 col21\" >0.024672</td>\n",
       "                        <td id=\"T_9749f_row52_col22\" class=\"data row52 col22\" >-0.037868</td>\n",
       "                        <td id=\"T_9749f_row52_col23\" class=\"data row52 col23\" >-0.490636</td>\n",
       "                        <td id=\"T_9749f_row52_col24\" class=\"data row52 col24\" >-0.558937</td>\n",
       "                        <td id=\"T_9749f_row52_col25\" class=\"data row52 col25\" >-0.539805</td>\n",
       "                        <td id=\"T_9749f_row52_col26\" class=\"data row52 col26\" >-0.578340</td>\n",
       "                        <td id=\"T_9749f_row52_col27\" class=\"data row52 col27\" >-0.515382</td>\n",
       "                        <td id=\"T_9749f_row52_col28\" class=\"data row52 col28\" >-0.560527</td>\n",
       "                        <td id=\"T_9749f_row52_col29\" class=\"data row52 col29\" >-0.539574</td>\n",
       "                        <td id=\"T_9749f_row52_col30\" class=\"data row52 col30\" >-0.577732</td>\n",
       "                        <td id=\"T_9749f_row52_col31\" class=\"data row52 col31\" >0.163480</td>\n",
       "                        <td id=\"T_9749f_row52_col32\" class=\"data row52 col32\" >0.249276</td>\n",
       "                        <td id=\"T_9749f_row52_col33\" class=\"data row52 col33\" >0.025585</td>\n",
       "                        <td id=\"T_9749f_row52_col34\" class=\"data row52 col34\" >0.045199</td>\n",
       "                        <td id=\"T_9749f_row52_col35\" class=\"data row52 col35\" >-0.085603</td>\n",
       "                        <td id=\"T_9749f_row52_col36\" class=\"data row52 col36\" >-0.157599</td>\n",
       "                        <td id=\"T_9749f_row52_col37\" class=\"data row52 col37\" >-0.048918</td>\n",
       "                        <td id=\"T_9749f_row52_col38\" class=\"data row52 col38\" >-0.070060</td>\n",
       "                        <td id=\"T_9749f_row52_col39\" class=\"data row52 col39\" >-0.166909</td>\n",
       "                        <td id=\"T_9749f_row52_col40\" class=\"data row52 col40\" >-0.193965</td>\n",
       "                        <td id=\"T_9749f_row52_col41\" class=\"data row52 col41\" >-0.512474</td>\n",
       "                        <td id=\"T_9749f_row52_col42\" class=\"data row52 col42\" >-0.562142</td>\n",
       "                        <td id=\"T_9749f_row52_col43\" class=\"data row52 col43\" >0.188555</td>\n",
       "                        <td id=\"T_9749f_row52_col44\" class=\"data row52 col44\" >0.249769</td>\n",
       "                        <td id=\"T_9749f_row52_col45\" class=\"data row52 col45\" >-0.047326</td>\n",
       "                        <td id=\"T_9749f_row52_col46\" class=\"data row52 col46\" >-0.055907</td>\n",
       "                        <td id=\"T_9749f_row52_col47\" class=\"data row52 col47\" >0.157237</td>\n",
       "                        <td id=\"T_9749f_row52_col48\" class=\"data row52 col48\" >0.234859</td>\n",
       "                        <td id=\"T_9749f_row52_col49\" class=\"data row52 col49\" >0.950912</td>\n",
       "                        <td id=\"T_9749f_row52_col50\" class=\"data row52 col50\" >0.999936</td>\n",
       "                        <td id=\"T_9749f_row52_col51\" class=\"data row52 col51\" >0.952061</td>\n",
       "                        <td id=\"T_9749f_row52_col52\" class=\"data row52 col52\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row52_col53\" class=\"data row52 col53\" >-0.050895</td>\n",
       "                        <td id=\"T_9749f_row52_col54\" class=\"data row52 col54\" >-0.263265</td>\n",
       "                        <td id=\"T_9749f_row52_col55\" class=\"data row52 col55\" >-0.101322</td>\n",
       "                        <td id=\"T_9749f_row52_col56\" class=\"data row52 col56\" >-0.024039</td>\n",
       "                        <td id=\"T_9749f_row52_col57\" class=\"data row52 col57\" >0.001186</td>\n",
       "                        <td id=\"T_9749f_row52_col58\" class=\"data row52 col58\" >0.000825</td>\n",
       "                        <td id=\"T_9749f_row52_col59\" class=\"data row52 col59\" >-0.819617</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row53\" class=\"row_heading level0 row53\" >Day_type_as_int</th>\n",
       "                        <td id=\"T_9749f_row53_col0\" class=\"data row53 col0\" >-0.189202</td>\n",
       "                        <td id=\"T_9749f_row53_col1\" class=\"data row53 col1\" >-0.262337</td>\n",
       "                        <td id=\"T_9749f_row53_col2\" class=\"data row53 col2\" >-0.106484</td>\n",
       "                        <td id=\"T_9749f_row53_col3\" class=\"data row53 col3\" >0.024258</td>\n",
       "                        <td id=\"T_9749f_row53_col4\" class=\"data row53 col4\" >-0.005796</td>\n",
       "                        <td id=\"T_9749f_row53_col5\" class=\"data row53 col5\" >-0.011190</td>\n",
       "                        <td id=\"T_9749f_row53_col6\" class=\"data row53 col6\" >-0.006473</td>\n",
       "                        <td id=\"T_9749f_row53_col7\" class=\"data row53 col7\" >-0.059621</td>\n",
       "                        <td id=\"T_9749f_row53_col8\" class=\"data row53 col8\" >-0.018816</td>\n",
       "                        <td id=\"T_9749f_row53_col9\" class=\"data row53 col9\" >-0.009252</td>\n",
       "                        <td id=\"T_9749f_row53_col10\" class=\"data row53 col10\" >0.000403</td>\n",
       "                        <td id=\"T_9749f_row53_col11\" class=\"data row53 col11\" >0.001947</td>\n",
       "                        <td id=\"T_9749f_row53_col12\" class=\"data row53 col12\" >-0.014770</td>\n",
       "                        <td id=\"T_9749f_row53_col13\" class=\"data row53 col13\" >0.018411</td>\n",
       "                        <td id=\"T_9749f_row53_col14\" class=\"data row53 col14\" >0.062022</td>\n",
       "                        <td id=\"T_9749f_row53_col15\" class=\"data row53 col15\" >0.009244</td>\n",
       "                        <td id=\"T_9749f_row53_col16\" class=\"data row53 col16\" >0.009930</td>\n",
       "                        <td id=\"T_9749f_row53_col17\" class=\"data row53 col17\" >0.009244</td>\n",
       "                        <td id=\"T_9749f_row53_col18\" class=\"data row53 col18\" >0.009930</td>\n",
       "                        <td id=\"T_9749f_row53_col19\" class=\"data row53 col19\" >-0.010841</td>\n",
       "                        <td id=\"T_9749f_row53_col20\" class=\"data row53 col20\" >-0.012323</td>\n",
       "                        <td id=\"T_9749f_row53_col21\" class=\"data row53 col21\" >0.028574</td>\n",
       "                        <td id=\"T_9749f_row53_col22\" class=\"data row53 col22\" >0.024814</td>\n",
       "                        <td id=\"T_9749f_row53_col23\" class=\"data row53 col23\" >0.028749</td>\n",
       "                        <td id=\"T_9749f_row53_col24\" class=\"data row53 col24\" >-0.002401</td>\n",
       "                        <td id=\"T_9749f_row53_col25\" class=\"data row53 col25\" >0.020965</td>\n",
       "                        <td id=\"T_9749f_row53_col26\" class=\"data row53 col26\" >-0.007236</td>\n",
       "                        <td id=\"T_9749f_row53_col27\" class=\"data row53 col27\" >0.026912</td>\n",
       "                        <td id=\"T_9749f_row53_col28\" class=\"data row53 col28\" >-0.003697</td>\n",
       "                        <td id=\"T_9749f_row53_col29\" class=\"data row53 col29\" >0.020439</td>\n",
       "                        <td id=\"T_9749f_row53_col30\" class=\"data row53 col30\" >-0.007420</td>\n",
       "                        <td id=\"T_9749f_row53_col31\" class=\"data row53 col31\" >0.045466</td>\n",
       "                        <td id=\"T_9749f_row53_col32\" class=\"data row53 col32\" >0.019342</td>\n",
       "                        <td id=\"T_9749f_row53_col33\" class=\"data row53 col33\" >0.055944</td>\n",
       "                        <td id=\"T_9749f_row53_col34\" class=\"data row53 col34\" >0.032563</td>\n",
       "                        <td id=\"T_9749f_row53_col35\" class=\"data row53 col35\" >0.013207</td>\n",
       "                        <td id=\"T_9749f_row53_col36\" class=\"data row53 col36\" >0.019431</td>\n",
       "                        <td id=\"T_9749f_row53_col37\" class=\"data row53 col37\" >0.029373</td>\n",
       "                        <td id=\"T_9749f_row53_col38\" class=\"data row53 col38\" >-0.006668</td>\n",
       "                        <td id=\"T_9749f_row53_col39\" class=\"data row53 col39\" >-0.013998</td>\n",
       "                        <td id=\"T_9749f_row53_col40\" class=\"data row53 col40\" >0.006343</td>\n",
       "                        <td id=\"T_9749f_row53_col41\" class=\"data row53 col41\" >0.024622</td>\n",
       "                        <td id=\"T_9749f_row53_col42\" class=\"data row53 col42\" >-0.003319</td>\n",
       "                        <td id=\"T_9749f_row53_col43\" class=\"data row53 col43\" >-0.002354</td>\n",
       "                        <td id=\"T_9749f_row53_col44\" class=\"data row53 col44\" >0.004467</td>\n",
       "                        <td id=\"T_9749f_row53_col45\" class=\"data row53 col45\" >-0.004017</td>\n",
       "                        <td id=\"T_9749f_row53_col46\" class=\"data row53 col46\" >-0.004299</td>\n",
       "                        <td id=\"T_9749f_row53_col47\" class=\"data row53 col47\" >0.035315</td>\n",
       "                        <td id=\"T_9749f_row53_col48\" class=\"data row53 col48\" >0.018918</td>\n",
       "                        <td id=\"T_9749f_row53_col49\" class=\"data row53 col49\" >-0.144606</td>\n",
       "                        <td id=\"T_9749f_row53_col50\" class=\"data row53 col50\" >-0.051715</td>\n",
       "                        <td id=\"T_9749f_row53_col51\" class=\"data row53 col51\" >-0.140686</td>\n",
       "                        <td id=\"T_9749f_row53_col52\" class=\"data row53 col52\" >-0.050895</td>\n",
       "                        <td id=\"T_9749f_row53_col53\" class=\"data row53 col53\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row53_col54\" class=\"data row53 col54\" >-0.033298</td>\n",
       "                        <td id=\"T_9749f_row53_col55\" class=\"data row53 col55\" >0.005472</td>\n",
       "                        <td id=\"T_9749f_row53_col56\" class=\"data row53 col56\" >0.035001</td>\n",
       "                        <td id=\"T_9749f_row53_col57\" class=\"data row53 col57\" >-0.000580</td>\n",
       "                        <td id=\"T_9749f_row53_col58\" class=\"data row53 col58\" >-0.000697</td>\n",
       "                        <td id=\"T_9749f_row53_col59\" class=\"data row53 col59\" >0.096762</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row54\" class=\"row_heading level0 row54\" >Year</th>\n",
       "                        <td id=\"T_9749f_row54_col0\" class=\"data row54 col0\" >0.131888</td>\n",
       "                        <td id=\"T_9749f_row54_col1\" class=\"data row54 col1\" >0.212361</td>\n",
       "                        <td id=\"T_9749f_row54_col2\" class=\"data row54 col2\" >0.193533</td>\n",
       "                        <td id=\"T_9749f_row54_col3\" class=\"data row54 col3\" >0.258379</td>\n",
       "                        <td id=\"T_9749f_row54_col4\" class=\"data row54 col4\" >0.275693</td>\n",
       "                        <td id=\"T_9749f_row54_col5\" class=\"data row54 col5\" >0.032750</td>\n",
       "                        <td id=\"T_9749f_row54_col6\" class=\"data row54 col6\" >0.044666</td>\n",
       "                        <td id=\"T_9749f_row54_col7\" class=\"data row54 col7\" >0.054797</td>\n",
       "                        <td id=\"T_9749f_row54_col8\" class=\"data row54 col8\" >0.115505</td>\n",
       "                        <td id=\"T_9749f_row54_col9\" class=\"data row54 col9\" >0.417509</td>\n",
       "                        <td id=\"T_9749f_row54_col10\" class=\"data row54 col10\" >0.437496</td>\n",
       "                        <td id=\"T_9749f_row54_col11\" class=\"data row54 col11\" >0.138374</td>\n",
       "                        <td id=\"T_9749f_row54_col12\" class=\"data row54 col12\" >0.140796</td>\n",
       "                        <td id=\"T_9749f_row54_col13\" class=\"data row54 col13\" >-0.062421</td>\n",
       "                        <td id=\"T_9749f_row54_col14\" class=\"data row54 col14\" >-0.068182</td>\n",
       "                        <td id=\"T_9749f_row54_col15\" class=\"data row54 col15\" >-0.455164</td>\n",
       "                        <td id=\"T_9749f_row54_col16\" class=\"data row54 col16\" >-0.436862</td>\n",
       "                        <td id=\"T_9749f_row54_col17\" class=\"data row54 col17\" >-0.455164</td>\n",
       "                        <td id=\"T_9749f_row54_col18\" class=\"data row54 col18\" >-0.436862</td>\n",
       "                        <td id=\"T_9749f_row54_col19\" class=\"data row54 col19\" >0.571146</td>\n",
       "                        <td id=\"T_9749f_row54_col20\" class=\"data row54 col20\" >0.554331</td>\n",
       "                        <td id=\"T_9749f_row54_col21\" class=\"data row54 col21\" >-0.138015</td>\n",
       "                        <td id=\"T_9749f_row54_col22\" class=\"data row54 col22\" >-0.102106</td>\n",
       "                        <td id=\"T_9749f_row54_col23\" class=\"data row54 col23\" >0.114187</td>\n",
       "                        <td id=\"T_9749f_row54_col24\" class=\"data row54 col24\" >0.138944</td>\n",
       "                        <td id=\"T_9749f_row54_col25\" class=\"data row54 col25\" >0.197930</td>\n",
       "                        <td id=\"T_9749f_row54_col26\" class=\"data row54 col26\" >0.212412</td>\n",
       "                        <td id=\"T_9749f_row54_col27\" class=\"data row54 col27\" >0.159265</td>\n",
       "                        <td id=\"T_9749f_row54_col28\" class=\"data row54 col28\" >0.174012</td>\n",
       "                        <td id=\"T_9749f_row54_col29\" class=\"data row54 col29\" >0.197939</td>\n",
       "                        <td id=\"T_9749f_row54_col30\" class=\"data row54 col30\" >0.212323</td>\n",
       "                        <td id=\"T_9749f_row54_col31\" class=\"data row54 col31\" >-0.188962</td>\n",
       "                        <td id=\"T_9749f_row54_col32\" class=\"data row54 col32\" >-0.272125</td>\n",
       "                        <td id=\"T_9749f_row54_col33\" class=\"data row54 col33\" >-0.054146</td>\n",
       "                        <td id=\"T_9749f_row54_col34\" class=\"data row54 col34\" >-0.034436</td>\n",
       "                        <td id=\"T_9749f_row54_col35\" class=\"data row54 col35\" >-0.150775</td>\n",
       "                        <td id=\"T_9749f_row54_col36\" class=\"data row54 col36\" >-0.194109</td>\n",
       "                        <td id=\"T_9749f_row54_col37\" class=\"data row54 col37\" >0.181255</td>\n",
       "                        <td id=\"T_9749f_row54_col38\" class=\"data row54 col38\" >0.289546</td>\n",
       "                        <td id=\"T_9749f_row54_col39\" class=\"data row54 col39\" >0.008746</td>\n",
       "                        <td id=\"T_9749f_row54_col40\" class=\"data row54 col40\" >0.027435</td>\n",
       "                        <td id=\"T_9749f_row54_col41\" class=\"data row54 col41\" >0.156584</td>\n",
       "                        <td id=\"T_9749f_row54_col42\" class=\"data row54 col42\" >0.173005</td>\n",
       "                        <td id=\"T_9749f_row54_col43\" class=\"data row54 col43\" >0.100944</td>\n",
       "                        <td id=\"T_9749f_row54_col44\" class=\"data row54 col44\" >0.117943</td>\n",
       "                        <td id=\"T_9749f_row54_col45\" class=\"data row54 col45\" >0.078389</td>\n",
       "                        <td id=\"T_9749f_row54_col46\" class=\"data row54 col46\" >0.147352</td>\n",
       "                        <td id=\"T_9749f_row54_col47\" class=\"data row54 col47\" >-0.193082</td>\n",
       "                        <td id=\"T_9749f_row54_col48\" class=\"data row54 col48\" >-0.283310</td>\n",
       "                        <td id=\"T_9749f_row54_col49\" class=\"data row54 col49\" >-0.215905</td>\n",
       "                        <td id=\"T_9749f_row54_col50\" class=\"data row54 col50\" >-0.264805</td>\n",
       "                        <td id=\"T_9749f_row54_col51\" class=\"data row54 col51\" >-0.215071</td>\n",
       "                        <td id=\"T_9749f_row54_col52\" class=\"data row54 col52\" >-0.263265</td>\n",
       "                        <td id=\"T_9749f_row54_col53\" class=\"data row54 col53\" >-0.033298</td>\n",
       "                        <td id=\"T_9749f_row54_col54\" class=\"data row54 col54\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row54_col55\" class=\"data row54 col55\" >-0.606507</td>\n",
       "                        <td id=\"T_9749f_row54_col56\" class=\"data row54 col56\" >-0.085119</td>\n",
       "                        <td id=\"T_9749f_row54_col57\" class=\"data row54 col57\" >-0.001351</td>\n",
       "                        <td id=\"T_9749f_row54_col58\" class=\"data row54 col58\" >0.000604</td>\n",
       "                        <td id=\"T_9749f_row54_col59\" class=\"data row54 col59\" >0.144125</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row55\" class=\"row_heading level0 row55\" >Month</th>\n",
       "                        <td id=\"T_9749f_row55_col0\" class=\"data row55 col0\" >-0.019445</td>\n",
       "                        <td id=\"T_9749f_row55_col1\" class=\"data row55 col1\" >-0.024544</td>\n",
       "                        <td id=\"T_9749f_row55_col2\" class=\"data row55 col2\" >0.024376</td>\n",
       "                        <td id=\"T_9749f_row55_col3\" class=\"data row55 col3\" >0.112700</td>\n",
       "                        <td id=\"T_9749f_row55_col4\" class=\"data row55 col4\" >0.155964</td>\n",
       "                        <td id=\"T_9749f_row55_col5\" class=\"data row55 col5\" >0.292447</td>\n",
       "                        <td id=\"T_9749f_row55_col6\" class=\"data row55 col6\" >0.350418</td>\n",
       "                        <td id=\"T_9749f_row55_col7\" class=\"data row55 col7\" >-0.153602</td>\n",
       "                        <td id=\"T_9749f_row55_col8\" class=\"data row55 col8\" >-0.296761</td>\n",
       "                        <td id=\"T_9749f_row55_col9\" class=\"data row55 col9\" >-0.197362</td>\n",
       "                        <td id=\"T_9749f_row55_col10\" class=\"data row55 col10\" >-0.174393</td>\n",
       "                        <td id=\"T_9749f_row55_col11\" class=\"data row55 col11\" >0.171633</td>\n",
       "                        <td id=\"T_9749f_row55_col12\" class=\"data row55 col12\" >0.242984</td>\n",
       "                        <td id=\"T_9749f_row55_col13\" class=\"data row55 col13\" >0.080944</td>\n",
       "                        <td id=\"T_9749f_row55_col14\" class=\"data row55 col14\" >0.069669</td>\n",
       "                        <td id=\"T_9749f_row55_col15\" class=\"data row55 col15\" >0.095349</td>\n",
       "                        <td id=\"T_9749f_row55_col16\" class=\"data row55 col16\" >0.053171</td>\n",
       "                        <td id=\"T_9749f_row55_col17\" class=\"data row55 col17\" >0.095349</td>\n",
       "                        <td id=\"T_9749f_row55_col18\" class=\"data row55 col18\" >0.053171</td>\n",
       "                        <td id=\"T_9749f_row55_col19\" class=\"data row55 col19\" >-0.290125</td>\n",
       "                        <td id=\"T_9749f_row55_col20\" class=\"data row55 col20\" >-0.244357</td>\n",
       "                        <td id=\"T_9749f_row55_col21\" class=\"data row55 col21\" >0.158621</td>\n",
       "                        <td id=\"T_9749f_row55_col22\" class=\"data row55 col22\" >0.164657</td>\n",
       "                        <td id=\"T_9749f_row55_col23\" class=\"data row55 col23\" >0.241234</td>\n",
       "                        <td id=\"T_9749f_row55_col24\" class=\"data row55 col24\" >0.290586</td>\n",
       "                        <td id=\"T_9749f_row55_col25\" class=\"data row55 col25\" >0.181440</td>\n",
       "                        <td id=\"T_9749f_row55_col26\" class=\"data row55 col26\" >0.219271</td>\n",
       "                        <td id=\"T_9749f_row55_col27\" class=\"data row55 col27\" >0.215840</td>\n",
       "                        <td id=\"T_9749f_row55_col28\" class=\"data row55 col28\" >0.261408</td>\n",
       "                        <td id=\"T_9749f_row55_col29\" class=\"data row55 col29\" >0.181852</td>\n",
       "                        <td id=\"T_9749f_row55_col30\" class=\"data row55 col30\" >0.219631</td>\n",
       "                        <td id=\"T_9749f_row55_col31\" class=\"data row55 col31\" >0.093873</td>\n",
       "                        <td id=\"T_9749f_row55_col32\" class=\"data row55 col32\" >0.143740</td>\n",
       "                        <td id=\"T_9749f_row55_col33\" class=\"data row55 col33\" >0.094751</td>\n",
       "                        <td id=\"T_9749f_row55_col34\" class=\"data row55 col34\" >0.097594</td>\n",
       "                        <td id=\"T_9749f_row55_col35\" class=\"data row55 col35\" >0.164302</td>\n",
       "                        <td id=\"T_9749f_row55_col36\" class=\"data row55 col36\" >0.219572</td>\n",
       "                        <td id=\"T_9749f_row55_col37\" class=\"data row55 col37\" >-0.049851</td>\n",
       "                        <td id=\"T_9749f_row55_col38\" class=\"data row55 col38\" >-0.056752</td>\n",
       "                        <td id=\"T_9749f_row55_col39\" class=\"data row55 col39\" >-0.152682</td>\n",
       "                        <td id=\"T_9749f_row55_col40\" class=\"data row55 col40\" >-0.226884</td>\n",
       "                        <td id=\"T_9749f_row55_col41\" class=\"data row55 col41\" >0.216534</td>\n",
       "                        <td id=\"T_9749f_row55_col42\" class=\"data row55 col42\" >0.262671</td>\n",
       "                        <td id=\"T_9749f_row55_col43\" class=\"data row55 col43\" >-0.163317</td>\n",
       "                        <td id=\"T_9749f_row55_col44\" class=\"data row55 col44\" >-0.193857</td>\n",
       "                        <td id=\"T_9749f_row55_col45\" class=\"data row55 col45\" >-0.213797</td>\n",
       "                        <td id=\"T_9749f_row55_col46\" class=\"data row55 col46\" >-0.318086</td>\n",
       "                        <td id=\"T_9749f_row55_col47\" class=\"data row55 col47\" >0.115026</td>\n",
       "                        <td id=\"T_9749f_row55_col48\" class=\"data row55 col48\" >0.180551</td>\n",
       "                        <td id=\"T_9749f_row55_col49\" class=\"data row55 col49\" >-0.142987</td>\n",
       "                        <td id=\"T_9749f_row55_col50\" class=\"data row55 col50\" >-0.101139</td>\n",
       "                        <td id=\"T_9749f_row55_col51\" class=\"data row55 col51\" >-0.142826</td>\n",
       "                        <td id=\"T_9749f_row55_col52\" class=\"data row55 col52\" >-0.101322</td>\n",
       "                        <td id=\"T_9749f_row55_col53\" class=\"data row55 col53\" >0.005472</td>\n",
       "                        <td id=\"T_9749f_row55_col54\" class=\"data row55 col54\" >-0.606507</td>\n",
       "                        <td id=\"T_9749f_row55_col55\" class=\"data row55 col55\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row55_col56\" class=\"data row55 col56\" >0.029835</td>\n",
       "                        <td id=\"T_9749f_row55_col57\" class=\"data row55 col57\" >-0.000135</td>\n",
       "                        <td id=\"T_9749f_row55_col58\" class=\"data row55 col58\" >-0.001390</td>\n",
       "                        <td id=\"T_9749f_row55_col59\" class=\"data row55 col59\" >0.009914</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row56\" class=\"row_heading level0 row56\" >Day</th>\n",
       "                        <td id=\"T_9749f_row56_col0\" class=\"data row56 col0\" >-0.033681</td>\n",
       "                        <td id=\"T_9749f_row56_col1\" class=\"data row56 col1\" >-0.048043</td>\n",
       "                        <td id=\"T_9749f_row56_col2\" class=\"data row56 col2\" >0.005952</td>\n",
       "                        <td id=\"T_9749f_row56_col3\" class=\"data row56 col3\" >0.137701</td>\n",
       "                        <td id=\"T_9749f_row56_col4\" class=\"data row56 col4\" >0.126849</td>\n",
       "                        <td id=\"T_9749f_row56_col5\" class=\"data row56 col5\" >0.112697</td>\n",
       "                        <td id=\"T_9749f_row56_col6\" class=\"data row56 col6\" >0.150269</td>\n",
       "                        <td id=\"T_9749f_row56_col7\" class=\"data row56 col7\" >0.078998</td>\n",
       "                        <td id=\"T_9749f_row56_col8\" class=\"data row56 col8\" >-0.094218</td>\n",
       "                        <td id=\"T_9749f_row56_col9\" class=\"data row56 col9\" >0.093434</td>\n",
       "                        <td id=\"T_9749f_row56_col10\" class=\"data row56 col10\" >0.067824</td>\n",
       "                        <td id=\"T_9749f_row56_col11\" class=\"data row56 col11\" >0.134628</td>\n",
       "                        <td id=\"T_9749f_row56_col12\" class=\"data row56 col12\" >0.111912</td>\n",
       "                        <td id=\"T_9749f_row56_col13\" class=\"data row56 col13\" >0.390340</td>\n",
       "                        <td id=\"T_9749f_row56_col14\" class=\"data row56 col14\" >0.597306</td>\n",
       "                        <td id=\"T_9749f_row56_col15\" class=\"data row56 col15\" >-0.016715</td>\n",
       "                        <td id=\"T_9749f_row56_col16\" class=\"data row56 col16\" >-0.043117</td>\n",
       "                        <td id=\"T_9749f_row56_col17\" class=\"data row56 col17\" >-0.016715</td>\n",
       "                        <td id=\"T_9749f_row56_col18\" class=\"data row56 col18\" >-0.043117</td>\n",
       "                        <td id=\"T_9749f_row56_col19\" class=\"data row56 col19\" >0.033062</td>\n",
       "                        <td id=\"T_9749f_row56_col20\" class=\"data row56 col20\" >0.059472</td>\n",
       "                        <td id=\"T_9749f_row56_col21\" class=\"data row56 col21\" >-0.036161</td>\n",
       "                        <td id=\"T_9749f_row56_col22\" class=\"data row56 col22\" >-0.217178</td>\n",
       "                        <td id=\"T_9749f_row56_col23\" class=\"data row56 col23\" >0.115384</td>\n",
       "                        <td id=\"T_9749f_row56_col24\" class=\"data row56 col24\" >0.111854</td>\n",
       "                        <td id=\"T_9749f_row56_col25\" class=\"data row56 col25\" >0.141187</td>\n",
       "                        <td id=\"T_9749f_row56_col26\" class=\"data row56 col26\" >0.131433</td>\n",
       "                        <td id=\"T_9749f_row56_col27\" class=\"data row56 col27\" >0.127536</td>\n",
       "                        <td id=\"T_9749f_row56_col28\" class=\"data row56 col28\" >0.130497</td>\n",
       "                        <td id=\"T_9749f_row56_col29\" class=\"data row56 col29\" >0.140167</td>\n",
       "                        <td id=\"T_9749f_row56_col30\" class=\"data row56 col30\" >0.130534</td>\n",
       "                        <td id=\"T_9749f_row56_col31\" class=\"data row56 col31\" >-0.132681</td>\n",
       "                        <td id=\"T_9749f_row56_col32\" class=\"data row56 col32\" >-0.109937</td>\n",
       "                        <td id=\"T_9749f_row56_col33\" class=\"data row56 col33\" >-0.164227</td>\n",
       "                        <td id=\"T_9749f_row56_col34\" class=\"data row56 col34\" >-0.092276</td>\n",
       "                        <td id=\"T_9749f_row56_col35\" class=\"data row56 col35\" >0.034549</td>\n",
       "                        <td id=\"T_9749f_row56_col36\" class=\"data row56 col36\" >-0.024028</td>\n",
       "                        <td id=\"T_9749f_row56_col37\" class=\"data row56 col37\" >-0.106381</td>\n",
       "                        <td id=\"T_9749f_row56_col38\" class=\"data row56 col38\" >-0.169866</td>\n",
       "                        <td id=\"T_9749f_row56_col39\" class=\"data row56 col39\" >0.191781</td>\n",
       "                        <td id=\"T_9749f_row56_col40\" class=\"data row56 col40\" >0.188793</td>\n",
       "                        <td id=\"T_9749f_row56_col41\" class=\"data row56 col41\" >0.127857</td>\n",
       "                        <td id=\"T_9749f_row56_col42\" class=\"data row56 col42\" >0.132393</td>\n",
       "                        <td id=\"T_9749f_row56_col43\" class=\"data row56 col43\" >0.024489</td>\n",
       "                        <td id=\"T_9749f_row56_col44\" class=\"data row56 col44\" >-0.027205</td>\n",
       "                        <td id=\"T_9749f_row56_col45\" class=\"data row56 col45\" >-0.041662</td>\n",
       "                        <td id=\"T_9749f_row56_col46\" class=\"data row56 col46\" >-0.051446</td>\n",
       "                        <td id=\"T_9749f_row56_col47\" class=\"data row56 col47\" >-0.152393</td>\n",
       "                        <td id=\"T_9749f_row56_col48\" class=\"data row56 col48\" >-0.122697</td>\n",
       "                        <td id=\"T_9749f_row56_col49\" class=\"data row56 col49\" >-0.027157</td>\n",
       "                        <td id=\"T_9749f_row56_col50\" class=\"data row56 col50\" >-0.023755</td>\n",
       "                        <td id=\"T_9749f_row56_col51\" class=\"data row56 col51\" >-0.027630</td>\n",
       "                        <td id=\"T_9749f_row56_col52\" class=\"data row56 col52\" >-0.024039</td>\n",
       "                        <td id=\"T_9749f_row56_col53\" class=\"data row56 col53\" >0.035001</td>\n",
       "                        <td id=\"T_9749f_row56_col54\" class=\"data row56 col54\" >-0.085119</td>\n",
       "                        <td id=\"T_9749f_row56_col55\" class=\"data row56 col55\" >0.029835</td>\n",
       "                        <td id=\"T_9749f_row56_col56\" class=\"data row56 col56\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row56_col57\" class=\"data row56 col57\" >-0.003489</td>\n",
       "                        <td id=\"T_9749f_row56_col58\" class=\"data row56 col58\" >0.000003</td>\n",
       "                        <td id=\"T_9749f_row56_col59\" class=\"data row56 col59\" >0.076449</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row57\" class=\"row_heading level0 row57\" >hour</th>\n",
       "                        <td id=\"T_9749f_row57_col0\" class=\"data row57 col0\" >0.335348</td>\n",
       "                        <td id=\"T_9749f_row57_col1\" class=\"data row57 col1\" >0.016805</td>\n",
       "                        <td id=\"T_9749f_row57_col2\" class=\"data row57 col2\" >0.020632</td>\n",
       "                        <td id=\"T_9749f_row57_col3\" class=\"data row57 col3\" >0.001300</td>\n",
       "                        <td id=\"T_9749f_row57_col4\" class=\"data row57 col4\" >0.002295</td>\n",
       "                        <td id=\"T_9749f_row57_col5\" class=\"data row57 col5\" >-0.000512</td>\n",
       "                        <td id=\"T_9749f_row57_col6\" class=\"data row57 col6\" >0.001658</td>\n",
       "                        <td id=\"T_9749f_row57_col7\" class=\"data row57 col7\" >-0.000502</td>\n",
       "                        <td id=\"T_9749f_row57_col8\" class=\"data row57 col8\" >0.003806</td>\n",
       "                        <td id=\"T_9749f_row57_col9\" class=\"data row57 col9\" >0.000337</td>\n",
       "                        <td id=\"T_9749f_row57_col10\" class=\"data row57 col10\" >0.000846</td>\n",
       "                        <td id=\"T_9749f_row57_col11\" class=\"data row57 col11\" >0.002533</td>\n",
       "                        <td id=\"T_9749f_row57_col12\" class=\"data row57 col12\" >0.002576</td>\n",
       "                        <td id=\"T_9749f_row57_col13\" class=\"data row57 col13\" >-0.001658</td>\n",
       "                        <td id=\"T_9749f_row57_col14\" class=\"data row57 col14\" >-0.003034</td>\n",
       "                        <td id=\"T_9749f_row57_col15\" class=\"data row57 col15\" >-0.000840</td>\n",
       "                        <td id=\"T_9749f_row57_col16\" class=\"data row57 col16\" >-0.000566</td>\n",
       "                        <td id=\"T_9749f_row57_col17\" class=\"data row57 col17\" >-0.000840</td>\n",
       "                        <td id=\"T_9749f_row57_col18\" class=\"data row57 col18\" >-0.000566</td>\n",
       "                        <td id=\"T_9749f_row57_col19\" class=\"data row57 col19\" >0.000705</td>\n",
       "                        <td id=\"T_9749f_row57_col20\" class=\"data row57 col20\" >0.000677</td>\n",
       "                        <td id=\"T_9749f_row57_col21\" class=\"data row57 col21\" >-0.000008</td>\n",
       "                        <td id=\"T_9749f_row57_col22\" class=\"data row57 col22\" >0.000902</td>\n",
       "                        <td id=\"T_9749f_row57_col23\" class=\"data row57 col23\" >-0.000271</td>\n",
       "                        <td id=\"T_9749f_row57_col24\" class=\"data row57 col24\" >0.003419</td>\n",
       "                        <td id=\"T_9749f_row57_col25\" class=\"data row57 col25\" >0.001033</td>\n",
       "                        <td id=\"T_9749f_row57_col26\" class=\"data row57 col26\" >0.006258</td>\n",
       "                        <td id=\"T_9749f_row57_col27\" class=\"data row57 col27\" >0.001526</td>\n",
       "                        <td id=\"T_9749f_row57_col28\" class=\"data row57 col28\" >0.005948</td>\n",
       "                        <td id=\"T_9749f_row57_col29\" class=\"data row57 col29\" >0.001044</td>\n",
       "                        <td id=\"T_9749f_row57_col30\" class=\"data row57 col30\" >0.006261</td>\n",
       "                        <td id=\"T_9749f_row57_col31\" class=\"data row57 col31\" >0.001789</td>\n",
       "                        <td id=\"T_9749f_row57_col32\" class=\"data row57 col32\" >0.006503</td>\n",
       "                        <td id=\"T_9749f_row57_col33\" class=\"data row57 col33\" >-0.001524</td>\n",
       "                        <td id=\"T_9749f_row57_col34\" class=\"data row57 col34\" >-0.003679</td>\n",
       "                        <td id=\"T_9749f_row57_col35\" class=\"data row57 col35\" >-0.005958</td>\n",
       "                        <td id=\"T_9749f_row57_col36\" class=\"data row57 col36\" >-0.015468</td>\n",
       "                        <td id=\"T_9749f_row57_col37\" class=\"data row57 col37\" >-0.004918</td>\n",
       "                        <td id=\"T_9749f_row57_col38\" class=\"data row57 col38\" >0.002545</td>\n",
       "                        <td id=\"T_9749f_row57_col39\" class=\"data row57 col39\" >0.000756</td>\n",
       "                        <td id=\"T_9749f_row57_col40\" class=\"data row57 col40\" >-0.001004</td>\n",
       "                        <td id=\"T_9749f_row57_col41\" class=\"data row57 col41\" >0.002171</td>\n",
       "                        <td id=\"T_9749f_row57_col42\" class=\"data row57 col42\" >0.005521</td>\n",
       "                        <td id=\"T_9749f_row57_col43\" class=\"data row57 col43\" >-0.006379</td>\n",
       "                        <td id=\"T_9749f_row57_col44\" class=\"data row57 col44\" >-0.003036</td>\n",
       "                        <td id=\"T_9749f_row57_col45\" class=\"data row57 col45\" >-0.001757</td>\n",
       "                        <td id=\"T_9749f_row57_col46\" class=\"data row57 col46\" >0.003388</td>\n",
       "                        <td id=\"T_9749f_row57_col47\" class=\"data row57 col47\" >0.004520</td>\n",
       "                        <td id=\"T_9749f_row57_col48\" class=\"data row57 col48\" >0.006402</td>\n",
       "                        <td id=\"T_9749f_row57_col49\" class=\"data row57 col49\" >-0.001227</td>\n",
       "                        <td id=\"T_9749f_row57_col50\" class=\"data row57 col50\" >0.001408</td>\n",
       "                        <td id=\"T_9749f_row57_col51\" class=\"data row57 col51\" >-0.001594</td>\n",
       "                        <td id=\"T_9749f_row57_col52\" class=\"data row57 col52\" >0.001186</td>\n",
       "                        <td id=\"T_9749f_row57_col53\" class=\"data row57 col53\" >-0.000580</td>\n",
       "                        <td id=\"T_9749f_row57_col54\" class=\"data row57 col54\" >-0.001351</td>\n",
       "                        <td id=\"T_9749f_row57_col55\" class=\"data row57 col55\" >-0.000135</td>\n",
       "                        <td id=\"T_9749f_row57_col56\" class=\"data row57 col56\" >-0.003489</td>\n",
       "                        <td id=\"T_9749f_row57_col57\" class=\"data row57 col57\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row57_col58\" class=\"data row57 col58\" >-0.000314</td>\n",
       "                        <td id=\"T_9749f_row57_col59\" class=\"data row57 col59\" >0.000537</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row58\" class=\"row_heading level0 row58\" >minute</th>\n",
       "                        <td id=\"T_9749f_row58_col0\" class=\"data row58 col0\" >-0.006055</td>\n",
       "                        <td id=\"T_9749f_row58_col1\" class=\"data row58 col1\" >-0.000519</td>\n",
       "                        <td id=\"T_9749f_row58_col2\" class=\"data row58 col2\" >-0.000964</td>\n",
       "                        <td id=\"T_9749f_row58_col3\" class=\"data row58 col3\" >-0.000883</td>\n",
       "                        <td id=\"T_9749f_row58_col4\" class=\"data row58 col4\" >-0.000850</td>\n",
       "                        <td id=\"T_9749f_row58_col5\" class=\"data row58 col5\" >-0.001023</td>\n",
       "                        <td id=\"T_9749f_row58_col6\" class=\"data row58 col6\" >-0.001132</td>\n",
       "                        <td id=\"T_9749f_row58_col7\" class=\"data row58 col7\" >0.000691</td>\n",
       "                        <td id=\"T_9749f_row58_col8\" class=\"data row58 col8\" >0.000865</td>\n",
       "                        <td id=\"T_9749f_row58_col9\" class=\"data row58 col9\" >0.000175</td>\n",
       "                        <td id=\"T_9749f_row58_col10\" class=\"data row58 col10\" >-0.000118</td>\n",
       "                        <td id=\"T_9749f_row58_col11\" class=\"data row58 col11\" >-0.000791</td>\n",
       "                        <td id=\"T_9749f_row58_col12\" class=\"data row58 col12\" >-0.000845</td>\n",
       "                        <td id=\"T_9749f_row58_col13\" class=\"data row58 col13\" >0.000242</td>\n",
       "                        <td id=\"T_9749f_row58_col14\" class=\"data row58 col14\" >-0.000047</td>\n",
       "                        <td id=\"T_9749f_row58_col15\" class=\"data row58 col15\" >0.000031</td>\n",
       "                        <td id=\"T_9749f_row58_col16\" class=\"data row58 col16\" >0.000146</td>\n",
       "                        <td id=\"T_9749f_row58_col17\" class=\"data row58 col17\" >0.000031</td>\n",
       "                        <td id=\"T_9749f_row58_col18\" class=\"data row58 col18\" >0.000146</td>\n",
       "                        <td id=\"T_9749f_row58_col19\" class=\"data row58 col19\" >0.000310</td>\n",
       "                        <td id=\"T_9749f_row58_col20\" class=\"data row58 col20\" >0.000230</td>\n",
       "                        <td id=\"T_9749f_row58_col21\" class=\"data row58 col21\" >-0.000871</td>\n",
       "                        <td id=\"T_9749f_row58_col22\" class=\"data row58 col22\" >-0.001044</td>\n",
       "                        <td id=\"T_9749f_row58_col23\" class=\"data row58 col23\" >-0.000971</td>\n",
       "                        <td id=\"T_9749f_row58_col24\" class=\"data row58 col24\" >-0.001107</td>\n",
       "                        <td id=\"T_9749f_row58_col25\" class=\"data row58 col25\" >-0.001012</td>\n",
       "                        <td id=\"T_9749f_row58_col26\" class=\"data row58 col26\" >-0.001060</td>\n",
       "                        <td id=\"T_9749f_row58_col27\" class=\"data row58 col27\" >-0.000969</td>\n",
       "                        <td id=\"T_9749f_row58_col28\" class=\"data row58 col28\" >-0.000991</td>\n",
       "                        <td id=\"T_9749f_row58_col29\" class=\"data row58 col29\" >-0.001014</td>\n",
       "                        <td id=\"T_9749f_row58_col30\" class=\"data row58 col30\" >-0.001059</td>\n",
       "                        <td id=\"T_9749f_row58_col31\" class=\"data row58 col31\" >0.000479</td>\n",
       "                        <td id=\"T_9749f_row58_col32\" class=\"data row58 col32\" >0.001056</td>\n",
       "                        <td id=\"T_9749f_row58_col33\" class=\"data row58 col33\" >0.000173</td>\n",
       "                        <td id=\"T_9749f_row58_col34\" class=\"data row58 col34\" >0.000081</td>\n",
       "                        <td id=\"T_9749f_row58_col35\" class=\"data row58 col35\" >-0.000326</td>\n",
       "                        <td id=\"T_9749f_row58_col36\" class=\"data row58 col36\" >-0.000985</td>\n",
       "                        <td id=\"T_9749f_row58_col37\" class=\"data row58 col37\" >0.000529</td>\n",
       "                        <td id=\"T_9749f_row58_col38\" class=\"data row58 col38\" >0.001036</td>\n",
       "                        <td id=\"T_9749f_row58_col39\" class=\"data row58 col39\" >-0.000001</td>\n",
       "                        <td id=\"T_9749f_row58_col40\" class=\"data row58 col40\" >-0.000376</td>\n",
       "                        <td id=\"T_9749f_row58_col41\" class=\"data row58 col41\" >-0.001003</td>\n",
       "                        <td id=\"T_9749f_row58_col42\" class=\"data row58 col42\" >-0.001009</td>\n",
       "                        <td id=\"T_9749f_row58_col43\" class=\"data row58 col43\" >0.000119</td>\n",
       "                        <td id=\"T_9749f_row58_col44\" class=\"data row58 col44\" >-0.000356</td>\n",
       "                        <td id=\"T_9749f_row58_col45\" class=\"data row58 col45\" >0.000922</td>\n",
       "                        <td id=\"T_9749f_row58_col46\" class=\"data row58 col46\" >0.001108</td>\n",
       "                        <td id=\"T_9749f_row58_col47\" class=\"data row58 col47\" >0.000537</td>\n",
       "                        <td id=\"T_9749f_row58_col48\" class=\"data row58 col48\" >0.001073</td>\n",
       "                        <td id=\"T_9749f_row58_col49\" class=\"data row58 col49\" >0.000923</td>\n",
       "                        <td id=\"T_9749f_row58_col50\" class=\"data row58 col50\" >0.000889</td>\n",
       "                        <td id=\"T_9749f_row58_col51\" class=\"data row58 col51\" >0.000912</td>\n",
       "                        <td id=\"T_9749f_row58_col52\" class=\"data row58 col52\" >0.000825</td>\n",
       "                        <td id=\"T_9749f_row58_col53\" class=\"data row58 col53\" >-0.000697</td>\n",
       "                        <td id=\"T_9749f_row58_col54\" class=\"data row58 col54\" >0.000604</td>\n",
       "                        <td id=\"T_9749f_row58_col55\" class=\"data row58 col55\" >-0.001390</td>\n",
       "                        <td id=\"T_9749f_row58_col56\" class=\"data row58 col56\" >0.000003</td>\n",
       "                        <td id=\"T_9749f_row58_col57\" class=\"data row58 col57\" >-0.000314</td>\n",
       "                        <td id=\"T_9749f_row58_col58\" class=\"data row58 col58\" >1.000000</td>\n",
       "                        <td id=\"T_9749f_row58_col59\" class=\"data row58 col59\" >-0.000711</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9749f_level0_row59\" class=\"row_heading level0 row59\" >Term_as_int</th>\n",
       "                        <td id=\"T_9749f_row59_col0\" class=\"data row59 col0\" >-0.081390</td>\n",
       "                        <td id=\"T_9749f_row59_col1\" class=\"data row59 col1\" >-0.120569</td>\n",
       "                        <td id=\"T_9749f_row59_col2\" class=\"data row59 col2\" >-0.073634</td>\n",
       "                        <td id=\"T_9749f_row59_col3\" class=\"data row59 col3\" >0.402953</td>\n",
       "                        <td id=\"T_9749f_row59_col4\" class=\"data row59 col4\" >0.421848</td>\n",
       "                        <td id=\"T_9749f_row59_col5\" class=\"data row59 col5\" >0.349717</td>\n",
       "                        <td id=\"T_9749f_row59_col6\" class=\"data row59 col6\" >0.378246</td>\n",
       "                        <td id=\"T_9749f_row59_col7\" class=\"data row59 col7\" >-0.060044</td>\n",
       "                        <td id=\"T_9749f_row59_col8\" class=\"data row59 col8\" >-0.126563</td>\n",
       "                        <td id=\"T_9749f_row59_col9\" class=\"data row59 col9\" >0.380821</td>\n",
       "                        <td id=\"T_9749f_row59_col10\" class=\"data row59 col10\" >0.450651</td>\n",
       "                        <td id=\"T_9749f_row59_col11\" class=\"data row59 col11\" >0.356827</td>\n",
       "                        <td id=\"T_9749f_row59_col12\" class=\"data row59 col12\" >0.436885</td>\n",
       "                        <td id=\"T_9749f_row59_col13\" class=\"data row59 col13\" >-0.006142</td>\n",
       "                        <td id=\"T_9749f_row59_col14\" class=\"data row59 col14\" >0.019234</td>\n",
       "                        <td id=\"T_9749f_row59_col15\" class=\"data row59 col15\" >-0.239723</td>\n",
       "                        <td id=\"T_9749f_row59_col16\" class=\"data row59 col16\" >-0.253482</td>\n",
       "                        <td id=\"T_9749f_row59_col17\" class=\"data row59 col17\" >-0.239723</td>\n",
       "                        <td id=\"T_9749f_row59_col18\" class=\"data row59 col18\" >-0.253482</td>\n",
       "                        <td id=\"T_9749f_row59_col19\" class=\"data row59 col19\" >0.283898</td>\n",
       "                        <td id=\"T_9749f_row59_col20\" class=\"data row59 col20\" >0.285200</td>\n",
       "                        <td id=\"T_9749f_row59_col21\" class=\"data row59 col21\" >-0.017314</td>\n",
       "                        <td id=\"T_9749f_row59_col22\" class=\"data row59 col22\" >0.050116</td>\n",
       "                        <td id=\"T_9749f_row59_col23\" class=\"data row59 col23\" >0.373342</td>\n",
       "                        <td id=\"T_9749f_row59_col24\" class=\"data row59 col24\" >0.384429</td>\n",
       "                        <td id=\"T_9749f_row59_col25\" class=\"data row59 col25\" >0.415039</td>\n",
       "                        <td id=\"T_9749f_row59_col26\" class=\"data row59 col26\" >0.426903</td>\n",
       "                        <td id=\"T_9749f_row59_col27\" class=\"data row59 col27\" >0.398544</td>\n",
       "                        <td id=\"T_9749f_row59_col28\" class=\"data row59 col28\" >0.407384</td>\n",
       "                        <td id=\"T_9749f_row59_col29\" class=\"data row59 col29\" >0.414733</td>\n",
       "                        <td id=\"T_9749f_row59_col30\" class=\"data row59 col30\" >0.426308</td>\n",
       "                        <td id=\"T_9749f_row59_col31\" class=\"data row59 col31\" >-0.106361</td>\n",
       "                        <td id=\"T_9749f_row59_col32\" class=\"data row59 col32\" >-0.238010</td>\n",
       "                        <td id=\"T_9749f_row59_col33\" class=\"data row59 col33\" >-0.045520</td>\n",
       "                        <td id=\"T_9749f_row59_col34\" class=\"data row59 col34\" >-0.186749</td>\n",
       "                        <td id=\"T_9749f_row59_col35\" class=\"data row59 col35\" >0.053890</td>\n",
       "                        <td id=\"T_9749f_row59_col36\" class=\"data row59 col36\" >0.014142</td>\n",
       "                        <td id=\"T_9749f_row59_col37\" class=\"data row59 col37\" >-0.000017</td>\n",
       "                        <td id=\"T_9749f_row59_col38\" class=\"data row59 col38\" >-0.107742</td>\n",
       "                        <td id=\"T_9749f_row59_col39\" class=\"data row59 col39\" >0.168439</td>\n",
       "                        <td id=\"T_9749f_row59_col40\" class=\"data row59 col40\" >0.316095</td>\n",
       "                        <td id=\"T_9749f_row59_col41\" class=\"data row59 col41\" >0.398692</td>\n",
       "                        <td id=\"T_9749f_row59_col42\" class=\"data row59 col42\" >0.410719</td>\n",
       "                        <td id=\"T_9749f_row59_col43\" class=\"data row59 col43\" >-0.150833</td>\n",
       "                        <td id=\"T_9749f_row59_col44\" class=\"data row59 col44\" >-0.173895</td>\n",
       "                        <td id=\"T_9749f_row59_col45\" class=\"data row59 col45\" >0.086045</td>\n",
       "                        <td id=\"T_9749f_row59_col46\" class=\"data row59 col46\" >0.052434</td>\n",
       "                        <td id=\"T_9749f_row59_col47\" class=\"data row59 col47\" >-0.100429</td>\n",
       "                        <td id=\"T_9749f_row59_col48\" class=\"data row59 col48\" >-0.225991</td>\n",
       "                        <td id=\"T_9749f_row59_col49\" class=\"data row59 col49\" >-0.864264</td>\n",
       "                        <td id=\"T_9749f_row59_col50\" class=\"data row59 col50\" >-0.819902</td>\n",
       "                        <td id=\"T_9749f_row59_col51\" class=\"data row59 col51\" >-0.864373</td>\n",
       "                        <td id=\"T_9749f_row59_col52\" class=\"data row59 col52\" >-0.819617</td>\n",
       "                        <td id=\"T_9749f_row59_col53\" class=\"data row59 col53\" >0.096762</td>\n",
       "                        <td id=\"T_9749f_row59_col54\" class=\"data row59 col54\" >0.144125</td>\n",
       "                        <td id=\"T_9749f_row59_col55\" class=\"data row59 col55\" >0.009914</td>\n",
       "                        <td id=\"T_9749f_row59_col56\" class=\"data row59 col56\" >0.076449</td>\n",
       "                        <td id=\"T_9749f_row59_col57\" class=\"data row59 col57\" >0.000537</td>\n",
       "                        <td id=\"T_9749f_row59_col58\" class=\"data row59 col58\" >-0.000711</td>\n",
       "                        <td id=\"T_9749f_row59_col59\" class=\"data row59 col59\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f816ad6640>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=['reading','day_avg_reading','week_avg_reading', 'day_avg_maxtemp', 'week_avg_maxtemp', 'day_avg_mintemp', \n",
    "          'week_avg_mintemp','day_avg_snow','week_avg_snow','day_avg_sunhour','week_avg_sunhour', 'day_avg_uvindex','week_avg_uvindex',\n",
    "          'day_avg_moonillumination','week_avg_moonillumination','day_avg_sunrise_hr','week_avg_sunrise_hr', 'day_avg_sunrise_min','week_avg_sunrise_min',\n",
    "          'day_avg_sunset_hr','week_avg_sunset_hr','day_avg_sunset_min','week_avg_sunset_min',\n",
    "          'day_avg_dewpoint','week_avg_dewpoint','day_avg_feelslike','week_avg_feelslike',\n",
    "          'day_avg_heatindex','week_avg_heatindex','day_avg_windchill','week_avg_windchill',\n",
    "          'day_avg_windgust','week_avg_windgust','day_avg_cloud','week_avg_cloud',\n",
    "          'day_avg_humidity','week_avg_humidity','day_avg_precip','week_avg_precip',\n",
    "          'day_avg_pressure','week_avg_pressure','day_avg_temp','week_avg_temp',\n",
    "          'day_avg_visibility','week_avg_visibility','day_avg_winddir','week_avg_winddir',\n",
    "          'day_avg_windspeed','week_avg_windspeed','day_avg_as_client','week_avg_as_client',\n",
    "          'day_avg_auth_client','week_avg_auth_client','Day_type_as_int', 'Year',\n",
    "          'Month', 'Day','hour','minute', 'Term_as_int']\n",
    "\n",
    "bowcorr=train_data_bow[features]\n",
    "corrmat = bowcorr.corr()\n",
    "\n",
    "see_correlation_values=False\n",
    "if see_correlation_values==True:\n",
    "    corrmat.style.background_gradient(cmap='coolwarm')\n",
    "else:\n",
    "    f, ax = plt.subplots(figsize =(10, 6))\n",
    "    sns.heatmap(corrmat, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1)\n",
    "    ax = sns.heatmap(corrmat, vmin=-1, vmax=1, center=0,cmap=\"YlGnBu\",square=False)\n",
    "    ax.set_xticklabels( ax.get_xticklabels(),rotation=45,horizontalalignment='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading</th>\n",
       "      <th>day_avg_reading</th>\n",
       "      <th>week_avg_reading</th>\n",
       "      <th>day_avg_maxtemp</th>\n",
       "      <th>week_avg_maxtemp</th>\n",
       "      <th>day_avg_mintemp</th>\n",
       "      <th>week_avg_mintemp</th>\n",
       "      <th>day_avg_snow</th>\n",
       "      <th>week_avg_snow</th>\n",
       "      <th>day_avg_sunhour</th>\n",
       "      <th>...</th>\n",
       "      <th>week_avg_as_client</th>\n",
       "      <th>day_avg_auth_client</th>\n",
       "      <th>week_avg_auth_client</th>\n",
       "      <th>Day_type_as_int</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>Term_as_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reading</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.567473</td>\n",
       "      <td>0.537752</td>\n",
       "      <td>0.204917</td>\n",
       "      <td>0.223379</td>\n",
       "      <td>0.226490</td>\n",
       "      <td>0.234687</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>0.028832</td>\n",
       "      <td>0.188191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010859</td>\n",
       "      <td>-0.002215</td>\n",
       "      <td>-0.011734</td>\n",
       "      <td>-0.189202</td>\n",
       "      <td>0.131888</td>\n",
       "      <td>-0.019445</td>\n",
       "      <td>-0.033681</td>\n",
       "      <td>0.335348</td>\n",
       "      <td>-6.055139e-03</td>\n",
       "      <td>-0.081390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_reading</th>\n",
       "      <td>0.567473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869261</td>\n",
       "      <td>0.338584</td>\n",
       "      <td>0.367994</td>\n",
       "      <td>0.379066</td>\n",
       "      <td>0.391613</td>\n",
       "      <td>0.024919</td>\n",
       "      <td>0.049471</td>\n",
       "      <td>0.309826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022856</td>\n",
       "      <td>-0.005689</td>\n",
       "      <td>-0.023453</td>\n",
       "      <td>-0.262337</td>\n",
       "      <td>0.212361</td>\n",
       "      <td>-0.024544</td>\n",
       "      <td>-0.048043</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>-5.190164e-04</td>\n",
       "      <td>-0.120569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_reading</th>\n",
       "      <td>0.537752</td>\n",
       "      <td>0.869261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381207</td>\n",
       "      <td>0.404759</td>\n",
       "      <td>0.432498</td>\n",
       "      <td>0.461932</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>0.311138</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>-0.101264</td>\n",
       "      <td>-0.058036</td>\n",
       "      <td>-0.106484</td>\n",
       "      <td>0.193533</td>\n",
       "      <td>0.024376</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.020632</td>\n",
       "      <td>-9.636967e-04</td>\n",
       "      <td>-0.073634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.335348</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>0.020632</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>-0.000502</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.003489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.142976e-04</td>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_sunset_hr</th>\n",
       "      <td>0.289345</td>\n",
       "      <td>0.474407</td>\n",
       "      <td>0.496088</td>\n",
       "      <td>0.740185</td>\n",
       "      <td>0.776557</td>\n",
       "      <td>0.530093</td>\n",
       "      <td>0.560914</td>\n",
       "      <td>-0.067602</td>\n",
       "      <td>-0.130147</td>\n",
       "      <td>0.823043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370882</td>\n",
       "      <td>-0.364725</td>\n",
       "      <td>-0.370186</td>\n",
       "      <td>-0.012323</td>\n",
       "      <td>0.554331</td>\n",
       "      <td>-0.244357</td>\n",
       "      <td>0.059472</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>2.297488e-04</td>\n",
       "      <td>0.285200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_sunset_hr</th>\n",
       "      <td>0.280387</td>\n",
       "      <td>0.457473</td>\n",
       "      <td>0.473132</td>\n",
       "      <td>0.715190</td>\n",
       "      <td>0.743256</td>\n",
       "      <td>0.493586</td>\n",
       "      <td>0.517201</td>\n",
       "      <td>-0.058424</td>\n",
       "      <td>-0.119625</td>\n",
       "      <td>0.828893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.357407</td>\n",
       "      <td>-0.355260</td>\n",
       "      <td>-0.356601</td>\n",
       "      <td>-0.010841</td>\n",
       "      <td>0.571146</td>\n",
       "      <td>-0.290125</td>\n",
       "      <td>0.033062</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>3.096417e-04</td>\n",
       "      <td>0.283898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_dewpoint</th>\n",
       "      <td>0.241993</td>\n",
       "      <td>0.397084</td>\n",
       "      <td>0.445747</td>\n",
       "      <td>0.807294</td>\n",
       "      <td>0.934835</td>\n",
       "      <td>0.822502</td>\n",
       "      <td>0.974610</td>\n",
       "      <td>-0.142405</td>\n",
       "      <td>-0.343206</td>\n",
       "      <td>0.419947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557556</td>\n",
       "      <td>-0.529398</td>\n",
       "      <td>-0.558937</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>0.138944</td>\n",
       "      <td>0.290586</td>\n",
       "      <td>0.111854</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-1.107102e-03</td>\n",
       "      <td>0.384429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_windchill</th>\n",
       "      <td>0.239797</td>\n",
       "      <td>0.387978</td>\n",
       "      <td>0.436514</td>\n",
       "      <td>0.855587</td>\n",
       "      <td>0.976085</td>\n",
       "      <td>0.809055</td>\n",
       "      <td>0.947995</td>\n",
       "      <td>-0.134871</td>\n",
       "      <td>-0.324467</td>\n",
       "      <td>0.532424</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576238</td>\n",
       "      <td>-0.547587</td>\n",
       "      <td>-0.577732</td>\n",
       "      <td>-0.007420</td>\n",
       "      <td>0.212323</td>\n",
       "      <td>0.219631</td>\n",
       "      <td>0.130534</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>-1.059031e-03</td>\n",
       "      <td>0.426308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_feelslike</th>\n",
       "      <td>0.239393</td>\n",
       "      <td>0.387338</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.855454</td>\n",
       "      <td>0.975984</td>\n",
       "      <td>0.809178</td>\n",
       "      <td>0.948215</td>\n",
       "      <td>-0.134624</td>\n",
       "      <td>-0.323827</td>\n",
       "      <td>0.532105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576847</td>\n",
       "      <td>-0.548243</td>\n",
       "      <td>-0.578340</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>0.212412</td>\n",
       "      <td>0.219271</td>\n",
       "      <td>0.131433</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>-1.059748e-03</td>\n",
       "      <td>0.426903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_heatindex</th>\n",
       "      <td>0.238363</td>\n",
       "      <td>0.386917</td>\n",
       "      <td>0.441748</td>\n",
       "      <td>0.846157</td>\n",
       "      <td>0.971681</td>\n",
       "      <td>0.818924</td>\n",
       "      <td>0.964164</td>\n",
       "      <td>-0.139292</td>\n",
       "      <td>-0.327886</td>\n",
       "      <td>0.503759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559063</td>\n",
       "      <td>-0.531371</td>\n",
       "      <td>-0.560527</td>\n",
       "      <td>-0.003697</td>\n",
       "      <td>0.174012</td>\n",
       "      <td>0.261408</td>\n",
       "      <td>0.130497</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>-9.908636e-04</td>\n",
       "      <td>0.407384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_temp</th>\n",
       "      <td>0.236778</td>\n",
       "      <td>0.385581</td>\n",
       "      <td>0.442421</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.973018</td>\n",
       "      <td>0.820206</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>-0.140540</td>\n",
       "      <td>-0.331191</td>\n",
       "      <td>0.507836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.560718</td>\n",
       "      <td>-0.534665</td>\n",
       "      <td>-0.562142</td>\n",
       "      <td>-0.003319</td>\n",
       "      <td>0.173005</td>\n",
       "      <td>0.262671</td>\n",
       "      <td>0.132393</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>-1.009001e-03</td>\n",
       "      <td>0.410719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_mintemp</th>\n",
       "      <td>0.234687</td>\n",
       "      <td>0.391613</td>\n",
       "      <td>0.461932</td>\n",
       "      <td>0.776365</td>\n",
       "      <td>0.902945</td>\n",
       "      <td>0.837436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.143012</td>\n",
       "      <td>-0.328774</td>\n",
       "      <td>0.378477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542480</td>\n",
       "      <td>-0.524206</td>\n",
       "      <td>-0.544106</td>\n",
       "      <td>-0.006473</td>\n",
       "      <td>0.044666</td>\n",
       "      <td>0.350418</td>\n",
       "      <td>0.150269</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>-1.131802e-03</td>\n",
       "      <td>0.378246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_mintemp</th>\n",
       "      <td>0.226490</td>\n",
       "      <td>0.379066</td>\n",
       "      <td>0.432498</td>\n",
       "      <td>0.861605</td>\n",
       "      <td>0.781017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837436</td>\n",
       "      <td>-0.160403</td>\n",
       "      <td>-0.279830</td>\n",
       "      <td>0.328401</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468744</td>\n",
       "      <td>-0.466607</td>\n",
       "      <td>-0.470018</td>\n",
       "      <td>-0.011190</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.292447</td>\n",
       "      <td>0.112697</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-1.022912e-03</td>\n",
       "      <td>0.349717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_maxtemp</th>\n",
       "      <td>0.223379</td>\n",
       "      <td>0.367994</td>\n",
       "      <td>0.404759</td>\n",
       "      <td>0.884754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781017</td>\n",
       "      <td>0.902945</td>\n",
       "      <td>-0.136741</td>\n",
       "      <td>-0.318507</td>\n",
       "      <td>0.616277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.540220</td>\n",
       "      <td>-0.511816</td>\n",
       "      <td>-0.541194</td>\n",
       "      <td>-0.005796</td>\n",
       "      <td>0.275693</td>\n",
       "      <td>0.155964</td>\n",
       "      <td>0.126849</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-8.504237e-04</td>\n",
       "      <td>0.421848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_uvindex</th>\n",
       "      <td>0.218208</td>\n",
       "      <td>0.360649</td>\n",
       "      <td>0.395077</td>\n",
       "      <td>0.845870</td>\n",
       "      <td>0.949715</td>\n",
       "      <td>0.747652</td>\n",
       "      <td>0.847447</td>\n",
       "      <td>-0.166102</td>\n",
       "      <td>-0.335365</td>\n",
       "      <td>0.617899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518686</td>\n",
       "      <td>-0.508019</td>\n",
       "      <td>-0.519531</td>\n",
       "      <td>-0.014770</td>\n",
       "      <td>0.140796</td>\n",
       "      <td>0.242984</td>\n",
       "      <td>0.111912</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>-8.454218e-04</td>\n",
       "      <td>0.436885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_windchill</th>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.361364</td>\n",
       "      <td>0.408468</td>\n",
       "      <td>0.961953</td>\n",
       "      <td>0.881796</td>\n",
       "      <td>0.905942</td>\n",
       "      <td>0.835460</td>\n",
       "      <td>-0.169717</td>\n",
       "      <td>-0.298495</td>\n",
       "      <td>0.518522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538732</td>\n",
       "      <td>-0.526756</td>\n",
       "      <td>-0.539574</td>\n",
       "      <td>0.020439</td>\n",
       "      <td>0.197939</td>\n",
       "      <td>0.181852</td>\n",
       "      <td>0.140167</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>-1.013704e-03</td>\n",
       "      <td>0.414733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_feelslike</th>\n",
       "      <td>0.212822</td>\n",
       "      <td>0.360822</td>\n",
       "      <td>0.408125</td>\n",
       "      <td>0.962176</td>\n",
       "      <td>0.881185</td>\n",
       "      <td>0.905904</td>\n",
       "      <td>0.835199</td>\n",
       "      <td>-0.169282</td>\n",
       "      <td>-0.297780</td>\n",
       "      <td>0.518536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538962</td>\n",
       "      <td>-0.527048</td>\n",
       "      <td>-0.539805</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>0.197930</td>\n",
       "      <td>0.181440</td>\n",
       "      <td>0.141187</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>-1.011851e-03</td>\n",
       "      <td>0.415039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_heatindex</th>\n",
       "      <td>0.210423</td>\n",
       "      <td>0.358737</td>\n",
       "      <td>0.413228</td>\n",
       "      <td>0.961054</td>\n",
       "      <td>0.872039</td>\n",
       "      <td>0.928573</td>\n",
       "      <td>0.840538</td>\n",
       "      <td>-0.169485</td>\n",
       "      <td>-0.295549</td>\n",
       "      <td>0.468925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514488</td>\n",
       "      <td>-0.506393</td>\n",
       "      <td>-0.515382</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>0.159265</td>\n",
       "      <td>0.215840</td>\n",
       "      <td>0.127536</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-9.688926e-04</td>\n",
       "      <td>0.398544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_temp</th>\n",
       "      <td>0.210208</td>\n",
       "      <td>0.359164</td>\n",
       "      <td>0.415279</td>\n",
       "      <td>0.960877</td>\n",
       "      <td>0.869199</td>\n",
       "      <td>0.938649</td>\n",
       "      <td>0.839086</td>\n",
       "      <td>-0.171503</td>\n",
       "      <td>-0.298036</td>\n",
       "      <td>0.469903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511592</td>\n",
       "      <td>-0.505765</td>\n",
       "      <td>-0.512474</td>\n",
       "      <td>0.024622</td>\n",
       "      <td>0.156584</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0.127857</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>-1.003106e-03</td>\n",
       "      <td>0.398692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_dewpoint</th>\n",
       "      <td>0.206195</td>\n",
       "      <td>0.349859</td>\n",
       "      <td>0.399792</td>\n",
       "      <td>0.899765</td>\n",
       "      <td>0.807959</td>\n",
       "      <td>0.917018</td>\n",
       "      <td>0.816186</td>\n",
       "      <td>-0.175404</td>\n",
       "      <td>-0.289747</td>\n",
       "      <td>0.337123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.489790</td>\n",
       "      <td>-0.485202</td>\n",
       "      <td>-0.490636</td>\n",
       "      <td>0.028749</td>\n",
       "      <td>0.114187</td>\n",
       "      <td>0.241234</td>\n",
       "      <td>0.115384</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>-9.710049e-04</td>\n",
       "      <td>0.373342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_sunhour</th>\n",
       "      <td>0.205086</td>\n",
       "      <td>0.336090</td>\n",
       "      <td>0.349772</td>\n",
       "      <td>0.694063</td>\n",
       "      <td>0.714330</td>\n",
       "      <td>0.445027</td>\n",
       "      <td>0.452878</td>\n",
       "      <td>-0.077554</td>\n",
       "      <td>-0.130591</td>\n",
       "      <td>0.900249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464352</td>\n",
       "      <td>-0.474436</td>\n",
       "      <td>-0.463565</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.437496</td>\n",
       "      <td>-0.174393</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>-1.176234e-04</td>\n",
       "      <td>0.450651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_maxtemp</th>\n",
       "      <td>0.204917</td>\n",
       "      <td>0.338584</td>\n",
       "      <td>0.381207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884754</td>\n",
       "      <td>0.861605</td>\n",
       "      <td>0.776365</td>\n",
       "      <td>-0.173640</td>\n",
       "      <td>-0.276800</td>\n",
       "      <td>0.606229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502095</td>\n",
       "      <td>-0.487376</td>\n",
       "      <td>-0.502675</td>\n",
       "      <td>0.024258</td>\n",
       "      <td>0.258379</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.137701</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>-8.826796e-04</td>\n",
       "      <td>0.402953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_uvindex</th>\n",
       "      <td>0.193354</td>\n",
       "      <td>0.329526</td>\n",
       "      <td>0.350469</td>\n",
       "      <td>0.874621</td>\n",
       "      <td>0.781366</td>\n",
       "      <td>0.733839</td>\n",
       "      <td>0.674645</td>\n",
       "      <td>-0.187128</td>\n",
       "      <td>-0.260289</td>\n",
       "      <td>0.621829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442816</td>\n",
       "      <td>-0.427006</td>\n",
       "      <td>-0.443274</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.138374</td>\n",
       "      <td>0.171633</td>\n",
       "      <td>0.134628</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>-7.912722e-04</td>\n",
       "      <td>0.356827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_sunhour</th>\n",
       "      <td>0.188191</td>\n",
       "      <td>0.309826</td>\n",
       "      <td>0.311138</td>\n",
       "      <td>0.606229</td>\n",
       "      <td>0.616277</td>\n",
       "      <td>0.328401</td>\n",
       "      <td>0.378477</td>\n",
       "      <td>-0.066769</td>\n",
       "      <td>-0.101416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401215</td>\n",
       "      <td>-0.408132</td>\n",
       "      <td>-0.400295</td>\n",
       "      <td>-0.009252</td>\n",
       "      <td>0.417509</td>\n",
       "      <td>-0.197362</td>\n",
       "      <td>0.093434</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1.751287e-04</td>\n",
       "      <td>0.380821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>0.131888</td>\n",
       "      <td>0.212361</td>\n",
       "      <td>0.193533</td>\n",
       "      <td>0.258379</td>\n",
       "      <td>0.275693</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.044666</td>\n",
       "      <td>0.054797</td>\n",
       "      <td>0.115505</td>\n",
       "      <td>0.417509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264805</td>\n",
       "      <td>-0.215071</td>\n",
       "      <td>-0.263265</td>\n",
       "      <td>-0.033298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.606507</td>\n",
       "      <td>-0.085119</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>6.041139e-04</td>\n",
       "      <td>0.144125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_visibility</th>\n",
       "      <td>0.109228</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.182091</td>\n",
       "      <td>0.082141</td>\n",
       "      <td>0.070536</td>\n",
       "      <td>-0.063482</td>\n",
       "      <td>-0.106805</td>\n",
       "      <td>-0.091325</td>\n",
       "      <td>-0.169104</td>\n",
       "      <td>0.405250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247908</td>\n",
       "      <td>0.202271</td>\n",
       "      <td>0.249769</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.117943</td>\n",
       "      <td>-0.193857</td>\n",
       "      <td>-0.027205</td>\n",
       "      <td>-0.003036</td>\n",
       "      <td>-3.558864e-04</td>\n",
       "      <td>-0.173895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_precip</th>\n",
       "      <td>0.085062</td>\n",
       "      <td>0.151275</td>\n",
       "      <td>0.201830</td>\n",
       "      <td>0.072691</td>\n",
       "      <td>0.111240</td>\n",
       "      <td>0.148859</td>\n",
       "      <td>0.214386</td>\n",
       "      <td>0.063152</td>\n",
       "      <td>0.156221</td>\n",
       "      <td>-0.113745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070236</td>\n",
       "      <td>-0.039149</td>\n",
       "      <td>-0.070060</td>\n",
       "      <td>-0.006668</td>\n",
       "      <td>0.289546</td>\n",
       "      <td>-0.056752</td>\n",
       "      <td>-0.169866</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>1.036388e-03</td>\n",
       "      <td>-0.107742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_visibility</th>\n",
       "      <td>0.075453</td>\n",
       "      <td>0.120612</td>\n",
       "      <td>0.102404</td>\n",
       "      <td>0.021373</td>\n",
       "      <td>0.041430</td>\n",
       "      <td>-0.105680</td>\n",
       "      <td>-0.081718</td>\n",
       "      <td>-0.078801</td>\n",
       "      <td>-0.063227</td>\n",
       "      <td>0.360661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187021</td>\n",
       "      <td>0.185021</td>\n",
       "      <td>0.188555</td>\n",
       "      <td>-0.002354</td>\n",
       "      <td>0.100944</td>\n",
       "      <td>-0.163317</td>\n",
       "      <td>0.024489</td>\n",
       "      <td>-0.006379</td>\n",
       "      <td>1.192842e-04</td>\n",
       "      <td>-0.150833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_sunset_min</th>\n",
       "      <td>0.064767</td>\n",
       "      <td>0.122808</td>\n",
       "      <td>0.181016</td>\n",
       "      <td>-0.020457</td>\n",
       "      <td>-0.012632</td>\n",
       "      <td>0.031147</td>\n",
       "      <td>0.039971</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>0.114647</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>-0.004099</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>-0.138015</td>\n",
       "      <td>0.158621</td>\n",
       "      <td>-0.036161</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-8.712124e-04</td>\n",
       "      <td>-0.017314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_humidity</th>\n",
       "      <td>0.063068</td>\n",
       "      <td>0.129756</td>\n",
       "      <td>0.110884</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>0.086222</td>\n",
       "      <td>0.262858</td>\n",
       "      <td>0.353141</td>\n",
       "      <td>-0.061721</td>\n",
       "      <td>-0.209299</td>\n",
       "      <td>-0.329134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157776</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.157599</td>\n",
       "      <td>0.019431</td>\n",
       "      <td>-0.194109</td>\n",
       "      <td>0.219572</td>\n",
       "      <td>-0.024028</td>\n",
       "      <td>-0.015468</td>\n",
       "      <td>-9.850624e-04</td>\n",
       "      <td>0.014142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_sunset_min</th>\n",
       "      <td>0.062920</td>\n",
       "      <td>0.110279</td>\n",
       "      <td>0.161922</td>\n",
       "      <td>-0.028389</td>\n",
       "      <td>-0.045283</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>0.092813</td>\n",
       "      <td>0.052959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038860</td>\n",
       "      <td>-0.094965</td>\n",
       "      <td>-0.037868</td>\n",
       "      <td>0.024814</td>\n",
       "      <td>-0.102106</td>\n",
       "      <td>0.164657</td>\n",
       "      <td>-0.217178</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>-1.043656e-03</td>\n",
       "      <td>0.050116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_precip</th>\n",
       "      <td>0.053676</td>\n",
       "      <td>0.105743</td>\n",
       "      <td>0.150654</td>\n",
       "      <td>0.077244</td>\n",
       "      <td>0.117555</td>\n",
       "      <td>0.139049</td>\n",
       "      <td>0.169635</td>\n",
       "      <td>0.089030</td>\n",
       "      <td>0.108632</td>\n",
       "      <td>-0.161127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048607</td>\n",
       "      <td>-0.059935</td>\n",
       "      <td>-0.048918</td>\n",
       "      <td>0.029373</td>\n",
       "      <td>0.181255</td>\n",
       "      <td>-0.049851</td>\n",
       "      <td>-0.106381</td>\n",
       "      <td>-0.004918</td>\n",
       "      <td>5.290927e-04</td>\n",
       "      <td>-0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_humidity</th>\n",
       "      <td>0.049246</td>\n",
       "      <td>0.078898</td>\n",
       "      <td>0.076198</td>\n",
       "      <td>0.127885</td>\n",
       "      <td>0.062376</td>\n",
       "      <td>0.311324</td>\n",
       "      <td>0.207099</td>\n",
       "      <td>-0.099852</td>\n",
       "      <td>-0.102398</td>\n",
       "      <td>-0.335275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085544</td>\n",
       "      <td>-0.094425</td>\n",
       "      <td>-0.085603</td>\n",
       "      <td>0.013207</td>\n",
       "      <td>-0.150775</td>\n",
       "      <td>0.164302</td>\n",
       "      <td>0.034549</td>\n",
       "      <td>-0.005958</td>\n",
       "      <td>-3.258299e-04</td>\n",
       "      <td>0.053890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_winddir</th>\n",
       "      <td>0.045745</td>\n",
       "      <td>0.062250</td>\n",
       "      <td>0.038451</td>\n",
       "      <td>-0.047302</td>\n",
       "      <td>-0.010975</td>\n",
       "      <td>0.037376</td>\n",
       "      <td>0.060154</td>\n",
       "      <td>0.113224</td>\n",
       "      <td>0.180318</td>\n",
       "      <td>-0.030465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055327</td>\n",
       "      <td>-0.034140</td>\n",
       "      <td>-0.055907</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>0.147352</td>\n",
       "      <td>-0.318086</td>\n",
       "      <td>-0.051446</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>1.107670e-03</td>\n",
       "      <td>0.052434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_snow</th>\n",
       "      <td>0.028832</td>\n",
       "      <td>0.049471</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>-0.276800</td>\n",
       "      <td>-0.318507</td>\n",
       "      <td>-0.279830</td>\n",
       "      <td>-0.328774</td>\n",
       "      <td>0.416091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.101416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172083</td>\n",
       "      <td>0.170157</td>\n",
       "      <td>0.171391</td>\n",
       "      <td>-0.018816</td>\n",
       "      <td>0.115505</td>\n",
       "      <td>-0.296761</td>\n",
       "      <td>-0.094218</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>8.652802e-04</td>\n",
       "      <td>-0.126563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_cloud</th>\n",
       "      <td>0.028084</td>\n",
       "      <td>0.049880</td>\n",
       "      <td>0.064772</td>\n",
       "      <td>-0.187650</td>\n",
       "      <td>-0.180175</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.061058</td>\n",
       "      <td>0.047489</td>\n",
       "      <td>0.051940</td>\n",
       "      <td>-0.393922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043984</td>\n",
       "      <td>0.070128</td>\n",
       "      <td>0.045199</td>\n",
       "      <td>0.032563</td>\n",
       "      <td>-0.034436</td>\n",
       "      <td>0.097594</td>\n",
       "      <td>-0.092276</td>\n",
       "      <td>-0.003679</td>\n",
       "      <td>8.066341e-05</td>\n",
       "      <td>-0.186749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_snow</th>\n",
       "      <td>0.023012</td>\n",
       "      <td>0.024919</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.173640</td>\n",
       "      <td>-0.136741</td>\n",
       "      <td>-0.160403</td>\n",
       "      <td>-0.143012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.416091</td>\n",
       "      <td>-0.066769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087494</td>\n",
       "      <td>0.100331</td>\n",
       "      <td>0.087062</td>\n",
       "      <td>-0.059621</td>\n",
       "      <td>0.054797</td>\n",
       "      <td>-0.153602</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>-0.000502</td>\n",
       "      <td>6.905249e-04</td>\n",
       "      <td>-0.060044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_winddir</th>\n",
       "      <td>0.007677</td>\n",
       "      <td>-0.003040</td>\n",
       "      <td>0.011296</td>\n",
       "      <td>-0.016343</td>\n",
       "      <td>0.031729</td>\n",
       "      <td>0.089084</td>\n",
       "      <td>0.054273</td>\n",
       "      <td>0.101061</td>\n",
       "      <td>0.073138</td>\n",
       "      <td>-0.086475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046555</td>\n",
       "      <td>-0.035793</td>\n",
       "      <td>-0.047326</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>0.078389</td>\n",
       "      <td>-0.213797</td>\n",
       "      <td>-0.041662</td>\n",
       "      <td>-0.001757</td>\n",
       "      <td>9.217002e-04</td>\n",
       "      <td>0.086045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_as_client</th>\n",
       "      <td>-0.001067</td>\n",
       "      <td>-0.002856</td>\n",
       "      <td>-0.099896</td>\n",
       "      <td>-0.485997</td>\n",
       "      <td>-0.510482</td>\n",
       "      <td>-0.464762</td>\n",
       "      <td>-0.522276</td>\n",
       "      <td>0.101001</td>\n",
       "      <td>0.171085</td>\n",
       "      <td>-0.408320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951030</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.950912</td>\n",
       "      <td>-0.144606</td>\n",
       "      <td>-0.215905</td>\n",
       "      <td>-0.142987</td>\n",
       "      <td>-0.027157</td>\n",
       "      <td>-0.001227</td>\n",
       "      <td>9.229941e-04</td>\n",
       "      <td>-0.864264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_cloud</th>\n",
       "      <td>-0.001699</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.034025</td>\n",
       "      <td>-0.079127</td>\n",
       "      <td>-0.076762</td>\n",
       "      <td>0.139211</td>\n",
       "      <td>0.053266</td>\n",
       "      <td>0.043144</td>\n",
       "      <td>0.018867</td>\n",
       "      <td>-0.531756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025014</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.025585</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>-0.054146</td>\n",
       "      <td>0.094751</td>\n",
       "      <td>-0.164227</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>1.732244e-04</td>\n",
       "      <td>-0.045520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_auth_client</th>\n",
       "      <td>-0.002215</td>\n",
       "      <td>-0.005689</td>\n",
       "      <td>-0.101264</td>\n",
       "      <td>-0.487376</td>\n",
       "      <td>-0.511816</td>\n",
       "      <td>-0.466607</td>\n",
       "      <td>-0.524206</td>\n",
       "      <td>0.100331</td>\n",
       "      <td>0.170157</td>\n",
       "      <td>-0.408132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952061</td>\n",
       "      <td>-0.140686</td>\n",
       "      <td>-0.215071</td>\n",
       "      <td>-0.142826</td>\n",
       "      <td>-0.027630</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>9.120595e-04</td>\n",
       "      <td>-0.864373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute</th>\n",
       "      <td>-0.006055</td>\n",
       "      <td>-0.000519</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>-0.000883</td>\n",
       "      <td>-0.000850</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>-0.001390</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.000711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_as_client</th>\n",
       "      <td>-0.010859</td>\n",
       "      <td>-0.022856</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>-0.502095</td>\n",
       "      <td>-0.540220</td>\n",
       "      <td>-0.468744</td>\n",
       "      <td>-0.542480</td>\n",
       "      <td>0.087494</td>\n",
       "      <td>0.172083</td>\n",
       "      <td>-0.401215</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952131</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>-0.051715</td>\n",
       "      <td>-0.264805</td>\n",
       "      <td>-0.101139</td>\n",
       "      <td>-0.023755</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>8.891216e-04</td>\n",
       "      <td>-0.819902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_auth_client</th>\n",
       "      <td>-0.011734</td>\n",
       "      <td>-0.023453</td>\n",
       "      <td>-0.058036</td>\n",
       "      <td>-0.502675</td>\n",
       "      <td>-0.541194</td>\n",
       "      <td>-0.470018</td>\n",
       "      <td>-0.544106</td>\n",
       "      <td>0.087062</td>\n",
       "      <td>0.171391</td>\n",
       "      <td>-0.400295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.952061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.050895</td>\n",
       "      <td>-0.263265</td>\n",
       "      <td>-0.101322</td>\n",
       "      <td>-0.024039</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>8.253068e-04</td>\n",
       "      <td>-0.819617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>-0.019445</td>\n",
       "      <td>-0.024544</td>\n",
       "      <td>0.024376</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.155964</td>\n",
       "      <td>0.292447</td>\n",
       "      <td>0.350418</td>\n",
       "      <td>-0.153602</td>\n",
       "      <td>-0.296761</td>\n",
       "      <td>-0.197362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101139</td>\n",
       "      <td>-0.142826</td>\n",
       "      <td>-0.101322</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>-0.606507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029835</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-1.390400e-03</td>\n",
       "      <td>0.009914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_moonillumination</th>\n",
       "      <td>-0.021305</td>\n",
       "      <td>-0.032049</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.011558</td>\n",
       "      <td>-0.072718</td>\n",
       "      <td>0.035097</td>\n",
       "      <td>-0.002655</td>\n",
       "      <td>-0.030214</td>\n",
       "      <td>-0.144168</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>-0.005551</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>0.018411</td>\n",
       "      <td>-0.062421</td>\n",
       "      <td>0.080944</td>\n",
       "      <td>0.390340</td>\n",
       "      <td>-0.001658</td>\n",
       "      <td>2.415189e-04</td>\n",
       "      <td>-0.006142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>-0.033681</td>\n",
       "      <td>-0.048043</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.137701</td>\n",
       "      <td>0.126849</td>\n",
       "      <td>0.112697</td>\n",
       "      <td>0.150269</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>-0.094218</td>\n",
       "      <td>0.093434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023755</td>\n",
       "      <td>-0.027630</td>\n",
       "      <td>-0.024039</td>\n",
       "      <td>0.035001</td>\n",
       "      <td>-0.085119</td>\n",
       "      <td>0.029835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003489</td>\n",
       "      <td>3.462923e-06</td>\n",
       "      <td>0.076449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_moonillumination</th>\n",
       "      <td>-0.040266</td>\n",
       "      <td>-0.063445</td>\n",
       "      <td>-0.037898</td>\n",
       "      <td>0.043751</td>\n",
       "      <td>-0.015772</td>\n",
       "      <td>0.043197</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>-0.083709</td>\n",
       "      <td>0.045993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011325</td>\n",
       "      <td>-0.033740</td>\n",
       "      <td>-0.011322</td>\n",
       "      <td>0.062022</td>\n",
       "      <td>-0.068182</td>\n",
       "      <td>0.069669</td>\n",
       "      <td>0.597306</td>\n",
       "      <td>-0.003034</td>\n",
       "      <td>-4.731672e-05</td>\n",
       "      <td>0.019234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_pressure</th>\n",
       "      <td>-0.043682</td>\n",
       "      <td>-0.083046</td>\n",
       "      <td>-0.121718</td>\n",
       "      <td>0.083486</td>\n",
       "      <td>0.033323</td>\n",
       "      <td>-0.055015</td>\n",
       "      <td>-0.036129</td>\n",
       "      <td>-0.102566</td>\n",
       "      <td>-0.143198</td>\n",
       "      <td>0.318731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166727</td>\n",
       "      <td>-0.115810</td>\n",
       "      <td>-0.166909</td>\n",
       "      <td>-0.013998</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>-0.152682</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>-6.176626e-07</td>\n",
       "      <td>0.168439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_windspeed</th>\n",
       "      <td>-0.051985</td>\n",
       "      <td>-0.074133</td>\n",
       "      <td>-0.037762</td>\n",
       "      <td>-0.180583</td>\n",
       "      <td>-0.181055</td>\n",
       "      <td>-0.024371</td>\n",
       "      <td>-0.085869</td>\n",
       "      <td>0.013553</td>\n",
       "      <td>0.087761</td>\n",
       "      <td>-0.376343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157568</td>\n",
       "      <td>0.139179</td>\n",
       "      <td>0.157237</td>\n",
       "      <td>0.035315</td>\n",
       "      <td>-0.193082</td>\n",
       "      <td>0.115026</td>\n",
       "      <td>-0.152393</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>5.365511e-04</td>\n",
       "      <td>-0.100429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_pressure</th>\n",
       "      <td>-0.053315</td>\n",
       "      <td>-0.093552</td>\n",
       "      <td>-0.134745</td>\n",
       "      <td>0.150299</td>\n",
       "      <td>0.110985</td>\n",
       "      <td>0.044785</td>\n",
       "      <td>-0.008474</td>\n",
       "      <td>-0.111542</td>\n",
       "      <td>-0.233963</td>\n",
       "      <td>0.283044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192988</td>\n",
       "      <td>-0.197051</td>\n",
       "      <td>-0.193965</td>\n",
       "      <td>0.006343</td>\n",
       "      <td>0.027435</td>\n",
       "      <td>-0.226884</td>\n",
       "      <td>0.188793</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>-3.759487e-04</td>\n",
       "      <td>0.316095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_windgust</th>\n",
       "      <td>-0.061662</td>\n",
       "      <td>-0.093435</td>\n",
       "      <td>-0.053038</td>\n",
       "      <td>-0.165842</td>\n",
       "      <td>-0.191524</td>\n",
       "      <td>-0.019270</td>\n",
       "      <td>-0.096715</td>\n",
       "      <td>0.017203</td>\n",
       "      <td>0.092737</td>\n",
       "      <td>-0.388742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163855</td>\n",
       "      <td>0.148473</td>\n",
       "      <td>0.163480</td>\n",
       "      <td>0.045466</td>\n",
       "      <td>-0.188962</td>\n",
       "      <td>0.093873</td>\n",
       "      <td>-0.132681</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>4.788685e-04</td>\n",
       "      <td>-0.106361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_windspeed</th>\n",
       "      <td>-0.076518</td>\n",
       "      <td>-0.118409</td>\n",
       "      <td>-0.085098</td>\n",
       "      <td>-0.343910</td>\n",
       "      <td>-0.339537</td>\n",
       "      <td>-0.178848</td>\n",
       "      <td>-0.168713</td>\n",
       "      <td>0.021794</td>\n",
       "      <td>0.108575</td>\n",
       "      <td>-0.405076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234434</td>\n",
       "      <td>0.232205</td>\n",
       "      <td>0.234859</td>\n",
       "      <td>0.018918</td>\n",
       "      <td>-0.283310</td>\n",
       "      <td>0.180551</td>\n",
       "      <td>-0.122697</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>1.073059e-03</td>\n",
       "      <td>-0.225991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term_as_int</th>\n",
       "      <td>-0.081390</td>\n",
       "      <td>-0.120569</td>\n",
       "      <td>-0.073634</td>\n",
       "      <td>0.402953</td>\n",
       "      <td>0.421848</td>\n",
       "      <td>0.349717</td>\n",
       "      <td>0.378246</td>\n",
       "      <td>-0.060044</td>\n",
       "      <td>-0.126563</td>\n",
       "      <td>0.380821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819902</td>\n",
       "      <td>-0.864373</td>\n",
       "      <td>-0.819617</td>\n",
       "      <td>0.096762</td>\n",
       "      <td>0.144125</td>\n",
       "      <td>0.009914</td>\n",
       "      <td>0.076449</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>-7.107947e-04</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_windgust</th>\n",
       "      <td>-0.088989</td>\n",
       "      <td>-0.135137</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>-0.346365</td>\n",
       "      <td>-0.341449</td>\n",
       "      <td>-0.182769</td>\n",
       "      <td>-0.173353</td>\n",
       "      <td>0.020589</td>\n",
       "      <td>0.107939</td>\n",
       "      <td>-0.437007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248909</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>0.249276</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>-0.272125</td>\n",
       "      <td>0.143740</td>\n",
       "      <td>-0.109937</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>1.055778e-03</td>\n",
       "      <td>-0.238010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_type_as_int</th>\n",
       "      <td>-0.189202</td>\n",
       "      <td>-0.262337</td>\n",
       "      <td>-0.106484</td>\n",
       "      <td>0.024258</td>\n",
       "      <td>-0.005796</td>\n",
       "      <td>-0.011190</td>\n",
       "      <td>-0.006473</td>\n",
       "      <td>-0.059621</td>\n",
       "      <td>-0.018816</td>\n",
       "      <td>-0.009252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051715</td>\n",
       "      <td>-0.140686</td>\n",
       "      <td>-0.050895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033298</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.035001</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-6.970428e-04</td>\n",
       "      <td>0.096762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_sunrise_hr</th>\n",
       "      <td>-0.293742</td>\n",
       "      <td>-0.480405</td>\n",
       "      <td>-0.501881</td>\n",
       "      <td>-0.722733</td>\n",
       "      <td>-0.769977</td>\n",
       "      <td>-0.523234</td>\n",
       "      <td>-0.561754</td>\n",
       "      <td>0.099517</td>\n",
       "      <td>0.153393</td>\n",
       "      <td>-0.814917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321434</td>\n",
       "      <td>0.329282</td>\n",
       "      <td>0.320497</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>-0.455164</td>\n",
       "      <td>0.095349</td>\n",
       "      <td>-0.016715</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>3.074681e-05</td>\n",
       "      <td>-0.239723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_sunrise_min</th>\n",
       "      <td>-0.293742</td>\n",
       "      <td>-0.480405</td>\n",
       "      <td>-0.501881</td>\n",
       "      <td>-0.722733</td>\n",
       "      <td>-0.769977</td>\n",
       "      <td>-0.523234</td>\n",
       "      <td>-0.561754</td>\n",
       "      <td>0.099517</td>\n",
       "      <td>0.153393</td>\n",
       "      <td>-0.814917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321434</td>\n",
       "      <td>0.329282</td>\n",
       "      <td>0.320497</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>-0.455164</td>\n",
       "      <td>0.095349</td>\n",
       "      <td>-0.016715</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>3.074681e-05</td>\n",
       "      <td>-0.239723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_sunrise_hr</th>\n",
       "      <td>-0.306035</td>\n",
       "      <td>-0.501050</td>\n",
       "      <td>-0.524205</td>\n",
       "      <td>-0.739911</td>\n",
       "      <td>-0.787543</td>\n",
       "      <td>-0.548903</td>\n",
       "      <td>-0.593415</td>\n",
       "      <td>0.101388</td>\n",
       "      <td>0.187781</td>\n",
       "      <td>-0.806576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344027</td>\n",
       "      <td>0.350775</td>\n",
       "      <td>0.343062</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>-0.436862</td>\n",
       "      <td>0.053171</td>\n",
       "      <td>-0.043117</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>1.462177e-04</td>\n",
       "      <td>-0.253482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_sunrise_min</th>\n",
       "      <td>-0.306035</td>\n",
       "      <td>-0.501050</td>\n",
       "      <td>-0.524205</td>\n",
       "      <td>-0.739911</td>\n",
       "      <td>-0.787543</td>\n",
       "      <td>-0.548903</td>\n",
       "      <td>-0.593415</td>\n",
       "      <td>0.101388</td>\n",
       "      <td>0.187781</td>\n",
       "      <td>-0.806576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344027</td>\n",
       "      <td>0.350775</td>\n",
       "      <td>0.343062</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>-0.436862</td>\n",
       "      <td>0.053171</td>\n",
       "      <td>-0.043117</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>1.462177e-04</td>\n",
       "      <td>-0.253482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows  60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            reading  day_avg_reading  week_avg_reading  \\\n",
       "reading                    1.000000         0.567473          0.537752   \n",
       "day_avg_reading            0.567473         1.000000          0.869261   \n",
       "week_avg_reading           0.537752         0.869261          1.000000   \n",
       "hour                       0.335348         0.016805          0.020632   \n",
       "week_avg_sunset_hr         0.289345         0.474407          0.496088   \n",
       "day_avg_sunset_hr          0.280387         0.457473          0.473132   \n",
       "week_avg_dewpoint          0.241993         0.397084          0.445747   \n",
       "week_avg_windchill         0.239797         0.387978          0.436514   \n",
       "week_avg_feelslike         0.239393         0.387338          0.436000   \n",
       "week_avg_heatindex         0.238363         0.386917          0.441748   \n",
       "week_avg_temp              0.236778         0.385581          0.442421   \n",
       "week_avg_mintemp           0.234687         0.391613          0.461932   \n",
       "day_avg_mintemp            0.226490         0.379066          0.432498   \n",
       "week_avg_maxtemp           0.223379         0.367994          0.404759   \n",
       "week_avg_uvindex           0.218208         0.360649          0.395077   \n",
       "day_avg_windchill          0.213159         0.361364          0.408468   \n",
       "day_avg_feelslike          0.212822         0.360822          0.408125   \n",
       "day_avg_heatindex          0.210423         0.358737          0.413228   \n",
       "day_avg_temp               0.210208         0.359164          0.415279   \n",
       "day_avg_dewpoint           0.206195         0.349859          0.399792   \n",
       "week_avg_sunhour           0.205086         0.336090          0.349772   \n",
       "day_avg_maxtemp            0.204917         0.338584          0.381207   \n",
       "day_avg_uvindex            0.193354         0.329526          0.350469   \n",
       "day_avg_sunhour            0.188191         0.309826          0.311138   \n",
       "Year                       0.131888         0.212361          0.193533   \n",
       "week_avg_visibility        0.109228         0.179000          0.182091   \n",
       "week_avg_precip            0.085062         0.151275          0.201830   \n",
       "day_avg_visibility         0.075453         0.120612          0.102404   \n",
       "day_avg_sunset_min         0.064767         0.122808          0.181016   \n",
       "week_avg_humidity          0.063068         0.129756          0.110884   \n",
       "week_avg_sunset_min        0.062920         0.110279          0.161922   \n",
       "day_avg_precip             0.053676         0.105743          0.150654   \n",
       "day_avg_humidity           0.049246         0.078898          0.076198   \n",
       "week_avg_winddir           0.045745         0.062250          0.038451   \n",
       "week_avg_snow              0.028832         0.049471          0.029085   \n",
       "week_avg_cloud             0.028084         0.049880          0.064772   \n",
       "day_avg_snow               0.023012         0.024919          0.001840   \n",
       "day_avg_winddir            0.007677        -0.003040          0.011296   \n",
       "day_avg_as_client         -0.001067        -0.002856         -0.099896   \n",
       "day_avg_cloud             -0.001699         0.007287          0.034025   \n",
       "day_avg_auth_client       -0.002215        -0.005689         -0.101264   \n",
       "minute                    -0.006055        -0.000519         -0.000964   \n",
       "week_avg_as_client        -0.010859        -0.022856         -0.056166   \n",
       "week_avg_auth_client      -0.011734        -0.023453         -0.058036   \n",
       "Month                     -0.019445        -0.024544          0.024376   \n",
       "day_avg_moonillumination  -0.021305        -0.032049          0.000936   \n",
       "Day                       -0.033681        -0.048043          0.005952   \n",
       "week_avg_moonillumination -0.040266        -0.063445         -0.037898   \n",
       "day_avg_pressure          -0.043682        -0.083046         -0.121718   \n",
       "day_avg_windspeed         -0.051985        -0.074133         -0.037762   \n",
       "week_avg_pressure         -0.053315        -0.093552         -0.134745   \n",
       "day_avg_windgust          -0.061662        -0.093435         -0.053038   \n",
       "week_avg_windspeed        -0.076518        -0.118409         -0.085098   \n",
       "Term_as_int               -0.081390        -0.120569         -0.073634   \n",
       "week_avg_windgust         -0.088989        -0.135137         -0.109000   \n",
       "Day_type_as_int           -0.189202        -0.262337         -0.106484   \n",
       "day_avg_sunrise_hr        -0.293742        -0.480405         -0.501881   \n",
       "day_avg_sunrise_min       -0.293742        -0.480405         -0.501881   \n",
       "week_avg_sunrise_hr       -0.306035        -0.501050         -0.524205   \n",
       "week_avg_sunrise_min      -0.306035        -0.501050         -0.524205   \n",
       "\n",
       "                           day_avg_maxtemp  week_avg_maxtemp  day_avg_mintemp  \\\n",
       "reading                           0.204917          0.223379         0.226490   \n",
       "day_avg_reading                   0.338584          0.367994         0.379066   \n",
       "week_avg_reading                  0.381207          0.404759         0.432498   \n",
       "hour                              0.001300          0.002295        -0.000512   \n",
       "week_avg_sunset_hr                0.740185          0.776557         0.530093   \n",
       "day_avg_sunset_hr                 0.715190          0.743256         0.493586   \n",
       "week_avg_dewpoint                 0.807294          0.934835         0.822502   \n",
       "week_avg_windchill                0.855587          0.976085         0.809055   \n",
       "week_avg_feelslike                0.855454          0.975984         0.809178   \n",
       "week_avg_heatindex                0.846157          0.971681         0.818924   \n",
       "week_avg_temp                     0.847666          0.973018         0.820206   \n",
       "week_avg_mintemp                  0.776365          0.902945         0.837436   \n",
       "day_avg_mintemp                   0.861605          0.781017         1.000000   \n",
       "week_avg_maxtemp                  0.884754          1.000000         0.781017   \n",
       "week_avg_uvindex                  0.845870          0.949715         0.747652   \n",
       "day_avg_windchill                 0.961953          0.881796         0.905942   \n",
       "day_avg_feelslike                 0.962176          0.881185         0.905904   \n",
       "day_avg_heatindex                 0.961054          0.872039         0.928573   \n",
       "day_avg_temp                      0.960877          0.869199         0.938649   \n",
       "day_avg_dewpoint                  0.899765          0.807959         0.917018   \n",
       "week_avg_sunhour                  0.694063          0.714330         0.445027   \n",
       "day_avg_maxtemp                   1.000000          0.884754         0.861605   \n",
       "day_avg_uvindex                   0.874621          0.781366         0.733839   \n",
       "day_avg_sunhour                   0.606229          0.616277         0.328401   \n",
       "Year                              0.258379          0.275693         0.032750   \n",
       "week_avg_visibility               0.082141          0.070536        -0.063482   \n",
       "week_avg_precip                   0.072691          0.111240         0.148859   \n",
       "day_avg_visibility                0.021373          0.041430        -0.105680   \n",
       "day_avg_sunset_min               -0.020457         -0.012632         0.031147   \n",
       "week_avg_humidity                 0.035357          0.086222         0.262858   \n",
       "week_avg_sunset_min              -0.028389         -0.045283         0.004150   \n",
       "day_avg_precip                    0.077244          0.117555         0.139049   \n",
       "day_avg_humidity                  0.127885          0.062376         0.311324   \n",
       "week_avg_winddir                 -0.047302         -0.010975         0.037376   \n",
       "week_avg_snow                    -0.276800         -0.318507        -0.279830   \n",
       "week_avg_cloud                   -0.187650         -0.180175         0.002010   \n",
       "day_avg_snow                     -0.173640         -0.136741        -0.160403   \n",
       "day_avg_winddir                  -0.016343          0.031729         0.089084   \n",
       "day_avg_as_client                -0.485997         -0.510482        -0.464762   \n",
       "day_avg_cloud                    -0.079127         -0.076762         0.139211   \n",
       "day_avg_auth_client              -0.487376         -0.511816        -0.466607   \n",
       "minute                           -0.000883         -0.000850        -0.001023   \n",
       "week_avg_as_client               -0.502095         -0.540220        -0.468744   \n",
       "week_avg_auth_client             -0.502675         -0.541194        -0.470018   \n",
       "Month                             0.112700          0.155964         0.292447   \n",
       "day_avg_moonillumination         -0.011558         -0.072718         0.035097   \n",
       "Day                               0.137701          0.126849         0.112697   \n",
       "week_avg_moonillumination         0.043751         -0.015772         0.043197   \n",
       "day_avg_pressure                  0.083486          0.033323        -0.055015   \n",
       "day_avg_windspeed                -0.180583         -0.181055        -0.024371   \n",
       "week_avg_pressure                 0.150299          0.110985         0.044785   \n",
       "day_avg_windgust                 -0.165842         -0.191524        -0.019270   \n",
       "week_avg_windspeed               -0.343910         -0.339537        -0.178848   \n",
       "Term_as_int                       0.402953          0.421848         0.349717   \n",
       "week_avg_windgust                -0.346365         -0.341449        -0.182769   \n",
       "Day_type_as_int                   0.024258         -0.005796        -0.011190   \n",
       "day_avg_sunrise_hr               -0.722733         -0.769977        -0.523234   \n",
       "day_avg_sunrise_min              -0.722733         -0.769977        -0.523234   \n",
       "week_avg_sunrise_hr              -0.739911         -0.787543        -0.548903   \n",
       "week_avg_sunrise_min             -0.739911         -0.787543        -0.548903   \n",
       "\n",
       "                           week_avg_mintemp  day_avg_snow  week_avg_snow  \\\n",
       "reading                            0.234687      0.023012       0.028832   \n",
       "day_avg_reading                    0.391613      0.024919       0.049471   \n",
       "week_avg_reading                   0.461932      0.001840       0.029085   \n",
       "hour                               0.001658     -0.000502       0.003806   \n",
       "week_avg_sunset_hr                 0.560914     -0.067602      -0.130147   \n",
       "day_avg_sunset_hr                  0.517201     -0.058424      -0.119625   \n",
       "week_avg_dewpoint                  0.974610     -0.142405      -0.343206   \n",
       "week_avg_windchill                 0.947995     -0.134871      -0.324467   \n",
       "week_avg_feelslike                 0.948215     -0.134624      -0.323827   \n",
       "week_avg_heatindex                 0.964164     -0.139292      -0.327886   \n",
       "week_avg_temp                      0.966837     -0.140540      -0.331191   \n",
       "week_avg_mintemp                   1.000000     -0.143012      -0.328774   \n",
       "day_avg_mintemp                    0.837436     -0.160403      -0.279830   \n",
       "week_avg_maxtemp                   0.902945     -0.136741      -0.318507   \n",
       "week_avg_uvindex                   0.847447     -0.166102      -0.335365   \n",
       "day_avg_windchill                  0.835460     -0.169717      -0.298495   \n",
       "day_avg_feelslike                  0.835199     -0.169282      -0.297780   \n",
       "day_avg_heatindex                  0.840538     -0.169485      -0.295549   \n",
       "day_avg_temp                       0.839086     -0.171503      -0.298036   \n",
       "day_avg_dewpoint                   0.816186     -0.175404      -0.289747   \n",
       "week_avg_sunhour                   0.452878     -0.077554      -0.130591   \n",
       "day_avg_maxtemp                    0.776365     -0.173640      -0.276800   \n",
       "day_avg_uvindex                    0.674645     -0.187128      -0.260289   \n",
       "day_avg_sunhour                    0.378477     -0.066769      -0.101416   \n",
       "Year                               0.044666      0.054797       0.115505   \n",
       "week_avg_visibility               -0.106805     -0.091325      -0.169104   \n",
       "week_avg_precip                    0.214386      0.063152       0.156221   \n",
       "day_avg_visibility                -0.081718     -0.078801      -0.063227   \n",
       "day_avg_sunset_min                 0.039971      0.021655       0.114647   \n",
       "week_avg_humidity                  0.353141     -0.061721      -0.209299   \n",
       "week_avg_sunset_min                0.009033      0.035819       0.092813   \n",
       "day_avg_precip                     0.169635      0.089030       0.108632   \n",
       "day_avg_humidity                   0.207099     -0.099852      -0.102398   \n",
       "week_avg_winddir                   0.060154      0.113224       0.180318   \n",
       "week_avg_snow                     -0.328774      0.416091       1.000000   \n",
       "week_avg_cloud                     0.061058      0.047489       0.051940   \n",
       "day_avg_snow                      -0.143012      1.000000       0.416091   \n",
       "day_avg_winddir                    0.054273      0.101061       0.073138   \n",
       "day_avg_as_client                 -0.522276      0.101001       0.171085   \n",
       "day_avg_cloud                      0.053266      0.043144       0.018867   \n",
       "day_avg_auth_client               -0.524206      0.100331       0.170157   \n",
       "minute                            -0.001132      0.000691       0.000865   \n",
       "week_avg_as_client                -0.542480      0.087494       0.172083   \n",
       "week_avg_auth_client              -0.544106      0.087062       0.171391   \n",
       "Month                              0.350418     -0.153602      -0.296761   \n",
       "day_avg_moonillumination          -0.002655     -0.030214      -0.144168   \n",
       "Day                                0.150269      0.078998      -0.094218   \n",
       "week_avg_moonillumination          0.030744      0.003476      -0.083709   \n",
       "day_avg_pressure                  -0.036129     -0.102566      -0.143198   \n",
       "day_avg_windspeed                 -0.085869      0.013553       0.087761   \n",
       "week_avg_pressure                 -0.008474     -0.111542      -0.233963   \n",
       "day_avg_windgust                  -0.096715      0.017203       0.092737   \n",
       "week_avg_windspeed                -0.168713      0.021794       0.108575   \n",
       "Term_as_int                        0.378246     -0.060044      -0.126563   \n",
       "week_avg_windgust                 -0.173353      0.020589       0.107939   \n",
       "Day_type_as_int                   -0.006473     -0.059621      -0.018816   \n",
       "day_avg_sunrise_hr                -0.561754      0.099517       0.153393   \n",
       "day_avg_sunrise_min               -0.561754      0.099517       0.153393   \n",
       "week_avg_sunrise_hr               -0.593415      0.101388       0.187781   \n",
       "week_avg_sunrise_min              -0.593415      0.101388       0.187781   \n",
       "\n",
       "                           day_avg_sunhour  ...  week_avg_as_client  \\\n",
       "reading                           0.188191  ...           -0.010859   \n",
       "day_avg_reading                   0.309826  ...           -0.022856   \n",
       "week_avg_reading                  0.311138  ...           -0.056166   \n",
       "hour                              0.000337  ...            0.001408   \n",
       "week_avg_sunset_hr                0.823043  ...           -0.370882   \n",
       "day_avg_sunset_hr                 0.828893  ...           -0.357407   \n",
       "week_avg_dewpoint                 0.419947  ...           -0.557556   \n",
       "week_avg_windchill                0.532424  ...           -0.576238   \n",
       "week_avg_feelslike                0.532105  ...           -0.576847   \n",
       "week_avg_heatindex                0.503759  ...           -0.559063   \n",
       "week_avg_temp                     0.507836  ...           -0.560718   \n",
       "week_avg_mintemp                  0.378477  ...           -0.542480   \n",
       "day_avg_mintemp                   0.328401  ...           -0.468744   \n",
       "week_avg_maxtemp                  0.616277  ...           -0.540220   \n",
       "week_avg_uvindex                  0.617899  ...           -0.518686   \n",
       "day_avg_windchill                 0.518522  ...           -0.538732   \n",
       "day_avg_feelslike                 0.518536  ...           -0.538962   \n",
       "day_avg_heatindex                 0.468925  ...           -0.514488   \n",
       "day_avg_temp                      0.469903  ...           -0.511592   \n",
       "day_avg_dewpoint                  0.337123  ...           -0.489790   \n",
       "week_avg_sunhour                  0.900249  ...           -0.464352   \n",
       "day_avg_maxtemp                   0.606229  ...           -0.502095   \n",
       "day_avg_uvindex                   0.621829  ...           -0.442816   \n",
       "day_avg_sunhour                   1.000000  ...           -0.401215   \n",
       "Year                              0.417509  ...           -0.264805   \n",
       "week_avg_visibility               0.405250  ...            0.247908   \n",
       "week_avg_precip                  -0.113745  ...           -0.070236   \n",
       "day_avg_visibility                0.360661  ...            0.187021   \n",
       "day_avg_sunset_min                0.007657  ...            0.024046   \n",
       "week_avg_humidity                -0.329134  ...           -0.157776   \n",
       "week_avg_sunset_min               0.052959  ...           -0.038860   \n",
       "day_avg_precip                   -0.161127  ...           -0.048607   \n",
       "day_avg_humidity                 -0.335275  ...           -0.085544   \n",
       "week_avg_winddir                 -0.030465  ...           -0.055327   \n",
       "week_avg_snow                    -0.101416  ...            0.172083   \n",
       "week_avg_cloud                   -0.393922  ...            0.043984   \n",
       "day_avg_snow                     -0.066769  ...            0.087494   \n",
       "day_avg_winddir                  -0.086475  ...           -0.046555   \n",
       "day_avg_as_client                -0.408320  ...            0.951030   \n",
       "day_avg_cloud                    -0.531756  ...            0.025014   \n",
       "day_avg_auth_client              -0.408132  ...            0.952131   \n",
       "minute                            0.000175  ...            0.000889   \n",
       "week_avg_as_client               -0.401215  ...            1.000000   \n",
       "week_avg_auth_client             -0.400295  ...            0.999936   \n",
       "Month                            -0.197362  ...           -0.101139   \n",
       "day_avg_moonillumination          0.000817  ...            0.005652   \n",
       "Day                               0.093434  ...           -0.023755   \n",
       "week_avg_moonillumination         0.045993  ...           -0.011325   \n",
       "day_avg_pressure                  0.318731  ...           -0.166727   \n",
       "day_avg_windspeed                -0.376343  ...            0.157568   \n",
       "week_avg_pressure                 0.283044  ...           -0.192988   \n",
       "day_avg_windgust                 -0.388742  ...            0.163855   \n",
       "week_avg_windspeed               -0.405076  ...            0.234434   \n",
       "Term_as_int                       0.380821  ...           -0.819902   \n",
       "week_avg_windgust                -0.437007  ...            0.248909   \n",
       "Day_type_as_int                  -0.009252  ...           -0.051715   \n",
       "day_avg_sunrise_hr               -0.814917  ...            0.321434   \n",
       "day_avg_sunrise_min              -0.814917  ...            0.321434   \n",
       "week_avg_sunrise_hr              -0.806576  ...            0.344027   \n",
       "week_avg_sunrise_min             -0.806576  ...            0.344027   \n",
       "\n",
       "                           day_avg_auth_client  week_avg_auth_client  \\\n",
       "reading                              -0.002215             -0.011734   \n",
       "day_avg_reading                      -0.005689             -0.023453   \n",
       "week_avg_reading                     -0.101264             -0.058036   \n",
       "hour                                 -0.001594              0.001186   \n",
       "week_avg_sunset_hr                   -0.364725             -0.370186   \n",
       "day_avg_sunset_hr                    -0.355260             -0.356601   \n",
       "week_avg_dewpoint                    -0.529398             -0.558937   \n",
       "week_avg_windchill                   -0.547587             -0.577732   \n",
       "week_avg_feelslike                   -0.548243             -0.578340   \n",
       "week_avg_heatindex                   -0.531371             -0.560527   \n",
       "week_avg_temp                        -0.534665             -0.562142   \n",
       "week_avg_mintemp                     -0.524206             -0.544106   \n",
       "day_avg_mintemp                      -0.466607             -0.470018   \n",
       "week_avg_maxtemp                     -0.511816             -0.541194   \n",
       "week_avg_uvindex                     -0.508019             -0.519531   \n",
       "day_avg_windchill                    -0.526756             -0.539574   \n",
       "day_avg_feelslike                    -0.527048             -0.539805   \n",
       "day_avg_heatindex                    -0.506393             -0.515382   \n",
       "day_avg_temp                         -0.505765             -0.512474   \n",
       "day_avg_dewpoint                     -0.485202             -0.490636   \n",
       "week_avg_sunhour                     -0.474436             -0.463565   \n",
       "day_avg_maxtemp                      -0.487376             -0.502675   \n",
       "day_avg_uvindex                      -0.427006             -0.443274   \n",
       "day_avg_sunhour                      -0.408132             -0.400295   \n",
       "Year                                 -0.215071             -0.263265   \n",
       "week_avg_visibility                   0.202271              0.249769   \n",
       "week_avg_precip                      -0.039149             -0.070060   \n",
       "day_avg_visibility                    0.185021              0.188555   \n",
       "day_avg_sunset_min                   -0.004099              0.024672   \n",
       "week_avg_humidity                    -0.144804             -0.157599   \n",
       "week_avg_sunset_min                  -0.094965             -0.037868   \n",
       "day_avg_precip                       -0.059935             -0.048918   \n",
       "day_avg_humidity                     -0.094425             -0.085603   \n",
       "week_avg_winddir                     -0.034140             -0.055907   \n",
       "week_avg_snow                         0.170157              0.171391   \n",
       "week_avg_cloud                        0.070128              0.045199   \n",
       "day_avg_snow                          0.100331              0.087062   \n",
       "day_avg_winddir                      -0.035793             -0.047326   \n",
       "day_avg_as_client                     0.999942              0.950912   \n",
       "day_avg_cloud                         0.012255              0.025585   \n",
       "day_avg_auth_client                   1.000000              0.952061   \n",
       "minute                                0.000912              0.000825   \n",
       "week_avg_as_client                    0.952131              0.999936   \n",
       "week_avg_auth_client                  0.952061              1.000000   \n",
       "Month                                -0.142826             -0.101322   \n",
       "day_avg_moonillumination             -0.005551              0.005641   \n",
       "Day                                  -0.027630             -0.024039   \n",
       "week_avg_moonillumination            -0.033740             -0.011322   \n",
       "day_avg_pressure                     -0.115810             -0.166909   \n",
       "day_avg_windspeed                     0.139179              0.157237   \n",
       "week_avg_pressure                    -0.197051             -0.193965   \n",
       "day_avg_windgust                      0.148473              0.163480   \n",
       "week_avg_windspeed                    0.232205              0.234859   \n",
       "Term_as_int                          -0.864373             -0.819617   \n",
       "week_avg_windgust                     0.252405              0.249276   \n",
       "Day_type_as_int                      -0.140686             -0.050895   \n",
       "day_avg_sunrise_hr                    0.329282              0.320497   \n",
       "day_avg_sunrise_min                   0.329282              0.320497   \n",
       "week_avg_sunrise_hr                   0.350775              0.343062   \n",
       "week_avg_sunrise_min                  0.350775              0.343062   \n",
       "\n",
       "                           Day_type_as_int      Year     Month       Day  \\\n",
       "reading                          -0.189202  0.131888 -0.019445 -0.033681   \n",
       "day_avg_reading                  -0.262337  0.212361 -0.024544 -0.048043   \n",
       "week_avg_reading                 -0.106484  0.193533  0.024376  0.005952   \n",
       "hour                             -0.000580 -0.001351 -0.000135 -0.003489   \n",
       "week_avg_sunset_hr               -0.012323  0.554331 -0.244357  0.059472   \n",
       "day_avg_sunset_hr                -0.010841  0.571146 -0.290125  0.033062   \n",
       "week_avg_dewpoint                -0.002401  0.138944  0.290586  0.111854   \n",
       "week_avg_windchill               -0.007420  0.212323  0.219631  0.130534   \n",
       "week_avg_feelslike               -0.007236  0.212412  0.219271  0.131433   \n",
       "week_avg_heatindex               -0.003697  0.174012  0.261408  0.130497   \n",
       "week_avg_temp                    -0.003319  0.173005  0.262671  0.132393   \n",
       "week_avg_mintemp                 -0.006473  0.044666  0.350418  0.150269   \n",
       "day_avg_mintemp                  -0.011190  0.032750  0.292447  0.112697   \n",
       "week_avg_maxtemp                 -0.005796  0.275693  0.155964  0.126849   \n",
       "week_avg_uvindex                 -0.014770  0.140796  0.242984  0.111912   \n",
       "day_avg_windchill                 0.020439  0.197939  0.181852  0.140167   \n",
       "day_avg_feelslike                 0.020965  0.197930  0.181440  0.141187   \n",
       "day_avg_heatindex                 0.026912  0.159265  0.215840  0.127536   \n",
       "day_avg_temp                      0.024622  0.156584  0.216534  0.127857   \n",
       "day_avg_dewpoint                  0.028749  0.114187  0.241234  0.115384   \n",
       "week_avg_sunhour                  0.000403  0.437496 -0.174393  0.067824   \n",
       "day_avg_maxtemp                   0.024258  0.258379  0.112700  0.137701   \n",
       "day_avg_uvindex                   0.001947  0.138374  0.171633  0.134628   \n",
       "day_avg_sunhour                  -0.009252  0.417509 -0.197362  0.093434   \n",
       "Year                             -0.033298  1.000000 -0.606507 -0.085119   \n",
       "week_avg_visibility               0.004467  0.117943 -0.193857 -0.027205   \n",
       "week_avg_precip                  -0.006668  0.289546 -0.056752 -0.169866   \n",
       "day_avg_visibility               -0.002354  0.100944 -0.163317  0.024489   \n",
       "day_avg_sunset_min                0.028574 -0.138015  0.158621 -0.036161   \n",
       "week_avg_humidity                 0.019431 -0.194109  0.219572 -0.024028   \n",
       "week_avg_sunset_min               0.024814 -0.102106  0.164657 -0.217178   \n",
       "day_avg_precip                    0.029373  0.181255 -0.049851 -0.106381   \n",
       "day_avg_humidity                  0.013207 -0.150775  0.164302  0.034549   \n",
       "week_avg_winddir                 -0.004299  0.147352 -0.318086 -0.051446   \n",
       "week_avg_snow                    -0.018816  0.115505 -0.296761 -0.094218   \n",
       "week_avg_cloud                    0.032563 -0.034436  0.097594 -0.092276   \n",
       "day_avg_snow                     -0.059621  0.054797 -0.153602  0.078998   \n",
       "day_avg_winddir                  -0.004017  0.078389 -0.213797 -0.041662   \n",
       "day_avg_as_client                -0.144606 -0.215905 -0.142987 -0.027157   \n",
       "day_avg_cloud                     0.055944 -0.054146  0.094751 -0.164227   \n",
       "day_avg_auth_client              -0.140686 -0.215071 -0.142826 -0.027630   \n",
       "minute                           -0.000697  0.000604 -0.001390  0.000003   \n",
       "week_avg_as_client               -0.051715 -0.264805 -0.101139 -0.023755   \n",
       "week_avg_auth_client             -0.050895 -0.263265 -0.101322 -0.024039   \n",
       "Month                             0.005472 -0.606507  1.000000  0.029835   \n",
       "day_avg_moonillumination          0.018411 -0.062421  0.080944  0.390340   \n",
       "Day                               0.035001 -0.085119  0.029835  1.000000   \n",
       "week_avg_moonillumination         0.062022 -0.068182  0.069669  0.597306   \n",
       "day_avg_pressure                 -0.013998  0.008746 -0.152682  0.191781   \n",
       "day_avg_windspeed                 0.035315 -0.193082  0.115026 -0.152393   \n",
       "week_avg_pressure                 0.006343  0.027435 -0.226884  0.188793   \n",
       "day_avg_windgust                  0.045466 -0.188962  0.093873 -0.132681   \n",
       "week_avg_windspeed                0.018918 -0.283310  0.180551 -0.122697   \n",
       "Term_as_int                       0.096762  0.144125  0.009914  0.076449   \n",
       "week_avg_windgust                 0.019342 -0.272125  0.143740 -0.109937   \n",
       "Day_type_as_int                   1.000000 -0.033298  0.005472  0.035001   \n",
       "day_avg_sunrise_hr                0.009244 -0.455164  0.095349 -0.016715   \n",
       "day_avg_sunrise_min               0.009244 -0.455164  0.095349 -0.016715   \n",
       "week_avg_sunrise_hr               0.009930 -0.436862  0.053171 -0.043117   \n",
       "week_avg_sunrise_min              0.009930 -0.436862  0.053171 -0.043117   \n",
       "\n",
       "                               hour        minute  Term_as_int  \n",
       "reading                    0.335348 -6.055139e-03    -0.081390  \n",
       "day_avg_reading            0.016805 -5.190164e-04    -0.120569  \n",
       "week_avg_reading           0.020632 -9.636967e-04    -0.073634  \n",
       "hour                       1.000000 -3.142976e-04     0.000537  \n",
       "week_avg_sunset_hr         0.000677  2.297488e-04     0.285200  \n",
       "day_avg_sunset_hr          0.000705  3.096417e-04     0.283898  \n",
       "week_avg_dewpoint          0.003419 -1.107102e-03     0.384429  \n",
       "week_avg_windchill         0.006261 -1.059031e-03     0.426308  \n",
       "week_avg_feelslike         0.006258 -1.059748e-03     0.426903  \n",
       "week_avg_heatindex         0.005948 -9.908636e-04     0.407384  \n",
       "week_avg_temp              0.005521 -1.009001e-03     0.410719  \n",
       "week_avg_mintemp           0.001658 -1.131802e-03     0.378246  \n",
       "day_avg_mintemp           -0.000512 -1.022912e-03     0.349717  \n",
       "week_avg_maxtemp           0.002295 -8.504237e-04     0.421848  \n",
       "week_avg_uvindex           0.002576 -8.454218e-04     0.436885  \n",
       "day_avg_windchill          0.001044 -1.013704e-03     0.414733  \n",
       "day_avg_feelslike          0.001033 -1.011851e-03     0.415039  \n",
       "day_avg_heatindex          0.001526 -9.688926e-04     0.398544  \n",
       "day_avg_temp               0.002171 -1.003106e-03     0.398692  \n",
       "day_avg_dewpoint          -0.000271 -9.710049e-04     0.373342  \n",
       "week_avg_sunhour           0.000846 -1.176234e-04     0.450651  \n",
       "day_avg_maxtemp            0.001300 -8.826796e-04     0.402953  \n",
       "day_avg_uvindex            0.002533 -7.912722e-04     0.356827  \n",
       "day_avg_sunhour            0.000337  1.751287e-04     0.380821  \n",
       "Year                      -0.001351  6.041139e-04     0.144125  \n",
       "week_avg_visibility       -0.003036 -3.558864e-04    -0.173895  \n",
       "week_avg_precip            0.002545  1.036388e-03    -0.107742  \n",
       "day_avg_visibility        -0.006379  1.192842e-04    -0.150833  \n",
       "day_avg_sunset_min        -0.000008 -8.712124e-04    -0.017314  \n",
       "week_avg_humidity         -0.015468 -9.850624e-04     0.014142  \n",
       "week_avg_sunset_min        0.000902 -1.043656e-03     0.050116  \n",
       "day_avg_precip            -0.004918  5.290927e-04    -0.000017  \n",
       "day_avg_humidity          -0.005958 -3.258299e-04     0.053890  \n",
       "week_avg_winddir           0.003388  1.107670e-03     0.052434  \n",
       "week_avg_snow              0.003806  8.652802e-04    -0.126563  \n",
       "week_avg_cloud            -0.003679  8.066341e-05    -0.186749  \n",
       "day_avg_snow              -0.000502  6.905249e-04    -0.060044  \n",
       "day_avg_winddir           -0.001757  9.217002e-04     0.086045  \n",
       "day_avg_as_client         -0.001227  9.229941e-04    -0.864264  \n",
       "day_avg_cloud             -0.001524  1.732244e-04    -0.045520  \n",
       "day_avg_auth_client       -0.001594  9.120595e-04    -0.864373  \n",
       "minute                    -0.000314  1.000000e+00    -0.000711  \n",
       "week_avg_as_client         0.001408  8.891216e-04    -0.819902  \n",
       "week_avg_auth_client       0.001186  8.253068e-04    -0.819617  \n",
       "Month                     -0.000135 -1.390400e-03     0.009914  \n",
       "day_avg_moonillumination  -0.001658  2.415189e-04    -0.006142  \n",
       "Day                       -0.003489  3.462923e-06     0.076449  \n",
       "week_avg_moonillumination -0.003034 -4.731672e-05     0.019234  \n",
       "day_avg_pressure           0.000756 -6.176626e-07     0.168439  \n",
       "day_avg_windspeed          0.004520  5.365511e-04    -0.100429  \n",
       "week_avg_pressure         -0.001004 -3.759487e-04     0.316095  \n",
       "day_avg_windgust           0.001789  4.788685e-04    -0.106361  \n",
       "week_avg_windspeed         0.006402  1.073059e-03    -0.225991  \n",
       "Term_as_int                0.000537 -7.107947e-04     1.000000  \n",
       "week_avg_windgust          0.006503  1.055778e-03    -0.238010  \n",
       "Day_type_as_int           -0.000580 -6.970428e-04     0.096762  \n",
       "day_avg_sunrise_hr        -0.000840  3.074681e-05    -0.239723  \n",
       "day_avg_sunrise_min       -0.000840  3.074681e-05    -0.239723  \n",
       "week_avg_sunrise_hr       -0.000566  1.462177e-04    -0.253482  \n",
       "week_avg_sunrise_min      -0.000566  1.462177e-04    -0.253482  \n",
       "\n",
       "[60 rows x 60 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = train_data_bow[features].corr().sort_values(by=['reading'], ascending=False)\n",
    "correlations.head(85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading</th>\n",
       "      <th>day_avg_reading</th>\n",
       "      <th>week_avg_reading</th>\n",
       "      <th>day_avg_maxtemp</th>\n",
       "      <th>week_avg_maxtemp</th>\n",
       "      <th>day_avg_mintemp</th>\n",
       "      <th>week_avg_mintemp</th>\n",
       "      <th>day_avg_snow</th>\n",
       "      <th>week_avg_snow</th>\n",
       "      <th>day_avg_sunhour</th>\n",
       "      <th>...</th>\n",
       "      <th>week_avg_as_client</th>\n",
       "      <th>day_avg_auth_client</th>\n",
       "      <th>week_avg_auth_client</th>\n",
       "      <th>Day_type_as_int</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>Term_as_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reading</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.567473</td>\n",
       "      <td>0.537752</td>\n",
       "      <td>0.204917</td>\n",
       "      <td>0.223379</td>\n",
       "      <td>0.226490</td>\n",
       "      <td>0.234687</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>0.028832</td>\n",
       "      <td>0.188191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010859</td>\n",
       "      <td>-0.002215</td>\n",
       "      <td>-0.011734</td>\n",
       "      <td>-0.189202</td>\n",
       "      <td>0.131888</td>\n",
       "      <td>-0.019445</td>\n",
       "      <td>-0.033681</td>\n",
       "      <td>0.335348</td>\n",
       "      <td>-0.006055</td>\n",
       "      <td>-0.081390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_reading</th>\n",
       "      <td>0.567473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869261</td>\n",
       "      <td>0.338584</td>\n",
       "      <td>0.367994</td>\n",
       "      <td>0.379066</td>\n",
       "      <td>0.391613</td>\n",
       "      <td>0.024919</td>\n",
       "      <td>0.049471</td>\n",
       "      <td>0.309826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022856</td>\n",
       "      <td>-0.005689</td>\n",
       "      <td>-0.023453</td>\n",
       "      <td>-0.262337</td>\n",
       "      <td>0.212361</td>\n",
       "      <td>-0.024544</td>\n",
       "      <td>-0.048043</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>-0.000519</td>\n",
       "      <td>-0.120569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_reading</th>\n",
       "      <td>0.537752</td>\n",
       "      <td>0.869261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381207</td>\n",
       "      <td>0.404759</td>\n",
       "      <td>0.432498</td>\n",
       "      <td>0.461932</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>0.311138</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056166</td>\n",
       "      <td>-0.101264</td>\n",
       "      <td>-0.058036</td>\n",
       "      <td>-0.106484</td>\n",
       "      <td>0.193533</td>\n",
       "      <td>0.024376</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.020632</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>-0.073634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.335348</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>0.020632</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>-0.000502</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.003489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_sunset_hr</th>\n",
       "      <td>0.289345</td>\n",
       "      <td>0.474407</td>\n",
       "      <td>0.496088</td>\n",
       "      <td>0.740185</td>\n",
       "      <td>0.776557</td>\n",
       "      <td>0.530093</td>\n",
       "      <td>0.560914</td>\n",
       "      <td>-0.067602</td>\n",
       "      <td>-0.130147</td>\n",
       "      <td>0.823043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370882</td>\n",
       "      <td>-0.364725</td>\n",
       "      <td>-0.370186</td>\n",
       "      <td>-0.012323</td>\n",
       "      <td>0.554331</td>\n",
       "      <td>-0.244357</td>\n",
       "      <td>0.059472</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.285200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_sunset_hr</th>\n",
       "      <td>0.280387</td>\n",
       "      <td>0.457473</td>\n",
       "      <td>0.473132</td>\n",
       "      <td>0.715190</td>\n",
       "      <td>0.743256</td>\n",
       "      <td>0.493586</td>\n",
       "      <td>0.517201</td>\n",
       "      <td>-0.058424</td>\n",
       "      <td>-0.119625</td>\n",
       "      <td>0.828893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.357407</td>\n",
       "      <td>-0.355260</td>\n",
       "      <td>-0.356601</td>\n",
       "      <td>-0.010841</td>\n",
       "      <td>0.571146</td>\n",
       "      <td>-0.290125</td>\n",
       "      <td>0.033062</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.283898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_dewpoint</th>\n",
       "      <td>0.241993</td>\n",
       "      <td>0.397084</td>\n",
       "      <td>0.445747</td>\n",
       "      <td>0.807294</td>\n",
       "      <td>0.934835</td>\n",
       "      <td>0.822502</td>\n",
       "      <td>0.974610</td>\n",
       "      <td>-0.142405</td>\n",
       "      <td>-0.343206</td>\n",
       "      <td>0.419947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557556</td>\n",
       "      <td>-0.529398</td>\n",
       "      <td>-0.558937</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>0.138944</td>\n",
       "      <td>0.290586</td>\n",
       "      <td>0.111854</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.001107</td>\n",
       "      <td>0.384429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_windchill</th>\n",
       "      <td>0.239797</td>\n",
       "      <td>0.387978</td>\n",
       "      <td>0.436514</td>\n",
       "      <td>0.855587</td>\n",
       "      <td>0.976085</td>\n",
       "      <td>0.809055</td>\n",
       "      <td>0.947995</td>\n",
       "      <td>-0.134871</td>\n",
       "      <td>-0.324467</td>\n",
       "      <td>0.532424</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576238</td>\n",
       "      <td>-0.547587</td>\n",
       "      <td>-0.577732</td>\n",
       "      <td>-0.007420</td>\n",
       "      <td>0.212323</td>\n",
       "      <td>0.219631</td>\n",
       "      <td>0.130534</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>0.426308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_feelslike</th>\n",
       "      <td>0.239393</td>\n",
       "      <td>0.387338</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.855454</td>\n",
       "      <td>0.975984</td>\n",
       "      <td>0.809178</td>\n",
       "      <td>0.948215</td>\n",
       "      <td>-0.134624</td>\n",
       "      <td>-0.323827</td>\n",
       "      <td>0.532105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576847</td>\n",
       "      <td>-0.548243</td>\n",
       "      <td>-0.578340</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>0.212412</td>\n",
       "      <td>0.219271</td>\n",
       "      <td>0.131433</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>-0.001060</td>\n",
       "      <td>0.426903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_heatindex</th>\n",
       "      <td>0.238363</td>\n",
       "      <td>0.386917</td>\n",
       "      <td>0.441748</td>\n",
       "      <td>0.846157</td>\n",
       "      <td>0.971681</td>\n",
       "      <td>0.818924</td>\n",
       "      <td>0.964164</td>\n",
       "      <td>-0.139292</td>\n",
       "      <td>-0.327886</td>\n",
       "      <td>0.503759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559063</td>\n",
       "      <td>-0.531371</td>\n",
       "      <td>-0.560527</td>\n",
       "      <td>-0.003697</td>\n",
       "      <td>0.174012</td>\n",
       "      <td>0.261408</td>\n",
       "      <td>0.130497</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>-0.000991</td>\n",
       "      <td>0.407384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_temp</th>\n",
       "      <td>0.236778</td>\n",
       "      <td>0.385581</td>\n",
       "      <td>0.442421</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.973018</td>\n",
       "      <td>0.820206</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>-0.140540</td>\n",
       "      <td>-0.331191</td>\n",
       "      <td>0.507836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.560718</td>\n",
       "      <td>-0.534665</td>\n",
       "      <td>-0.562142</td>\n",
       "      <td>-0.003319</td>\n",
       "      <td>0.173005</td>\n",
       "      <td>0.262671</td>\n",
       "      <td>0.132393</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>0.410719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_mintemp</th>\n",
       "      <td>0.234687</td>\n",
       "      <td>0.391613</td>\n",
       "      <td>0.461932</td>\n",
       "      <td>0.776365</td>\n",
       "      <td>0.902945</td>\n",
       "      <td>0.837436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.143012</td>\n",
       "      <td>-0.328774</td>\n",
       "      <td>0.378477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542480</td>\n",
       "      <td>-0.524206</td>\n",
       "      <td>-0.544106</td>\n",
       "      <td>-0.006473</td>\n",
       "      <td>0.044666</td>\n",
       "      <td>0.350418</td>\n",
       "      <td>0.150269</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>0.378246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_mintemp</th>\n",
       "      <td>0.226490</td>\n",
       "      <td>0.379066</td>\n",
       "      <td>0.432498</td>\n",
       "      <td>0.861605</td>\n",
       "      <td>0.781017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837436</td>\n",
       "      <td>-0.160403</td>\n",
       "      <td>-0.279830</td>\n",
       "      <td>0.328401</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468744</td>\n",
       "      <td>-0.466607</td>\n",
       "      <td>-0.470018</td>\n",
       "      <td>-0.011190</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.292447</td>\n",
       "      <td>0.112697</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>0.349717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_maxtemp</th>\n",
       "      <td>0.223379</td>\n",
       "      <td>0.367994</td>\n",
       "      <td>0.404759</td>\n",
       "      <td>0.884754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781017</td>\n",
       "      <td>0.902945</td>\n",
       "      <td>-0.136741</td>\n",
       "      <td>-0.318507</td>\n",
       "      <td>0.616277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.540220</td>\n",
       "      <td>-0.511816</td>\n",
       "      <td>-0.541194</td>\n",
       "      <td>-0.005796</td>\n",
       "      <td>0.275693</td>\n",
       "      <td>0.155964</td>\n",
       "      <td>0.126849</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.000850</td>\n",
       "      <td>0.421848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_uvindex</th>\n",
       "      <td>0.218208</td>\n",
       "      <td>0.360649</td>\n",
       "      <td>0.395077</td>\n",
       "      <td>0.845870</td>\n",
       "      <td>0.949715</td>\n",
       "      <td>0.747652</td>\n",
       "      <td>0.847447</td>\n",
       "      <td>-0.166102</td>\n",
       "      <td>-0.335365</td>\n",
       "      <td>0.617899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518686</td>\n",
       "      <td>-0.508019</td>\n",
       "      <td>-0.519531</td>\n",
       "      <td>-0.014770</td>\n",
       "      <td>0.140796</td>\n",
       "      <td>0.242984</td>\n",
       "      <td>0.111912</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>-0.000845</td>\n",
       "      <td>0.436885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_windchill</th>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.361364</td>\n",
       "      <td>0.408468</td>\n",
       "      <td>0.961953</td>\n",
       "      <td>0.881796</td>\n",
       "      <td>0.905942</td>\n",
       "      <td>0.835460</td>\n",
       "      <td>-0.169717</td>\n",
       "      <td>-0.298495</td>\n",
       "      <td>0.518522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538732</td>\n",
       "      <td>-0.526756</td>\n",
       "      <td>-0.539574</td>\n",
       "      <td>0.020439</td>\n",
       "      <td>0.197939</td>\n",
       "      <td>0.181852</td>\n",
       "      <td>0.140167</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>-0.001014</td>\n",
       "      <td>0.414733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_feelslike</th>\n",
       "      <td>0.212822</td>\n",
       "      <td>0.360822</td>\n",
       "      <td>0.408125</td>\n",
       "      <td>0.962176</td>\n",
       "      <td>0.881185</td>\n",
       "      <td>0.905904</td>\n",
       "      <td>0.835199</td>\n",
       "      <td>-0.169282</td>\n",
       "      <td>-0.297780</td>\n",
       "      <td>0.518536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538962</td>\n",
       "      <td>-0.527048</td>\n",
       "      <td>-0.539805</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>0.197930</td>\n",
       "      <td>0.181440</td>\n",
       "      <td>0.141187</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>-0.001012</td>\n",
       "      <td>0.415039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_heatindex</th>\n",
       "      <td>0.210423</td>\n",
       "      <td>0.358737</td>\n",
       "      <td>0.413228</td>\n",
       "      <td>0.961054</td>\n",
       "      <td>0.872039</td>\n",
       "      <td>0.928573</td>\n",
       "      <td>0.840538</td>\n",
       "      <td>-0.169485</td>\n",
       "      <td>-0.295549</td>\n",
       "      <td>0.468925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514488</td>\n",
       "      <td>-0.506393</td>\n",
       "      <td>-0.515382</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>0.159265</td>\n",
       "      <td>0.215840</td>\n",
       "      <td>0.127536</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.000969</td>\n",
       "      <td>0.398544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_temp</th>\n",
       "      <td>0.210208</td>\n",
       "      <td>0.359164</td>\n",
       "      <td>0.415279</td>\n",
       "      <td>0.960877</td>\n",
       "      <td>0.869199</td>\n",
       "      <td>0.938649</td>\n",
       "      <td>0.839086</td>\n",
       "      <td>-0.171503</td>\n",
       "      <td>-0.298036</td>\n",
       "      <td>0.469903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511592</td>\n",
       "      <td>-0.505765</td>\n",
       "      <td>-0.512474</td>\n",
       "      <td>0.024622</td>\n",
       "      <td>0.156584</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0.127857</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>0.398692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_dewpoint</th>\n",
       "      <td>0.206195</td>\n",
       "      <td>0.349859</td>\n",
       "      <td>0.399792</td>\n",
       "      <td>0.899765</td>\n",
       "      <td>0.807959</td>\n",
       "      <td>0.917018</td>\n",
       "      <td>0.816186</td>\n",
       "      <td>-0.175404</td>\n",
       "      <td>-0.289747</td>\n",
       "      <td>0.337123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.489790</td>\n",
       "      <td>-0.485202</td>\n",
       "      <td>-0.490636</td>\n",
       "      <td>0.028749</td>\n",
       "      <td>0.114187</td>\n",
       "      <td>0.241234</td>\n",
       "      <td>0.115384</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>-0.000971</td>\n",
       "      <td>0.373342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_sunhour</th>\n",
       "      <td>0.205086</td>\n",
       "      <td>0.336090</td>\n",
       "      <td>0.349772</td>\n",
       "      <td>0.694063</td>\n",
       "      <td>0.714330</td>\n",
       "      <td>0.445027</td>\n",
       "      <td>0.452878</td>\n",
       "      <td>-0.077554</td>\n",
       "      <td>-0.130591</td>\n",
       "      <td>0.900249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464352</td>\n",
       "      <td>-0.474436</td>\n",
       "      <td>-0.463565</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.437496</td>\n",
       "      <td>-0.174393</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>0.450651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_maxtemp</th>\n",
       "      <td>0.204917</td>\n",
       "      <td>0.338584</td>\n",
       "      <td>0.381207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884754</td>\n",
       "      <td>0.861605</td>\n",
       "      <td>0.776365</td>\n",
       "      <td>-0.173640</td>\n",
       "      <td>-0.276800</td>\n",
       "      <td>0.606229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502095</td>\n",
       "      <td>-0.487376</td>\n",
       "      <td>-0.502675</td>\n",
       "      <td>0.024258</td>\n",
       "      <td>0.258379</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.137701</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>-0.000883</td>\n",
       "      <td>0.402953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_uvindex</th>\n",
       "      <td>0.193354</td>\n",
       "      <td>0.329526</td>\n",
       "      <td>0.350469</td>\n",
       "      <td>0.874621</td>\n",
       "      <td>0.781366</td>\n",
       "      <td>0.733839</td>\n",
       "      <td>0.674645</td>\n",
       "      <td>-0.187128</td>\n",
       "      <td>-0.260289</td>\n",
       "      <td>0.621829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442816</td>\n",
       "      <td>-0.427006</td>\n",
       "      <td>-0.443274</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.138374</td>\n",
       "      <td>0.171633</td>\n",
       "      <td>0.134628</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>0.356827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_sunhour</th>\n",
       "      <td>0.188191</td>\n",
       "      <td>0.309826</td>\n",
       "      <td>0.311138</td>\n",
       "      <td>0.606229</td>\n",
       "      <td>0.616277</td>\n",
       "      <td>0.328401</td>\n",
       "      <td>0.378477</td>\n",
       "      <td>-0.066769</td>\n",
       "      <td>-0.101416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401215</td>\n",
       "      <td>-0.408132</td>\n",
       "      <td>-0.400295</td>\n",
       "      <td>-0.009252</td>\n",
       "      <td>0.417509</td>\n",
       "      <td>-0.197362</td>\n",
       "      <td>0.093434</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.380821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_type_as_int</th>\n",
       "      <td>0.189202</td>\n",
       "      <td>-0.262337</td>\n",
       "      <td>-0.106484</td>\n",
       "      <td>0.024258</td>\n",
       "      <td>-0.005796</td>\n",
       "      <td>-0.011190</td>\n",
       "      <td>-0.006473</td>\n",
       "      <td>-0.059621</td>\n",
       "      <td>-0.018816</td>\n",
       "      <td>-0.009252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051715</td>\n",
       "      <td>-0.140686</td>\n",
       "      <td>-0.050895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033298</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.035001</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>0.096762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_sunrise_hr</th>\n",
       "      <td>0.293742</td>\n",
       "      <td>-0.480405</td>\n",
       "      <td>-0.501881</td>\n",
       "      <td>-0.722733</td>\n",
       "      <td>-0.769977</td>\n",
       "      <td>-0.523234</td>\n",
       "      <td>-0.561754</td>\n",
       "      <td>0.099517</td>\n",
       "      <td>0.153393</td>\n",
       "      <td>-0.814917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321434</td>\n",
       "      <td>0.329282</td>\n",
       "      <td>0.320497</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>-0.455164</td>\n",
       "      <td>0.095349</td>\n",
       "      <td>-0.016715</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.239723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_avg_sunrise_min</th>\n",
       "      <td>0.293742</td>\n",
       "      <td>-0.480405</td>\n",
       "      <td>-0.501881</td>\n",
       "      <td>-0.722733</td>\n",
       "      <td>-0.769977</td>\n",
       "      <td>-0.523234</td>\n",
       "      <td>-0.561754</td>\n",
       "      <td>0.099517</td>\n",
       "      <td>0.153393</td>\n",
       "      <td>-0.814917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321434</td>\n",
       "      <td>0.329282</td>\n",
       "      <td>0.320497</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>-0.455164</td>\n",
       "      <td>0.095349</td>\n",
       "      <td>-0.016715</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.239723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_sunrise_hr</th>\n",
       "      <td>0.306035</td>\n",
       "      <td>-0.501050</td>\n",
       "      <td>-0.524205</td>\n",
       "      <td>-0.739911</td>\n",
       "      <td>-0.787543</td>\n",
       "      <td>-0.548903</td>\n",
       "      <td>-0.593415</td>\n",
       "      <td>0.101388</td>\n",
       "      <td>0.187781</td>\n",
       "      <td>-0.806576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344027</td>\n",
       "      <td>0.350775</td>\n",
       "      <td>0.343062</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>-0.436862</td>\n",
       "      <td>0.053171</td>\n",
       "      <td>-0.043117</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.253482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_sunrise_min</th>\n",
       "      <td>0.306035</td>\n",
       "      <td>-0.501050</td>\n",
       "      <td>-0.524205</td>\n",
       "      <td>-0.739911</td>\n",
       "      <td>-0.787543</td>\n",
       "      <td>-0.548903</td>\n",
       "      <td>-0.593415</td>\n",
       "      <td>0.101388</td>\n",
       "      <td>0.187781</td>\n",
       "      <td>-0.806576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344027</td>\n",
       "      <td>0.350775</td>\n",
       "      <td>0.343062</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>-0.436862</td>\n",
       "      <td>0.053171</td>\n",
       "      <td>-0.043117</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.253482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows  60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       reading  day_avg_reading  week_avg_reading  \\\n",
       "reading               1.000000         0.567473          0.537752   \n",
       "day_avg_reading       0.567473         1.000000          0.869261   \n",
       "week_avg_reading      0.537752         0.869261          1.000000   \n",
       "hour                  0.335348         0.016805          0.020632   \n",
       "week_avg_sunset_hr    0.289345         0.474407          0.496088   \n",
       "day_avg_sunset_hr     0.280387         0.457473          0.473132   \n",
       "week_avg_dewpoint     0.241993         0.397084          0.445747   \n",
       "week_avg_windchill    0.239797         0.387978          0.436514   \n",
       "week_avg_feelslike    0.239393         0.387338          0.436000   \n",
       "week_avg_heatindex    0.238363         0.386917          0.441748   \n",
       "week_avg_temp         0.236778         0.385581          0.442421   \n",
       "week_avg_mintemp      0.234687         0.391613          0.461932   \n",
       "day_avg_mintemp       0.226490         0.379066          0.432498   \n",
       "week_avg_maxtemp      0.223379         0.367994          0.404759   \n",
       "week_avg_uvindex      0.218208         0.360649          0.395077   \n",
       "day_avg_windchill     0.213159         0.361364          0.408468   \n",
       "day_avg_feelslike     0.212822         0.360822          0.408125   \n",
       "day_avg_heatindex     0.210423         0.358737          0.413228   \n",
       "day_avg_temp          0.210208         0.359164          0.415279   \n",
       "day_avg_dewpoint      0.206195         0.349859          0.399792   \n",
       "week_avg_sunhour      0.205086         0.336090          0.349772   \n",
       "day_avg_maxtemp       0.204917         0.338584          0.381207   \n",
       "day_avg_uvindex       0.193354         0.329526          0.350469   \n",
       "day_avg_sunhour       0.188191         0.309826          0.311138   \n",
       "Day_type_as_int       0.189202        -0.262337         -0.106484   \n",
       "day_avg_sunrise_hr    0.293742        -0.480405         -0.501881   \n",
       "day_avg_sunrise_min   0.293742        -0.480405         -0.501881   \n",
       "week_avg_sunrise_hr   0.306035        -0.501050         -0.524205   \n",
       "week_avg_sunrise_min  0.306035        -0.501050         -0.524205   \n",
       "\n",
       "                      day_avg_maxtemp  week_avg_maxtemp  day_avg_mintemp  \\\n",
       "reading                      0.204917          0.223379         0.226490   \n",
       "day_avg_reading              0.338584          0.367994         0.379066   \n",
       "week_avg_reading             0.381207          0.404759         0.432498   \n",
       "hour                         0.001300          0.002295        -0.000512   \n",
       "week_avg_sunset_hr           0.740185          0.776557         0.530093   \n",
       "day_avg_sunset_hr            0.715190          0.743256         0.493586   \n",
       "week_avg_dewpoint            0.807294          0.934835         0.822502   \n",
       "week_avg_windchill           0.855587          0.976085         0.809055   \n",
       "week_avg_feelslike           0.855454          0.975984         0.809178   \n",
       "week_avg_heatindex           0.846157          0.971681         0.818924   \n",
       "week_avg_temp                0.847666          0.973018         0.820206   \n",
       "week_avg_mintemp             0.776365          0.902945         0.837436   \n",
       "day_avg_mintemp              0.861605          0.781017         1.000000   \n",
       "week_avg_maxtemp             0.884754          1.000000         0.781017   \n",
       "week_avg_uvindex             0.845870          0.949715         0.747652   \n",
       "day_avg_windchill            0.961953          0.881796         0.905942   \n",
       "day_avg_feelslike            0.962176          0.881185         0.905904   \n",
       "day_avg_heatindex            0.961054          0.872039         0.928573   \n",
       "day_avg_temp                 0.960877          0.869199         0.938649   \n",
       "day_avg_dewpoint             0.899765          0.807959         0.917018   \n",
       "week_avg_sunhour             0.694063          0.714330         0.445027   \n",
       "day_avg_maxtemp              1.000000          0.884754         0.861605   \n",
       "day_avg_uvindex              0.874621          0.781366         0.733839   \n",
       "day_avg_sunhour              0.606229          0.616277         0.328401   \n",
       "Day_type_as_int              0.024258         -0.005796        -0.011190   \n",
       "day_avg_sunrise_hr          -0.722733         -0.769977        -0.523234   \n",
       "day_avg_sunrise_min         -0.722733         -0.769977        -0.523234   \n",
       "week_avg_sunrise_hr         -0.739911         -0.787543        -0.548903   \n",
       "week_avg_sunrise_min        -0.739911         -0.787543        -0.548903   \n",
       "\n",
       "                      week_avg_mintemp  day_avg_snow  week_avg_snow  \\\n",
       "reading                       0.234687      0.023012       0.028832   \n",
       "day_avg_reading               0.391613      0.024919       0.049471   \n",
       "week_avg_reading              0.461932      0.001840       0.029085   \n",
       "hour                          0.001658     -0.000502       0.003806   \n",
       "week_avg_sunset_hr            0.560914     -0.067602      -0.130147   \n",
       "day_avg_sunset_hr             0.517201     -0.058424      -0.119625   \n",
       "week_avg_dewpoint             0.974610     -0.142405      -0.343206   \n",
       "week_avg_windchill            0.947995     -0.134871      -0.324467   \n",
       "week_avg_feelslike            0.948215     -0.134624      -0.323827   \n",
       "week_avg_heatindex            0.964164     -0.139292      -0.327886   \n",
       "week_avg_temp                 0.966837     -0.140540      -0.331191   \n",
       "week_avg_mintemp              1.000000     -0.143012      -0.328774   \n",
       "day_avg_mintemp               0.837436     -0.160403      -0.279830   \n",
       "week_avg_maxtemp              0.902945     -0.136741      -0.318507   \n",
       "week_avg_uvindex              0.847447     -0.166102      -0.335365   \n",
       "day_avg_windchill             0.835460     -0.169717      -0.298495   \n",
       "day_avg_feelslike             0.835199     -0.169282      -0.297780   \n",
       "day_avg_heatindex             0.840538     -0.169485      -0.295549   \n",
       "day_avg_temp                  0.839086     -0.171503      -0.298036   \n",
       "day_avg_dewpoint              0.816186     -0.175404      -0.289747   \n",
       "week_avg_sunhour              0.452878     -0.077554      -0.130591   \n",
       "day_avg_maxtemp               0.776365     -0.173640      -0.276800   \n",
       "day_avg_uvindex               0.674645     -0.187128      -0.260289   \n",
       "day_avg_sunhour               0.378477     -0.066769      -0.101416   \n",
       "Day_type_as_int              -0.006473     -0.059621      -0.018816   \n",
       "day_avg_sunrise_hr           -0.561754      0.099517       0.153393   \n",
       "day_avg_sunrise_min          -0.561754      0.099517       0.153393   \n",
       "week_avg_sunrise_hr          -0.593415      0.101388       0.187781   \n",
       "week_avg_sunrise_min         -0.593415      0.101388       0.187781   \n",
       "\n",
       "                      day_avg_sunhour  ...  week_avg_as_client  \\\n",
       "reading                      0.188191  ...           -0.010859   \n",
       "day_avg_reading              0.309826  ...           -0.022856   \n",
       "week_avg_reading             0.311138  ...           -0.056166   \n",
       "hour                         0.000337  ...            0.001408   \n",
       "week_avg_sunset_hr           0.823043  ...           -0.370882   \n",
       "day_avg_sunset_hr            0.828893  ...           -0.357407   \n",
       "week_avg_dewpoint            0.419947  ...           -0.557556   \n",
       "week_avg_windchill           0.532424  ...           -0.576238   \n",
       "week_avg_feelslike           0.532105  ...           -0.576847   \n",
       "week_avg_heatindex           0.503759  ...           -0.559063   \n",
       "week_avg_temp                0.507836  ...           -0.560718   \n",
       "week_avg_mintemp             0.378477  ...           -0.542480   \n",
       "day_avg_mintemp              0.328401  ...           -0.468744   \n",
       "week_avg_maxtemp             0.616277  ...           -0.540220   \n",
       "week_avg_uvindex             0.617899  ...           -0.518686   \n",
       "day_avg_windchill            0.518522  ...           -0.538732   \n",
       "day_avg_feelslike            0.518536  ...           -0.538962   \n",
       "day_avg_heatindex            0.468925  ...           -0.514488   \n",
       "day_avg_temp                 0.469903  ...           -0.511592   \n",
       "day_avg_dewpoint             0.337123  ...           -0.489790   \n",
       "week_avg_sunhour             0.900249  ...           -0.464352   \n",
       "day_avg_maxtemp              0.606229  ...           -0.502095   \n",
       "day_avg_uvindex              0.621829  ...           -0.442816   \n",
       "day_avg_sunhour              1.000000  ...           -0.401215   \n",
       "Day_type_as_int             -0.009252  ...           -0.051715   \n",
       "day_avg_sunrise_hr          -0.814917  ...            0.321434   \n",
       "day_avg_sunrise_min         -0.814917  ...            0.321434   \n",
       "week_avg_sunrise_hr         -0.806576  ...            0.344027   \n",
       "week_avg_sunrise_min        -0.806576  ...            0.344027   \n",
       "\n",
       "                      day_avg_auth_client  week_avg_auth_client  \\\n",
       "reading                         -0.002215             -0.011734   \n",
       "day_avg_reading                 -0.005689             -0.023453   \n",
       "week_avg_reading                -0.101264             -0.058036   \n",
       "hour                            -0.001594              0.001186   \n",
       "week_avg_sunset_hr              -0.364725             -0.370186   \n",
       "day_avg_sunset_hr               -0.355260             -0.356601   \n",
       "week_avg_dewpoint               -0.529398             -0.558937   \n",
       "week_avg_windchill              -0.547587             -0.577732   \n",
       "week_avg_feelslike              -0.548243             -0.578340   \n",
       "week_avg_heatindex              -0.531371             -0.560527   \n",
       "week_avg_temp                   -0.534665             -0.562142   \n",
       "week_avg_mintemp                -0.524206             -0.544106   \n",
       "day_avg_mintemp                 -0.466607             -0.470018   \n",
       "week_avg_maxtemp                -0.511816             -0.541194   \n",
       "week_avg_uvindex                -0.508019             -0.519531   \n",
       "day_avg_windchill               -0.526756             -0.539574   \n",
       "day_avg_feelslike               -0.527048             -0.539805   \n",
       "day_avg_heatindex               -0.506393             -0.515382   \n",
       "day_avg_temp                    -0.505765             -0.512474   \n",
       "day_avg_dewpoint                -0.485202             -0.490636   \n",
       "week_avg_sunhour                -0.474436             -0.463565   \n",
       "day_avg_maxtemp                 -0.487376             -0.502675   \n",
       "day_avg_uvindex                 -0.427006             -0.443274   \n",
       "day_avg_sunhour                 -0.408132             -0.400295   \n",
       "Day_type_as_int                 -0.140686             -0.050895   \n",
       "day_avg_sunrise_hr               0.329282              0.320497   \n",
       "day_avg_sunrise_min              0.329282              0.320497   \n",
       "week_avg_sunrise_hr              0.350775              0.343062   \n",
       "week_avg_sunrise_min             0.350775              0.343062   \n",
       "\n",
       "                      Day_type_as_int      Year     Month       Day      hour  \\\n",
       "reading                     -0.189202  0.131888 -0.019445 -0.033681  0.335348   \n",
       "day_avg_reading             -0.262337  0.212361 -0.024544 -0.048043  0.016805   \n",
       "week_avg_reading            -0.106484  0.193533  0.024376  0.005952  0.020632   \n",
       "hour                        -0.000580 -0.001351 -0.000135 -0.003489  1.000000   \n",
       "week_avg_sunset_hr          -0.012323  0.554331 -0.244357  0.059472  0.000677   \n",
       "day_avg_sunset_hr           -0.010841  0.571146 -0.290125  0.033062  0.000705   \n",
       "week_avg_dewpoint           -0.002401  0.138944  0.290586  0.111854  0.003419   \n",
       "week_avg_windchill          -0.007420  0.212323  0.219631  0.130534  0.006261   \n",
       "week_avg_feelslike          -0.007236  0.212412  0.219271  0.131433  0.006258   \n",
       "week_avg_heatindex          -0.003697  0.174012  0.261408  0.130497  0.005948   \n",
       "week_avg_temp               -0.003319  0.173005  0.262671  0.132393  0.005521   \n",
       "week_avg_mintemp            -0.006473  0.044666  0.350418  0.150269  0.001658   \n",
       "day_avg_mintemp             -0.011190  0.032750  0.292447  0.112697 -0.000512   \n",
       "week_avg_maxtemp            -0.005796  0.275693  0.155964  0.126849  0.002295   \n",
       "week_avg_uvindex            -0.014770  0.140796  0.242984  0.111912  0.002576   \n",
       "day_avg_windchill            0.020439  0.197939  0.181852  0.140167  0.001044   \n",
       "day_avg_feelslike            0.020965  0.197930  0.181440  0.141187  0.001033   \n",
       "day_avg_heatindex            0.026912  0.159265  0.215840  0.127536  0.001526   \n",
       "day_avg_temp                 0.024622  0.156584  0.216534  0.127857  0.002171   \n",
       "day_avg_dewpoint             0.028749  0.114187  0.241234  0.115384 -0.000271   \n",
       "week_avg_sunhour             0.000403  0.437496 -0.174393  0.067824  0.000846   \n",
       "day_avg_maxtemp              0.024258  0.258379  0.112700  0.137701  0.001300   \n",
       "day_avg_uvindex              0.001947  0.138374  0.171633  0.134628  0.002533   \n",
       "day_avg_sunhour             -0.009252  0.417509 -0.197362  0.093434  0.000337   \n",
       "Day_type_as_int              1.000000 -0.033298  0.005472  0.035001 -0.000580   \n",
       "day_avg_sunrise_hr           0.009244 -0.455164  0.095349 -0.016715 -0.000840   \n",
       "day_avg_sunrise_min          0.009244 -0.455164  0.095349 -0.016715 -0.000840   \n",
       "week_avg_sunrise_hr          0.009930 -0.436862  0.053171 -0.043117 -0.000566   \n",
       "week_avg_sunrise_min         0.009930 -0.436862  0.053171 -0.043117 -0.000566   \n",
       "\n",
       "                        minute  Term_as_int  \n",
       "reading              -0.006055    -0.081390  \n",
       "day_avg_reading      -0.000519    -0.120569  \n",
       "week_avg_reading     -0.000964    -0.073634  \n",
       "hour                 -0.000314     0.000537  \n",
       "week_avg_sunset_hr    0.000230     0.285200  \n",
       "day_avg_sunset_hr     0.000310     0.283898  \n",
       "week_avg_dewpoint    -0.001107     0.384429  \n",
       "week_avg_windchill   -0.001059     0.426308  \n",
       "week_avg_feelslike   -0.001060     0.426903  \n",
       "week_avg_heatindex   -0.000991     0.407384  \n",
       "week_avg_temp        -0.001009     0.410719  \n",
       "week_avg_mintemp     -0.001132     0.378246  \n",
       "day_avg_mintemp      -0.001023     0.349717  \n",
       "week_avg_maxtemp     -0.000850     0.421848  \n",
       "week_avg_uvindex     -0.000845     0.436885  \n",
       "day_avg_windchill    -0.001014     0.414733  \n",
       "day_avg_feelslike    -0.001012     0.415039  \n",
       "day_avg_heatindex    -0.000969     0.398544  \n",
       "day_avg_temp         -0.001003     0.398692  \n",
       "day_avg_dewpoint     -0.000971     0.373342  \n",
       "week_avg_sunhour     -0.000118     0.450651  \n",
       "day_avg_maxtemp      -0.000883     0.402953  \n",
       "day_avg_uvindex      -0.000791     0.356827  \n",
       "day_avg_sunhour       0.000175     0.380821  \n",
       "Day_type_as_int      -0.000697     0.096762  \n",
       "day_avg_sunrise_hr    0.000031    -0.239723  \n",
       "day_avg_sunrise_min   0.000031    -0.239723  \n",
       "week_avg_sunrise_hr   0.000146    -0.253482  \n",
       "week_avg_sunrise_min  0.000146    -0.253482  \n",
       "\n",
       "[29 rows x 60 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations.reading=correlations.reading.abs()\n",
    "correlations.reading.mean()\n",
    "read_correlations=correlations[correlations['reading']>0.16]\n",
    "read_correlations.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['reading', 'day_avg_reading', 'week_avg_reading', 'hour',\n",
      "       'week_avg_sunset_hr', 'day_avg_sunset_hr', 'week_avg_dewpoint',\n",
      "       'week_avg_windchill', 'week_avg_feelslike', 'week_avg_heatindex',\n",
      "       'week_avg_temp', 'week_avg_mintemp', 'day_avg_mintemp',\n",
      "       'week_avg_maxtemp', 'week_avg_uvindex', 'day_avg_windchill',\n",
      "       'day_avg_feelslike', 'day_avg_heatindex', 'day_avg_temp',\n",
      "       'day_avg_dewpoint', 'week_avg_sunhour', 'day_avg_maxtemp',\n",
      "       'day_avg_uvindex', 'day_avg_sunhour', 'Day_type_as_int',\n",
      "       'day_avg_sunrise_hr', 'day_avg_sunrise_min', 'week_avg_sunrise_hr',\n",
      "       'week_avg_sunrise_min'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(read_correlations.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 training \n",
    "#very short forecast horizon \n",
    "          \n",
    "         \n",
    "features=[ 'day_avg_reading', 'week_avg_reading', 'hour',\n",
    "          'week_avg_sunset_hr', 'day_avg_sunset_hr', 'week_avg_dewpoint',\n",
    "          'week_avg_windchill', 'week_avg_feelslike', 'week_avg_heatindex',\n",
    "          'week_avg_temp', 'week_avg_mintemp', 'day_avg_mintemp',\n",
    "          'week_avg_maxtemp', 'week_avg_uvindex', 'day_avg_windchill',\n",
    "          'day_avg_feelslike', 'day_avg_heatindex', 'day_avg_temp',\n",
    "          'day_avg_dewpoint', 'week_avg_sunhour', 'day_avg_maxtemp',\n",
    "          'day_avg_uvindex', 'day_avg_sunhour',\n",
    "          'day_avg_sunrise_hr', 'day_avg_sunrise_min', 'week_avg_sunrise_hr',\n",
    "          'week_avg_sunrise_min' ,'day_avg_as_client','week_avg_as_client',\n",
    "          'day_avg_auth_client','week_avg_auth_client','Day_type_as_int', \n",
    "          'Month', 'Day','minute', 'Term_as_int', 'Year']\n",
    "\n",
    "features_no_occ=['day_avg_reading', 'week_avg_reading', 'hour',\n",
    "          'week_avg_sunset_hr', 'day_avg_sunset_hr', 'week_avg_dewpoint',\n",
    "          'week_avg_windchill', 'week_avg_feelslike', 'week_avg_heatindex',\n",
    "          'week_avg_temp', 'week_avg_mintemp', 'day_avg_mintemp',\n",
    "          'week_avg_maxtemp', 'week_avg_uvindex', 'day_avg_windchill',\n",
    "          'day_avg_feelslike', 'day_avg_heatindex', 'day_avg_temp',\n",
    "          'day_avg_dewpoint', 'week_avg_sunhour', 'day_avg_maxtemp',\n",
    "          'day_avg_uvindex', 'day_avg_sunhour',\n",
    "          'day_avg_sunrise_hr', 'day_avg_sunrise_min', 'week_avg_sunrise_hr',\n",
    "          'week_avg_sunrise_min','Day_type_as_int', \n",
    "          'Month', 'Day','minute', 'Term_as_int', 'Year']\n",
    "train_data_bow['future_reading']=train_data_bow['reading']\n",
    "train_data_lec['future_reading']=train_data_lec['reading']\n",
    "train_data=train_data_bow.append(train_data_lec)\n",
    "X1=train_data[features]\n",
    "y1=train_data['future_reading']\n",
    "\n",
    "\n",
    "train_data_no_occ['future_reading']=train_data_no_occ['reading']\n",
    "ltrain_data_no_occ['future_reading']=ltrain_data_no_occ['reading']\n",
    "train_data_no_occ_1=train_data_no_occ.append(ltrain_data_no_occ)\n",
    "X1no=train_data_no_occ[features_no_occ]\n",
    "y1no=train_data_no_occ['future_reading']\n",
    "\n",
    "\n",
    "\n",
    "train_X1, val_X1, train_y1, val_y1 = train_test_split(X1, y1, random_state = 0)\n",
    "train_X1no, val_X1no, train_y1no, val_y1no=train_test_split(X1no, y1no, random_state = 0)\n",
    "\n",
    "# model2 training\n",
    "# approx few hours forecast horizon \n",
    "\n",
    "shift_train_data_bow1=train_data_bow.shift(10)\n",
    "shift_train_data_bow1['day_type_int']=train_data_bow['Day_type_as_int']\n",
    "shift_train_data_bow1['Year']=train_data_bow['Year']\n",
    "shift_train_data_bow1['Month']=train_data_bow['Month']\n",
    "shift_train_data_bow1['day']=train_data_bow['Day']\n",
    "shift_train_data_bow1['hour']=train_data_bow['hour']\n",
    "shift_train_data_bow1['minute']=train_data_bow['minute']\n",
    "shift_train_data_bow1['term_int']=train_data_bow['Term_as_int']\n",
    "shift_train_data_bow1['future_reading']=train_data_bow['future_reading']\n",
    "\n",
    "shift_train_data_bow1=shift_train_data_bow1.dropna(subset=['Year', 'day_avg_reading'])\n",
    "\n",
    "shift_train_data_lec1=train_data_lec.shift(10)\n",
    "shift_train_data_lec1['day_type_int']=train_data_lec['Day_type_as_int']\n",
    "shift_train_data_lec1['Year']=train_data_lec['Year']\n",
    "shift_train_data_lec1['Month']=train_data_lec['Month']\n",
    "shift_train_data_lec1['day']=train_data_lec['Day']\n",
    "shift_train_data_lec1['hour']=train_data_lec['hour']\n",
    "shift_train_data_lec1['minute']=train_data_lec['minute']\n",
    "shift_train_data_lec1['term_int']=train_data_lec['Term_as_int']\n",
    "shift_train_data_lec1['future_reading']=train_data_lec['future_reading']\n",
    "\n",
    "shift_train_data_lec1=shift_train_data_lec1.dropna(subset=['Year', 'day_avg_reading'])\n",
    "shift_train_data1=shift_train_data_bow1.append(shift_train_data_lec1)\n",
    "\n",
    "X2=shift_train_data1[features]\n",
    "y2=shift_train_data1['future_reading']\n",
    "\n",
    "train_X2, val_X2, train_y2, val_y2 = train_test_split(X2, y2, random_state = 0)\n",
    "\n",
    "shift_train_data1no=train_data_no_occ.shift(10)\n",
    "shift_train_data1no['day_type_int']=train_data_no_occ['Day_type_as_int']\n",
    "shift_train_data1no['Year']=train_data_no_occ['Year']\n",
    "shift_train_data1no['Month']=train_data_no_occ['Month']\n",
    "shift_train_data1no['day']=train_data_no_occ['Day']\n",
    "shift_train_data1no['hour']=train_data_no_occ['hour']\n",
    "shift_train_data1no['minute']=train_data_no_occ['minute']\n",
    "shift_train_data1no['term_int']=train_data_no_occ['Term_as_int']\n",
    "shift_train_data1no['future_reading']=train_data_no_occ['future_reading']\n",
    "\n",
    "shift_train_data1no=shift_train_data1no.dropna(subset=['Year', 'day_avg_reading'])\n",
    "\n",
    "\n",
    "lshift_train_data1no=ltrain_data_no_occ.shift(10)\n",
    "lshift_train_data1no['day_type_int']=ltrain_data_no_occ['Day_type_as_int']\n",
    "lshift_train_data1no['Year']=ltrain_data_no_occ['Year']\n",
    "lshift_train_data1no['Month']=ltrain_data_no_occ['Month']\n",
    "lshift_train_data1no['day']=ltrain_data_no_occ['Day']\n",
    "lshift_train_data1no['hour']=ltrain_data_no_occ['hour']\n",
    "lshift_train_data1no['minute']=ltrain_data_no_occ['minute']\n",
    "lshift_train_data1no['term_int']=ltrain_data_no_occ['Term_as_int']\n",
    "lshift_train_data1no['future_reading']=ltrain_data_no_occ['future_reading']\n",
    "\n",
    "lshift_train_data1no=shift_train_data1no.dropna(subset=['Year', 'day_avg_reading'])\n",
    "\n",
    "shift_train_data1no=shift_train_data1no.append(lshift_train_data1no)\n",
    "\n",
    "X2no=shift_train_data1no[features_no_occ]\n",
    "y2no=shift_train_data1no['future_reading']\n",
    "\n",
    "train_X2no, val_X2no, train_y2no, val_y2no = train_test_split(X2no, y2no, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "# model3 training\n",
    "# approx 10 hours forecast horizon \n",
    "\n",
    "shift_train_data2=train_data_bow.shift(50)\n",
    "shift_train_data2['day_type_int']=train_data_bow['Day_type_as_int']\n",
    "shift_train_data2['Year']=train_data_bow['Year']\n",
    "shift_train_data2['Month']=train_data_bow['Month']\n",
    "shift_train_data2['day']=train_data_bow['Day']\n",
    "shift_train_data2['hour']=train_data_bow['hour']\n",
    "shift_train_data2['minute']=train_data_bow['minute']\n",
    "shift_train_data2['term_int']=train_data_bow['Term_as_int']\n",
    "shift_train_data2['future_reading']=train_data_bow['future_reading']\n",
    "\n",
    "shift_train_data2=shift_train_data2.dropna()\n",
    "\n",
    "lshift_train_data2=train_data_lec.shift(50)\n",
    "lshift_train_data2['day_type_int']=train_data_lec['Day_type_as_int']\n",
    "lshift_train_data2['Year']=train_data_lec['Year']\n",
    "lshift_train_data2['Month']=train_data_lec['Month']\n",
    "lshift_train_data2['day']=train_data_lec['Day']\n",
    "lshift_train_data2['hour']=train_data_lec['hour']\n",
    "lshift_train_data2['minute']=train_data_lec['minute']\n",
    "lshift_train_data2['term_int']=train_data_lec['Term_as_int']\n",
    "lshift_train_data2['future_reading']=train_data_lec['future_reading']\n",
    "\n",
    "lshift_train_data2=lshift_train_data2.dropna()\n",
    "shift_train_data2=shift_train_data2.append(lshift_train_data2)\n",
    "\n",
    "X3=shift_train_data2[features]\n",
    "y3=shift_train_data2['future_reading']\n",
    "\n",
    "train_X3, val_X3, train_y3, val_y3 = train_test_split(X3, y3, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "shift_train_data2no=train_data_no_occ.shift(50)\n",
    "shift_train_data2no['day_type_int']=train_data_no_occ['Day_type_as_int']\n",
    "shift_train_data2no['Year']=train_data_no_occ['Year']\n",
    "shift_train_data2no['Month']=train_data_no_occ['Month']\n",
    "shift_train_data2no['day']=train_data_no_occ['Day']\n",
    "shift_train_data2no['hour']=train_data_no_occ['hour']\n",
    "shift_train_data2no['minute']=train_data_no_occ['minute']\n",
    "shift_train_data2no['term_int']=train_data_no_occ['Term_as_int']\n",
    "shift_train_data2no['future_reading']=train_data_no_occ['future_reading']\n",
    "\n",
    "shift_train_data2no=shift_train_data2no.dropna()\n",
    "\n",
    "lshift_train_data2no=ltrain_data_no_occ.shift(50)\n",
    "lshift_train_data2no['day_type_int']=ltrain_data_no_occ['Day_type_as_int']\n",
    "lshift_train_data2no['Year']=ltrain_data_no_occ['Year']\n",
    "lshift_train_data2no['Month']=ltrain_data_no_occ['Month']\n",
    "lshift_train_data2no['day']=ltrain_data_no_occ['Day']\n",
    "lshift_train_data2no['hour']=ltrain_data_no_occ['hour']\n",
    "lshift_train_data2no['minute']=ltrain_data_no_occ['minute']\n",
    "lshift_train_data2no['term_int']=ltrain_data_no_occ['Term_as_int']\n",
    "lshift_train_data2no['future_reading']=ltrain_data_no_occ['future_reading']\n",
    "\n",
    "lshift_train_data2no=lshift_train_data2no.dropna()\n",
    "\n",
    "shift_train_data2no=shift_train_data2no.append(lshift_train_data2no)\n",
    "y3no=shift_train_data2no['future_reading']\n",
    "\n",
    "X3no=shift_train_data2no[features_no_occ]\n",
    "\n",
    "train_X3no, val_X3no, train_y3no, val_y3no = train_test_split(X3no, y3no, random_state = 0)\n",
    "\n",
    "# model4 training\n",
    "# approx 15 hours forecast horizon \n",
    "\n",
    "shift_train_data3=train_data_bow.shift(100)\n",
    "shift_train_data3['day_type_int']=train_data_bow['Day_type_as_int']\n",
    "shift_train_data3['Year']=train_data_bow['Year']\n",
    "shift_train_data3['Month']=train_data_bow['Month']\n",
    "shift_train_data3['day']=train_data_bow['Day']\n",
    "shift_train_data3['hour']=train_data_bow['hour']\n",
    "shift_train_data3['minute']=train_data_bow['minute']\n",
    "shift_train_data3['term_int']=train_data_bow['Term_as_int']\n",
    "shift_train_data3['future_reading']=train_data_bow['future_reading']\n",
    "\n",
    "shift_train_data3=shift_train_data3.dropna()\n",
    "\n",
    "lshift_train_data3=train_data_lec.shift(100)\n",
    "lshift_train_data3['day_type_int']=train_data_lec['Day_type_as_int']\n",
    "lshift_train_data3['Year']=train_data_lec['Year']\n",
    "lshift_train_data3['Month']=train_data_lec['Month']\n",
    "lshift_train_data3['day']=train_data_lec['Day']\n",
    "lshift_train_data3['hour']=train_data_lec['hour']\n",
    "lshift_train_data3['minute']=train_data_lec['minute']\n",
    "lshift_train_data3['term_int']=train_data_lec['Term_as_int']\n",
    "lshift_train_data3['future_reading']=train_data_lec['future_reading']\n",
    "\n",
    "lshift_train_data3=lshift_train_data3.dropna()\n",
    "shift_train_data3=shift_train_data3.append(lshift_train_data3)\n",
    "\n",
    "X4=shift_train_data3[features]\n",
    "y4=shift_train_data3['future_reading']\n",
    "\n",
    "train_X4, val_X4, train_y4, val_y4 = train_test_split(X4, y4, random_state = 0)\n",
    "\n",
    "shift_train_data3no=train_data_no_occ.shift(100)\n",
    "shift_train_data3no['day_type_int']=train_data_no_occ['Day_type_as_int']\n",
    "shift_train_data3no['Year']=train_data_no_occ['Year']\n",
    "shift_train_data3no['Month']=train_data_no_occ['Month']\n",
    "shift_train_data3no['day']=train_data_no_occ['Day']\n",
    "shift_train_data3no['hour']=train_data_no_occ['hour']\n",
    "shift_train_data3no['minute']=train_data_no_occ['minute']\n",
    "shift_train_data3no['term_int']=train_data_no_occ['Term_as_int']\n",
    "shift_train_data3no['future_reading']=train_data_no_occ['future_reading']\n",
    "\n",
    "shift_train_data3no=shift_train_data3no.dropna()\n",
    "\n",
    "lshift_train_data3no=ltrain_data_no_occ.shift(100)\n",
    "lshift_train_data3no['day_type_int']=ltrain_data_no_occ['Day_type_as_int']\n",
    "lshift_train_data3no['Year']=ltrain_data_no_occ['Year']\n",
    "lshift_train_data3no['Month']=ltrain_data_no_occ['Month']\n",
    "lshift_train_data3no['day']=ltrain_data_no_occ['Day']\n",
    "lshift_train_data3no['hour']=ltrain_data_no_occ['hour']\n",
    "lshift_train_data3no['minute']=ltrain_data_no_occ['minute']\n",
    "lshift_train_data3no['term_int']=ltrain_data_no_occ['Term_as_int']\n",
    "lshift_train_data3no['future_reading']=ltrain_data_no_occ['future_reading']\n",
    "\n",
    "lshift_train_data3no=lshift_train_data3no.dropna()\n",
    "shift_train_data3no=shift_train_data3no.append(lshift_train_data3no)\n",
    "\n",
    "y4no=shift_train_data3no['future_reading']\n",
    "\n",
    "X4no=shift_train_data3no[features_no_occ]\n",
    "\n",
    "train_X4no, val_X4no, train_y4no, val_y4no = train_test_split(X4no, y4no, random_state = 0)\n",
    "\n",
    "# model5 training\n",
    "# approx 1 day forecast horizon \n",
    "\n",
    "shift_train_data4=train_data_bow.shift(140)\n",
    "shift_train_data4['day_type_int']=train_data_bow['Day_type_as_int']\n",
    "shift_train_data4['Year']=train_data_bow['Year']\n",
    "shift_train_data4['Month']=train_data_bow['Month']\n",
    "shift_train_data4['day']=train_data_bow['Day']\n",
    "shift_train_data4['hour']=train_data_bow['hour']\n",
    "shift_train_data4['minute']=train_data_bow['minute']\n",
    "shift_train_data4['term_int']=train_data_bow['Term_as_int']\n",
    "shift_train_data4['future_reading']=train_data_bow['future_reading']\n",
    "\n",
    "shift_train_data4=shift_train_data4.dropna()\n",
    "\n",
    "lshift_train_data4=train_data_lec.shift(140)\n",
    "lshift_train_data4['day_type_int']=train_data_lec['Day_type_as_int']\n",
    "lshift_train_data4['Year']=train_data_lec['Year']\n",
    "lshift_train_data4['Month']=train_data_lec['Month']\n",
    "lshift_train_data4['day']=train_data_lec['Day']\n",
    "lshift_train_data4['hour']=train_data_lec['hour']\n",
    "lshift_train_data4['minute']=train_data_lec['minute']\n",
    "lshift_train_data4['term_int']=train_data_lec['Term_as_int']\n",
    "lshift_train_data4['future_reading']=train_data_lec['future_reading']\n",
    "\n",
    "lshift_train_data4=lshift_train_data4.dropna()\n",
    "shift_train_data4=shift_train_data4.append(lshift_train_data4)\n",
    "\n",
    "X5=shift_train_data4[features]\n",
    "y5=shift_train_data4['future_reading']\n",
    "\n",
    "train_X5, val_X5, train_y5, val_y5 = train_test_split(X5, y5, random_state = 0)\n",
    "\n",
    "shift_train_data4no=train_data_no_occ.shift(140)\n",
    "shift_train_data4no['day_type_int']=train_data_no_occ['Day_type_as_int']\n",
    "shift_train_data4no['Year']=train_data_no_occ['Year']\n",
    "shift_train_data4no['Month']=train_data_no_occ['Month']\n",
    "shift_train_data4no['day']=train_data_no_occ['Day']\n",
    "shift_train_data4no['hour']=train_data_no_occ['hour']\n",
    "shift_train_data4no['minute']=train_data_no_occ['minute']\n",
    "shift_train_data4no['term_int']=train_data_no_occ['Term_as_int']\n",
    "shift_train_data4no['future_reading']=train_data_no_occ['future_reading']\n",
    "\n",
    "shift_train_data4no=shift_train_data4no.dropna()\n",
    "\n",
    "lshift_train_data4no=ltrain_data_no_occ.shift(140)\n",
    "lshift_train_data4no['day_type_int']=ltrain_data_no_occ['Day_type_as_int']\n",
    "lshift_train_data4no['Year']=ltrain_data_no_occ['Year']\n",
    "lshift_train_data4no['Month']=ltrain_data_no_occ['Month']\n",
    "lshift_train_data4no['day']=ltrain_data_no_occ['Day']\n",
    "lshift_train_data4no['hour']=ltrain_data_no_occ['hour']\n",
    "lshift_train_data4no['minute']=ltrain_data_no_occ['minute']\n",
    "lshift_train_data4no['term_int']=ltrain_data_no_occ['Term_as_int']\n",
    "lshift_train_data4no['future_reading']=ltrain_data_no_occ['future_reading']\n",
    "\n",
    "lshift_train_data4no=lshift_train_data4no.dropna()\n",
    "shift_train_data4no=shift_train_data4no.append(lshift_train_data4no)\n",
    "\n",
    "y5no=shift_train_data4no['future_reading']\n",
    "\n",
    "X5no=shift_train_data4no[features_no_occ]\n",
    "\n",
    "train_X5no, val_X5no, train_y5no, val_y5no = train_test_split(X5no, y5no, random_state = 0)\n",
    "\n",
    "# model6 training\n",
    "# approx day and a half forecast horizon \n",
    "\n",
    "shift_train_data5=train_data_bow.shift(200)\n",
    "shift_train_data5['day_type_int']=train_data_bow['Day_type_as_int']\n",
    "shift_train_data5['Year']=train_data_bow['Year']\n",
    "shift_train_data5['Month']=train_data_bow['Month']\n",
    "shift_train_data5['day']=train_data_bow['Day']\n",
    "shift_train_data5['hour']=train_data_bow['hour']\n",
    "shift_train_data5['minute']=train_data_bow['minute']\n",
    "shift_train_data5['term_int']=train_data_bow['Term_as_int']\n",
    "shift_train_data5['future_reading']=train_data_bow['future_reading']\n",
    "\n",
    "shift_train_data5=shift_train_data5.dropna()\n",
    "\n",
    "lshift_train_data5=train_data_lec.shift(200)\n",
    "lshift_train_data5['day_type_int']=train_data_lec['Day_type_as_int']\n",
    "lshift_train_data5['Year']=train_data_lec['Year']\n",
    "lshift_train_data5['Month']=train_data_lec['Month']\n",
    "lshift_train_data5['day']=train_data_lec['Day']\n",
    "lshift_train_data5['hour']=train_data_lec['hour']\n",
    "lshift_train_data5['minute']=train_data_lec['minute']\n",
    "lshift_train_data5['term_int']=train_data_lec['Term_as_int']\n",
    "lshift_train_data5['future_reading']=train_data_lec['future_reading']\n",
    "\n",
    "lshift_train_data5=lshift_train_data5.dropna()\n",
    "shift_train_data5=shift_train_data5.append(lshift_train_data5)\n",
    "\n",
    "X6=shift_train_data5[features]\n",
    "y6=shift_train_data5['future_reading']\n",
    "\n",
    "train_X6, val_X6, train_y6, val_y6 = train_test_split(X6, y6, random_state = 0)\n",
    "\n",
    "shift_train_data5no=train_data_no_occ.shift(200)\n",
    "shift_train_data5no['day_type_int']=train_data_no_occ['Day_type_as_int']\n",
    "shift_train_data5no['Year']=train_data_no_occ['Year']\n",
    "shift_train_data5no['Month']=train_data_no_occ['Month']\n",
    "shift_train_data5no['day']=train_data_no_occ['Day']\n",
    "shift_train_data5no['hour']=train_data_no_occ['hour']\n",
    "shift_train_data5no['minute']=train_data_no_occ['minute']\n",
    "shift_train_data5no['term_int']=train_data_no_occ['Term_as_int']\n",
    "shift_train_data5no['future_reading']=train_data_no_occ['future_reading']\n",
    "\n",
    "shift_train_data5no=shift_train_data5no.dropna()\n",
    "\n",
    "lshift_train_data5no=ltrain_data_no_occ.shift(200)\n",
    "lshift_train_data5no['day_type_int']=ltrain_data_no_occ['Day_type_as_int']\n",
    "lshift_train_data5no['Year']=ltrain_data_no_occ['Year']\n",
    "lshift_train_data5no['Month']=ltrain_data_no_occ['Month']\n",
    "lshift_train_data5no['day']=ltrain_data_no_occ['Day']\n",
    "lshift_train_data5no['hour']=ltrain_data_no_occ['hour']\n",
    "lshift_train_data5no['minute']=ltrain_data_no_occ['minute']\n",
    "lshift_train_data5no['term_int']=ltrain_data_no_occ['Term_as_int']\n",
    "lshift_train_data5no['future_reading']=ltrain_data_no_occ['future_reading']\n",
    "\n",
    "lshift_train_data5no=lshift_train_data5no.dropna()\n",
    "shift_train_data5no=shift_train_data5no.append(lshift_train_data5no)\n",
    "\n",
    "y6no=shift_train_data5no['future_reading']\n",
    "X6no=shift_train_data5no[features_no_occ]\n",
    "\n",
    "train_X6no, val_X6no, train_y6no, val_y6no = train_test_split(X6no, y6no, random_state = 0)\n",
    "\n",
    "# model7 training\n",
    "# approx two days forecast horizon \n",
    "\n",
    "shift_train_data6=train_data_bow.shift(280)\n",
    "shift_train_data6['day_type_int']=train_data_bow['Day_type_as_int']\n",
    "shift_train_data6['Year']=train_data_bow['Year']\n",
    "shift_train_data6['Month']=train_data_bow['Month']\n",
    "shift_train_data6['day']=train_data_bow['Day']\n",
    "shift_train_data6['hour']=train_data_bow['hour']\n",
    "shift_train_data6['minute']=train_data_bow['minute']\n",
    "shift_train_data6['term_int']=train_data_bow['Term_as_int']\n",
    "shift_train_data6['future_reading']=train_data_bow['future_reading']\n",
    "\n",
    "shift_train_data6=shift_train_data6.dropna()\n",
    "\n",
    "lshift_train_data6=train_data_lec.shift(280)\n",
    "lshift_train_data6['day_type_int']=train_data_lec['Day_type_as_int']\n",
    "lshift_train_data6['Year']=train_data_lec['Year']\n",
    "lshift_train_data6['Month']=train_data_lec['Month']\n",
    "lshift_train_data6['day']=train_data_lec['Day']\n",
    "lshift_train_data6['hour']=train_data_lec['hour']\n",
    "lshift_train_data6['minute']=train_data_lec['minute']\n",
    "lshift_train_data6['term_int']=train_data_lec['Term_as_int']\n",
    "lshift_train_data6['future_reading']=train_data_lec['future_reading']\n",
    "\n",
    "lshift_train_data6=lshift_train_data6.dropna()\n",
    "shift_train_data6=shift_train_data6.append(lshift_train_data6)\n",
    "\n",
    "X7=shift_train_data6[features]\n",
    "y7=shift_train_data6['future_reading']\n",
    "\n",
    "train_X7, val_X7, train_y7, val_y7 = train_test_split(X7, y7, random_state = 0)\n",
    "\n",
    "\n",
    "shift_train_data6no=train_data_no_occ.shift(280)\n",
    "shift_train_data6no['day_type_int']=train_data_no_occ['Day_type_as_int']\n",
    "shift_train_data6no['Year']=train_data_no_occ['Year']\n",
    "shift_train_data6no['Month']=train_data_no_occ['Month']\n",
    "shift_train_data6no['day']=train_data_no_occ['Day']\n",
    "shift_train_data6no['hour']=train_data_no_occ['hour']\n",
    "shift_train_data6no['minute']=train_data_no_occ['minute']\n",
    "shift_train_data6no['term_int']=train_data_no_occ['Term_as_int']\n",
    "shift_train_data6no['future_reading']=train_data_no_occ['future_reading']\n",
    "\n",
    "shift_train_data6no=shift_train_data6no.dropna()\n",
    "\n",
    "lshift_train_data6no=ltrain_data_no_occ.shift(280)\n",
    "lshift_train_data6no['day_type_int']=ltrain_data_no_occ['Day_type_as_int']\n",
    "lshift_train_data6no['Year']=ltrain_data_no_occ['Year']\n",
    "lshift_train_data6no['Month']=ltrain_data_no_occ['Month']\n",
    "lshift_train_data6no['day']=ltrain_data_no_occ['Day']\n",
    "lshift_train_data6no['hour']=ltrain_data_no_occ['hour']\n",
    "lshift_train_data6no['minute']=ltrain_data_no_occ['minute']\n",
    "lshift_train_data6no['term_int']=ltrain_data_no_occ['Term_as_int']\n",
    "lshift_train_data6no['future_reading']=ltrain_data_no_occ['future_reading']\n",
    "\n",
    "lshift_train_data6no=lshift_train_data6no.dropna()\n",
    "\n",
    "shift_train_data6no=shift_train_data6no.append(lshift_train_data6no)\n",
    "\n",
    "y7no=shift_train_data6no['future_reading']\n",
    "X7no=shift_train_data6no[features_no_occ]\n",
    "\n",
    "\n",
    "train_X7no, val_X7no, train_y7no, val_y7no = train_test_split(X7no, y7no, random_state = 0)\n",
    "\n",
    "# model8 training\n",
    "# approx 2 and a half days forecast horizon \n",
    "\n",
    "shift_train_data7=train_data_bow.shift(350)\n",
    "shift_train_data7['day_type_int']=train_data_bow['Day_type_as_int']\n",
    "shift_train_data7['Year']=train_data_bow['Year']\n",
    "shift_train_data7['Month']=train_data_bow['Month']\n",
    "shift_train_data7['day']=train_data_bow['Day']\n",
    "shift_train_data7['hour']=train_data_bow['hour']\n",
    "shift_train_data7['minute']=train_data_bow['minute']\n",
    "shift_train_data7['term_int']=train_data_bow['Term_as_int']\n",
    "shift_train_data7['future_reading']=train_data_bow['future_reading']\n",
    "\n",
    "shift_train_data7=shift_train_data7.dropna()\n",
    "\n",
    "lshift_train_data7=train_data_lec.shift(350)\n",
    "lshift_train_data7['day_type_int']=train_data_lec['Day_type_as_int']\n",
    "lshift_train_data7['Year']=train_data_lec['Year']\n",
    "lshift_train_data7['Month']=train_data_lec['Month']\n",
    "lshift_train_data7['day']=train_data_lec['Day']\n",
    "lshift_train_data7['hour']=train_data_lec['hour']\n",
    "lshift_train_data7['minute']=train_data_lec['minute']\n",
    "lshift_train_data7['term_int']=train_data_lec['Term_as_int']\n",
    "lshift_train_data7['future_reading']=train_data_lec['future_reading']\n",
    "\n",
    "lshift_train_data7=lshift_train_data7.dropna()\n",
    "shift_train_data7=shift_train_data7.append(lshift_train_data7)\n",
    "\n",
    "X8=shift_train_data7[features]\n",
    "y8=shift_train_data7['future_reading']\n",
    "\n",
    "train_X8, val_X8, train_y8, val_y8 = train_test_split(X8, y8, random_state = 0)\n",
    "\n",
    "shift_train_data7no=train_data_no_occ.shift(350)\n",
    "shift_train_data7no['day_type_int']=train_data_no_occ['Day_type_as_int']\n",
    "shift_train_data7no['Year']=train_data_no_occ['Year']\n",
    "shift_train_data7no['Month']=train_data_no_occ['Month']\n",
    "shift_train_data7no['day']=train_data_no_occ['Day']\n",
    "shift_train_data7no['hour']=train_data_no_occ['hour']\n",
    "shift_train_data7no['minute']=train_data_no_occ['minute']\n",
    "shift_train_data7no['term_int']=train_data_no_occ['Term_as_int']\n",
    "shift_train_data7no['future_reading']=train_data_no_occ['future_reading']\n",
    "\n",
    "shift_train_data7no=shift_train_data7no.dropna()\n",
    "\n",
    "lshift_train_data7no=ltrain_data_no_occ.shift(350)\n",
    "lshift_train_data7no['day_type_int']=ltrain_data_no_occ['Day_type_as_int']\n",
    "lshift_train_data7no['Year']=ltrain_data_no_occ['Year']\n",
    "lshift_train_data7no['Month']=ltrain_data_no_occ['Month']\n",
    "lshift_train_data7no['day']=ltrain_data_no_occ['Day']\n",
    "lshift_train_data7no['hour']=ltrain_data_no_occ['hour']\n",
    "lshift_train_data7no['minute']=ltrain_data_no_occ['minute']\n",
    "lshift_train_data7no['term_int']=ltrain_data_no_occ['Term_as_int']\n",
    "lshift_train_data7no['future_reading']=ltrain_data_no_occ['future_reading']\n",
    "\n",
    "lshift_train_data7no=lshift_train_data7no.dropna()\n",
    "shift_train_data7no=shift_train_data7no.append(shift_train_data7no)\n",
    "\n",
    "y8no=shift_train_data7no['future_reading']\n",
    "X8no=shift_train_data7no[features_no_occ]\n",
    "\n",
    "train_X8no, val_X8no, train_y8no, val_y8no = train_test_split(X8no, y8no, random_state = 0)\n",
    "\n",
    "# model9 training\n",
    "# approx three days forecast horizon \n",
    "\n",
    "shift_train_data8=train_data_bow.shift(430)\n",
    "shift_train_data8['day_type_int']=train_data_bow['Day_type_as_int']\n",
    "shift_train_data8['Year']=train_data_bow['Year']\n",
    "shift_train_data8['Month']=train_data_bow['Month']\n",
    "shift_train_data8['day']=train_data_bow['Day']\n",
    "shift_train_data8['hour']=train_data_bow['hour']\n",
    "shift_train_data8['minute']=train_data_bow['minute']\n",
    "shift_train_data8['term_int']=train_data_bow['Term_as_int']\n",
    "shift_train_data8['future_reading']=train_data_bow['future_reading']\n",
    "\n",
    "shift_train_data8=shift_train_data8.dropna()\n",
    "\n",
    "lshift_train_data8=train_data_lec.shift(430)\n",
    "lshift_train_data8['day_type_int']=train_data_lec['Day_type_as_int']\n",
    "lshift_train_data8['Year']=train_data_lec['Year']\n",
    "lshift_train_data8['Month']=train_data_lec['Month']\n",
    "lshift_train_data8['day']=train_data_lec['Day']\n",
    "lshift_train_data8['hour']=train_data_lec['hour']\n",
    "lshift_train_data8['minute']=train_data_lec['minute']\n",
    "lshift_train_data8['term_int']=train_data_lec['Term_as_int']\n",
    "lshift_train_data8['future_reading']=train_data_lec['future_reading']\n",
    "\n",
    "lshift_train_data8=lshift_train_data8.dropna()\n",
    "shift_train_data8=shift_train_data8.append(lshift_train_data8)\n",
    "\n",
    "X9=shift_train_data8[features]\n",
    "y9=shift_train_data8['future_reading']\n",
    "\n",
    "train_X9, val_X9, train_y9, val_y9 = train_test_split(X9, y9, random_state = 0)\n",
    "\n",
    "shift_train_data8no=train_data_no_occ.shift(430)\n",
    "shift_train_data8no['day_type_int']=train_data_no_occ['Day_type_as_int']\n",
    "shift_train_data8no['Year']=train_data_no_occ['Year']\n",
    "shift_train_data8no['Month']=train_data_no_occ['Month']\n",
    "shift_train_data8no['day']=train_data_no_occ['Day']\n",
    "shift_train_data8no['hour']=train_data_no_occ['hour']\n",
    "shift_train_data8no['minute']=train_data_no_occ['minute']\n",
    "shift_train_data8no['term_int']=train_data_no_occ['Term_as_int']\n",
    "shift_train_data8no['future_reading']=train_data_no_occ['future_reading']\n",
    "\n",
    "shift_train_data8no=shift_train_data8no.dropna()\n",
    "\n",
    "lshift_train_data8no=ltrain_data_no_occ.shift(430)\n",
    "lshift_train_data8no['day_type_int']=ltrain_data_no_occ['Day_type_as_int']\n",
    "lshift_train_data8no['Year']=ltrain_data_no_occ['Year']\n",
    "lshift_train_data8no['Month']=ltrain_data_no_occ['Month']\n",
    "lshift_train_data8no['day']=ltrain_data_no_occ['Day']\n",
    "lshift_train_data8no['hour']=ltrain_data_no_occ['hour']\n",
    "lshift_train_data8no['minute']=ltrain_data_no_occ['minute']\n",
    "lshift_train_data8no['term_int']=ltrain_data_no_occ['Term_as_int']\n",
    "lshift_train_data8no['future_reading']=ltrain_data_no_occ['future_reading']\n",
    "\n",
    "lshift_train_data8no=lshift_train_data8no.dropna()\n",
    "shift_train_data8no=shift_train_data8no.append(lshift_train_data8no)\n",
    "\n",
    "y9no=shift_train_data8no['future_reading']\n",
    "\n",
    "X9no=shift_train_data8no[features_no_occ]\n",
    "train_X9no, val_X9no, train_y9no, val_y9no = train_test_split(X9no, y9no, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "         \n",
    "features=[ 'day_avg_reading', 'week_avg_reading', 'hour',\n",
    "          'week_avg_sunset_hr', 'day_avg_sunset_hr', 'week_avg_dewpoint',\n",
    "          'week_avg_windchill', 'week_avg_feelslike', 'week_avg_heatindex',\n",
    "          'week_avg_temp', 'week_avg_mintemp', 'day_avg_mintemp',\n",
    "          'week_avg_maxtemp', 'week_avg_uvindex', 'day_avg_windchill',\n",
    "          'day_avg_feelslike', 'day_avg_heatindex', 'day_avg_temp',\n",
    "          'day_avg_dewpoint', 'week_avg_sunhour', 'day_avg_maxtemp',\n",
    "          'day_avg_uvindex', 'day_avg_sunhour',\n",
    "          'day_avg_sunrise_hr', 'day_avg_sunrise_min', 'week_avg_sunrise_hr',\n",
    "          'week_avg_sunrise_min' ,'day_avg_as_client','week_avg_as_client',\n",
    "          'day_avg_auth_client','week_avg_auth_client','Day_type_as_int', \n",
    "          'Month', 'Day','minute', 'Term_as_int', 'Year']\n",
    "\n",
    "features_no_occ=['day_avg_reading', 'week_avg_reading', 'hour',\n",
    "          'week_avg_sunset_hr', 'day_avg_sunset_hr', 'week_avg_dewpoint',\n",
    "          'week_avg_windchill', 'week_avg_feelslike', 'week_avg_heatindex',\n",
    "          'week_avg_temp', 'week_avg_mintemp', 'day_avg_mintemp',\n",
    "          'week_avg_maxtemp', 'week_avg_uvindex', 'day_avg_windchill',\n",
    "          'day_avg_feelslike', 'day_avg_heatindex', 'day_avg_temp',\n",
    "          'day_avg_dewpoint', 'week_avg_sunhour', 'day_avg_maxtemp',\n",
    "          'day_avg_uvindex', 'day_avg_sunhour',\n",
    "          'day_avg_sunrise_hr', 'day_avg_sunrise_min', 'week_avg_sunrise_hr',\n",
    "          'week_avg_sunrise_min','Day_type_as_int', \n",
    "          'Month', 'Day','minute', 'Term_as_int', 'Year']\n",
    "train_data_bow['future_reading']=train_data_bow['reading']\n",
    "train_data_lec['future_reading']=train_data_lec['reading']\n",
    "\n",
    "shift_train_data4=train_data_bow.shift(140)\n",
    "shift_train_data4['day_type_int']=train_data_bow['Day_type_as_int']\n",
    "shift_train_data4['Year']=train_data_bow['Year']\n",
    "shift_train_data4['Month']=train_data_bow['Month']\n",
    "shift_train_data4['day']=train_data_bow['Day']\n",
    "shift_train_data4['hour']=train_data_bow['hour']\n",
    "shift_train_data4['minute']=train_data_bow['minute']\n",
    "shift_train_data4['term_int']=train_data_bow['Term_as_int']\n",
    "shift_train_data4['future_reading']=train_data_bow['future_reading']\n",
    "\n",
    "shift_train_data4=shift_train_data4.dropna()\n",
    "\n",
    "lshift_train_data4=train_data_lec.shift(140)\n",
    "lshift_train_data4['day_type_int']=train_data_lec['Day_type_as_int']\n",
    "lshift_train_data4['Year']=train_data_lec['Year']\n",
    "lshift_train_data4['Month']=train_data_lec['Month']\n",
    "lshift_train_data4['day']=train_data_lec['Day']\n",
    "lshift_train_data4['hour']=train_data_lec['hour']\n",
    "lshift_train_data4['minute']=train_data_lec['minute']\n",
    "lshift_train_data4['term_int']=train_data_lec['Term_as_int']\n",
    "lshift_train_data4['future_reading']=train_data_lec['future_reading']\n",
    "\n",
    "lshift_train_data4=lshift_train_data4.dropna()\n",
    "shift_train_data4=shift_train_data4.append(lshift_train_data4)\n",
    "\n",
    "X5=shift_train_data4[features]\n",
    "y5=shift_train_data4['future_reading']\n",
    "\n",
    "train_X5, val_X5, train_y5, val_y5 = train_test_split(X5, y5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading</th>\n",
       "      <th>previous_maxtempC</th>\n",
       "      <th>previous_mintempC</th>\n",
       "      <th>previous_totalSnow_cm</th>\n",
       "      <th>previous_sunHour</th>\n",
       "      <th>previous_uvIndex</th>\n",
       "      <th>previous_moon_illumination</th>\n",
       "      <th>previous_sunrise_hour</th>\n",
       "      <th>previous_sunrise_minute</th>\n",
       "      <th>previous_sunset_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>week_avg_cloud</th>\n",
       "      <th>week_avg_humidity</th>\n",
       "      <th>week_avg_precip</th>\n",
       "      <th>week_avg_pressure</th>\n",
       "      <th>week_avg_temp</th>\n",
       "      <th>week_avg_visibility</th>\n",
       "      <th>week_avg_winddir</th>\n",
       "      <th>week_avg_windspeed</th>\n",
       "      <th>week_avg_as_client</th>\n",
       "      <th>week_avg_auth_client</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>995.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>995.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>995.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>995.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>995.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reading  previous_maxtempC  previous_mintempC  previous_totalSnow_cm  \\\n",
       "0      0.0               17.0               10.0                    0.0   \n",
       "1     11.0               17.0               10.0                    0.0   \n",
       "2     10.0               17.0               10.0                    0.0   \n",
       "3     11.0               17.0               10.0                    0.0   \n",
       "4     10.0               17.0               10.0                    0.0   \n",
       "\n",
       "   previous_sunHour  previous_uvIndex  previous_moon_illumination  \\\n",
       "0               4.1               5.0                        15.0   \n",
       "1               4.1               5.0                        15.0   \n",
       "2               4.1               5.0                        15.0   \n",
       "3               4.1               5.0                        15.0   \n",
       "4               4.1               5.0                        15.0   \n",
       "\n",
       "   previous_sunrise_hour  previous_sunrise_minute  previous_sunset_hour  ...  \\\n",
       "0                    6.0                      6.0                  17.0  ...   \n",
       "1                    6.0                      6.0                  17.0  ...   \n",
       "2                    6.0                      6.0                  17.0  ...   \n",
       "3                    6.0                      6.0                  17.0  ...   \n",
       "4                    6.0                      6.0                  17.0  ...   \n",
       "\n",
       "   week_avg_cloud  week_avg_humidity  week_avg_precip  week_avg_pressure  \\\n",
       "0           100.0               86.0              6.7              995.0   \n",
       "1           100.0               86.0              6.7              995.0   \n",
       "2           100.0               86.0              6.7              995.0   \n",
       "3           100.0               86.0              6.7              995.0   \n",
       "4           100.0               86.0              6.7              995.0   \n",
       "\n",
       "   week_avg_temp  week_avg_visibility  week_avg_winddir  week_avg_windspeed  \\\n",
       "0           17.0                  7.0             181.0                54.0   \n",
       "1           17.0                  7.0             181.0                54.0   \n",
       "2           17.0                  7.0             181.0                54.0   \n",
       "3           17.0                  7.0             181.0                54.0   \n",
       "4           17.0                  7.0             181.0                54.0   \n",
       "\n",
       "   week_avg_as_client  week_avg_auth_client  \n",
       "0               358.0                 344.0  \n",
       "1               366.0                 346.0  \n",
       "2               341.0                 332.0  \n",
       "3               324.0                 316.0  \n",
       "4               366.0                 333.0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forest_model1 = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model1.fit(train_X1, train_y1)\n",
    "pickle.dump(forest_model1, open('forest_model1.sav', 'wb'))\n",
    "forest_model1no = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model1no.fit(train_X1no, train_y1no)\n",
    "pickle.dump(forest_model1no, open('forest_model1no.sav', 'wb'))\n",
    "\n",
    "forest_model2 = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model2.fit(train_X2, train_y2)\n",
    "pickle.dump(forest_model2, open('forest_model2.sav', 'wb'))\n",
    "forest_model2no = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model2no.fit(train_X2no, train_y2no)\n",
    "pickle.dump(forest_model2no, open('forest_model2no.sav', 'wb'))\n",
    "\n",
    "forest_model3 = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model3.fit(train_X3, train_y3)\n",
    "pickle.dump(forest_model3, open('forest_model3.sav', 'wb'))\n",
    "forest_model3no = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model3no.fit(train_X3no, train_y3no)\n",
    "pickle.dump(forest_model3no, open('forest_model3no.sav', 'wb'))\n",
    "\n",
    "forest_model4 = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model4.fit(train_X4, train_y4)\n",
    "pickle.dump(forest_model4, open('forest_model4.sav', 'wb'))\n",
    "forest_model4no = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model4no.fit(train_X4no, train_y4no)\n",
    "pickle.dump(forest_model4no, open('forest_model4no.sav', 'wb'))\n",
    "\n",
    "forest_model5 = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model5.fit(train_X5, train_y5)\n",
    "pickle.dump(forest_model5, open('forest_model5.sav', 'wb'))\n",
    "forest_model5no = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model5no.fit(train_X5no, train_y5no)\n",
    "pickle.dump(forest_model5no, open('forest_model5no.sav', 'wb'))\n",
    "\n",
    "forest_model6 = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model6.fit(train_X6, train_y6)\n",
    "pickle.dump(forest_model6, open('forest_model6.sav', 'wb'))\n",
    "forest_model6no = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model6no.fit(train_X6no, train_y6no)\n",
    "pickle.dump(forest_model6no, open('forest_model6no.sav', 'wb'))\n",
    "\n",
    "forest_model7 = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model7.fit(train_X7, train_y7)\n",
    "pickle.dump(forest_model7, open('forest_model7.sav', 'wb'))\n",
    "forest_model7no = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model7no.fit(train_X7no, train_y7no)\n",
    "pickle.dump(forest_model7no, open('forest_model7no.sav', 'wb'))\n",
    "\n",
    "forest_model8 = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model8.fit(train_X8, train_y8)\n",
    "pickle.dump(forest_model8, open('forest_model8.sav', 'wb'))\n",
    "forest_model8no = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model8no.fit(train_X8no, train_y8no)\n",
    "pickle.dump(forest_model8no, open('forest_model8no.sav', 'wb'))\n",
    "\n",
    "forest_model9 = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model9.fit(train_X9, train_y9)\n",
    "pickle.dump(forest_model9, open('forest_model9.sav', 'wb'))\n",
    "forest_model9no = RandomForestRegressor(n_estimators=300, random_state=1)\n",
    "forest_model9no.fit(train_X9no, train_y9no)\n",
    "pickle.dump(forest_model9no, open('forest_model9no.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1=LinearRegression()     #initiating linear regression\n",
    "reg1.fit(train_X1,train_y1)\n",
    "reg1_preds=reg1.predict(val_X1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#decision tree\n",
    "depth=[1, 5, 10, 20, 40, 100]\n",
    "samples=[1, 5, 10, 20, 50, 100]\n",
    "for d in depth:\n",
    "    if d==1:\n",
    "        co='green'\n",
    "    elif d==5:\n",
    "        co='blue'\n",
    "    elif d==10:\n",
    "        co='red'\n",
    "    elif d==20:\n",
    "        co='orange'\n",
    "    elif d==40:\n",
    "        co='yellow'\n",
    "    elif d==100:\n",
    "        co='magenta'\n",
    "    for s in samples:\n",
    "        dtree = DecisionTreeRegressor(max_depth=d, min_samples_leaf=s, random_state=1)\n",
    "        dtree.fit(train_X1, train_y1)\n",
    "        dec_preds= dtree.predict(val_X1)\n",
    "        plt.xlabel('Samples size')\n",
    "        plt.ylabel('Mean absolute error')\n",
    "        plt.scatter(s, mean_absolute_error(val_y1, dec_preds), c=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators=[50,100, 250, 350]\n",
    "for n in n_estimators:\n",
    "    forest_model1 = RandomForestRegressor(n_estimators=n, random_state=1)\n",
    "    forest_model1.fit(train_X1, train_y1)\n",
    "    forest1_preds = forest_model1.predict(val_X1)\n",
    "    plt.scatter(n, mean_absolute_error(val_y1, forest1_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#gradient boost\n",
    "nest=[1200, 1800]\n",
    "lra=[ 0.1, 0.5, 1]\n",
    "for nes in nest:\n",
    "    if nes==1200:\n",
    "        co='red'\n",
    "    elif nes==1800:\n",
    "        co='blue'\n",
    "    #elif nes==1000:\n",
    "       # co='orange'        \n",
    "    for lr in lra:    \n",
    "        grad=GradientBoostingRegressor(learning_rate=lr, n_estimators=nes, subsample=1)\n",
    "        grad.fit(train_X1, train_y1)\n",
    "        grad1_preds=grad.predict(val_X1)\n",
    "        plt.scatter(lr, mean_absolute_error(val_y1, grad1_preds), c=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#light       \n",
    "lnes=[1, 5, 10, 50, 100, 500]\n",
    "leaves=[2, 5, 20, 50, 100]\n",
    "for lne in lnes:\n",
    "    if lne==1:\n",
    "        co='red'\n",
    "    elif lne==5:\n",
    "        co='blue'\n",
    "    elif lne==10:\n",
    "        co='green'\n",
    "    elif lne==50:\n",
    "        co='orange'\n",
    "    elif lne==100:\n",
    "        co='magenta'\n",
    "    elif lne==500:\n",
    "        co='yellow'\n",
    "    \n",
    "    for le in leaves:\n",
    "        light = lgm.LGBMClassifier(num_leaves=le, n_estimators=lne)\n",
    "        light.fit(train_X1, train_y1)\n",
    "        lpreds1=light.predict(val_X1)\n",
    "        plt.scatter(le, mean_absolute_error(val_y1, lpreds1), c=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 8.2267 - val_loss: 8.7674\n",
      "Epoch 2/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 4.8400 - val_loss: 4.1201\n",
      "Epoch 3/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 4.3514 - val_loss: 5.4043\n",
      "Epoch 4/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 4.1486 - val_loss: 4.4758\n",
      "Epoch 5/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 3.4504 - val_loss: 3.3984\n",
      "Epoch 6/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.9700 - val_loss: 3.0865\n",
      "Epoch 7/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.8158 - val_loss: 2.5598\n",
      "Epoch 8/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.6692 - val_loss: 2.9249\n",
      "Epoch 9/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.6141 - val_loss: 2.7094\n",
      "Epoch 10/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.5585 - val_loss: 2.4447\n",
      "Epoch 11/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.5265 - val_loss: 2.4787\n",
      "Epoch 12/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.4911 - val_loss: 2.4067\n",
      "Epoch 13/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.4678 - val_loss: 2.4009\n",
      "Epoch 14/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.4427 - val_loss: 2.4073\n",
      "Epoch 15/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.4233 - val_loss: 2.3044\n",
      "Epoch 16/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.3889 - val_loss: 2.3861\n",
      "Epoch 17/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.3822 - val_loss: 2.5614\n",
      "Epoch 18/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.3413 - val_loss: 2.3284\n",
      "Epoch 19/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.3357 - val_loss: 2.4383\n",
      "Epoch 20/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.3217 - val_loss: 2.2874\n",
      "Epoch 21/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.3039 - val_loss: 2.1752\n",
      "Epoch 22/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.2796 - val_loss: 2.4669\n",
      "Epoch 23/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.2534 - val_loss: 2.3110\n",
      "Epoch 24/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.2136 - val_loss: 2.1944\n",
      "Epoch 25/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1886 - val_loss: 2.0678\n",
      "Epoch 26/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1822 - val_loss: 2.1516\n",
      "Epoch 27/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1632 - val_loss: 2.0687\n",
      "Epoch 28/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1561 - val_loss: 2.0744\n",
      "Epoch 29/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1549 - val_loss: 2.0332\n",
      "Epoch 30/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1283 - val_loss: 2.1680\n",
      "Epoch 31/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1287 - val_loss: 2.1397\n",
      "Epoch 32/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1176 - val_loss: 2.1096\n",
      "Epoch 33/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.1106 - val_loss: 2.3248\n",
      "Epoch 34/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1150 - val_loss: 2.2058\n",
      "Epoch 35/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0856 - val_loss: 2.1541\n",
      "Epoch 36/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0790 - val_loss: 2.0151\n",
      "Epoch 37/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0893 - val_loss: 2.2229\n",
      "Epoch 38/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0609 - val_loss: 2.0883\n",
      "Epoch 39/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0633 - val_loss: 1.9816\n",
      "Epoch 40/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0509 - val_loss: 2.1918\n",
      "Epoch 41/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0568 - val_loss: 2.0450\n",
      "Epoch 42/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0453 - val_loss: 2.4778\n",
      "Epoch 43/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0334 - val_loss: 2.0229\n",
      "Epoch 44/100\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 2.0424 - val_loss: 1.9552\n",
      "Epoch 45/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0103 - val_loss: 2.0843\n",
      "Epoch 46/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0306 - val_loss: 2.0483\n",
      "Epoch 47/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0336 - val_loss: 1.9477\n",
      "Epoch 48/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0204 - val_loss: 2.0129\n",
      "Epoch 49/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9962 - val_loss: 2.0160\n",
      "Epoch 50/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9953 - val_loss: 2.0085\n",
      "Epoch 51/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0134 - val_loss: 1.9953\n",
      "Epoch 52/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0016 - val_loss: 1.9189\n",
      "Epoch 53/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9969 - val_loss: 2.0687\n",
      "Epoch 54/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9846 - val_loss: 1.9575\n",
      "Epoch 55/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9887 - val_loss: 1.9907\n",
      "Epoch 56/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9883 - val_loss: 2.0525\n",
      "Epoch 57/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9803 - val_loss: 1.9882\n",
      "Epoch 58/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9728 - val_loss: 1.9380\n",
      "Epoch 59/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9676 - val_loss: 1.9161\n",
      "Epoch 60/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9537 - val_loss: 1.9154\n",
      "Epoch 61/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9612 - val_loss: 1.9020\n",
      "Epoch 62/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9686 - val_loss: 1.9703\n",
      "Epoch 63/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9620 - val_loss: 2.0741\n",
      "Epoch 64/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9601 - val_loss: 1.9037\n",
      "Epoch 65/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9492 - val_loss: 1.9193\n",
      "Epoch 66/100\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.9560 - val_loss: 1.9107\n",
      "Epoch 67/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9451 - val_loss: 1.9427\n",
      "Epoch 68/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9352 - val_loss: 1.9836\n",
      "Epoch 69/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9365 - val_loss: 1.9558\n",
      "Epoch 70/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9341 - val_loss: 1.9181\n",
      "Epoch 71/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9273 - val_loss: 2.0608\n",
      "Epoch 72/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9327 - val_loss: 1.9604\n",
      "Epoch 73/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9342 - val_loss: 1.8832\n",
      "Epoch 74/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9231 - val_loss: 1.9360\n",
      "Epoch 75/100\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.9261 - val_loss: 1.9412\n",
      "Epoch 76/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9360 - val_loss: 1.9880\n",
      "Epoch 77/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9243 - val_loss: 1.9634\n",
      "Epoch 78/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9168 - val_loss: 1.8894\n",
      "Epoch 79/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9205 - val_loss: 1.8922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9251 - val_loss: 1.9078\n",
      "Epoch 81/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9169 - val_loss: 1.8388\n",
      "Epoch 82/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9026 - val_loss: 2.1683\n",
      "Epoch 83/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9107 - val_loss: 2.1837\n",
      "Epoch 84/100\n",
      "1728/1728 [==============================] - 13s 7ms/step - loss: 1.9018 - val_loss: 1.8391\n",
      "Epoch 85/100\n",
      "1728/1728 [==============================] - 9s 5ms/step - loss: 1.8992 - val_loss: 1.8990\n",
      "Epoch 86/100\n",
      "1728/1728 [==============================] - 9s 5ms/step - loss: 1.8993 - val_loss: 1.9334\n",
      "Epoch 87/100\n",
      "1728/1728 [==============================] - 12s 7ms/step - loss: 1.8984 - val_loss: 1.9356\n",
      "Epoch 88/100\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.9009 - val_loss: 1.9511\n",
      "Epoch 89/100\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.8898 - val_loss: 1.8257\n",
      "Epoch 90/100\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.8978 - val_loss: 2.0827\n",
      "Epoch 91/100\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.8906 - val_loss: 2.1493\n",
      "Epoch 92/100\n",
      "1728/1728 [==============================] - 10s 6ms/step - loss: 1.8985 - val_loss: 1.8757\n",
      "Epoch 93/100\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.8898 - val_loss: 1.8638\n",
      "Epoch 94/100\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8887 - val_loss: 1.9610\n",
      "Epoch 95/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8880 - val_loss: 1.8576\n",
      "Epoch 96/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8795 - val_loss: 1.8416\n",
      "Epoch 97/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8763 - val_loss: 1.8873\n",
      "Epoch 98/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8832 - val_loss: 1.9335\n",
      "Epoch 99/100\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8757 - val_loss: 2.0357\n",
      "Epoch 100/100\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8770 - val_loss: 1.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8447104136392014\n",
      "0.9411786398789679\n",
      "Epoch 1/100\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 8.0810 - val_loss: 4.1653\n",
      "Epoch 2/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 5.2646 - val_loss: 4.6258\n",
      "Epoch 3/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 4.5375 - val_loss: 4.0130\n",
      "Epoch 4/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 4.3731 - val_loss: 3.9575\n",
      "Epoch 5/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 4.1853 - val_loss: 3.9199\n",
      "Epoch 6/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 4.1479 - val_loss: 3.7322\n",
      "Epoch 7/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 3.6080 - val_loss: 3.2497\n",
      "Epoch 8/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 3.2477 - val_loss: 4.1665\n",
      "Epoch 9/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 3.0932 - val_loss: 2.8786\n",
      "Epoch 10/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.9583 - val_loss: 2.8203\n",
      "Epoch 11/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.9073 - val_loss: 2.8843\n",
      "Epoch 12/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.8063 - val_loss: 2.7626\n",
      "Epoch 13/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.7437 - val_loss: 2.5496\n",
      "Epoch 14/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.6793 - val_loss: 2.8317\n",
      "Epoch 15/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.6199 - val_loss: 2.5096\n",
      "Epoch 16/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.6037 - val_loss: 2.7124\n",
      "Epoch 17/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.5696 - val_loss: 2.4991\n",
      "Epoch 18/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.5236 - val_loss: 2.4031\n",
      "Epoch 19/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.4719 - val_loss: 2.5463\n",
      "Epoch 20/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.4720 - val_loss: 2.3933\n",
      "Epoch 21/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.4341 - val_loss: 2.5470\n",
      "Epoch 22/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.4282 - val_loss: 2.3488\n",
      "Epoch 23/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.4037 - val_loss: 2.3792\n",
      "Epoch 24/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.3840 - val_loss: 2.3952\n",
      "Epoch 25/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3718 - val_loss: 2.3898\n",
      "Epoch 26/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3434 - val_loss: 2.2827\n",
      "Epoch 27/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.3140 - val_loss: 2.2571\n",
      "Epoch 28/100\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.2884 - val_loss: 2.3123\n",
      "Epoch 29/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.2722 - val_loss: 2.1702\n",
      "Epoch 30/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.2480 - val_loss: 2.1852\n",
      "Epoch 31/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.2330 - val_loss: 2.2077\n",
      "Epoch 32/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.2039 - val_loss: 2.1623\n",
      "Epoch 33/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.2000 - val_loss: 2.3515\n",
      "Epoch 34/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.1921 - val_loss: 2.4993\n",
      "Epoch 35/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.1986 - val_loss: 2.2285\n",
      "Epoch 36/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1657 - val_loss: 2.4331\n",
      "Epoch 37/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1546 - val_loss: 2.3415\n",
      "Epoch 38/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1320 - val_loss: 2.0834\n",
      "Epoch 39/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1309 - val_loss: 2.0618\n",
      "Epoch 40/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.1151 - val_loss: 2.3344\n",
      "Epoch 41/100\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 2.1188 - val_loss: 2.1064\n",
      "Epoch 42/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0854 - val_loss: 2.1033\n",
      "Epoch 43/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0960 - val_loss: 2.0324\n",
      "Epoch 44/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1019 - val_loss: 2.0034\n",
      "Epoch 45/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0793 - val_loss: 2.0650\n",
      "Epoch 46/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0575 - val_loss: 2.0219\n",
      "Epoch 47/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0415 - val_loss: 2.0336\n",
      "Epoch 48/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0553 - val_loss: 2.0980\n",
      "Epoch 49/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0554 - val_loss: 2.0744\n",
      "Epoch 50/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0256 - val_loss: 1.9586\n",
      "Epoch 51/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0254 - val_loss: 1.9979\n",
      "Epoch 52/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.0264 - val_loss: 1.9611\n",
      "Epoch 53/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0092 - val_loss: 1.9667\n",
      "Epoch 54/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0289 - val_loss: 1.9478\n",
      "Epoch 55/100\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.9968 - val_loss: 1.9931\n",
      "Epoch 56/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0045 - val_loss: 1.9393\n",
      "Epoch 57/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9828 - val_loss: 1.9413\n",
      "Epoch 58/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9771 - val_loss: 1.8967\n",
      "Epoch 59/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9803 - val_loss: 1.9316\n",
      "Epoch 60/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.9661 - val_loss: 1.9483\n",
      "Epoch 61/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.9696 - val_loss: 1.9258\n",
      "Epoch 62/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9531 - val_loss: 1.8772\n",
      "Epoch 63/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9593 - val_loss: 1.9092\n",
      "Epoch 64/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9462 - val_loss: 1.9270\n",
      "Epoch 65/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9411 - val_loss: 1.9767\n",
      "Epoch 66/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9385 - val_loss: 2.1346\n",
      "Epoch 67/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9437 - val_loss: 1.8916\n",
      "Epoch 68/100\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.9259 - val_loss: 1.9332\n",
      "Epoch 69/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9234 - val_loss: 1.9395\n",
      "Epoch 70/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9189 - val_loss: 1.9182\n",
      "Epoch 71/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9319 - val_loss: 1.8558\n",
      "Epoch 72/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9111 - val_loss: 1.9213\n",
      "Epoch 73/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9228 - val_loss: 1.8748\n",
      "Epoch 74/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8997 - val_loss: 1.9007\n",
      "Epoch 75/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8993 - val_loss: 1.8668\n",
      "Epoch 76/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8954 - val_loss: 1.9199\n",
      "Epoch 77/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8915 - val_loss: 1.9429\n",
      "Epoch 78/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8920 - val_loss: 1.9517\n",
      "Epoch 79/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8951 - val_loss: 1.8499\n",
      "Epoch 80/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8747 - val_loss: 1.8578\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8798 - val_loss: 1.9004\n",
      "Epoch 82/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8793 - val_loss: 1.9525\n",
      "Epoch 83/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8749 - val_loss: 1.9085\n",
      "Epoch 84/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8683 - val_loss: 1.8580\n",
      "Epoch 85/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8752 - val_loss: 1.8192\n",
      "Epoch 86/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8712 - val_loss: 1.8553\n",
      "Epoch 87/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8703 - val_loss: 1.8135\n",
      "Epoch 88/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8466 - val_loss: 1.8154\n",
      "Epoch 89/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8598 - val_loss: 1.8149\n",
      "Epoch 90/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8262 - val_loss: 1.8299\n",
      "Epoch 91/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8425 - val_loss: 1.8503\n",
      "Epoch 92/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8295 - val_loss: 1.8259\n",
      "Epoch 93/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8446 - val_loss: 1.8824\n",
      "Epoch 94/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8275 - val_loss: 1.8093\n",
      "Epoch 95/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8298 - val_loss: 1.9091\n",
      "Epoch 96/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8245 - val_loss: 1.8064\n",
      "Epoch 97/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8236 - val_loss: 1.7932\n",
      "Epoch 98/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8106 - val_loss: 1.8595\n",
      "Epoch 99/100\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8205 - val_loss: 1.8629\n",
      "Epoch 100/100\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8242 - val_loss: 1.8565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8565135457126565\n",
      "0.939331409091977\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 8.4456 - val_loss: 7.6771\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.9846 - val_loss: 5.4548\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.6802 - val_loss: 3.9556\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.5332 - val_loss: 4.4911\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.3784 - val_loss: 5.8528\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.3246 - val_loss: 3.9474\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.1843 - val_loss: 3.7792\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.0239 - val_loss: 4.1384\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.8014 - val_loss: 3.2890\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.3902 - val_loss: 3.1396\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.2826 - val_loss: 3.4227\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.1029 - val_loss: 2.9586\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.0517 - val_loss: 2.9794\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.9314 - val_loss: 2.7258\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.7912 - val_loss: 2.6883\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.7113 - val_loss: 2.6400\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.6695 - val_loss: 2.5816\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.6173 - val_loss: 2.6572\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.6175 - val_loss: 2.4365\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.5586 - val_loss: 2.7881\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.5144 - val_loss: 2.4989\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.4918 - val_loss: 2.4056\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.4731 - val_loss: 2.4407\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.4454 - val_loss: 2.4650\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.4337 - val_loss: 2.6289\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.3973 - val_loss: 2.5795\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.3800 - val_loss: 2.5829\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.3395 - val_loss: 2.2186\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.3019 - val_loss: 2.2315\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.3295 - val_loss: 2.2340\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.2887 - val_loss: 2.3504\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2525 - val_loss: 2.1458\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.2152 - val_loss: 2.1372\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.2035 - val_loss: 2.1480\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.1771 - val_loss: 2.1675\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1660 - val_loss: 2.1645\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1375 - val_loss: 2.1249\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.1316 - val_loss: 2.1146\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.1280 - val_loss: 2.3034\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.1058 - val_loss: 2.0186\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0939 - val_loss: 2.1966\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0759 - val_loss: 2.0433\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0668 - val_loss: 2.0423\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0438 - val_loss: 2.0073\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0488 - val_loss: 1.9764\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0809 - val_loss: 2.1312\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0629 - val_loss: 2.1613\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0205 - val_loss: 1.9442\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0222 - val_loss: 2.0379\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0065 - val_loss: 1.9158\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9912 - val_loss: 2.0080\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9808 - val_loss: 1.9102\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9910 - val_loss: 1.9303\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9951 - val_loss: 2.0672\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9882 - val_loss: 2.3682\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9837 - val_loss: 1.9516\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9589 - val_loss: 1.9564\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9463 - val_loss: 1.8702\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9325 - val_loss: 1.9700\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9263 - val_loss: 1.9407\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9241 - val_loss: 1.9501\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9230 - val_loss: 1.9292\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9237 - val_loss: 1.9560\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9119 - val_loss: 2.0392\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8977 - val_loss: 1.8991\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9021 - val_loss: 1.8299\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8942 - val_loss: 1.8994\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8992 - val_loss: 2.0316\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8777 - val_loss: 1.9275\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8731 - val_loss: 1.8640\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8658 - val_loss: 1.8272\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8676 - val_loss: 1.8374\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8676 - val_loss: 1.8349\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8597 - val_loss: 1.9349\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8383 - val_loss: 1.8949\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8572 - val_loss: 1.8499\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8424 - val_loss: 1.8023\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8291 - val_loss: 1.8300\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8352 - val_loss: 1.8623\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8350 - val_loss: 1.8118\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8203 - val_loss: 1.8702\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8222 - val_loss: 1.8540\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8127 - val_loss: 1.8531\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8064 - val_loss: 1.7772\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8098 - val_loss: 1.8152\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7970 - val_loss: 1.8820\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8172 - val_loss: 1.7435\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7979 - val_loss: 1.9273\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7935 - val_loss: 1.8210\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7986 - val_loss: 1.7879\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7933 - val_loss: 1.7755\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7741 - val_loss: 1.8174\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7746 - val_loss: 1.8475\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7719 - val_loss: 1.8479\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7917 - val_loss: 1.7941\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7690 - val_loss: 1.7883\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7679 - val_loss: 1.7988\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7621 - val_loss: 1.7795\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7583 - val_loss: 1.7442\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7451 - val_loss: 1.6981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6980741124783532\n",
      "0.9526073226098646\n",
      "Epoch 1/100\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 10.3837 - val_loss: 4.9676\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 6.2189 - val_loss: 4.3325\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 4.6225 - val_loss: 4.7715\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 5.0095 - val_loss: 3.9475\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.2232 - val_loss: 4.1706\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 4.3323 - val_loss: 3.9911\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 4.3424 - val_loss: 3.7784\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 4.0828 - val_loss: 3.6124\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 3.8672 - val_loss: 3.4289\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.6556 - val_loss: 3.3642\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.5532 - val_loss: 3.2238\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.5334 - val_loss: 3.0798\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.3122 - val_loss: 3.0307\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.1812 - val_loss: 2.9382\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.1303 - val_loss: 2.9051\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.1000 - val_loss: 2.8359\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.9123 - val_loss: 2.7513\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.9158 - val_loss: 2.7113\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.8011 - val_loss: 2.7043\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.8335 - val_loss: 3.0969\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.7233 - val_loss: 2.8105\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.7020 - val_loss: 2.7181\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.6321 - val_loss: 2.5180\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.5947 - val_loss: 2.4845\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5819 - val_loss: 2.5497\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5555 - val_loss: 2.4273\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5311 - val_loss: 2.4633\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5058 - val_loss: 2.4110\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4706 - val_loss: 2.4346\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4147 - val_loss: 2.3644\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.4267 - val_loss: 2.4338\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4221 - val_loss: 2.5142\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3715 - val_loss: 2.3680\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3591 - val_loss: 2.3169\n",
      "Epoch 35/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3192 - val_loss: 2.2776\n",
      "Epoch 36/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3280 - val_loss: 2.2236\n",
      "Epoch 37/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2879 - val_loss: 2.2141\n",
      "Epoch 38/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2935 - val_loss: 2.1802\n",
      "Epoch 39/100\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 2.2680 - val_loss: 2.3059\n",
      "Epoch 40/100\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.2512 - val_loss: 2.5290\n",
      "Epoch 41/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2408 - val_loss: 2.1979\n",
      "Epoch 42/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1832 - val_loss: 2.1569\n",
      "Epoch 43/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1964 - val_loss: 2.1868\n",
      "Epoch 44/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1861 - val_loss: 2.2075\n",
      "Epoch 45/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1699 - val_loss: 2.0757\n",
      "Epoch 46/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1873 - val_loss: 2.1607\n",
      "Epoch 47/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1300 - val_loss: 2.1071\n",
      "Epoch 48/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1188 - val_loss: 2.1565\n",
      "Epoch 49/100\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.1387 - val_loss: 2.1090\n",
      "Epoch 50/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1046 - val_loss: 2.3123\n",
      "Epoch 51/100\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.0880 - val_loss: 2.0786\n",
      "Epoch 52/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0813 - val_loss: 2.1063\n",
      "Epoch 53/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0825 - val_loss: 2.0926\n",
      "Epoch 54/100\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.0710 - val_loss: 1.9982\n",
      "Epoch 55/100\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.0835 - val_loss: 2.0972\n",
      "Epoch 56/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0536 - val_loss: 2.0485\n",
      "Epoch 57/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0918 - val_loss: 2.0660\n",
      "Epoch 58/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0423 - val_loss: 2.0295\n",
      "Epoch 59/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0300 - val_loss: 2.2386\n",
      "Epoch 60/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0259 - val_loss: 2.0420\n",
      "Epoch 61/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0022 - val_loss: 2.0236\n",
      "Epoch 62/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0015 - val_loss: 2.1245\n",
      "Epoch 63/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0051 - val_loss: 1.9481\n",
      "Epoch 64/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9651 - val_loss: 1.9340\n",
      "Epoch 65/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9770 - val_loss: 2.0251\n",
      "Epoch 66/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9718 - val_loss: 1.9583\n",
      "Epoch 67/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9753 - val_loss: 1.8944\n",
      "Epoch 68/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9353 - val_loss: 1.9325\n",
      "Epoch 69/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9320 - val_loss: 1.9119\n",
      "Epoch 70/100\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.9494 - val_loss: 1.9453\n",
      "Epoch 71/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9364 - val_loss: 1.8710\n",
      "Epoch 72/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9445 - val_loss: 1.9131\n",
      "Epoch 73/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9081 - val_loss: 1.9204\n",
      "Epoch 74/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9020 - val_loss: 1.8796\n",
      "Epoch 75/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9014 - val_loss: 1.9070\n",
      "Epoch 76/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9115 - val_loss: 1.9883\n",
      "Epoch 77/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8785 - val_loss: 1.8808\n",
      "Epoch 78/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8979 - val_loss: 1.9215\n",
      "Epoch 79/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8961 - val_loss: 1.8606\n",
      "Epoch 80/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8772 - val_loss: 1.9012\n",
      "Epoch 81/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8797 - val_loss: 1.8657\n",
      "Epoch 82/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8649 - val_loss: 1.7852\n",
      "Epoch 83/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8631 - val_loss: 1.8263\n",
      "Epoch 84/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8539 - val_loss: 1.8628\n",
      "Epoch 85/100\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.8565 - val_loss: 1.8807\n",
      "Epoch 86/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8382 - val_loss: 1.8071\n",
      "Epoch 87/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8434 - val_loss: 1.9509\n",
      "Epoch 88/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8330 - val_loss: 1.8034\n",
      "Epoch 89/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8199 - val_loss: 1.8397\n",
      "Epoch 90/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8429 - val_loss: 1.9154\n",
      "Epoch 91/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8286 - val_loss: 1.9793\n",
      "Epoch 92/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8059 - val_loss: 1.8640\n",
      "Epoch 93/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8218 - val_loss: 1.9141\n",
      "Epoch 94/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8052 - val_loss: 1.8328\n",
      "Epoch 95/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8009 - val_loss: 1.8249\n",
      "Epoch 96/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7874 - val_loss: 1.7675\n",
      "Epoch 97/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8027 - val_loss: 1.8354\n",
      "Epoch 98/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7795 - val_loss: 1.8030\n",
      "Epoch 99/100\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7636 - val_loss: 1.7104\n",
      "Epoch 100/100\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7966 - val_loss: 1.7927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7926951128957238\n",
      "0.9469110819196762\n",
      "Epoch 1/100\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 12.4741 - val_loss: 4.8871\n",
      "Epoch 2/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 7.1339 - val_loss: 6.7387\n",
      "Epoch 3/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 5.4880 - val_loss: 6.2892\n",
      "Epoch 4/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.8263 - val_loss: 5.8520\n",
      "Epoch 5/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.8869 - val_loss: 4.3572\n",
      "Epoch 6/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 5.2159 - val_loss: 5.3077\n",
      "Epoch 7/100\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 4.3951 - val_loss: 4.5943\n",
      "Epoch 8/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.7323 - val_loss: 5.9757\n",
      "Epoch 9/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 4.4364 - val_loss: 6.5135\n",
      "Epoch 10/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.2142 - val_loss: 4.5206\n",
      "Epoch 11/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.2349 - val_loss: 3.8636\n",
      "Epoch 12/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.1242 - val_loss: 4.6243\n",
      "Epoch 13/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.4280 - val_loss: 3.7483\n",
      "Epoch 14/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.6313 - val_loss: 3.4801\n",
      "Epoch 15/100\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 3.5009 - val_loss: 5.0096\n",
      "Epoch 16/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.4253 - val_loss: 4.9932\n",
      "Epoch 17/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.3387 - val_loss: 3.1027\n",
      "Epoch 18/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.0709 - val_loss: 3.1417\n",
      "Epoch 19/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.1591 - val_loss: 4.1752\n",
      "Epoch 20/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.0975 - val_loss: 3.3029\n",
      "Epoch 21/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.2201 - val_loss: 2.8706\n",
      "Epoch 22/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.0506 - val_loss: 2.9116\n",
      "Epoch 23/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.9273 - val_loss: 2.7851\n",
      "Epoch 24/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.8719 - val_loss: 2.7873\n",
      "Epoch 25/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.8631 - val_loss: 2.8045\n",
      "Epoch 26/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.8527 - val_loss: 2.6330\n",
      "Epoch 27/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.7573 - val_loss: 2.8978\n",
      "Epoch 28/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.7178 - val_loss: 2.7840\n",
      "Epoch 29/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.7023 - val_loss: 2.6817\n",
      "Epoch 30/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.6631 - val_loss: 2.5958\n",
      "Epoch 31/100\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 2.5882 - val_loss: 2.8034\n",
      "Epoch 32/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.5338 - val_loss: 2.5190\n",
      "Epoch 33/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.5665 - val_loss: 2.4361\n",
      "Epoch 34/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.5081 - val_loss: 2.4937\n",
      "Epoch 35/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.4569 - val_loss: 2.4678\n",
      "Epoch 36/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4017 - val_loss: 2.6070\n",
      "Epoch 37/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.4313 - val_loss: 2.5528\n",
      "Epoch 38/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3683 - val_loss: 2.3303\n",
      "Epoch 39/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3638 - val_loss: 2.6500\n",
      "Epoch 40/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3533 - val_loss: 2.3141\n",
      "Epoch 41/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3099 - val_loss: 2.2794\n",
      "Epoch 42/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3207 - val_loss: 2.2285\n",
      "Epoch 43/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2745 - val_loss: 2.2983\n",
      "Epoch 44/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.2785 - val_loss: 2.2385\n",
      "Epoch 45/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2911 - val_loss: 2.4055\n",
      "Epoch 46/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2520 - val_loss: 2.1839\n",
      "Epoch 47/100\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 2.2397 - val_loss: 2.2535\n",
      "Epoch 48/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2323 - val_loss: 2.1102\n",
      "Epoch 49/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2042 - val_loss: 2.2496\n",
      "Epoch 50/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1864 - val_loss: 2.1218\n",
      "Epoch 51/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1898 - val_loss: 2.1835\n",
      "Epoch 52/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.1659 - val_loss: 2.2356\n",
      "Epoch 53/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1369 - val_loss: 2.0551\n",
      "Epoch 54/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0980 - val_loss: 2.2527\n",
      "Epoch 55/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1210 - val_loss: 2.0620\n",
      "Epoch 56/100\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 2.0971 - val_loss: 2.2782\n",
      "Epoch 57/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.1008 - val_loss: 2.0655\n",
      "Epoch 58/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0673 - val_loss: 2.0888\n",
      "Epoch 59/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0699 - val_loss: 2.0353\n",
      "Epoch 60/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0461 - val_loss: 2.1535\n",
      "Epoch 61/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0448 - val_loss: 2.0441\n",
      "Epoch 62/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0464 - val_loss: 2.0756\n",
      "Epoch 63/100\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 2.0381 - val_loss: 2.0613\n",
      "Epoch 64/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0244 - val_loss: 2.0264\n",
      "Epoch 65/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9994 - val_loss: 1.9681\n",
      "Epoch 66/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0018 - val_loss: 2.0958\n",
      "Epoch 67/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0140 - val_loss: 1.9200\n",
      "Epoch 68/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9850 - val_loss: 1.9326\n",
      "Epoch 69/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9945 - val_loss: 1.9560\n",
      "Epoch 70/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9709 - val_loss: 1.9812\n",
      "Epoch 71/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9666 - val_loss: 2.1130\n",
      "Epoch 72/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9652 - val_loss: 2.1048\n",
      "Epoch 73/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9675 - val_loss: 1.9373\n",
      "Epoch 74/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9568 - val_loss: 1.9174\n",
      "Epoch 75/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9514 - val_loss: 1.9363\n",
      "Epoch 76/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9451 - val_loss: 1.9700\n",
      "Epoch 77/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9286 - val_loss: 1.9719\n",
      "Epoch 78/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9231 - val_loss: 1.9889\n",
      "Epoch 79/100\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.9369 - val_loss: 1.9266\n",
      "Epoch 80/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9006 - val_loss: 1.8527\n",
      "Epoch 81/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9076 - val_loss: 1.9235\n",
      "Epoch 82/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9080 - val_loss: 1.9947\n",
      "Epoch 83/100\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.9160 - val_loss: 1.8592\n",
      "Epoch 84/100\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.8870 - val_loss: 1.8399\n",
      "Epoch 85/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8878 - val_loss: 1.9505\n",
      "Epoch 86/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8625 - val_loss: 1.8532\n",
      "Epoch 87/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8744 - val_loss: 1.8353\n",
      "Epoch 88/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8701 - val_loss: 1.8407\n",
      "Epoch 89/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8486 - val_loss: 1.8096\n",
      "Epoch 90/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8521 - val_loss: 1.8832\n",
      "Epoch 91/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8405 - val_loss: 1.8488\n",
      "Epoch 92/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8443 - val_loss: 1.8316\n",
      "Epoch 93/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8318 - val_loss: 1.8440\n",
      "Epoch 94/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8247 - val_loss: 1.8732\n",
      "Epoch 95/100\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.8375 - val_loss: 1.8033\n",
      "Epoch 96/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8130 - val_loss: 1.8106\n",
      "Epoch 97/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8037 - val_loss: 1.8130\n",
      "Epoch 98/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7972 - val_loss: 1.9685\n",
      "Epoch 99/100\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7963 - val_loss: 1.8175\n",
      "Epoch 100/100\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8145 - val_loss: 1.8721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8721303422903441\n",
      "0.9435188213980233\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 13.7341 - val_loss: 20.0349\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 6.7362 - val_loss: 6.3968\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 8.0700 - val_loss: 3.9814\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 4.5150 - val_loss: 5.1544\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 6.2097 - val_loss: 4.3338\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 5.0204 - val_loss: 3.9438\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 4.2430 - val_loss: 4.2326\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.2394 - val_loss: 6.3246\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 4.2942 - val_loss: 5.4393\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.4545 - val_loss: 4.6237\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.1911 - val_loss: 4.5285\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.1306 - val_loss: 3.3895\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.4284 - val_loss: 3.1653\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 3.4963 - val_loss: 7.5333\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 3.6322 - val_loss: 3.2156\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.6521 - val_loss: 4.1995\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 3.4578 - val_loss: 3.8447\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.1766 - val_loss: 3.1109\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.1582 - val_loss: 3.7479\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.1078 - val_loss: 2.9912\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.1070 - val_loss: 3.1034\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 3.1535 - val_loss: 2.8564\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.0892 - val_loss: 2.8150\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.0130 - val_loss: 3.1314\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 3.0728 - val_loss: 2.8378\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 3.0085 - val_loss: 2.7206\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.9062 - val_loss: 2.7962\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.8513 - val_loss: 2.6984\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.8311 - val_loss: 2.8956\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.7496 - val_loss: 3.0064\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7609 - val_loss: 2.6223\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.7321 - val_loss: 2.5892\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.6032 - val_loss: 2.5854\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.5734 - val_loss: 2.5148\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.6172 - val_loss: 2.4773\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5176 - val_loss: 2.4571\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5505 - val_loss: 2.5115\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5106 - val_loss: 2.6296\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.4633 - val_loss: 2.4991\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4227 - val_loss: 2.3967\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3966 - val_loss: 2.3990\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 2.4019 - val_loss: 2.4077\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3897 - val_loss: 2.3257\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3806 - val_loss: 2.3678\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.3716 - val_loss: 2.3635\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3844 - val_loss: 2.3276\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.3179 - val_loss: 2.3913\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2906 - val_loss: 2.3544\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2701 - val_loss: 2.4500\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2652 - val_loss: 2.2188\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.2627 - val_loss: 2.3350\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.2226 - val_loss: 2.3411\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1896 - val_loss: 2.1399\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 2.2155 - val_loss: 2.0754\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1495 - val_loss: 2.0614\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1361 - val_loss: 2.1114\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1286 - val_loss: 2.0647\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 2.1196 - val_loss: 2.0515\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.1182 - val_loss: 2.0176\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1012 - val_loss: 2.2055\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1003 - val_loss: 2.0611\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.0900 - val_loss: 2.0389\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0734 - val_loss: 2.0302\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0588 - val_loss: 1.9918\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0686 - val_loss: 2.0281\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.0277 - val_loss: 2.0319\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0378 - val_loss: 2.0566\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.0207 - val_loss: 2.1204\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0164 - val_loss: 2.0666\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0006 - val_loss: 2.1148\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0234 - val_loss: 2.0159\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9917 - val_loss: 1.9559\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9785 - val_loss: 1.9723\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.9954 - val_loss: 1.9852\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.9581 - val_loss: 2.0394\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9703 - val_loss: 1.9920\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9711 - val_loss: 1.9914\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9448 - val_loss: 1.9322\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9691 - val_loss: 1.9127\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9374 - val_loss: 2.0246\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9390 - val_loss: 1.9815\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9459 - val_loss: 2.1462\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9221 - val_loss: 1.9007\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9113 - val_loss: 1.8886\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9200 - val_loss: 1.8628\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9408 - val_loss: 1.8882\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8950 - val_loss: 1.9351\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9076 - val_loss: 1.9060\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8935 - val_loss: 2.0237\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9032 - val_loss: 1.9288\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.8987 - val_loss: 1.8920\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8725 - val_loss: 1.9043\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8760 - val_loss: 1.8863\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8646 - val_loss: 1.9801\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8613 - val_loss: 1.8865\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8527 - val_loss: 1.8816\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8452 - val_loss: 1.8504\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8526 - val_loss: 1.9295\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8445 - val_loss: 1.8610\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8340 - val_loss: 1.8115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8114886091990163\n",
      "0.9440774407700155\n",
      "Epoch 1/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 6.7658 - val_loss: 11.2191\n",
      "Epoch 2/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 4.6004 - val_loss: 3.7136\n",
      "Epoch 3/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 3.9587 - val_loss: 3.5757\n",
      "Epoch 4/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 3.5021 - val_loss: 3.4980\n",
      "Epoch 5/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 3.2129 - val_loss: 2.8699\n",
      "Epoch 6/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.9855 - val_loss: 2.9917\n",
      "Epoch 7/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.8586 - val_loss: 2.5877\n",
      "Epoch 8/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.7558 - val_loss: 2.5684\n",
      "Epoch 9/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.6580 - val_loss: 2.5979\n",
      "Epoch 10/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.6224 - val_loss: 2.5269\n",
      "Epoch 11/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.5895 - val_loss: 2.4864\n",
      "Epoch 12/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.5595 - val_loss: 2.4641\n",
      "Epoch 13/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.5137 - val_loss: 2.7548\n",
      "Epoch 14/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.4741 - val_loss: 2.4814\n",
      "Epoch 15/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.4413 - val_loss: 2.6504\n",
      "Epoch 16/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.4150 - val_loss: 2.4695\n",
      "Epoch 17/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.3919 - val_loss: 2.4042\n",
      "Epoch 18/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.3758 - val_loss: 2.3893\n",
      "Epoch 19/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.3468 - val_loss: 2.3740\n",
      "Epoch 20/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.3112 - val_loss: 2.3948\n",
      "Epoch 21/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2938 - val_loss: 2.2132\n",
      "Epoch 22/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2645 - val_loss: 2.3607\n",
      "Epoch 23/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2364 - val_loss: 2.1051\n",
      "Epoch 24/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2322 - val_loss: 2.5104\n",
      "Epoch 25/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2011 - val_loss: 2.2697\n",
      "Epoch 26/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2052 - val_loss: 2.1931\n",
      "Epoch 27/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.1808 - val_loss: 2.1742\n",
      "Epoch 28/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1689 - val_loss: 2.0771\n",
      "Epoch 29/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1675 - val_loss: 2.0905\n",
      "Epoch 30/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1435 - val_loss: 2.1652\n",
      "Epoch 31/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1376 - val_loss: 2.1157\n",
      "Epoch 32/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1400 - val_loss: 2.1382\n",
      "Epoch 33/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1149 - val_loss: 2.1151\n",
      "Epoch 34/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1101 - val_loss: 2.0631\n",
      "Epoch 35/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1187 - val_loss: 2.1632\n",
      "Epoch 36/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0970 - val_loss: 2.0208\n",
      "Epoch 37/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1041 - val_loss: 1.9934\n",
      "Epoch 38/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0993 - val_loss: 2.1513\n",
      "Epoch 39/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0866 - val_loss: 2.1392\n",
      "Epoch 40/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0875 - val_loss: 2.1685\n",
      "Epoch 41/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0720 - val_loss: 2.0344\n",
      "Epoch 42/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0716 - val_loss: 2.0042\n",
      "Epoch 43/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0629 - val_loss: 2.0285\n",
      "Epoch 44/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0541 - val_loss: 2.0025\n",
      "Epoch 45/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0561 - val_loss: 1.9780\n",
      "Epoch 46/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0493 - val_loss: 2.0297\n",
      "Epoch 47/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0428 - val_loss: 2.0897\n",
      "Epoch 48/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0451 - val_loss: 2.3605\n",
      "Epoch 49/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0329 - val_loss: 2.0684\n",
      "Epoch 50/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0314 - val_loss: 1.9976\n",
      "Epoch 51/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0307 - val_loss: 2.0029\n",
      "Epoch 52/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0278 - val_loss: 2.1081\n",
      "Epoch 53/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0248 - val_loss: 1.9600\n",
      "Epoch 54/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0233 - val_loss: 2.0002\n",
      "Epoch 55/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0130 - val_loss: 1.9151\n",
      "Epoch 56/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0162 - val_loss: 1.9697\n",
      "Epoch 57/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0045 - val_loss: 2.0177\n",
      "Epoch 58/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0024 - val_loss: 2.0871\n",
      "Epoch 59/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0045 - val_loss: 2.0202\n",
      "Epoch 60/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9950 - val_loss: 2.0203\n",
      "Epoch 61/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9794 - val_loss: 2.0092\n",
      "Epoch 62/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9846 - val_loss: 1.9819\n",
      "Epoch 63/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9871 - val_loss: 1.9163\n",
      "Epoch 64/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9818 - val_loss: 2.0225\n",
      "Epoch 65/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9753 - val_loss: 2.0812\n",
      "Epoch 66/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9747 - val_loss: 2.0301\n",
      "Epoch 67/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9794 - val_loss: 1.8956\n",
      "Epoch 68/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9621 - val_loss: 1.9116\n",
      "Epoch 69/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9646 - val_loss: 1.9802\n",
      "Epoch 70/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9542 - val_loss: 1.8825\n",
      "Epoch 71/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9582 - val_loss: 1.9427\n",
      "Epoch 72/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9553 - val_loss: 2.0104\n",
      "Epoch 73/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9538 - val_loss: 1.9380\n",
      "Epoch 74/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9504 - val_loss: 1.9084\n",
      "Epoch 75/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9514 - val_loss: 1.9617\n",
      "Epoch 76/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9487 - val_loss: 1.9390\n",
      "Epoch 77/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9472 - val_loss: 1.9568\n",
      "Epoch 78/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9424 - val_loss: 1.9011\n",
      "Epoch 79/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9300 - val_loss: 1.9406\n",
      "Epoch 80/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9374 - val_loss: 1.9322\n",
      "Epoch 81/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9316 - val_loss: 2.0678\n",
      "Epoch 82/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9355 - val_loss: 1.9291\n",
      "Epoch 83/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9332 - val_loss: 1.8901\n",
      "Epoch 84/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9332 - val_loss: 1.9436\n",
      "Epoch 85/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9298 - val_loss: 1.9835\n",
      "Epoch 86/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9170 - val_loss: 1.9937\n",
      "Epoch 87/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9129 - val_loss: 2.0163\n",
      "Epoch 88/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9273 - val_loss: 1.8901\n",
      "Epoch 89/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9069 - val_loss: 1.9207\n",
      "Epoch 90/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9298 - val_loss: 1.8405\n",
      "Epoch 91/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9126 - val_loss: 2.0930\n",
      "Epoch 92/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9179 - val_loss: 1.8815\n",
      "Epoch 93/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9041 - val_loss: 1.8926\n",
      "Epoch 94/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9085 - val_loss: 1.8853\n",
      "Epoch 95/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9095 - val_loss: 1.8618\n",
      "Epoch 96/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9025 - val_loss: 2.0018\n",
      "Epoch 97/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9128 - val_loss: 1.8521\n",
      "Epoch 98/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9054 - val_loss: 1.9724\n",
      "Epoch 99/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9011 - val_loss: 1.8979\n",
      "Epoch 100/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8970 - val_loss: 1.8624\n",
      "Epoch 101/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8976 - val_loss: 1.9661\n",
      "Epoch 102/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8982 - val_loss: 1.9012\n",
      "Epoch 103/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8952 - val_loss: 2.0038\n",
      "Epoch 104/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8840 - val_loss: 1.8401\n",
      "Epoch 105/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8843 - val_loss: 1.9023\n",
      "Epoch 106/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8889 - val_loss: 1.8571\n",
      "Epoch 107/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9019 - val_loss: 1.8327\n",
      "Epoch 108/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8858 - val_loss: 1.8534\n",
      "Epoch 109/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8843 - val_loss: 1.8686\n",
      "Epoch 110/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8803 - val_loss: 1.9369\n",
      "Epoch 111/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8828 - val_loss: 1.8924\n",
      "Epoch 112/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8831 - val_loss: 2.0949\n",
      "Epoch 113/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8789 - val_loss: 1.9735\n",
      "Epoch 114/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8694 - val_loss: 1.8644\n",
      "Epoch 115/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8723 - val_loss: 1.8976\n",
      "Epoch 116/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8820 - val_loss: 1.9026\n",
      "Epoch 117/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8805 - val_loss: 1.8942\n",
      "Epoch 118/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8657 - val_loss: 1.8461\n",
      "Epoch 119/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8613 - val_loss: 1.8624\n",
      "Epoch 120/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8723 - val_loss: 1.8396\n",
      "Epoch 121/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8657 - val_loss: 1.8832\n",
      "Epoch 122/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8629 - val_loss: 1.8820\n",
      "Epoch 123/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8646 - val_loss: 1.8100\n",
      "Epoch 124/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8647 - val_loss: 1.8448\n",
      "Epoch 125/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8545 - val_loss: 1.9135\n",
      "Epoch 126/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8659 - val_loss: 1.8358\n",
      "Epoch 127/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8587 - val_loss: 1.9519\n",
      "Epoch 128/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8614 - val_loss: 1.8773\n",
      "Epoch 129/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8607 - val_loss: 1.8210\n",
      "Epoch 130/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8634 - val_loss: 1.8484\n",
      "Epoch 131/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8472 - val_loss: 1.9767\n",
      "Epoch 132/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8476 - val_loss: 1.8341\n",
      "Epoch 133/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8460 - val_loss: 1.9315\n",
      "Epoch 134/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8560 - val_loss: 1.9092\n",
      "Epoch 135/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8465 - val_loss: 1.9316\n",
      "Epoch 136/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8493 - val_loss: 1.7929\n",
      "Epoch 137/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8434 - val_loss: 1.8256\n",
      "Epoch 138/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8528 - val_loss: 1.8061\n",
      "Epoch 139/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8415 - val_loss: 1.8073\n",
      "Epoch 140/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8500 - val_loss: 1.8275\n",
      "Epoch 141/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8370 - val_loss: 1.8183\n",
      "Epoch 142/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8382 - val_loss: 1.8416\n",
      "Epoch 143/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8438 - val_loss: 1.7734\n",
      "Epoch 144/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8387 - val_loss: 1.8437\n",
      "Epoch 145/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8288 - val_loss: 1.8183\n",
      "Epoch 146/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8380 - val_loss: 1.8484\n",
      "Epoch 147/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8263 - val_loss: 1.8078\n",
      "Epoch 148/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8397 - val_loss: 1.7811\n",
      "Epoch 149/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8326 - val_loss: 1.9312\n",
      "Epoch 150/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8307 - val_loss: 1.8062\n",
      "Epoch 151/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8354 - val_loss: 1.8260\n",
      "Epoch 152/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8365 - val_loss: 1.8620\n",
      "Epoch 153/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8299 - val_loss: 1.8394\n",
      "Epoch 154/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8346 - val_loss: 1.9440\n",
      "Epoch 155/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8381 - val_loss: 1.8006\n",
      "Epoch 156/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8287 - val_loss: 1.8932\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8256 - val_loss: 1.8593\n",
      "Epoch 158/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8275 - val_loss: 1.8867\n",
      "Epoch 159/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8248 - val_loss: 1.8236\n",
      "Epoch 160/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8190 - val_loss: 1.8917\n",
      "Epoch 161/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8217 - val_loss: 1.9063\n",
      "Epoch 162/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8172 - val_loss: 1.8653\n",
      "Epoch 163/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8212 - val_loss: 1.8409\n",
      "Epoch 164/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8204 - val_loss: 1.9405\n",
      "Epoch 165/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8226 - val_loss: 1.7631\n",
      "Epoch 166/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8188 - val_loss: 1.8342\n",
      "Epoch 167/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8266 - val_loss: 1.8575\n",
      "Epoch 168/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8149 - val_loss: 1.8895\n",
      "Epoch 169/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8215 - val_loss: 1.8485\n",
      "Epoch 170/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8193 - val_loss: 1.8521\n",
      "Epoch 171/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8159 - val_loss: 1.8163\n",
      "Epoch 172/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8112 - val_loss: 1.9037\n",
      "Epoch 173/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8118 - val_loss: 1.8044\n",
      "Epoch 174/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8078 - val_loss: 1.8201\n",
      "Epoch 175/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8105 - val_loss: 1.7947\n",
      "Epoch 176/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8108 - val_loss: 1.8600\n",
      "Epoch 177/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8139 - val_loss: 1.8312\n",
      "Epoch 178/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7984 - val_loss: 1.7754\n",
      "Epoch 179/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8070 - val_loss: 1.7790\n",
      "Epoch 180/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8043 - val_loss: 1.7288\n",
      "Epoch 181/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8061 - val_loss: 1.8303\n",
      "Epoch 182/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8024 - val_loss: 1.7824\n",
      "Epoch 183/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8032 - val_loss: 1.8940\n",
      "Epoch 184/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8011 - val_loss: 1.7918\n",
      "Epoch 185/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7962 - val_loss: 1.7501\n",
      "Epoch 186/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8088 - val_loss: 1.8321\n",
      "Epoch 187/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8063 - val_loss: 1.8548\n",
      "Epoch 188/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8005 - val_loss: 1.7997\n",
      "Epoch 189/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8049 - val_loss: 1.7719\n",
      "Epoch 190/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7990 - val_loss: 1.8179\n",
      "Epoch 191/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8128 - val_loss: 2.0521\n",
      "Epoch 192/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7939 - val_loss: 1.8137\n",
      "Epoch 193/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7991 - val_loss: 1.8433\n",
      "Epoch 194/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7918 - val_loss: 1.7950\n",
      "Epoch 195/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7940 - val_loss: 1.8524\n",
      "Epoch 196/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7953 - val_loss: 1.8279\n",
      "Epoch 197/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7939 - val_loss: 1.8532\n",
      "Epoch 198/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7962 - val_loss: 1.8837\n",
      "Epoch 199/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7924 - val_loss: 1.8421\n",
      "Epoch 200/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7940 - val_loss: 1.7576\n",
      "Epoch 201/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7899 - val_loss: 2.0003\n",
      "Epoch 202/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7908 - val_loss: 1.7605\n",
      "Epoch 203/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7883 - val_loss: 1.7901\n",
      "Epoch 204/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7874 - val_loss: 1.8163\n",
      "Epoch 205/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7847 - val_loss: 1.9019\n",
      "Epoch 206/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7895 - val_loss: 1.8586\n",
      "Epoch 207/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7884 - val_loss: 2.0142\n",
      "Epoch 208/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7920 - val_loss: 1.8853\n",
      "Epoch 209/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7900 - val_loss: 1.8430\n",
      "Epoch 210/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7800 - val_loss: 1.7941\n",
      "Epoch 211/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7832 - val_loss: 1.8375\n",
      "Epoch 212/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7895 - val_loss: 1.8596\n",
      "Epoch 213/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7778 - val_loss: 1.8169\n",
      "Epoch 214/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7799 - val_loss: 1.7780\n",
      "Epoch 215/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7852 - val_loss: 1.7324\n",
      "Epoch 216/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7832 - val_loss: 1.7395\n",
      "Epoch 217/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7941 - val_loss: 1.8444\n",
      "Epoch 218/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7826 - val_loss: 1.7755\n",
      "Epoch 219/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7785 - val_loss: 1.8807\n",
      "Epoch 220/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7850 - val_loss: 1.8011\n",
      "Epoch 221/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7787 - val_loss: 1.8326\n",
      "Epoch 222/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7815 - val_loss: 2.0022\n",
      "Epoch 223/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7723 - val_loss: 1.7576\n",
      "Epoch 224/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7792 - val_loss: 1.8266\n",
      "Epoch 225/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7788 - val_loss: 1.8367\n",
      "Epoch 226/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7792 - val_loss: 1.9247\n",
      "Epoch 227/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7757 - val_loss: 1.8713\n",
      "Epoch 228/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7723 - val_loss: 1.7496\n",
      "Epoch 229/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7659 - val_loss: 1.7618\n",
      "Epoch 230/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7716 - val_loss: 1.8444\n",
      "Epoch 231/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7721 - val_loss: 1.8202\n",
      "Epoch 232/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7709 - val_loss: 1.8105\n",
      "Epoch 233/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7696 - val_loss: 1.8085\n",
      "Epoch 234/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7698 - val_loss: 1.8256\n",
      "Epoch 235/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7656 - val_loss: 1.8498\n",
      "Epoch 236/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7688 - val_loss: 1.8546\n",
      "Epoch 237/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7727 - val_loss: 1.7908\n",
      "Epoch 238/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7606 - val_loss: 1.7850\n",
      "Epoch 239/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7680 - val_loss: 1.7950\n",
      "Epoch 240/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7590 - val_loss: 1.7545\n",
      "Epoch 241/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7621 - val_loss: 1.7904\n",
      "Epoch 242/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7684 - val_loss: 1.7481\n",
      "Epoch 243/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7727 - val_loss: 1.9802\n",
      "Epoch 244/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7621 - val_loss: 1.8254\n",
      "Epoch 245/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7631 - val_loss: 1.7279\n",
      "Epoch 246/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7612 - val_loss: 1.7629\n",
      "Epoch 247/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7583 - val_loss: 1.8221\n",
      "Epoch 248/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7653 - val_loss: 1.7474\n",
      "Epoch 249/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7614 - val_loss: 1.8510\n",
      "Epoch 250/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7560 - val_loss: 1.7571\n",
      "Epoch 251/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7617 - val_loss: 1.7555\n",
      "Epoch 252/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7551 - val_loss: 1.8471\n",
      "Epoch 253/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7579 - val_loss: 1.7928\n",
      "Epoch 254/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7620 - val_loss: 1.7022\n",
      "Epoch 255/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7553 - val_loss: 1.7332\n",
      "Epoch 256/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7580 - val_loss: 1.7608\n",
      "Epoch 257/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7525 - val_loss: 1.8294\n",
      "Epoch 258/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7579 - val_loss: 1.7091\n",
      "Epoch 259/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7518 - val_loss: 1.9046\n",
      "Epoch 260/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7550 - val_loss: 1.8054\n",
      "Epoch 261/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7484 - val_loss: 1.7792\n",
      "Epoch 262/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7549 - val_loss: 1.8151\n",
      "Epoch 263/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7485 - val_loss: 1.7793\n",
      "Epoch 264/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7563 - val_loss: 1.8234\n",
      "Epoch 265/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7510 - val_loss: 1.7476\n",
      "Epoch 266/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7530 - val_loss: 1.7261\n",
      "Epoch 267/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7533 - val_loss: 1.7083\n",
      "Epoch 268/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7568 - val_loss: 1.7403\n",
      "Epoch 269/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7515 - val_loss: 1.7874\n",
      "Epoch 270/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7418 - val_loss: 1.8363\n",
      "Epoch 271/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7505 - val_loss: 1.7973\n",
      "Epoch 272/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7494 - val_loss: 1.9918\n",
      "Epoch 273/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7472 - val_loss: 1.7763\n",
      "Epoch 274/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7491 - val_loss: 1.7709\n",
      "Epoch 275/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7542 - val_loss: 1.7599\n",
      "Epoch 276/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7521 - val_loss: 1.8060\n",
      "Epoch 277/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7423 - val_loss: 1.7976\n",
      "Epoch 278/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7479 - val_loss: 1.7877\n",
      "Epoch 279/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7433 - val_loss: 1.7621\n",
      "Epoch 280/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7461 - val_loss: 1.8959\n",
      "Epoch 281/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7461 - val_loss: 1.6733\n",
      "Epoch 282/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7414 - val_loss: 1.7288\n",
      "Epoch 283/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7473 - val_loss: 1.8951\n",
      "Epoch 284/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7345 - val_loss: 1.8397\n",
      "Epoch 285/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7437 - val_loss: 1.7440\n",
      "Epoch 286/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7370 - val_loss: 1.7639\n",
      "Epoch 287/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7354 - val_loss: 1.8121\n",
      "Epoch 288/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7419 - val_loss: 1.7406\n",
      "Epoch 289/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7410 - val_loss: 1.8256\n",
      "Epoch 290/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7356 - val_loss: 1.7865\n",
      "Epoch 291/300\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7403 - val_loss: 1.7578\n",
      "Epoch 292/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7361 - val_loss: 1.7888\n",
      "Epoch 293/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7331 - val_loss: 1.8205\n",
      "Epoch 294/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7344 - val_loss: 1.7907\n",
      "Epoch 295/300\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7335 - val_loss: 1.7452\n",
      "Epoch 296/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7362 - val_loss: 1.7491\n",
      "Epoch 297/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7329 - val_loss: 1.7402\n",
      "Epoch 298/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7364 - val_loss: 1.7446\n",
      "Epoch 299/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7318 - val_loss: 1.7500\n",
      "Epoch 300/300\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7316 - val_loss: 1.8260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8259610709842924\n",
      "0.9493466859861599\n",
      "Epoch 1/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 8.2130 - val_loss: 4.1387\n",
      "Epoch 2/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 4.6437 - val_loss: 4.1208\n",
      "Epoch 3/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 4.3492 - val_loss: 4.2298\n",
      "Epoch 4/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 4.0236 - val_loss: 3.2601\n",
      "Epoch 5/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 3.5436 - val_loss: 3.0788\n",
      "Epoch 6/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 3.2368 - val_loss: 2.9274\n",
      "Epoch 7/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 3.0984 - val_loss: 2.9336\n",
      "Epoch 8/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.9792 - val_loss: 2.9060\n",
      "Epoch 9/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.9209 - val_loss: 2.7921\n",
      "Epoch 10/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.8443 - val_loss: 2.9561\n",
      "Epoch 11/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.7708 - val_loss: 2.6463\n",
      "Epoch 12/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.7163 - val_loss: 2.7377\n",
      "Epoch 13/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.6782 - val_loss: 2.6248\n",
      "Epoch 14/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.5974 - val_loss: 2.7410\n",
      "Epoch 15/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.5614 - val_loss: 2.4542\n",
      "Epoch 16/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.5195 - val_loss: 2.4317\n",
      "Epoch 17/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.4822 - val_loss: 2.3955\n",
      "Epoch 18/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.4375 - val_loss: 2.4002\n",
      "Epoch 19/300\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.4006 - val_loss: 2.4908\n",
      "Epoch 20/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3859 - val_loss: 2.3929\n",
      "Epoch 21/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.4045 - val_loss: 2.2931\n",
      "Epoch 22/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.3619 - val_loss: 2.3833\n",
      "Epoch 23/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3331 - val_loss: 2.2286\n",
      "Epoch 24/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3102 - val_loss: 2.2938\n",
      "Epoch 25/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.3016 - val_loss: 2.4420\n",
      "Epoch 26/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.2434 - val_loss: 2.3274\n",
      "Epoch 27/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.2363 - val_loss: 2.2611\n",
      "Epoch 28/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.1852 - val_loss: 2.1321\n",
      "Epoch 29/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.1831 - val_loss: 2.3589\n",
      "Epoch 30/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.1785 - val_loss: 2.1166\n",
      "Epoch 31/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.1564 - val_loss: 2.0842\n",
      "Epoch 32/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1335 - val_loss: 2.1076\n",
      "Epoch 33/300\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 2.1266 - val_loss: 2.1242\n",
      "Epoch 34/300\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.1080 - val_loss: 2.0030\n",
      "Epoch 35/300\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.0839 - val_loss: 2.1053\n",
      "Epoch 36/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.0958 - val_loss: 2.0737\n",
      "Epoch 37/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0807 - val_loss: 1.9645\n",
      "Epoch 38/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0615 - val_loss: 2.0657\n",
      "Epoch 39/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0675 - val_loss: 1.9934\n",
      "Epoch 40/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.0591 - val_loss: 2.0800\n",
      "Epoch 41/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.0436 - val_loss: 1.9866\n",
      "Epoch 42/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.0334 - val_loss: 2.0241\n",
      "Epoch 43/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.0383 - val_loss: 1.9759\n",
      "Epoch 44/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.0046 - val_loss: 2.0195\n",
      "Epoch 45/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0110 - val_loss: 2.0614\n",
      "Epoch 46/300\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9932 - val_loss: 2.0266\n",
      "Epoch 47/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.9980 - val_loss: 1.9722\n",
      "Epoch 48/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9808 - val_loss: 2.0508\n",
      "Epoch 49/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.9776 - val_loss: 2.1377\n",
      "Epoch 50/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.9864 - val_loss: 1.9752\n",
      "Epoch 51/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9524 - val_loss: 2.0116\n",
      "Epoch 52/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9629 - val_loss: 1.9776\n",
      "Epoch 53/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9428 - val_loss: 2.1001\n",
      "Epoch 54/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.9385 - val_loss: 2.0404\n",
      "Epoch 55/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.9258 - val_loss: 1.9032\n",
      "Epoch 56/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9217 - val_loss: 1.9740\n",
      "Epoch 57/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.9380 - val_loss: 1.8531\n",
      "Epoch 58/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9286 - val_loss: 2.1277\n",
      "Epoch 59/300\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.9119 - val_loss: 1.9482\n",
      "Epoch 60/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9105 - val_loss: 1.9947\n",
      "Epoch 61/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9024 - val_loss: 1.8944\n",
      "Epoch 62/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8949 - val_loss: 1.8520\n",
      "Epoch 63/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8868 - val_loss: 1.8824\n",
      "Epoch 64/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8953 - val_loss: 1.9963\n",
      "Epoch 65/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8946 - val_loss: 1.9094\n",
      "Epoch 66/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8735 - val_loss: 1.9481\n",
      "Epoch 67/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8857 - val_loss: 1.9004\n",
      "Epoch 68/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8797 - val_loss: 1.9746\n",
      "Epoch 69/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8597 - val_loss: 1.8659\n",
      "Epoch 70/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8607 - val_loss: 1.8975\n",
      "Epoch 71/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8563 - val_loss: 1.9964\n",
      "Epoch 72/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8355 - val_loss: 1.8848\n",
      "Epoch 73/300\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.8516 - val_loss: 1.8463\n",
      "Epoch 74/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8322 - val_loss: 1.9827\n",
      "Epoch 75/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8359 - val_loss: 1.9646\n",
      "Epoch 76/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8434 - val_loss: 1.8625\n",
      "Epoch 77/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8192 - val_loss: 1.8148\n",
      "Epoch 78/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8137 - val_loss: 1.8216\n",
      "Epoch 79/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8215 - val_loss: 1.8613\n",
      "Epoch 80/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8218 - val_loss: 1.8221\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8173 - val_loss: 1.9085\n",
      "Epoch 82/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8093 - val_loss: 1.7513\n",
      "Epoch 83/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8011 - val_loss: 1.7814\n",
      "Epoch 84/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8007 - val_loss: 1.7687\n",
      "Epoch 85/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8010 - val_loss: 1.8376\n",
      "Epoch 86/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7874 - val_loss: 1.7496\n",
      "Epoch 87/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7939 - val_loss: 1.7945\n",
      "Epoch 88/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7853 - val_loss: 1.7653\n",
      "Epoch 89/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7938 - val_loss: 1.7830\n",
      "Epoch 90/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7846 - val_loss: 1.8384\n",
      "Epoch 91/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7718 - val_loss: 1.7395\n",
      "Epoch 92/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7684 - val_loss: 1.7561\n",
      "Epoch 93/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7689 - val_loss: 1.8226\n",
      "Epoch 94/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7689 - val_loss: 2.0255\n",
      "Epoch 95/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7829 - val_loss: 1.7974\n",
      "Epoch 96/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7592 - val_loss: 1.8059\n",
      "Epoch 97/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7530 - val_loss: 1.8367\n",
      "Epoch 98/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7547 - val_loss: 1.7345\n",
      "Epoch 99/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7603 - val_loss: 1.7399\n",
      "Epoch 100/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7622 - val_loss: 1.7149\n",
      "Epoch 101/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7634 - val_loss: 1.7678\n",
      "Epoch 102/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7501 - val_loss: 1.7654\n",
      "Epoch 103/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7391 - val_loss: 1.7261\n",
      "Epoch 104/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7493 - val_loss: 1.7860\n",
      "Epoch 105/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7412 - val_loss: 1.7240\n",
      "Epoch 106/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7322 - val_loss: 1.7826\n",
      "Epoch 107/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7358 - val_loss: 1.8746\n",
      "Epoch 108/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7387 - val_loss: 1.7740\n",
      "Epoch 109/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7316 - val_loss: 1.7299\n",
      "Epoch 110/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7274 - val_loss: 1.7321\n",
      "Epoch 111/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7313 - val_loss: 1.6912\n",
      "Epoch 112/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7274 - val_loss: 1.7540\n",
      "Epoch 113/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7268 - val_loss: 1.6915\n",
      "Epoch 114/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7077 - val_loss: 1.8614\n",
      "Epoch 115/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7162 - val_loss: 1.7718\n",
      "Epoch 116/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7187 - val_loss: 1.8015\n",
      "Epoch 117/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7136 - val_loss: 1.6607\n",
      "Epoch 118/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7050 - val_loss: 1.6916\n",
      "Epoch 119/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7221 - val_loss: 1.7839\n",
      "Epoch 120/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7010 - val_loss: 1.7260\n",
      "Epoch 121/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7187 - val_loss: 1.8329\n",
      "Epoch 122/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7012 - val_loss: 1.7505\n",
      "Epoch 123/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6953 - val_loss: 1.8160\n",
      "Epoch 124/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6995 - val_loss: 1.7009\n",
      "Epoch 125/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7053 - val_loss: 1.7239\n",
      "Epoch 126/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6990 - val_loss: 1.7343\n",
      "Epoch 127/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6968 - val_loss: 1.6598\n",
      "Epoch 128/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6810 - val_loss: 1.6657\n",
      "Epoch 129/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6874 - val_loss: 1.6904\n",
      "Epoch 130/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6896 - val_loss: 1.6681\n",
      "Epoch 131/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6884 - val_loss: 1.7801\n",
      "Epoch 132/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6764 - val_loss: 1.6960\n",
      "Epoch 133/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6829 - val_loss: 1.7977\n",
      "Epoch 134/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6739 - val_loss: 1.6391\n",
      "Epoch 135/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6746 - val_loss: 1.7031\n",
      "Epoch 136/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6743 - val_loss: 1.6902\n",
      "Epoch 137/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6755 - val_loss: 1.7842\n",
      "Epoch 138/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6760 - val_loss: 1.7162\n",
      "Epoch 139/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6706 - val_loss: 1.7220\n",
      "Epoch 140/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6681 - val_loss: 1.6743\n",
      "Epoch 141/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6714 - val_loss: 1.7847\n",
      "Epoch 142/300\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6571 - val_loss: 1.7814\n",
      "Epoch 143/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6664 - val_loss: 1.7929\n",
      "Epoch 144/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6686 - val_loss: 1.6589\n",
      "Epoch 145/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6574 - val_loss: 1.6583\n",
      "Epoch 146/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6594 - val_loss: 1.6560\n",
      "Epoch 147/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6657 - val_loss: 1.6794\n",
      "Epoch 148/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6558 - val_loss: 1.7019\n",
      "Epoch 149/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6560 - val_loss: 1.7480\n",
      "Epoch 150/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6603 - val_loss: 1.6315\n",
      "Epoch 151/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6475 - val_loss: 1.6314\n",
      "Epoch 152/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6583 - val_loss: 1.7111\n",
      "Epoch 153/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6483 - val_loss: 1.7102\n",
      "Epoch 154/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6518 - val_loss: 1.6162\n",
      "Epoch 155/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6421 - val_loss: 1.6729\n",
      "Epoch 156/300\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6397 - val_loss: 1.6902\n",
      "Epoch 157/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6400 - val_loss: 1.6659\n",
      "Epoch 158/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6384 - val_loss: 1.7052\n",
      "Epoch 159/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6308 - val_loss: 1.7593\n",
      "Epoch 160/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6458 - val_loss: 1.7741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6379 - val_loss: 1.6809\n",
      "Epoch 162/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6420 - val_loss: 1.6554\n",
      "Epoch 163/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6420 - val_loss: 1.6359\n",
      "Epoch 164/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6379 - val_loss: 1.6133\n",
      "Epoch 165/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6384 - val_loss: 1.6037\n",
      "Epoch 166/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6335 - val_loss: 1.5987\n",
      "Epoch 167/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6374 - val_loss: 1.6458\n",
      "Epoch 168/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6294 - val_loss: 1.6526\n",
      "Epoch 169/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6339 - val_loss: 1.6782\n",
      "Epoch 170/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6212 - val_loss: 1.6321\n",
      "Epoch 171/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6346 - val_loss: 1.6374\n",
      "Epoch 172/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6247 - val_loss: 1.6323\n",
      "Epoch 173/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6183 - val_loss: 1.6645\n",
      "Epoch 174/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6179 - val_loss: 1.6284\n",
      "Epoch 175/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6129 - val_loss: 1.6125\n",
      "Epoch 176/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6255 - val_loss: 1.6374\n",
      "Epoch 177/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6257 - val_loss: 1.6128\n",
      "Epoch 178/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6238 - val_loss: 1.6872\n",
      "Epoch 179/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6231 - val_loss: 1.6933\n",
      "Epoch 180/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6093 - val_loss: 1.6232\n",
      "Epoch 181/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6083 - val_loss: 1.6047\n",
      "Epoch 182/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6138 - val_loss: 1.6417\n",
      "Epoch 183/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6065 - val_loss: 1.6001\n",
      "Epoch 184/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6125 - val_loss: 1.7342\n",
      "Epoch 185/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6105 - val_loss: 1.6188\n",
      "Epoch 186/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6165 - val_loss: 1.5774\n",
      "Epoch 187/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6004 - val_loss: 1.6126\n",
      "Epoch 188/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5958 - val_loss: 1.6470\n",
      "Epoch 189/300\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6143 - val_loss: 1.6807\n",
      "Epoch 190/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6056 - val_loss: 1.6266\n",
      "Epoch 191/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6059 - val_loss: 1.6702\n",
      "Epoch 192/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6044 - val_loss: 1.5858\n",
      "Epoch 193/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6057 - val_loss: 1.5919\n",
      "Epoch 194/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6002 - val_loss: 1.5792\n",
      "Epoch 195/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5944 - val_loss: 1.6144\n",
      "Epoch 196/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5916 - val_loss: 1.5916\n",
      "Epoch 197/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6078 - val_loss: 1.6715\n",
      "Epoch 198/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5900 - val_loss: 1.6805\n",
      "Epoch 199/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5997 - val_loss: 1.5350\n",
      "Epoch 200/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5904 - val_loss: 1.5737\n",
      "Epoch 201/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5909 - val_loss: 1.6202\n",
      "Epoch 202/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5900 - val_loss: 1.6596\n",
      "Epoch 203/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6063 - val_loss: 1.5857\n",
      "Epoch 204/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5977 - val_loss: 1.6009\n",
      "Epoch 205/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5983 - val_loss: 1.5642\n",
      "Epoch 206/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5964 - val_loss: 1.6568\n",
      "Epoch 207/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5825 - val_loss: 1.6113\n",
      "Epoch 208/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5777 - val_loss: 1.6134\n",
      "Epoch 209/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6011 - val_loss: 1.6239\n",
      "Epoch 210/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5828 - val_loss: 1.7532\n",
      "Epoch 211/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5817 - val_loss: 1.7232\n",
      "Epoch 212/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5914 - val_loss: 1.5655\n",
      "Epoch 213/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5831 - val_loss: 1.6075\n",
      "Epoch 214/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5932 - val_loss: 1.6075\n",
      "Epoch 215/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5846 - val_loss: 1.5596\n",
      "Epoch 216/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5819 - val_loss: 1.6233\n",
      "Epoch 217/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5706 - val_loss: 1.6134\n",
      "Epoch 218/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5909 - val_loss: 1.5456\n",
      "Epoch 219/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5749 - val_loss: 1.5714\n",
      "Epoch 220/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5681 - val_loss: 1.5649\n",
      "Epoch 221/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5725 - val_loss: 1.7385\n",
      "Epoch 222/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5767 - val_loss: 1.6579\n",
      "Epoch 223/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5686 - val_loss: 1.5642\n",
      "Epoch 224/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5808 - val_loss: 1.5882\n",
      "Epoch 225/300\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5724 - val_loss: 1.5870\n",
      "Epoch 226/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5747 - val_loss: 1.6019\n",
      "Epoch 227/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5686 - val_loss: 1.6319\n",
      "Epoch 228/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5668 - val_loss: 1.6280\n",
      "Epoch 229/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5671 - val_loss: 1.5738\n",
      "Epoch 230/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5741 - val_loss: 1.5638\n",
      "Epoch 231/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5665 - val_loss: 1.5451\n",
      "Epoch 232/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5585 - val_loss: 1.6668\n",
      "Epoch 233/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5673 - val_loss: 1.7189\n",
      "Epoch 234/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5660 - val_loss: 1.7934\n",
      "Epoch 235/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5642 - val_loss: 1.6309\n",
      "Epoch 236/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5664 - val_loss: 1.6035\n",
      "Epoch 237/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5642 - val_loss: 1.6137\n",
      "Epoch 238/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5703 - val_loss: 1.5964\n",
      "Epoch 239/300\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5560 - val_loss: 1.6714\n",
      "Epoch 240/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5540 - val_loss: 1.6286\n",
      "Epoch 241/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5564 - val_loss: 1.6894\n",
      "Epoch 242/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5548 - val_loss: 1.6100\n",
      "Epoch 243/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5595 - val_loss: 1.5470\n",
      "Epoch 244/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5601 - val_loss: 1.5434\n",
      "Epoch 245/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5679 - val_loss: 1.6542\n",
      "Epoch 246/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5508 - val_loss: 1.6828\n",
      "Epoch 247/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5575 - val_loss: 1.5361\n",
      "Epoch 248/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5508 - val_loss: 1.5673\n",
      "Epoch 249/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5436 - val_loss: 1.5775\n",
      "Epoch 250/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5670 - val_loss: 1.6197\n",
      "Epoch 251/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5499 - val_loss: 1.6022\n",
      "Epoch 252/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5474 - val_loss: 1.5715\n",
      "Epoch 253/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5477 - val_loss: 1.5627\n",
      "Epoch 254/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5487 - val_loss: 1.6006\n",
      "Epoch 255/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5627 - val_loss: 1.6345\n",
      "Epoch 256/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5387 - val_loss: 1.5450\n",
      "Epoch 257/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5477 - val_loss: 1.5524\n",
      "Epoch 258/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5520 - val_loss: 1.5677\n",
      "Epoch 259/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5494 - val_loss: 1.5538\n",
      "Epoch 260/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5443 - val_loss: 1.5683\n",
      "Epoch 261/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5421 - val_loss: 1.5216\n",
      "Epoch 262/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5472 - val_loss: 1.5730\n",
      "Epoch 263/300\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5493 - val_loss: 1.6439\n",
      "Epoch 264/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5441 - val_loss: 1.7194\n",
      "Epoch 265/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5403 - val_loss: 1.5929\n",
      "Epoch 266/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5319 - val_loss: 1.5629\n",
      "Epoch 267/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5431 - val_loss: 1.5760\n",
      "Epoch 268/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5344 - val_loss: 1.5857\n",
      "Epoch 269/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5325 - val_loss: 1.5275\n",
      "Epoch 270/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5363 - val_loss: 1.5601\n",
      "Epoch 271/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5342 - val_loss: 1.6422\n",
      "Epoch 272/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5336 - val_loss: 1.5197\n",
      "Epoch 273/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5455 - val_loss: 1.6397\n",
      "Epoch 274/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5356 - val_loss: 1.5558\n",
      "Epoch 275/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5336 - val_loss: 1.5217\n",
      "Epoch 276/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5360 - val_loss: 1.5464\n",
      "Epoch 277/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5245 - val_loss: 1.5074\n",
      "Epoch 278/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5365 - val_loss: 1.6023\n",
      "Epoch 279/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5309 - val_loss: 1.5926\n",
      "Epoch 280/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5279 - val_loss: 1.5178\n",
      "Epoch 281/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5352 - val_loss: 1.5500\n",
      "Epoch 282/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5396 - val_loss: 1.4986\n",
      "Epoch 283/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5303 - val_loss: 1.6491\n",
      "Epoch 284/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5318 - val_loss: 1.5507\n",
      "Epoch 285/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5262 - val_loss: 1.6236\n",
      "Epoch 286/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5285 - val_loss: 1.5439\n",
      "Epoch 287/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5268 - val_loss: 1.5512\n",
      "Epoch 288/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5297 - val_loss: 1.6101\n",
      "Epoch 289/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5210 - val_loss: 1.5339\n",
      "Epoch 290/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5255 - val_loss: 1.6370\n",
      "Epoch 291/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5312 - val_loss: 1.5556\n",
      "Epoch 292/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5273 - val_loss: 1.5245\n",
      "Epoch 293/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5287 - val_loss: 1.5824\n",
      "Epoch 294/300\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5295 - val_loss: 1.5894\n",
      "Epoch 295/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5261 - val_loss: 1.5490\n",
      "Epoch 296/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5159 - val_loss: 1.5950\n",
      "Epoch 297/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5146 - val_loss: 1.5597\n",
      "Epoch 298/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5222 - val_loss: 1.5179\n",
      "Epoch 299/300\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5105 - val_loss: 1.6004\n",
      "Epoch 300/300\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5114 - val_loss: 1.5232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5232383426271194\n",
      "0.9633224203878082\n",
      "Epoch 1/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 11.4031 - val_loss: 4.2456\n",
      "Epoch 2/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 5.0085 - val_loss: 3.9639\n",
      "Epoch 3/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.9706 - val_loss: 3.9787\n",
      "Epoch 4/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.4927 - val_loss: 5.3679\n",
      "Epoch 5/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.4891 - val_loss: 4.3512\n",
      "Epoch 6/300\n",
      "576/576 [==============================] - 5s 10ms/step - loss: 4.2530 - val_loss: 4.1514\n",
      "Epoch 7/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.2739 - val_loss: 3.6456\n",
      "Epoch 8/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.7969 - val_loss: 3.3192\n",
      "Epoch 9/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.4298 - val_loss: 3.2386\n",
      "Epoch 10/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.3504 - val_loss: 3.5228\n",
      "Epoch 11/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.1152 - val_loss: 3.0566\n",
      "Epoch 12/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.0931 - val_loss: 2.8238\n",
      "Epoch 13/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.9511 - val_loss: 2.7177\n",
      "Epoch 14/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.8850 - val_loss: 3.2046\n",
      "Epoch 15/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.8318 - val_loss: 2.6201\n",
      "Epoch 16/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.7832 - val_loss: 2.5826\n",
      "Epoch 17/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.6865 - val_loss: 2.4850\n",
      "Epoch 18/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.6400 - val_loss: 2.8398\n",
      "Epoch 19/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.6008 - val_loss: 2.4846\n",
      "Epoch 20/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.5504 - val_loss: 2.6704\n",
      "Epoch 21/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.5426 - val_loss: 2.5010\n",
      "Epoch 22/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.4782 - val_loss: 2.5391\n",
      "Epoch 23/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.5082 - val_loss: 2.5035\n",
      "Epoch 24/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4193 - val_loss: 2.4096\n",
      "Epoch 25/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4102 - val_loss: 2.3149\n",
      "Epoch 26/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.3599 - val_loss: 2.4390\n",
      "Epoch 27/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.3451 - val_loss: 2.3202\n",
      "Epoch 28/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.3450 - val_loss: 2.3949\n",
      "Epoch 29/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2956 - val_loss: 2.2409\n",
      "Epoch 30/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.2546 - val_loss: 2.2551\n",
      "Epoch 31/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.2626 - val_loss: 2.2168\n",
      "Epoch 32/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2464 - val_loss: 2.1699\n",
      "Epoch 33/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.2190 - val_loss: 2.1756\n",
      "Epoch 34/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1949 - val_loss: 2.2347\n",
      "Epoch 35/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.1588 - val_loss: 2.1288\n",
      "Epoch 36/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1724 - val_loss: 2.1044\n",
      "Epoch 37/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1531 - val_loss: 2.1700\n",
      "Epoch 38/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1431 - val_loss: 2.1391\n",
      "Epoch 39/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1345 - val_loss: 2.1258\n",
      "Epoch 40/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.1138 - val_loss: 2.1830\n",
      "Epoch 41/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.1054 - val_loss: 2.0275\n",
      "Epoch 42/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.1000 - val_loss: 2.0767\n",
      "Epoch 43/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0861 - val_loss: 2.3116\n",
      "Epoch 44/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0732 - val_loss: 2.0191\n",
      "Epoch 45/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0740 - val_loss: 1.9475\n",
      "Epoch 46/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0349 - val_loss: 2.0013\n",
      "Epoch 47/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0459 - val_loss: 2.0451\n",
      "Epoch 48/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0490 - val_loss: 2.0016\n",
      "Epoch 49/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0263 - val_loss: 2.0926\n",
      "Epoch 50/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.0282 - val_loss: 1.9573\n",
      "Epoch 51/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0133 - val_loss: 1.9929\n",
      "Epoch 52/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0025 - val_loss: 1.9846\n",
      "Epoch 53/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9817 - val_loss: 1.9573\n",
      "Epoch 54/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9872 - val_loss: 1.9376\n",
      "Epoch 55/300\n",
      "576/576 [==============================] - 5s 10ms/step - loss: 1.9722 - val_loss: 1.9492\n",
      "Epoch 56/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9881 - val_loss: 2.0046\n",
      "Epoch 57/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9631 - val_loss: 1.8972\n",
      "Epoch 58/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9344 - val_loss: 1.9943\n",
      "Epoch 59/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9334 - val_loss: 2.0323\n",
      "Epoch 60/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9451 - val_loss: 1.9485\n",
      "Epoch 61/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9110 - val_loss: 1.8531\n",
      "Epoch 62/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9295 - val_loss: 2.0315\n",
      "Epoch 63/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9160 - val_loss: 1.9487\n",
      "Epoch 64/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8966 - val_loss: 1.8504\n",
      "Epoch 65/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8900 - val_loss: 1.9074\n",
      "Epoch 66/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8772 - val_loss: 1.8596\n",
      "Epoch 67/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8857 - val_loss: 1.8439\n",
      "Epoch 68/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8820 - val_loss: 2.0371\n",
      "Epoch 69/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8756 - val_loss: 1.8239\n",
      "Epoch 70/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8895 - val_loss: 1.9405\n",
      "Epoch 71/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8731 - val_loss: 1.8264\n",
      "Epoch 72/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8662 - val_loss: 1.9711\n",
      "Epoch 73/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8547 - val_loss: 1.8438\n",
      "Epoch 74/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8692 - val_loss: 1.9670\n",
      "Epoch 75/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8443 - val_loss: 1.8220\n",
      "Epoch 76/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8384 - val_loss: 1.8855\n",
      "Epoch 77/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8516 - val_loss: 1.8841\n",
      "Epoch 78/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8406 - val_loss: 1.7894\n",
      "Epoch 79/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8310 - val_loss: 1.8488\n",
      "Epoch 80/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8303 - val_loss: 1.8824\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8130 - val_loss: 1.8235\n",
      "Epoch 82/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8079 - val_loss: 1.7974\n",
      "Epoch 83/300\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.8152 - val_loss: 1.8728\n",
      "Epoch 84/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8069 - val_loss: 1.8226\n",
      "Epoch 85/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8040 - val_loss: 1.8022\n",
      "Epoch 86/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7972 - val_loss: 1.8081\n",
      "Epoch 87/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8114 - val_loss: 1.7732\n",
      "Epoch 88/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7969 - val_loss: 1.7646\n",
      "Epoch 89/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7999 - val_loss: 1.8267\n",
      "Epoch 90/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7941 - val_loss: 1.8178\n",
      "Epoch 91/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7840 - val_loss: 1.7652\n",
      "Epoch 92/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7779 - val_loss: 1.7373\n",
      "Epoch 93/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7743 - val_loss: 1.7904\n",
      "Epoch 94/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7764 - val_loss: 1.9513\n",
      "Epoch 95/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7709 - val_loss: 1.7744\n",
      "Epoch 96/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7726 - val_loss: 1.7346\n",
      "Epoch 97/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7590 - val_loss: 1.8193\n",
      "Epoch 98/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7656 - val_loss: 1.7706\n",
      "Epoch 99/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7580 - val_loss: 1.7381\n",
      "Epoch 100/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7543 - val_loss: 1.7868\n",
      "Epoch 101/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7521 - val_loss: 1.6978\n",
      "Epoch 102/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7475 - val_loss: 1.7991\n",
      "Epoch 103/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7364 - val_loss: 1.7212\n",
      "Epoch 104/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7437 - val_loss: 1.7517\n",
      "Epoch 105/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7447 - val_loss: 1.7190\n",
      "Epoch 106/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7324 - val_loss: 1.8037\n",
      "Epoch 107/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7410 - val_loss: 1.7085\n",
      "Epoch 108/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7321 - val_loss: 1.7699\n",
      "Epoch 109/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7365 - val_loss: 1.7594\n",
      "Epoch 110/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7262 - val_loss: 1.7163\n",
      "Epoch 111/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7305 - val_loss: 1.7128\n",
      "Epoch 112/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7160 - val_loss: 1.6603\n",
      "Epoch 113/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7243 - val_loss: 1.7351\n",
      "Epoch 114/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7117 - val_loss: 1.7008\n",
      "Epoch 115/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7035 - val_loss: 1.6812\n",
      "Epoch 116/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6980 - val_loss: 1.7758\n",
      "Epoch 117/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7029 - val_loss: 1.7350\n",
      "Epoch 118/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7014 - val_loss: 1.6838\n",
      "Epoch 119/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7045 - val_loss: 1.7381\n",
      "Epoch 120/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6997 - val_loss: 1.7000\n",
      "Epoch 121/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6849 - val_loss: 1.7159\n",
      "Epoch 122/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7046 - val_loss: 1.8608\n",
      "Epoch 123/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6977 - val_loss: 1.7709\n",
      "Epoch 124/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6742 - val_loss: 1.6880\n",
      "Epoch 125/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6886 - val_loss: 1.7517\n",
      "Epoch 126/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6911 - val_loss: 1.7013\n",
      "Epoch 127/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6829 - val_loss: 1.7231\n",
      "Epoch 128/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6761 - val_loss: 1.7144\n",
      "Epoch 129/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6700 - val_loss: 1.7059\n",
      "Epoch 130/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6849 - val_loss: 1.7904\n",
      "Epoch 131/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6666 - val_loss: 1.7145\n",
      "Epoch 132/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6623 - val_loss: 1.7154\n",
      "Epoch 133/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6596 - val_loss: 1.6819\n",
      "Epoch 134/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6689 - val_loss: 1.6951\n",
      "Epoch 135/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6655 - val_loss: 1.7252\n",
      "Epoch 136/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6495 - val_loss: 1.6680\n",
      "Epoch 137/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6523 - val_loss: 1.6755\n",
      "Epoch 138/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6627 - val_loss: 1.7068\n",
      "Epoch 139/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6442 - val_loss: 1.6640\n",
      "Epoch 140/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6466 - val_loss: 1.6843\n",
      "Epoch 141/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6516 - val_loss: 1.6569\n",
      "Epoch 142/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6442 - val_loss: 1.6525\n",
      "Epoch 143/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6417 - val_loss: 1.6596\n",
      "Epoch 144/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6499 - val_loss: 1.7009\n",
      "Epoch 145/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6329 - val_loss: 1.6337\n",
      "Epoch 146/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6379 - val_loss: 1.7068\n",
      "Epoch 147/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6293 - val_loss: 1.6343\n",
      "Epoch 148/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6427 - val_loss: 1.6626\n",
      "Epoch 149/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6404 - val_loss: 1.6609\n",
      "Epoch 150/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6287 - val_loss: 1.6343\n",
      "Epoch 151/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6280 - val_loss: 1.7719\n",
      "Epoch 152/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6378 - val_loss: 1.6606\n",
      "Epoch 153/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6241 - val_loss: 1.6206\n",
      "Epoch 154/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6216 - val_loss: 1.6551\n",
      "Epoch 155/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6193 - val_loss: 1.6689\n",
      "Epoch 156/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6191 - val_loss: 1.7230\n",
      "Epoch 157/300\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.6300 - val_loss: 1.6441\n",
      "Epoch 158/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6238 - val_loss: 1.6523\n",
      "Epoch 159/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6106 - val_loss: 1.6058\n",
      "Epoch 160/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6169 - val_loss: 1.7220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6127 - val_loss: 1.6658\n",
      "Epoch 162/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6208 - val_loss: 1.6138\n",
      "Epoch 163/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6118 - val_loss: 1.6005\n",
      "Epoch 164/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5966 - val_loss: 1.6592\n",
      "Epoch 165/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6144 - val_loss: 1.6451\n",
      "Epoch 166/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5950 - val_loss: 1.6449\n",
      "Epoch 167/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5988 - val_loss: 1.6825\n",
      "Epoch 168/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5889 - val_loss: 1.6011\n",
      "Epoch 169/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6048 - val_loss: 1.6811\n",
      "Epoch 170/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6003 - val_loss: 1.6685\n",
      "Epoch 171/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5928 - val_loss: 1.6168\n",
      "Epoch 172/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5972 - val_loss: 1.6148\n",
      "Epoch 173/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5892 - val_loss: 1.6396\n",
      "Epoch 174/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5926 - val_loss: 1.6347\n",
      "Epoch 175/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5946 - val_loss: 1.6244\n",
      "Epoch 176/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5950 - val_loss: 1.6361\n",
      "Epoch 177/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5873 - val_loss: 1.6178\n",
      "Epoch 178/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5836 - val_loss: 1.6317\n",
      "Epoch 179/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5830 - val_loss: 1.6034\n",
      "Epoch 180/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5789 - val_loss: 1.5514\n",
      "Epoch 181/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5914 - val_loss: 1.6637\n",
      "Epoch 182/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5839 - val_loss: 1.5765\n",
      "Epoch 183/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5761 - val_loss: 1.6707\n",
      "Epoch 184/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5690 - val_loss: 1.6130\n",
      "Epoch 185/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5752 - val_loss: 1.6518\n",
      "Epoch 186/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5721 - val_loss: 1.6366\n",
      "Epoch 187/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5809 - val_loss: 1.6166\n",
      "Epoch 188/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5759 - val_loss: 1.6829\n",
      "Epoch 189/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5653 - val_loss: 1.6106\n",
      "Epoch 190/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5682 - val_loss: 1.6172\n",
      "Epoch 191/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5742 - val_loss: 1.6558\n",
      "Epoch 192/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5675 - val_loss: 1.6587\n",
      "Epoch 193/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5790 - val_loss: 1.5919\n",
      "Epoch 194/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5782 - val_loss: 1.5575\n",
      "Epoch 195/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5646 - val_loss: 1.6352\n",
      "Epoch 196/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5580 - val_loss: 1.6510\n",
      "Epoch 197/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5578 - val_loss: 1.5727\n",
      "Epoch 198/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5682 - val_loss: 1.5656\n",
      "Epoch 199/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5651 - val_loss: 1.5701\n",
      "Epoch 200/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5584 - val_loss: 1.5736\n",
      "Epoch 201/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5567 - val_loss: 1.6012\n",
      "Epoch 202/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5451 - val_loss: 1.5759\n",
      "Epoch 203/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5557 - val_loss: 1.5841\n",
      "Epoch 204/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5526 - val_loss: 1.6607\n",
      "Epoch 205/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5588 - val_loss: 1.6613\n",
      "Epoch 206/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5434 - val_loss: 1.6257\n",
      "Epoch 207/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5444 - val_loss: 1.6034\n",
      "Epoch 208/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5559 - val_loss: 1.5531\n",
      "Epoch 209/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5496 - val_loss: 1.6489\n",
      "Epoch 210/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5489 - val_loss: 1.5702\n",
      "Epoch 211/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5452 - val_loss: 1.5828\n",
      "Epoch 212/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5441 - val_loss: 1.5859\n",
      "Epoch 213/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5415 - val_loss: 1.6045\n",
      "Epoch 214/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5458 - val_loss: 1.5749\n",
      "Epoch 215/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5441 - val_loss: 1.6324\n",
      "Epoch 216/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5366 - val_loss: 1.6666\n",
      "Epoch 217/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5335 - val_loss: 1.5264\n",
      "Epoch 218/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5380 - val_loss: 1.5583\n",
      "Epoch 219/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5282 - val_loss: 1.5867\n",
      "Epoch 220/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5303 - val_loss: 1.5331\n",
      "Epoch 221/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5300 - val_loss: 1.5439\n",
      "Epoch 222/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5293 - val_loss: 1.5544\n",
      "Epoch 223/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5409 - val_loss: 1.5390\n",
      "Epoch 224/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5444 - val_loss: 1.6174\n",
      "Epoch 225/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5272 - val_loss: 1.5476\n",
      "Epoch 226/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5326 - val_loss: 1.6213\n",
      "Epoch 227/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5186 - val_loss: 1.5335\n",
      "Epoch 228/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5270 - val_loss: 1.5816\n",
      "Epoch 229/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5223 - val_loss: 1.5853\n",
      "Epoch 230/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5244 - val_loss: 1.5402\n",
      "Epoch 231/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5203 - val_loss: 1.5033\n",
      "Epoch 232/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5167 - val_loss: 1.6852\n",
      "Epoch 233/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5253 - val_loss: 1.5388\n",
      "Epoch 234/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5027 - val_loss: 1.5735\n",
      "Epoch 235/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5111 - val_loss: 1.5340\n",
      "Epoch 236/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5037 - val_loss: 1.6354\n",
      "Epoch 237/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5014 - val_loss: 1.5384\n",
      "Epoch 238/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5084 - val_loss: 1.5386\n",
      "Epoch 239/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5149 - val_loss: 1.5141\n",
      "Epoch 240/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5076 - val_loss: 1.5701\n",
      "Epoch 241/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5159 - val_loss: 1.5298\n",
      "Epoch 242/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5014 - val_loss: 1.5544\n",
      "Epoch 243/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4983 - val_loss: 1.5301\n",
      "Epoch 244/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4976 - val_loss: 1.5194\n",
      "Epoch 245/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5103 - val_loss: 1.5080\n",
      "Epoch 246/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5045 - val_loss: 1.5549\n",
      "Epoch 247/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5161 - val_loss: 1.4790\n",
      "Epoch 248/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5008 - val_loss: 1.5436\n",
      "Epoch 249/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4915 - val_loss: 1.4862\n",
      "Epoch 250/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5017 - val_loss: 1.5683\n",
      "Epoch 251/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5011 - val_loss: 1.5047\n",
      "Epoch 252/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4855 - val_loss: 1.4969\n",
      "Epoch 253/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5072 - val_loss: 1.5932\n",
      "Epoch 254/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4809 - val_loss: 1.5268\n",
      "Epoch 255/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4854 - val_loss: 1.5155\n",
      "Epoch 256/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4829 - val_loss: 1.5458\n",
      "Epoch 257/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4775 - val_loss: 1.5230\n",
      "Epoch 258/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4867 - val_loss: 1.4864\n",
      "Epoch 259/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4828 - val_loss: 1.6269\n",
      "Epoch 260/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4914 - val_loss: 1.5552\n",
      "Epoch 261/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4756 - val_loss: 1.4795\n",
      "Epoch 262/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4860 - val_loss: 1.5285\n",
      "Epoch 263/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4776 - val_loss: 1.5271\n",
      "Epoch 264/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4876 - val_loss: 1.5435\n",
      "Epoch 265/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4836 - val_loss: 1.5792\n",
      "Epoch 266/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4841 - val_loss: 1.5707\n",
      "Epoch 267/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4817 - val_loss: 1.6143\n",
      "Epoch 268/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4880 - val_loss: 1.5252\n",
      "Epoch 269/300\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4832 - val_loss: 1.4977\n",
      "Epoch 270/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4832 - val_loss: 1.5384\n",
      "Epoch 271/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4692 - val_loss: 1.5003\n",
      "Epoch 272/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4739 - val_loss: 1.5657\n",
      "Epoch 273/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4716 - val_loss: 1.5502\n",
      "Epoch 274/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4684 - val_loss: 1.5383\n",
      "Epoch 275/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4687 - val_loss: 1.4884\n",
      "Epoch 276/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4654 - val_loss: 1.5790\n",
      "Epoch 277/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4667 - val_loss: 1.4998\n",
      "Epoch 278/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4630 - val_loss: 1.5088\n",
      "Epoch 279/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4541 - val_loss: 1.5286\n",
      "Epoch 280/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4642 - val_loss: 1.4925\n",
      "Epoch 281/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4650 - val_loss: 1.4774\n",
      "Epoch 282/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4646 - val_loss: 1.5246\n",
      "Epoch 283/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4595 - val_loss: 1.4997\n",
      "Epoch 284/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4612 - val_loss: 1.5143\n",
      "Epoch 285/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4560 - val_loss: 1.4974\n",
      "Epoch 286/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4583 - val_loss: 1.5432\n",
      "Epoch 287/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4536 - val_loss: 1.4770\n",
      "Epoch 288/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4694 - val_loss: 1.4919\n",
      "Epoch 289/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4589 - val_loss: 1.4571\n",
      "Epoch 290/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4505 - val_loss: 1.5087\n",
      "Epoch 291/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4627 - val_loss: 1.5014\n",
      "Epoch 292/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4537 - val_loss: 1.4983\n",
      "Epoch 293/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4530 - val_loss: 1.5187\n",
      "Epoch 294/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4534 - val_loss: 1.4767\n",
      "Epoch 295/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4491 - val_loss: 1.5166\n",
      "Epoch 296/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4621 - val_loss: 1.4984\n",
      "Epoch 297/300\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4532 - val_loss: 1.5081\n",
      "Epoch 298/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4536 - val_loss: 1.4872\n",
      "Epoch 299/300\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4449 - val_loss: 1.4771\n",
      "Epoch 300/300\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4475 - val_loss: 1.4915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4914851337893849\n",
      "0.9647872339613185\n",
      "Epoch 1/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 14.0727 - val_loss: 9.1203\n",
      "Epoch 2/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 6.6893 - val_loss: 8.7571\n",
      "Epoch 3/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 5.2983 - val_loss: 3.9507\n",
      "Epoch 4/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 5.2777 - val_loss: 10.7316\n",
      "Epoch 5/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 4.6523 - val_loss: 4.3692\n",
      "Epoch 6/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 5.0265 - val_loss: 3.8021\n",
      "Epoch 7/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.3406 - val_loss: 3.6451\n",
      "Epoch 8/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.7003 - val_loss: 3.3296\n",
      "Epoch 9/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.7581 - val_loss: 3.4714\n",
      "Epoch 10/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 3.6552 - val_loss: 3.2448\n",
      "Epoch 11/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.6272 - val_loss: 4.6374\n",
      "Epoch 12/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.5002 - val_loss: 4.3485\n",
      "Epoch 13/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.3153 - val_loss: 3.4072\n",
      "Epoch 14/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.2601 - val_loss: 3.1139\n",
      "Epoch 15/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.2199 - val_loss: 2.9138\n",
      "Epoch 16/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.1491 - val_loss: 3.4108\n",
      "Epoch 17/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.9778 - val_loss: 2.7754\n",
      "Epoch 18/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.9343 - val_loss: 2.7081\n",
      "Epoch 19/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.9129 - val_loss: 2.6836\n",
      "Epoch 20/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.8412 - val_loss: 3.5984\n",
      "Epoch 21/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.8034 - val_loss: 2.7804\n",
      "Epoch 22/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.7008 - val_loss: 2.8356\n",
      "Epoch 23/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.6705 - val_loss: 2.6626\n",
      "Epoch 24/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.6568 - val_loss: 2.4702\n",
      "Epoch 25/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5714 - val_loss: 2.5336\n",
      "Epoch 26/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.5512 - val_loss: 2.4870\n",
      "Epoch 27/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5529 - val_loss: 2.4637\n",
      "Epoch 28/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5233 - val_loss: 2.8212\n",
      "Epoch 29/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5202 - val_loss: 2.7167\n",
      "Epoch 30/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4977 - val_loss: 2.3807\n",
      "Epoch 31/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4606 - val_loss: 2.3949\n",
      "Epoch 32/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4123 - val_loss: 2.4187\n",
      "Epoch 33/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4095 - val_loss: 2.2878\n",
      "Epoch 34/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3595 - val_loss: 2.4262\n",
      "Epoch 35/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3554 - val_loss: 2.2823\n",
      "Epoch 36/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3511 - val_loss: 2.2989\n",
      "Epoch 37/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3277 - val_loss: 2.4091\n",
      "Epoch 38/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2876 - val_loss: 2.3803\n",
      "Epoch 39/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2673 - val_loss: 2.3055\n",
      "Epoch 40/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2798 - val_loss: 2.1485\n",
      "Epoch 41/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.2270 - val_loss: 2.2033\n",
      "Epoch 42/300\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 2.1831 - val_loss: 2.1257\n",
      "Epoch 43/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1875 - val_loss: 2.2601\n",
      "Epoch 44/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1756 - val_loss: 2.1917\n",
      "Epoch 45/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1786 - val_loss: 2.1923\n",
      "Epoch 46/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1495 - val_loss: 2.0751\n",
      "Epoch 47/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1240 - val_loss: 2.1062\n",
      "Epoch 48/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1233 - val_loss: 2.0935\n",
      "Epoch 49/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1365 - val_loss: 2.0904\n",
      "Epoch 50/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.1029 - val_loss: 2.1509\n",
      "Epoch 51/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0787 - val_loss: 2.0457\n",
      "Epoch 52/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0751 - val_loss: 2.0034\n",
      "Epoch 53/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0789 - val_loss: 2.2843\n",
      "Epoch 54/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0414 - val_loss: 2.0213\n",
      "Epoch 55/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0591 - val_loss: 2.0886\n",
      "Epoch 56/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.0459 - val_loss: 2.0626\n",
      "Epoch 57/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.0300 - val_loss: 2.0330\n",
      "Epoch 58/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0196 - val_loss: 2.0671\n",
      "Epoch 59/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0165 - val_loss: 2.1773\n",
      "Epoch 60/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0092 - val_loss: 2.2350\n",
      "Epoch 61/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0004 - val_loss: 2.0162\n",
      "Epoch 62/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0072 - val_loss: 2.0155\n",
      "Epoch 63/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9757 - val_loss: 2.0017\n",
      "Epoch 64/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9818 - val_loss: 2.0101\n",
      "Epoch 65/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9563 - val_loss: 1.9565\n",
      "Epoch 66/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9586 - val_loss: 1.9838\n",
      "Epoch 67/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9517 - val_loss: 1.9140\n",
      "Epoch 68/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9391 - val_loss: 1.8803\n",
      "Epoch 69/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9351 - val_loss: 1.9106\n",
      "Epoch 70/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9322 - val_loss: 1.9086\n",
      "Epoch 71/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.9610 - val_loss: 1.9609\n",
      "Epoch 72/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.9203 - val_loss: 1.9103\n",
      "Epoch 73/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9440 - val_loss: 2.1361\n",
      "Epoch 74/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9096 - val_loss: 1.9797\n",
      "Epoch 75/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9402 - val_loss: 1.9790\n",
      "Epoch 76/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8940 - val_loss: 1.9397\n",
      "Epoch 77/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9000 - val_loss: 1.8848\n",
      "Epoch 78/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8931 - val_loss: 1.8839\n",
      "Epoch 79/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8950 - val_loss: 1.9715\n",
      "Epoch 80/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8878 - val_loss: 1.9628\n",
      "Epoch 81/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8884 - val_loss: 1.8529\n",
      "Epoch 82/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8682 - val_loss: 1.8543\n",
      "Epoch 83/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8685 - val_loss: 1.8317\n",
      "Epoch 84/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8562 - val_loss: 1.9223\n",
      "Epoch 85/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8419 - val_loss: 1.8796\n",
      "Epoch 86/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8295 - val_loss: 1.8229\n",
      "Epoch 87/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.8420 - val_loss: 1.8306\n",
      "Epoch 88/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8278 - val_loss: 1.8081\n",
      "Epoch 89/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8144 - val_loss: 1.8324\n",
      "Epoch 90/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8459 - val_loss: 1.8325\n",
      "Epoch 91/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8095 - val_loss: 1.8151\n",
      "Epoch 92/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8039 - val_loss: 1.8139\n",
      "Epoch 93/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8231 - val_loss: 1.8127\n",
      "Epoch 94/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7942 - val_loss: 1.7667\n",
      "Epoch 95/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7824 - val_loss: 1.8191\n",
      "Epoch 96/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7879 - val_loss: 1.7479\n",
      "Epoch 97/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7913 - val_loss: 1.8642\n",
      "Epoch 98/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7771 - val_loss: 1.7982\n",
      "Epoch 99/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7673 - val_loss: 1.8602\n",
      "Epoch 100/300\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.7692 - val_loss: 1.7952\n",
      "Epoch 101/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7584 - val_loss: 1.7782\n",
      "Epoch 102/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7459 - val_loss: 2.0249\n",
      "Epoch 103/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.7400 - val_loss: 1.7250\n",
      "Epoch 104/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7528 - val_loss: 1.7736\n",
      "Epoch 105/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7429 - val_loss: 1.7427\n",
      "Epoch 106/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7398 - val_loss: 1.7045\n",
      "Epoch 107/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7044 - val_loss: 1.8027\n",
      "Epoch 108/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7135 - val_loss: 1.8065\n",
      "Epoch 109/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7300 - val_loss: 1.7389\n",
      "Epoch 110/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7163 - val_loss: 1.6724\n",
      "Epoch 111/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7156 - val_loss: 1.7827\n",
      "Epoch 112/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7077 - val_loss: 1.6840\n",
      "Epoch 113/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6979 - val_loss: 1.7690\n",
      "Epoch 114/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6867 - val_loss: 1.7328\n",
      "Epoch 115/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6910 - val_loss: 1.6780\n",
      "Epoch 116/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6827 - val_loss: 1.7076\n",
      "Epoch 117/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6698 - val_loss: 1.8072\n",
      "Epoch 118/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.6727 - val_loss: 1.7099\n",
      "Epoch 119/300\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.6647 - val_loss: 1.6395\n",
      "Epoch 120/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6738 - val_loss: 1.6602\n",
      "Epoch 121/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6692 - val_loss: 1.7295\n",
      "Epoch 122/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6550 - val_loss: 1.7316\n",
      "Epoch 123/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6639 - val_loss: 1.6362\n",
      "Epoch 124/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6569 - val_loss: 1.6724\n",
      "Epoch 125/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6341 - val_loss: 1.7126\n",
      "Epoch 126/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6364 - val_loss: 1.6384\n",
      "Epoch 127/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6555 - val_loss: 1.6979\n",
      "Epoch 128/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6473 - val_loss: 1.6550\n",
      "Epoch 129/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6397 - val_loss: 1.6538\n",
      "Epoch 130/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6433 - val_loss: 1.6335\n",
      "Epoch 131/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6306 - val_loss: 1.7078\n",
      "Epoch 132/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6251 - val_loss: 1.5777\n",
      "Epoch 133/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.6303 - val_loss: 1.7131\n",
      "Epoch 134/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.6200 - val_loss: 1.6908\n",
      "Epoch 135/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6131 - val_loss: 1.6383\n",
      "Epoch 136/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6326 - val_loss: 1.6241\n",
      "Epoch 137/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6272 - val_loss: 1.6160\n",
      "Epoch 138/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6191 - val_loss: 1.6169\n",
      "Epoch 139/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6058 - val_loss: 1.6323\n",
      "Epoch 140/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6058 - val_loss: 1.6289\n",
      "Epoch 141/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6019 - val_loss: 1.6065\n",
      "Epoch 142/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5898 - val_loss: 1.6010\n",
      "Epoch 143/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6039 - val_loss: 1.6158\n",
      "Epoch 144/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6043 - val_loss: 1.6266\n",
      "Epoch 145/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5884 - val_loss: 1.6391\n",
      "Epoch 146/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5965 - val_loss: 1.6660\n",
      "Epoch 147/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5929 - val_loss: 1.5852\n",
      "Epoch 148/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5789 - val_loss: 1.6044\n",
      "Epoch 149/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.6025 - val_loss: 1.6969\n",
      "Epoch 150/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5845 - val_loss: 1.5757\n",
      "Epoch 151/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5822 - val_loss: 1.7588\n",
      "Epoch 152/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5918 - val_loss: 1.6172\n",
      "Epoch 153/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5774 - val_loss: 1.7322\n",
      "Epoch 154/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5701 - val_loss: 1.6396\n",
      "Epoch 155/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5861 - val_loss: 1.5953\n",
      "Epoch 156/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5600 - val_loss: 1.5690\n",
      "Epoch 157/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5571 - val_loss: 1.6217\n",
      "Epoch 158/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5622 - val_loss: 1.5618\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5663 - val_loss: 1.5998\n",
      "Epoch 160/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5688 - val_loss: 1.6383\n",
      "Epoch 161/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5605 - val_loss: 1.6351\n",
      "Epoch 162/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5588 - val_loss: 1.5856\n",
      "Epoch 163/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5683 - val_loss: 1.6462\n",
      "Epoch 164/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5593 - val_loss: 1.6029\n",
      "Epoch 165/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5571 - val_loss: 1.6267\n",
      "Epoch 166/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5583 - val_loss: 1.6484\n",
      "Epoch 167/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5557 - val_loss: 1.6176\n",
      "Epoch 168/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5651 - val_loss: 1.5896\n",
      "Epoch 169/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5320 - val_loss: 1.5587\n",
      "Epoch 170/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5569 - val_loss: 1.6491\n",
      "Epoch 171/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5421 - val_loss: 1.5537\n",
      "Epoch 172/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5702 - val_loss: 1.5723\n",
      "Epoch 173/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5447 - val_loss: 1.5986\n",
      "Epoch 174/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5358 - val_loss: 1.5353\n",
      "Epoch 175/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5315 - val_loss: 1.6340\n",
      "Epoch 176/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5308 - val_loss: 1.6232\n",
      "Epoch 177/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5400 - val_loss: 1.6006\n",
      "Epoch 178/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5328 - val_loss: 1.6008\n",
      "Epoch 179/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5222 - val_loss: 1.5321\n",
      "Epoch 180/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5358 - val_loss: 1.6676\n",
      "Epoch 181/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5365 - val_loss: 1.5397\n",
      "Epoch 182/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5259 - val_loss: 1.5356\n",
      "Epoch 183/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5272 - val_loss: 1.5629\n",
      "Epoch 184/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5328 - val_loss: 1.6219\n",
      "Epoch 185/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5127 - val_loss: 1.5412\n",
      "Epoch 186/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5185 - val_loss: 1.5225\n",
      "Epoch 187/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5224 - val_loss: 1.5740\n",
      "Epoch 188/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5269 - val_loss: 1.6387\n",
      "Epoch 189/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5158 - val_loss: 1.5212\n",
      "Epoch 190/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5099 - val_loss: 1.5922\n",
      "Epoch 191/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5086 - val_loss: 1.5846\n",
      "Epoch 192/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5317 - val_loss: 1.5725\n",
      "Epoch 193/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5110 - val_loss: 1.5768\n",
      "Epoch 194/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5153 - val_loss: 1.5552\n",
      "Epoch 195/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5129 - val_loss: 1.5978\n",
      "Epoch 196/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5104 - val_loss: 1.5035\n",
      "Epoch 197/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5028 - val_loss: 1.6250\n",
      "Epoch 198/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4988 - val_loss: 1.5300\n",
      "Epoch 199/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5073 - val_loss: 1.5467\n",
      "Epoch 200/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4959 - val_loss: 1.5235\n",
      "Epoch 201/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5126 - val_loss: 1.5197\n",
      "Epoch 202/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5141 - val_loss: 1.5751\n",
      "Epoch 203/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4836 - val_loss: 1.5389\n",
      "Epoch 204/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5029 - val_loss: 1.5055\n",
      "Epoch 205/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5160 - val_loss: 1.5685\n",
      "Epoch 206/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5059 - val_loss: 1.5372\n",
      "Epoch 207/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4963 - val_loss: 1.5225\n",
      "Epoch 208/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4971 - val_loss: 1.5130\n",
      "Epoch 209/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4980 - val_loss: 1.4802\n",
      "Epoch 210/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4844 - val_loss: 1.5640\n",
      "Epoch 211/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4879 - val_loss: 1.4634\n",
      "Epoch 212/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4935 - val_loss: 1.5119\n",
      "Epoch 213/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4760 - val_loss: 1.5089\n",
      "Epoch 214/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4913 - val_loss: 1.4970\n",
      "Epoch 215/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4792 - val_loss: 1.5732\n",
      "Epoch 216/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4820 - val_loss: 1.5170\n",
      "Epoch 217/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4866 - val_loss: 1.5124\n",
      "Epoch 218/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4800 - val_loss: 1.5821\n",
      "Epoch 219/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4961 - val_loss: 1.5514\n",
      "Epoch 220/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4791 - val_loss: 1.5193\n",
      "Epoch 221/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4828 - val_loss: 1.5401\n",
      "Epoch 222/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4821 - val_loss: 1.5237\n",
      "Epoch 223/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4829 - val_loss: 1.5146\n",
      "Epoch 224/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4753 - val_loss: 1.5268\n",
      "Epoch 225/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4835 - val_loss: 1.5103\n",
      "Epoch 226/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4845 - val_loss: 1.5374\n",
      "Epoch 227/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4678 - val_loss: 1.5429\n",
      "Epoch 228/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4643 - val_loss: 1.4586\n",
      "Epoch 229/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4637 - val_loss: 1.5964\n",
      "Epoch 230/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4669 - val_loss: 1.4964\n",
      "Epoch 231/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4610 - val_loss: 1.4774\n",
      "Epoch 232/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4616 - val_loss: 1.4917\n",
      "Epoch 233/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4503 - val_loss: 1.5461\n",
      "Epoch 234/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4642 - val_loss: 1.5883\n",
      "Epoch 235/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4656 - val_loss: 1.5043\n",
      "Epoch 236/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4669 - val_loss: 1.4710\n",
      "Epoch 237/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4582 - val_loss: 1.4834\n",
      "Epoch 238/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4520 - val_loss: 1.4926\n",
      "Epoch 239/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4694 - val_loss: 1.5496\n",
      "Epoch 240/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4747 - val_loss: 1.4832\n",
      "Epoch 241/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4509 - val_loss: 1.6013\n",
      "Epoch 242/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4656 - val_loss: 1.5895\n",
      "Epoch 243/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4521 - val_loss: 1.5067\n",
      "Epoch 244/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4462 - val_loss: 1.5097\n",
      "Epoch 245/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4623 - val_loss: 1.4836\n",
      "Epoch 246/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4542 - val_loss: 1.5409\n",
      "Epoch 247/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4466 - val_loss: 1.5638\n",
      "Epoch 248/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4536 - val_loss: 1.4984\n",
      "Epoch 249/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4572 - val_loss: 1.5553\n",
      "Epoch 250/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4572 - val_loss: 1.5638\n",
      "Epoch 251/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4478 - val_loss: 1.4436\n",
      "Epoch 252/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4574 - val_loss: 1.4589\n",
      "Epoch 253/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4415 - val_loss: 1.4433\n",
      "Epoch 254/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4407 - val_loss: 1.5272\n",
      "Epoch 255/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4418 - val_loss: 1.5011\n",
      "Epoch 256/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4456 - val_loss: 1.5661\n",
      "Epoch 257/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4480 - val_loss: 1.5307\n",
      "Epoch 258/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4410 - val_loss: 1.4584\n",
      "Epoch 259/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4462 - val_loss: 1.4537\n",
      "Epoch 260/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4430 - val_loss: 1.5541\n",
      "Epoch 261/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4361 - val_loss: 1.5019\n",
      "Epoch 262/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4514 - val_loss: 1.4180\n",
      "Epoch 263/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4327 - val_loss: 1.4432\n",
      "Epoch 264/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4324 - val_loss: 1.5373\n",
      "Epoch 265/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4477 - val_loss: 1.4199\n",
      "Epoch 266/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4301 - val_loss: 1.5120\n",
      "Epoch 267/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4441 - val_loss: 1.5055\n",
      "Epoch 268/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4336 - val_loss: 1.5056\n",
      "Epoch 269/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4309 - val_loss: 1.4591\n",
      "Epoch 270/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4427 - val_loss: 1.4534\n",
      "Epoch 271/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4175 - val_loss: 1.4997\n",
      "Epoch 272/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4382 - val_loss: 1.4779\n",
      "Epoch 273/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4357 - val_loss: 1.4551\n",
      "Epoch 274/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4248 - val_loss: 1.4488\n",
      "Epoch 275/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4350 - val_loss: 1.4553\n",
      "Epoch 276/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4321 - val_loss: 1.4582\n",
      "Epoch 277/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4265 - val_loss: 1.5169\n",
      "Epoch 278/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4181 - val_loss: 1.4641\n",
      "Epoch 279/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4291 - val_loss: 1.4184\n",
      "Epoch 280/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4247 - val_loss: 1.4212\n",
      "Epoch 281/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4120 - val_loss: 1.4481\n",
      "Epoch 282/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4256 - val_loss: 1.4830\n",
      "Epoch 283/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4393 - val_loss: 1.4345\n",
      "Epoch 284/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4237 - val_loss: 1.4261\n",
      "Epoch 285/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4227 - val_loss: 1.5293\n",
      "Epoch 286/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4198 - val_loss: 1.4568\n",
      "Epoch 287/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4083 - val_loss: 1.4455\n",
      "Epoch 288/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4158 - val_loss: 1.4734\n",
      "Epoch 289/300\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4068 - val_loss: 1.4029\n",
      "Epoch 290/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4148 - val_loss: 1.5087\n",
      "Epoch 291/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4119 - val_loss: 1.4881\n",
      "Epoch 292/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4161 - val_loss: 1.4983\n",
      "Epoch 293/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4114 - val_loss: 1.4465\n",
      "Epoch 294/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4198 - val_loss: 1.4598\n",
      "Epoch 295/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4233 - val_loss: 1.4917\n",
      "Epoch 296/300\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4079 - val_loss: 1.4434\n",
      "Epoch 297/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4152 - val_loss: 1.4659\n",
      "Epoch 298/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4147 - val_loss: 1.4659\n",
      "Epoch 299/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4248 - val_loss: 1.4754\n",
      "Epoch 300/300\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4099 - val_loss: 1.4257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4256968903530798\n",
      "0.9678807180287757\n",
      "Epoch 1/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 12.8936 - val_loss: 4.0555\n",
      "Epoch 2/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 5.4157 - val_loss: 4.1113\n",
      "Epoch 3/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 6.1016 - val_loss: 3.9840\n",
      "Epoch 4/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.4173 - val_loss: 3.9267\n",
      "Epoch 5/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.9147 - val_loss: 4.1881\n",
      "Epoch 6/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 4.5939 - val_loss: 4.0592\n",
      "Epoch 7/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.3338 - val_loss: 6.5607\n",
      "Epoch 8/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.7254 - val_loss: 3.7320\n",
      "Epoch 9/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.0406 - val_loss: 3.2615\n",
      "Epoch 10/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.3690 - val_loss: 3.3852\n",
      "Epoch 11/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 3.4047 - val_loss: 3.2728\n",
      "Epoch 12/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.5824 - val_loss: 3.4174\n",
      "Epoch 13/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.4998 - val_loss: 2.9999\n",
      "Epoch 14/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.3359 - val_loss: 3.2874\n",
      "Epoch 15/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.2122 - val_loss: 2.9005\n",
      "Epoch 16/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.4345 - val_loss: 3.4453\n",
      "Epoch 17/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.2863 - val_loss: 2.8284\n",
      "Epoch 18/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 3.1519 - val_loss: 3.3470\n",
      "Epoch 19/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.0469 - val_loss: 2.9624\n",
      "Epoch 20/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.0533 - val_loss: 2.8033\n",
      "Epoch 21/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.9376 - val_loss: 3.0698\n",
      "Epoch 22/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.9792 - val_loss: 2.6653\n",
      "Epoch 23/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.8155 - val_loss: 2.5930\n",
      "Epoch 24/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.8338 - val_loss: 2.5802\n",
      "Epoch 25/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.7898 - val_loss: 2.7674\n",
      "Epoch 26/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.7024 - val_loss: 2.6480\n",
      "Epoch 27/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.6770 - val_loss: 2.7509\n",
      "Epoch 28/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.7273 - val_loss: 2.6760\n",
      "Epoch 29/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.6309 - val_loss: 2.4707\n",
      "Epoch 30/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.6145 - val_loss: 3.1963\n",
      "Epoch 31/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.5946 - val_loss: 2.4986\n",
      "Epoch 32/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.5824 - val_loss: 2.8248\n",
      "Epoch 33/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.5891 - val_loss: 2.8316\n",
      "Epoch 34/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 2.5422 - val_loss: 2.4294\n",
      "Epoch 35/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 2.4891 - val_loss: 2.3774\n",
      "Epoch 36/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4397 - val_loss: 2.3533\n",
      "Epoch 37/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4426 - val_loss: 2.8828\n",
      "Epoch 38/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4665 - val_loss: 2.3617\n",
      "Epoch 39/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4084 - val_loss: 3.3460\n",
      "Epoch 40/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4123 - val_loss: 2.5894\n",
      "Epoch 41/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.4266 - val_loss: 2.4063\n",
      "Epoch 42/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3467 - val_loss: 2.3388\n",
      "Epoch 43/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3255 - val_loss: 2.4414\n",
      "Epoch 44/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3578 - val_loss: 2.2276\n",
      "Epoch 45/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3301 - val_loss: 2.3861\n",
      "Epoch 46/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3050 - val_loss: 2.6526\n",
      "Epoch 47/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.3263 - val_loss: 2.2536\n",
      "Epoch 48/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3254 - val_loss: 2.1573\n",
      "Epoch 49/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2988 - val_loss: 2.2410\n",
      "Epoch 50/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 2.2725 - val_loss: 2.2993\n",
      "Epoch 51/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2604 - val_loss: 2.5343\n",
      "Epoch 52/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2356 - val_loss: 2.1687\n",
      "Epoch 53/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2527 - val_loss: 2.2966\n",
      "Epoch 54/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2133 - val_loss: 2.1100\n",
      "Epoch 55/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1883 - val_loss: 2.1184\n",
      "Epoch 56/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.1923 - val_loss: 2.1153\n",
      "Epoch 57/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2053 - val_loss: 2.1591\n",
      "Epoch 58/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1745 - val_loss: 2.1193\n",
      "Epoch 59/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.1445 - val_loss: 2.1035\n",
      "Epoch 60/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1727 - val_loss: 2.0639\n",
      "Epoch 61/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1520 - val_loss: 2.1436\n",
      "Epoch 62/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1169 - val_loss: 2.0213\n",
      "Epoch 63/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1221 - val_loss: 2.3011\n",
      "Epoch 64/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.1184 - val_loss: 2.0961\n",
      "Epoch 65/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0978 - val_loss: 2.0779\n",
      "Epoch 66/300\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 2.1089 - val_loss: 2.0444\n",
      "Epoch 67/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1066 - val_loss: 2.0120\n",
      "Epoch 68/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0951 - val_loss: 2.1519\n",
      "Epoch 69/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0815 - val_loss: 1.9922\n",
      "Epoch 70/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0802 - val_loss: 1.9791\n",
      "Epoch 71/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0645 - val_loss: 1.9841\n",
      "Epoch 72/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0630 - val_loss: 2.0439\n",
      "Epoch 73/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0255 - val_loss: 2.0211\n",
      "Epoch 74/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0380 - val_loss: 2.0204\n",
      "Epoch 75/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0478 - val_loss: 2.1602\n",
      "Epoch 76/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0119 - val_loss: 1.9472\n",
      "Epoch 77/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0078 - val_loss: 1.9807\n",
      "Epoch 78/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9926 - val_loss: 1.9619\n",
      "Epoch 79/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0045 - val_loss: 1.9665\n",
      "Epoch 80/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9917 - val_loss: 1.9310\n",
      "Epoch 81/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9903 - val_loss: 2.0081\n",
      "Epoch 82/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.9729 - val_loss: 2.0062\n",
      "Epoch 83/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.9966 - val_loss: 1.9531\n",
      "Epoch 84/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9820 - val_loss: 2.0416\n",
      "Epoch 85/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9657 - val_loss: 1.9363\n",
      "Epoch 86/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9696 - val_loss: 1.9120\n",
      "Epoch 87/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9322 - val_loss: 1.9982\n",
      "Epoch 88/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9525 - val_loss: 2.0309\n",
      "Epoch 89/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9652 - val_loss: 1.9254\n",
      "Epoch 90/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9527 - val_loss: 1.8856\n",
      "Epoch 91/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9144 - val_loss: 2.0496\n",
      "Epoch 92/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9404 - val_loss: 2.0396\n",
      "Epoch 93/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9409 - val_loss: 1.9316\n",
      "Epoch 94/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9503 - val_loss: 1.9652\n",
      "Epoch 95/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9021 - val_loss: 2.0244\n",
      "Epoch 96/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9248 - val_loss: 1.9634\n",
      "Epoch 97/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8939 - val_loss: 1.8755\n",
      "Epoch 98/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.8899 - val_loss: 1.9104\n",
      "Epoch 99/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.9063 - val_loss: 1.9358\n",
      "Epoch 100/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9079 - val_loss: 1.8025\n",
      "Epoch 101/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8805 - val_loss: 1.8295\n",
      "Epoch 102/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8727 - val_loss: 2.0191\n",
      "Epoch 103/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.8973 - val_loss: 1.8754\n",
      "Epoch 104/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8721 - val_loss: 1.8378\n",
      "Epoch 105/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8579 - val_loss: 1.8758\n",
      "Epoch 106/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8538 - val_loss: 2.0028\n",
      "Epoch 107/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8656 - val_loss: 1.9702\n",
      "Epoch 108/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8753 - val_loss: 1.8498\n",
      "Epoch 109/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8702 - val_loss: 1.8686\n",
      "Epoch 110/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8459 - val_loss: 1.8738\n",
      "Epoch 111/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8474 - val_loss: 1.8320\n",
      "Epoch 112/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8308 - val_loss: 2.0227\n",
      "Epoch 113/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8456 - val_loss: 1.8218\n",
      "Epoch 114/300\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.8304 - val_loss: 1.8416\n",
      "Epoch 115/300\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.8204 - val_loss: 1.8618\n",
      "Epoch 116/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8676 - val_loss: 1.8049\n",
      "Epoch 117/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8448 - val_loss: 1.8198\n",
      "Epoch 118/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8206 - val_loss: 1.8840\n",
      "Epoch 119/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8216 - val_loss: 1.8290\n",
      "Epoch 120/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8170 - val_loss: 1.8627\n",
      "Epoch 121/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8082 - val_loss: 1.8653\n",
      "Epoch 122/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8260 - val_loss: 1.8287\n",
      "Epoch 123/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7988 - val_loss: 1.9534\n",
      "Epoch 124/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7857 - val_loss: 1.7946\n",
      "Epoch 125/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8170 - val_loss: 1.9743\n",
      "Epoch 126/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8021 - val_loss: 1.8229\n",
      "Epoch 127/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7962 - val_loss: 1.8213\n",
      "Epoch 128/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7768 - val_loss: 1.8103\n",
      "Epoch 129/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7937 - val_loss: 1.8660\n",
      "Epoch 130/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.7880 - val_loss: 1.7991\n",
      "Epoch 131/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.7881 - val_loss: 1.8328\n",
      "Epoch 132/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7720 - val_loss: 1.7597\n",
      "Epoch 133/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7772 - val_loss: 1.7909\n",
      "Epoch 134/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7740 - val_loss: 1.7924\n",
      "Epoch 135/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7626 - val_loss: 1.7802\n",
      "Epoch 136/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7737 - val_loss: 1.7652\n",
      "Epoch 137/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7600 - val_loss: 1.8269\n",
      "Epoch 138/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7705 - val_loss: 1.7628\n",
      "Epoch 139/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7517 - val_loss: 1.7359\n",
      "Epoch 140/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7464 - val_loss: 1.7632\n",
      "Epoch 141/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7587 - val_loss: 1.7458\n",
      "Epoch 142/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7379 - val_loss: 1.7591\n",
      "Epoch 143/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7497 - val_loss: 1.8148\n",
      "Epoch 144/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7397 - val_loss: 1.8391\n",
      "Epoch 145/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7477 - val_loss: 1.8122\n",
      "Epoch 146/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.7190 - val_loss: 1.7562\n",
      "Epoch 147/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7124 - val_loss: 1.8335\n",
      "Epoch 148/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7288 - val_loss: 1.7335\n",
      "Epoch 149/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7186 - val_loss: 1.7979\n",
      "Epoch 150/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7181 - val_loss: 1.7538\n",
      "Epoch 151/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7105 - val_loss: 1.6820\n",
      "Epoch 152/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7198 - val_loss: 1.7778\n",
      "Epoch 153/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7255 - val_loss: 1.7069\n",
      "Epoch 154/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6955 - val_loss: 1.7361\n",
      "Epoch 155/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7008 - val_loss: 1.8294\n",
      "Epoch 156/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6914 - val_loss: 1.7047\n",
      "Epoch 157/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6890 - val_loss: 1.6522\n",
      "Epoch 158/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6852 - val_loss: 1.6542\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6871 - val_loss: 1.7612\n",
      "Epoch 160/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6846 - val_loss: 1.6837\n",
      "Epoch 161/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7074 - val_loss: 1.7371\n",
      "Epoch 162/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.6734 - val_loss: 1.7401\n",
      "Epoch 163/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6967 - val_loss: 1.7289\n",
      "Epoch 164/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6907 - val_loss: 1.6756\n",
      "Epoch 165/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6660 - val_loss: 1.7214\n",
      "Epoch 166/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6760 - val_loss: 1.7211\n",
      "Epoch 167/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6539 - val_loss: 1.7703\n",
      "Epoch 168/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6583 - val_loss: 1.6842\n",
      "Epoch 169/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6754 - val_loss: 1.6732\n",
      "Epoch 170/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6626 - val_loss: 1.7882\n",
      "Epoch 171/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6718 - val_loss: 1.7311\n",
      "Epoch 172/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6667 - val_loss: 1.8019\n",
      "Epoch 173/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6836 - val_loss: 1.7150\n",
      "Epoch 174/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6586 - val_loss: 1.7058\n",
      "Epoch 175/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6488 - val_loss: 1.6485\n",
      "Epoch 176/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6378 - val_loss: 1.8776\n",
      "Epoch 177/300\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.6620 - val_loss: 1.8192\n",
      "Epoch 178/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.6389 - val_loss: 1.6841\n",
      "Epoch 179/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6545 - val_loss: 1.6460\n",
      "Epoch 180/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6327 - val_loss: 1.6641\n",
      "Epoch 181/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6312 - val_loss: 1.6655\n",
      "Epoch 182/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6531 - val_loss: 1.6480\n",
      "Epoch 183/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6212 - val_loss: 1.6292\n",
      "Epoch 184/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6191 - val_loss: 1.6333\n",
      "Epoch 185/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6136 - val_loss: 1.6514\n",
      "Epoch 186/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6344 - val_loss: 1.6392\n",
      "Epoch 187/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6302 - val_loss: 1.7363\n",
      "Epoch 188/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6365 - val_loss: 1.7679\n",
      "Epoch 189/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6354 - val_loss: 1.6545\n",
      "Epoch 190/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6165 - val_loss: 1.6756\n",
      "Epoch 191/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6252 - val_loss: 1.7264\n",
      "Epoch 192/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6089 - val_loss: 1.6066\n",
      "Epoch 193/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5992 - val_loss: 1.6158\n",
      "Epoch 194/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.6135 - val_loss: 1.7292\n",
      "Epoch 195/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.6146 - val_loss: 1.7695\n",
      "Epoch 196/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6222 - val_loss: 1.6592\n",
      "Epoch 197/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6161 - val_loss: 1.5762\n",
      "Epoch 198/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6029 - val_loss: 1.7636\n",
      "Epoch 199/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.6159 - val_loss: 1.6075\n",
      "Epoch 200/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6119 - val_loss: 1.6637\n",
      "Epoch 201/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5866 - val_loss: 1.5990\n",
      "Epoch 202/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5995 - val_loss: 1.6825\n",
      "Epoch 203/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5928 - val_loss: 1.7425\n",
      "Epoch 204/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5962 - val_loss: 1.7253\n",
      "Epoch 205/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5925 - val_loss: 1.6651\n",
      "Epoch 206/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6037 - val_loss: 1.5988\n",
      "Epoch 207/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5833 - val_loss: 1.5664\n",
      "Epoch 208/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5797 - val_loss: 1.5756\n",
      "Epoch 209/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5703 - val_loss: 1.6085\n",
      "Epoch 210/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.5693 - val_loss: 1.6081\n",
      "Epoch 211/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5890 - val_loss: 1.6015\n",
      "Epoch 212/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5809 - val_loss: 1.6321\n",
      "Epoch 213/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5770 - val_loss: 1.5655\n",
      "Epoch 214/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5714 - val_loss: 1.5821\n",
      "Epoch 215/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5686 - val_loss: 1.6185\n",
      "Epoch 216/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5565 - val_loss: 1.5949\n",
      "Epoch 217/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5807 - val_loss: 1.5639\n",
      "Epoch 218/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5604 - val_loss: 1.5629\n",
      "Epoch 219/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5612 - val_loss: 1.6265\n",
      "Epoch 220/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5533 - val_loss: 1.6080\n",
      "Epoch 221/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5611 - val_loss: 1.5569\n",
      "Epoch 222/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5920 - val_loss: 1.5548\n",
      "Epoch 223/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5625 - val_loss: 1.5420\n",
      "Epoch 224/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5524 - val_loss: 1.6980\n",
      "Epoch 225/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5541 - val_loss: 1.5794\n",
      "Epoch 226/300\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.5544 - val_loss: 1.5754\n",
      "Epoch 227/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5628 - val_loss: 1.5913\n",
      "Epoch 228/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5518 - val_loss: 1.6441\n",
      "Epoch 229/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5492 - val_loss: 1.6099\n",
      "Epoch 230/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5444 - val_loss: 1.6434\n",
      "Epoch 231/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.5503 - val_loss: 1.6758\n",
      "Epoch 232/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5438 - val_loss: 1.6061\n",
      "Epoch 233/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5435 - val_loss: 1.6008\n",
      "Epoch 234/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5390 - val_loss: 1.5433\n",
      "Epoch 235/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5352 - val_loss: 1.5754\n",
      "Epoch 236/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5569 - val_loss: 1.6017\n",
      "Epoch 237/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5530 - val_loss: 1.5351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5400 - val_loss: 1.5663\n",
      "Epoch 239/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5374 - val_loss: 1.5642\n",
      "Epoch 240/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5339 - val_loss: 1.5712\n",
      "Epoch 241/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5330 - val_loss: 1.5592\n",
      "Epoch 242/300\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.5308 - val_loss: 1.7113\n",
      "Epoch 243/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5377 - val_loss: 1.6349\n",
      "Epoch 244/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5261 - val_loss: 1.5278\n",
      "Epoch 245/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5366 - val_loss: 1.5036\n",
      "Epoch 246/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5413 - val_loss: 1.5699\n",
      "Epoch 247/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5270 - val_loss: 1.5613\n",
      "Epoch 248/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5079 - val_loss: 1.6513\n",
      "Epoch 249/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5250 - val_loss: 1.5952\n",
      "Epoch 250/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5176 - val_loss: 1.5331\n",
      "Epoch 251/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5316 - val_loss: 1.6092\n",
      "Epoch 252/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5096 - val_loss: 1.5780\n",
      "Epoch 253/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5133 - val_loss: 1.5742\n",
      "Epoch 254/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5174 - val_loss: 1.6492\n",
      "Epoch 255/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5091 - val_loss: 1.6156\n",
      "Epoch 256/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5230 - val_loss: 1.6091\n",
      "Epoch 257/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5137 - val_loss: 1.6483\n",
      "Epoch 258/300\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.5123 - val_loss: 1.5872\n",
      "Epoch 259/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5151 - val_loss: 1.6111\n",
      "Epoch 260/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5218 - val_loss: 1.5672\n",
      "Epoch 261/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4926 - val_loss: 1.5822\n",
      "Epoch 262/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5043 - val_loss: 1.5728\n",
      "Epoch 263/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5020 - val_loss: 1.5479\n",
      "Epoch 264/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4990 - val_loss: 1.5371\n",
      "Epoch 265/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5131 - val_loss: 1.5327\n",
      "Epoch 266/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5048 - val_loss: 1.5999\n",
      "Epoch 267/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5003 - val_loss: 1.6353\n",
      "Epoch 268/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4985 - val_loss: 1.5159\n",
      "Epoch 269/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5068 - val_loss: 1.4968\n",
      "Epoch 270/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4976 - val_loss: 1.5494\n",
      "Epoch 271/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5029 - val_loss: 1.5588\n",
      "Epoch 272/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5087 - val_loss: 1.5633\n",
      "Epoch 273/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5006 - val_loss: 1.5523\n",
      "Epoch 274/300\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.4817 - val_loss: 1.5629\n",
      "Epoch 275/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4938 - val_loss: 1.5360\n",
      "Epoch 276/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5019 - val_loss: 1.5276\n",
      "Epoch 277/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4912 - val_loss: 1.5058\n",
      "Epoch 278/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5034 - val_loss: 1.5192\n",
      "Epoch 279/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4839 - val_loss: 1.6242\n",
      "Epoch 280/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4928 - val_loss: 1.5854\n",
      "Epoch 281/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4769 - val_loss: 1.4999\n",
      "Epoch 282/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4807 - val_loss: 1.5293\n",
      "Epoch 283/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4788 - val_loss: 1.5271\n",
      "Epoch 284/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4938 - val_loss: 1.5411\n",
      "Epoch 285/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4862 - val_loss: 1.5366\n",
      "Epoch 286/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4818 - val_loss: 1.5067\n",
      "Epoch 287/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4831 - val_loss: 1.5307\n",
      "Epoch 288/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4919 - val_loss: 1.5605\n",
      "Epoch 289/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4745 - val_loss: 1.4974\n",
      "Epoch 290/300\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.4785 - val_loss: 1.6075\n",
      "Epoch 291/300\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4885 - val_loss: 1.5241\n",
      "Epoch 292/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4878 - val_loss: 1.5232\n",
      "Epoch 293/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4990 - val_loss: 1.5240\n",
      "Epoch 294/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4643 - val_loss: 1.5057\n",
      "Epoch 295/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4656 - val_loss: 1.6467\n",
      "Epoch 296/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4652 - val_loss: 1.5287\n",
      "Epoch 297/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4757 - val_loss: 1.5132\n",
      "Epoch 298/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4753 - val_loss: 1.4926\n",
      "Epoch 299/300\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4599 - val_loss: 1.4985\n",
      "Epoch 300/300\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4709 - val_loss: 1.5217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5217136508986437\n",
      "0.9660859302607405\n",
      "Epoch 1/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 14.8560 - val_loss: 8.1260\n",
      "Epoch 2/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 8.2187 - val_loss: 6.6392\n",
      "Epoch 3/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 5.6885 - val_loss: 4.2571\n",
      "Epoch 4/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 5.3401 - val_loss: 4.3081\n",
      "Epoch 5/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.8859 - val_loss: 4.0072\n",
      "Epoch 6/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 4.6523 - val_loss: 5.9750\n",
      "Epoch 7/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 4.4273 - val_loss: 4.1464\n",
      "Epoch 8/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.3414 - val_loss: 4.8030\n",
      "Epoch 9/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.4077 - val_loss: 4.0815\n",
      "Epoch 10/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 4.1484 - val_loss: 4.7668\n",
      "Epoch 11/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.2337 - val_loss: 3.8790\n",
      "Epoch 12/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.5654 - val_loss: 3.8137\n",
      "Epoch 13/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.0697 - val_loss: 3.4405\n",
      "Epoch 14/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.6942 - val_loss: 4.0702\n",
      "Epoch 15/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.5729 - val_loss: 4.1895\n",
      "Epoch 16/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.5942 - val_loss: 4.7051\n",
      "Epoch 17/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.9664 - val_loss: 3.4722\n",
      "Epoch 18/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.3980 - val_loss: 3.0865\n",
      "Epoch 19/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.3017 - val_loss: 3.2816\n",
      "Epoch 20/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 3.4557 - val_loss: 3.0049\n",
      "Epoch 21/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 3.3041 - val_loss: 3.0741\n",
      "Epoch 22/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.1844 - val_loss: 4.3193\n",
      "Epoch 23/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.2483 - val_loss: 3.1026\n",
      "Epoch 24/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.2131 - val_loss: 2.8843\n",
      "Epoch 25/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.0158 - val_loss: 2.9164\n",
      "Epoch 26/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.9153 - val_loss: 2.7561\n",
      "Epoch 27/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.8947 - val_loss: 3.5485\n",
      "Epoch 28/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.8642 - val_loss: 2.8227\n",
      "Epoch 29/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.9040 - val_loss: 2.7026\n",
      "Epoch 30/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7732 - val_loss: 3.3428\n",
      "Epoch 31/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7632 - val_loss: 2.5916\n",
      "Epoch 32/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7695 - val_loss: 2.5652\n",
      "Epoch 33/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.6880 - val_loss: 2.5489\n",
      "Epoch 34/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.6444 - val_loss: 2.9137\n",
      "Epoch 35/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.6385 - val_loss: 3.2255\n",
      "Epoch 36/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.6878 - val_loss: 3.8237\n",
      "Epoch 37/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.5704 - val_loss: 2.5165\n",
      "Epoch 38/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5412 - val_loss: 2.9069\n",
      "Epoch 39/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5541 - val_loss: 2.4967\n",
      "Epoch 40/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5401 - val_loss: 2.4460\n",
      "Epoch 41/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4558 - val_loss: 2.5734\n",
      "Epoch 42/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.4584 - val_loss: 2.5476\n",
      "Epoch 43/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4396 - val_loss: 2.3753\n",
      "Epoch 44/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4110 - val_loss: 2.3842\n",
      "Epoch 45/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3886 - val_loss: 2.4800\n",
      "Epoch 46/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3679 - val_loss: 2.5020\n",
      "Epoch 47/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3852 - val_loss: 2.2853\n",
      "Epoch 48/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3921 - val_loss: 2.3270\n",
      "Epoch 49/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3574 - val_loss: 2.2850\n",
      "Epoch 50/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3082 - val_loss: 2.1977\n",
      "Epoch 51/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3262 - val_loss: 2.2401\n",
      "Epoch 52/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.2864 - val_loss: 2.2319\n",
      "Epoch 53/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 2.2702 - val_loss: 2.1875\n",
      "Epoch 54/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2881 - val_loss: 2.2279\n",
      "Epoch 55/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2302 - val_loss: 2.3197\n",
      "Epoch 56/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2078 - val_loss: 2.1300\n",
      "Epoch 57/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2320 - val_loss: 2.2891\n",
      "Epoch 58/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1887 - val_loss: 2.2617\n",
      "Epoch 59/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.1877 - val_loss: 2.2420\n",
      "Epoch 60/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1741 - val_loss: 2.1549\n",
      "Epoch 61/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1949 - val_loss: 2.0902\n",
      "Epoch 62/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1745 - val_loss: 2.4385\n",
      "Epoch 63/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1944 - val_loss: 2.1288\n",
      "Epoch 64/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1179 - val_loss: 2.0394\n",
      "Epoch 65/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1112 - val_loss: 2.0530\n",
      "Epoch 66/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1336 - val_loss: 2.1134\n",
      "Epoch 67/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1233 - val_loss: 2.1290\n",
      "Epoch 68/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1114 - val_loss: 2.1079\n",
      "Epoch 69/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 2.0767 - val_loss: 2.0369\n",
      "Epoch 70/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0889 - val_loss: 2.1686\n",
      "Epoch 71/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0797 - val_loss: 2.1005\n",
      "Epoch 72/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0885 - val_loss: 2.1239\n",
      "Epoch 73/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0528 - val_loss: 2.0343\n",
      "Epoch 74/300\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 2.0469 - val_loss: 2.1840\n",
      "Epoch 75/300\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 2.0603 - val_loss: 2.0589\n",
      "Epoch 76/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0494 - val_loss: 2.0542\n",
      "Epoch 77/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0310 - val_loss: 2.1110\n",
      "Epoch 78/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0408 - val_loss: 2.0035\n",
      "Epoch 79/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0207 - val_loss: 1.9802\n",
      "Epoch 80/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0222 - val_loss: 2.1584\n",
      "Epoch 81/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9947 - val_loss: 1.9708\n",
      "Epoch 82/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9827 - val_loss: 2.0561\n",
      "Epoch 83/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9990 - val_loss: 1.9899\n",
      "Epoch 84/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.0045 - val_loss: 1.9999\n",
      "Epoch 85/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.0041 - val_loss: 2.0882\n",
      "Epoch 86/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9757 - val_loss: 2.0381\n",
      "Epoch 87/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9726 - val_loss: 1.9914\n",
      "Epoch 88/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9749 - val_loss: 1.9968\n",
      "Epoch 89/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9439 - val_loss: 1.9451\n",
      "Epoch 90/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9660 - val_loss: 1.8804\n",
      "Epoch 91/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9459 - val_loss: 1.9921\n",
      "Epoch 92/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9749 - val_loss: 1.9854\n",
      "Epoch 93/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9331 - val_loss: 1.9351\n",
      "Epoch 94/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.9232 - val_loss: 1.9104\n",
      "Epoch 95/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9230 - val_loss: 2.0247\n",
      "Epoch 96/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9126 - val_loss: 1.9530\n",
      "Epoch 97/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9113 - val_loss: 1.8478\n",
      "Epoch 98/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9141 - val_loss: 1.9931\n",
      "Epoch 99/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9173 - val_loss: 1.8966\n",
      "Epoch 100/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.9053 - val_loss: 1.8194\n",
      "Epoch 101/300\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.9012 - val_loss: 1.9120\n",
      "Epoch 102/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9032 - val_loss: 2.0315\n",
      "Epoch 103/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8878 - val_loss: 1.8704\n",
      "Epoch 104/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9155 - val_loss: 1.8878\n",
      "Epoch 105/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8933 - val_loss: 1.9213\n",
      "Epoch 106/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8745 - val_loss: 1.8630\n",
      "Epoch 107/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8532 - val_loss: 1.8843\n",
      "Epoch 108/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8823 - val_loss: 1.9107\n",
      "Epoch 109/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8465 - val_loss: 1.8904\n",
      "Epoch 110/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8539 - val_loss: 1.8273\n",
      "Epoch 111/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8609 - val_loss: 1.8217\n",
      "Epoch 112/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8506 - val_loss: 1.8476\n",
      "Epoch 113/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8329 - val_loss: 1.9098\n",
      "Epoch 114/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8273 - val_loss: 1.9062\n",
      "Epoch 115/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8482 - val_loss: 1.7993\n",
      "Epoch 116/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8280 - val_loss: 1.8427\n",
      "Epoch 117/300\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.8503 - val_loss: 1.7856\n",
      "Epoch 118/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.8197 - val_loss: 1.8905\n",
      "Epoch 119/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8504 - val_loss: 1.8842\n",
      "Epoch 120/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8263 - val_loss: 1.8509\n",
      "Epoch 121/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7898 - val_loss: 1.8804\n",
      "Epoch 122/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8260 - val_loss: 1.7523\n",
      "Epoch 123/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7962 - val_loss: 1.7574\n",
      "Epoch 124/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7881 - val_loss: 1.8007\n",
      "Epoch 125/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8054 - val_loss: 2.0159\n",
      "Epoch 126/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7977 - val_loss: 1.8872\n",
      "Epoch 127/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7956 - val_loss: 1.7289\n",
      "Epoch 128/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7802 - val_loss: 1.7678\n",
      "Epoch 129/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7751 - val_loss: 1.7515\n",
      "Epoch 130/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7704 - val_loss: 1.9542\n",
      "Epoch 131/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7840 - val_loss: 1.8004\n",
      "Epoch 132/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.7562 - val_loss: 1.8848\n",
      "Epoch 133/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.7834 - val_loss: 1.7907\n",
      "Epoch 134/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.7502 - val_loss: 1.7316\n",
      "Epoch 135/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7500 - val_loss: 1.7485\n",
      "Epoch 136/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7433 - val_loss: 1.9012\n",
      "Epoch 137/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7512 - val_loss: 1.7992\n",
      "Epoch 138/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7467 - val_loss: 1.7728\n",
      "Epoch 139/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7547 - val_loss: 1.8493\n",
      "Epoch 140/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7385 - val_loss: 1.7409\n",
      "Epoch 141/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7661 - val_loss: 1.7570\n",
      "Epoch 142/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7399 - val_loss: 1.6959\n",
      "Epoch 143/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7290 - val_loss: 1.7245\n",
      "Epoch 144/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.7379 - val_loss: 1.7639\n",
      "Epoch 145/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7192 - val_loss: 1.9685\n",
      "Epoch 146/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7288 - val_loss: 1.7223\n",
      "Epoch 147/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7108 - val_loss: 1.7243\n",
      "Epoch 148/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7032 - val_loss: 1.6873\n",
      "Epoch 149/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6996 - val_loss: 1.7242\n",
      "Epoch 150/300\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.7219 - val_loss: 1.7334\n",
      "Epoch 151/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6939 - val_loss: 1.7073\n",
      "Epoch 152/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6836 - val_loss: 1.6979\n",
      "Epoch 153/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7069 - val_loss: 1.7503\n",
      "Epoch 154/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6879 - val_loss: 1.7277\n",
      "Epoch 155/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6845 - val_loss: 1.6678\n",
      "Epoch 156/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6799 - val_loss: 1.7263\n",
      "Epoch 157/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6965 - val_loss: 1.6578\n",
      "Epoch 158/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6710 - val_loss: 1.6744\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6838 - val_loss: 1.7399\n",
      "Epoch 160/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6726 - val_loss: 1.7357\n",
      "Epoch 161/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6621 - val_loss: 1.7208\n",
      "Epoch 162/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6759 - val_loss: 1.7071\n",
      "Epoch 163/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6404 - val_loss: 1.6898\n",
      "Epoch 164/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6595 - val_loss: 1.6597\n",
      "Epoch 165/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6682 - val_loss: 1.6876\n",
      "Epoch 166/300\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.6404 - val_loss: 1.6794\n",
      "Epoch 167/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6402 - val_loss: 1.6458\n",
      "Epoch 168/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6533 - val_loss: 1.6187\n",
      "Epoch 169/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6319 - val_loss: 1.6879\n",
      "Epoch 170/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6240 - val_loss: 1.6198\n",
      "Epoch 171/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6350 - val_loss: 1.6787\n",
      "Epoch 172/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6383 - val_loss: 1.6617\n",
      "Epoch 173/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6433 - val_loss: 1.7190\n",
      "Epoch 174/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6221 - val_loss: 1.6456\n",
      "Epoch 175/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6132 - val_loss: 1.6342\n",
      "Epoch 176/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6063 - val_loss: 1.6079\n",
      "Epoch 177/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6346 - val_loss: 1.6980\n",
      "Epoch 178/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6198 - val_loss: 1.6288\n",
      "Epoch 179/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6266 - val_loss: 1.6059\n",
      "Epoch 180/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5960 - val_loss: 1.6179\n",
      "Epoch 181/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6038 - val_loss: 1.7947\n",
      "Epoch 182/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5981 - val_loss: 1.6133\n",
      "Epoch 183/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5940 - val_loss: 1.6123\n",
      "Epoch 184/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5972 - val_loss: 1.8358\n",
      "Epoch 185/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6186 - val_loss: 1.5908\n",
      "Epoch 186/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5872 - val_loss: 1.6158\n",
      "Epoch 187/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5982 - val_loss: 1.6202\n",
      "Epoch 188/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5994 - val_loss: 1.6649\n",
      "Epoch 189/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5791 - val_loss: 1.5555\n",
      "Epoch 190/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5764 - val_loss: 1.5977\n",
      "Epoch 191/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5840 - val_loss: 1.6819\n",
      "Epoch 192/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5949 - val_loss: 1.6011\n",
      "Epoch 193/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5889 - val_loss: 1.5994\n",
      "Epoch 194/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5732 - val_loss: 1.6686\n",
      "Epoch 195/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6295 - val_loss: 1.5890\n",
      "Epoch 196/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5664 - val_loss: 1.5992\n",
      "Epoch 197/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5672 - val_loss: 1.6060\n",
      "Epoch 198/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5761 - val_loss: 1.6536\n",
      "Epoch 199/300\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.5768 - val_loss: 1.6590\n",
      "Epoch 200/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5808 - val_loss: 1.5684\n",
      "Epoch 201/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5674 - val_loss: 1.5228\n",
      "Epoch 202/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5519 - val_loss: 1.6391\n",
      "Epoch 203/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5502 - val_loss: 1.5792\n",
      "Epoch 204/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5598 - val_loss: 1.5987\n",
      "Epoch 205/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5473 - val_loss: 1.5320\n",
      "Epoch 206/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5445 - val_loss: 1.5717\n",
      "Epoch 207/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5418 - val_loss: 1.5962\n",
      "Epoch 208/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5441 - val_loss: 1.6158\n",
      "Epoch 209/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5711 - val_loss: 1.6310\n",
      "Epoch 210/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5540 - val_loss: 1.5683\n",
      "Epoch 211/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5419 - val_loss: 1.6791\n",
      "Epoch 212/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5580 - val_loss: 1.5681\n",
      "Epoch 213/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5537 - val_loss: 1.5959\n",
      "Epoch 214/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5446 - val_loss: 1.5792\n",
      "Epoch 215/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5373 - val_loss: 1.6432\n",
      "Epoch 216/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5261 - val_loss: 1.5820\n",
      "Epoch 217/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5371 - val_loss: 1.5753\n",
      "Epoch 218/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5438 - val_loss: 1.5365\n",
      "Epoch 219/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5433 - val_loss: 1.6858\n",
      "Epoch 220/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5442 - val_loss: 1.5870\n",
      "Epoch 221/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5356 - val_loss: 1.5785\n",
      "Epoch 222/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5159 - val_loss: 1.5014\n",
      "Epoch 223/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5150 - val_loss: 1.5696\n",
      "Epoch 224/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5314 - val_loss: 1.6284\n",
      "Epoch 225/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5222 - val_loss: 1.5598\n",
      "Epoch 226/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5288 - val_loss: 1.5607\n",
      "Epoch 227/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5147 - val_loss: 1.5317\n",
      "Epoch 228/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5094 - val_loss: 1.5428\n",
      "Epoch 229/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5209 - val_loss: 1.5232\n",
      "Epoch 230/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5225 - val_loss: 1.6159\n",
      "Epoch 231/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5239 - val_loss: 1.5793\n",
      "Epoch 232/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5179 - val_loss: 1.5469\n",
      "Epoch 233/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5183 - val_loss: 1.5065\n",
      "Epoch 234/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5140 - val_loss: 1.5892\n",
      "Epoch 235/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4898 - val_loss: 1.5187\n",
      "Epoch 236/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4943 - val_loss: 1.5051\n",
      "Epoch 237/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5145 - val_loss: 1.5313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5066 - val_loss: 1.5435\n",
      "Epoch 239/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5018 - val_loss: 1.5645\n",
      "Epoch 240/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5045 - val_loss: 1.5009\n",
      "Epoch 241/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4964 - val_loss: 1.5969\n",
      "Epoch 242/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5219 - val_loss: 1.5361\n",
      "Epoch 243/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4956 - val_loss: 1.5000\n",
      "Epoch 244/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4948 - val_loss: 1.5177\n",
      "Epoch 245/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4849 - val_loss: 1.5330\n",
      "Epoch 246/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5075 - val_loss: 1.5019\n",
      "Epoch 247/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4914 - val_loss: 1.6152\n",
      "Epoch 248/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4923 - val_loss: 1.5768\n",
      "Epoch 249/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4823 - val_loss: 1.5423\n",
      "Epoch 250/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5122 - val_loss: 1.5300\n",
      "Epoch 251/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4974 - val_loss: 1.5196\n",
      "Epoch 252/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4922 - val_loss: 1.5078\n",
      "Epoch 253/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4879 - val_loss: 1.5076\n",
      "Epoch 254/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4876 - val_loss: 1.5305\n",
      "Epoch 255/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4778 - val_loss: 1.5143\n",
      "Epoch 256/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4772 - val_loss: 1.4944\n",
      "Epoch 257/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4804 - val_loss: 1.5296\n",
      "Epoch 258/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4740 - val_loss: 1.5225\n",
      "Epoch 259/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4864 - val_loss: 1.5021\n",
      "Epoch 260/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4802 - val_loss: 1.5106\n",
      "Epoch 261/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4678 - val_loss: 1.4588\n",
      "Epoch 262/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4732 - val_loss: 1.5310\n",
      "Epoch 263/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4688 - val_loss: 1.5077\n",
      "Epoch 264/300\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4797 - val_loss: 1.6237\n",
      "Epoch 265/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4925 - val_loss: 1.6062\n",
      "Epoch 266/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4616 - val_loss: 1.5068\n",
      "Epoch 267/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4710 - val_loss: 1.4909\n",
      "Epoch 268/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4757 - val_loss: 1.4737\n",
      "Epoch 269/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4592 - val_loss: 1.5984\n",
      "Epoch 270/300\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4614 - val_loss: 1.5188\n",
      "Epoch 271/300\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4460 - val_loss: 1.4920\n",
      "Epoch 272/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4664 - val_loss: 1.4955\n",
      "Epoch 273/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4558 - val_loss: 1.4826\n",
      "Epoch 274/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4553 - val_loss: 1.5027\n",
      "Epoch 275/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4518 - val_loss: 1.4793\n",
      "Epoch 276/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4629 - val_loss: 1.4958\n",
      "Epoch 277/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4601 - val_loss: 1.4774\n",
      "Epoch 278/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4672 - val_loss: 1.4975\n",
      "Epoch 279/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4512 - val_loss: 1.6236\n",
      "Epoch 280/300\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4525 - val_loss: 1.4968\n",
      "Epoch 281/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4589 - val_loss: 1.6279\n",
      "Epoch 282/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4514 - val_loss: 1.4853\n",
      "Epoch 283/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4415 - val_loss: 1.4772\n",
      "Epoch 284/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4393 - val_loss: 1.6648\n",
      "Epoch 285/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4530 - val_loss: 1.4604\n",
      "Epoch 286/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4338 - val_loss: 1.4621\n",
      "Epoch 287/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4351 - val_loss: 1.4566\n",
      "Epoch 288/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4418 - val_loss: 1.4569\n",
      "Epoch 289/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4436 - val_loss: 1.4799\n",
      "Epoch 290/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4353 - val_loss: 1.5184\n",
      "Epoch 291/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4326 - val_loss: 1.4950\n",
      "Epoch 292/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4525 - val_loss: 1.4398\n",
      "Epoch 293/300\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4288 - val_loss: 1.4997\n",
      "Epoch 294/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4191 - val_loss: 1.5315\n",
      "Epoch 295/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4385 - val_loss: 1.4549\n",
      "Epoch 296/300\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4425 - val_loss: 1.4706\n",
      "Epoch 297/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4272 - val_loss: 1.5451\n",
      "Epoch 298/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4165 - val_loss: 1.4321\n",
      "Epoch 299/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4377 - val_loss: 1.4496\n",
      "Epoch 300/300\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4456 - val_loss: 1.5476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5475981103371446\n",
      "0.9655067570121497\n",
      "Epoch 1/500\n",
      "1722/1728 [============================>.] - ETA: 0s - loss: 7.0784WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 7.0694 - val_loss: 7.2340\n",
      "Epoch 2/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 4.7697 - val_loss: 4.0353\n",
      "Epoch 3/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 4.2585 - val_loss: 3.9615\n",
      "Epoch 4/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 3.9694 - val_loss: 3.9855\n",
      "Epoch 5/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 3.2911 - val_loss: 2.9397\n",
      "Epoch 6/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.9744 - val_loss: 3.1006\n",
      "Epoch 7/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.8126 - val_loss: 2.8348\n",
      "Epoch 8/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.6930 - val_loss: 2.5814\n",
      "Epoch 9/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.6342 - val_loss: 2.8005\n",
      "Epoch 10/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.5960 - val_loss: 2.6190\n",
      "Epoch 11/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.5618 - val_loss: 2.4905\n",
      "Epoch 12/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.5283 - val_loss: 2.5595\n",
      "Epoch 13/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.4936 - val_loss: 2.7595\n",
      "Epoch 14/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.4834 - val_loss: 2.5295\n",
      "Epoch 15/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.4673 - val_loss: 2.5414\n",
      "Epoch 16/500\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 2.4284 - val_loss: 2.4199\n",
      "Epoch 17/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.4008 - val_loss: 2.5788\n",
      "Epoch 18/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.3983 - val_loss: 2.2573\n",
      "Epoch 19/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.3636 - val_loss: 2.4805\n",
      "Epoch 20/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.3692 - val_loss: 2.4065\n",
      "Epoch 21/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.3311 - val_loss: 2.2414\n",
      "Epoch 22/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.3037 - val_loss: 2.2752\n",
      "Epoch 23/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.2623 - val_loss: 2.4028\n",
      "Epoch 24/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.2499 - val_loss: 2.1794\n",
      "Epoch 25/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.2278 - val_loss: 2.5165\n",
      "Epoch 26/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.2065 - val_loss: 2.2110\n",
      "Epoch 27/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1844 - val_loss: 2.3506\n",
      "Epoch 28/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1692 - val_loss: 2.1167\n",
      "Epoch 29/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1685 - val_loss: 2.4994\n",
      "Epoch 30/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1481 - val_loss: 2.0740\n",
      "Epoch 31/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1397 - val_loss: 2.4309\n",
      "Epoch 32/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1388 - val_loss: 2.0516\n",
      "Epoch 33/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1243 - val_loss: 2.1454\n",
      "Epoch 34/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1188 - val_loss: 2.0718\n",
      "Epoch 35/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.1128 - val_loss: 2.5158\n",
      "Epoch 36/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1123 - val_loss: 2.2405\n",
      "Epoch 37/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0943 - val_loss: 2.2388\n",
      "Epoch 38/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0928 - val_loss: 2.0752\n",
      "Epoch 39/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0832 - val_loss: 2.1043\n",
      "Epoch 40/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0757 - val_loss: 1.9929\n",
      "Epoch 41/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0781 - val_loss: 2.0379\n",
      "Epoch 42/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0618 - val_loss: 1.9915\n",
      "Epoch 43/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0644 - val_loss: 2.4367\n",
      "Epoch 44/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0627 - val_loss: 2.0283\n",
      "Epoch 45/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0573 - val_loss: 2.0263\n",
      "Epoch 46/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0471 - val_loss: 2.0049\n",
      "Epoch 47/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0412 - val_loss: 2.1061\n",
      "Epoch 48/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0368 - val_loss: 1.9887\n",
      "Epoch 49/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0402 - val_loss: 2.2104\n",
      "Epoch 50/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0222 - val_loss: 1.9831\n",
      "Epoch 51/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0211 - val_loss: 1.9698\n",
      "Epoch 52/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0071 - val_loss: 1.9814\n",
      "Epoch 53/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0162 - val_loss: 1.9964\n",
      "Epoch 54/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0077 - val_loss: 2.2290\n",
      "Epoch 55/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0084 - val_loss: 2.0943\n",
      "Epoch 56/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9906 - val_loss: 1.9681\n",
      "Epoch 57/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0038 - val_loss: 1.9806\n",
      "Epoch 58/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9983 - val_loss: 1.8823\n",
      "Epoch 59/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0004 - val_loss: 1.9226\n",
      "Epoch 60/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9843 - val_loss: 2.0322\n",
      "Epoch 61/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9971 - val_loss: 2.0471\n",
      "Epoch 62/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9837 - val_loss: 2.0701\n",
      "Epoch 63/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9897 - val_loss: 1.9896\n",
      "Epoch 64/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9913 - val_loss: 2.0073\n",
      "Epoch 65/500\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.9820 - val_loss: 2.1522\n",
      "Epoch 66/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9692 - val_loss: 1.9825\n",
      "Epoch 67/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9738 - val_loss: 1.9043\n",
      "Epoch 68/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9697 - val_loss: 1.9927\n",
      "Epoch 69/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9732 - val_loss: 1.9061\n",
      "Epoch 70/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9610 - val_loss: 2.0115\n",
      "Epoch 71/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9701 - val_loss: 1.9441\n",
      "Epoch 72/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9598 - val_loss: 1.9563\n",
      "Epoch 73/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9611 - val_loss: 1.8655\n",
      "Epoch 74/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9616 - val_loss: 1.9850\n",
      "Epoch 75/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9555 - val_loss: 1.9551\n",
      "Epoch 76/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9495 - val_loss: 1.8515\n",
      "Epoch 77/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9565 - val_loss: 2.0181\n",
      "Epoch 78/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9495 - val_loss: 1.9298\n",
      "Epoch 79/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9528 - val_loss: 1.9096\n",
      "Epoch 80/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9533 - val_loss: 2.0915\n",
      "Epoch 81/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9358 - val_loss: 1.9714\n",
      "Epoch 82/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9415 - val_loss: 2.0015\n",
      "Epoch 83/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9420 - val_loss: 1.9067\n",
      "Epoch 84/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9369 - val_loss: 1.9523\n",
      "Epoch 85/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9393 - val_loss: 1.9253\n",
      "Epoch 86/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9404 - val_loss: 1.9083\n",
      "Epoch 87/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9225 - val_loss: 1.9294\n",
      "Epoch 88/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9341 - val_loss: 1.8901\n",
      "Epoch 89/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9318 - val_loss: 1.9308\n",
      "Epoch 90/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9269 - val_loss: 1.9171\n",
      "Epoch 91/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9252 - val_loss: 1.9559\n",
      "Epoch 92/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9187 - val_loss: 1.9364\n",
      "Epoch 93/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9173 - val_loss: 2.3689\n",
      "Epoch 94/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9138 - val_loss: 2.0593\n",
      "Epoch 95/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9120 - val_loss: 1.9306\n",
      "Epoch 96/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9124 - val_loss: 1.8388\n",
      "Epoch 97/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9220 - val_loss: 1.8944\n",
      "Epoch 98/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9199 - val_loss: 1.9301\n",
      "Epoch 99/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9129 - val_loss: 1.8737\n",
      "Epoch 100/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9110 - val_loss: 1.9127\n",
      "Epoch 101/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9064 - val_loss: 1.8456\n",
      "Epoch 102/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9180 - val_loss: 1.9201\n",
      "Epoch 103/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9027 - val_loss: 1.8534\n",
      "Epoch 104/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9043 - val_loss: 1.9609\n",
      "Epoch 105/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9080 - val_loss: 1.8821\n",
      "Epoch 106/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9047 - val_loss: 1.8927\n",
      "Epoch 107/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9084 - val_loss: 1.8818\n",
      "Epoch 108/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8963 - val_loss: 1.9033\n",
      "Epoch 109/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8989 - val_loss: 1.9472\n",
      "Epoch 110/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8922 - val_loss: 1.9697\n",
      "Epoch 111/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8891 - val_loss: 1.8775\n",
      "Epoch 112/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8956 - val_loss: 1.9251\n",
      "Epoch 113/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8883 - val_loss: 1.9050\n",
      "Epoch 114/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8931 - val_loss: 1.8758\n",
      "Epoch 115/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8897 - val_loss: 1.8747\n",
      "Epoch 116/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8766 - val_loss: 1.8829\n",
      "Epoch 117/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8913 - val_loss: 1.9038\n",
      "Epoch 118/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8835 - val_loss: 1.8850\n",
      "Epoch 119/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8813 - val_loss: 2.1434\n",
      "Epoch 120/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8847 - val_loss: 1.9131\n",
      "Epoch 121/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8735 - val_loss: 1.8602\n",
      "Epoch 122/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8757 - val_loss: 1.8951\n",
      "Epoch 123/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8705 - val_loss: 1.8445\n",
      "Epoch 124/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8825 - val_loss: 1.9846\n",
      "Epoch 125/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8744 - val_loss: 1.8846\n",
      "Epoch 126/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8670 - val_loss: 1.8875\n",
      "Epoch 127/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8758 - val_loss: 1.8843\n",
      "Epoch 128/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8806 - val_loss: 1.8572\n",
      "Epoch 129/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8644 - val_loss: 1.9325\n",
      "Epoch 130/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8687 - val_loss: 1.8643\n",
      "Epoch 131/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8677 - val_loss: 2.0780\n",
      "Epoch 132/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8642 - val_loss: 2.0194\n",
      "Epoch 133/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8633 - val_loss: 1.9011\n",
      "Epoch 134/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8621 - val_loss: 1.8735\n",
      "Epoch 135/500\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.8621 - val_loss: 1.8236\n",
      "Epoch 136/500\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.8607 - val_loss: 1.8696\n",
      "Epoch 137/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8565 - val_loss: 1.8588\n",
      "Epoch 138/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8576 - val_loss: 1.8176\n",
      "Epoch 139/500\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.8613 - val_loss: 1.8832\n",
      "Epoch 140/500\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.8636 - val_loss: 1.8394\n",
      "Epoch 141/500\n",
      "1728/1728 [==============================] - 9s 5ms/step - loss: 1.8507 - val_loss: 1.8552\n",
      "Epoch 142/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8519 - val_loss: 1.8135\n",
      "Epoch 143/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8492 - val_loss: 1.7611\n",
      "Epoch 144/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8522 - val_loss: 1.8590\n",
      "Epoch 145/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8418 - val_loss: 1.8281\n",
      "Epoch 146/500\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.8476 - val_loss: 1.8201\n",
      "Epoch 147/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8539 - val_loss: 1.8501\n",
      "Epoch 148/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8514 - val_loss: 1.8186\n",
      "Epoch 149/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8472 - val_loss: 1.8401\n",
      "Epoch 150/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8402 - val_loss: 2.1336\n",
      "Epoch 151/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8412 - val_loss: 1.9757\n",
      "Epoch 152/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8393 - val_loss: 1.9082\n",
      "Epoch 153/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8444 - val_loss: 1.8110\n",
      "Epoch 154/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8399 - val_loss: 1.9195\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8359 - val_loss: 1.8217\n",
      "Epoch 156/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8268 - val_loss: 1.9100\n",
      "Epoch 157/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8393 - val_loss: 2.0080\n",
      "Epoch 158/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8364 - val_loss: 1.9380\n",
      "Epoch 159/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8383 - val_loss: 1.8264\n",
      "Epoch 160/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8399 - val_loss: 1.8260\n",
      "Epoch 161/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8313 - val_loss: 1.8602\n",
      "Epoch 162/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8351 - val_loss: 1.8263\n",
      "Epoch 163/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8273 - val_loss: 1.8095\n",
      "Epoch 164/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8303 - val_loss: 1.7849\n",
      "Epoch 165/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8239 - val_loss: 1.8492\n",
      "Epoch 166/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8299 - val_loss: 1.8381\n",
      "Epoch 167/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8312 - val_loss: 1.7734\n",
      "Epoch 168/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8216 - val_loss: 1.9121\n",
      "Epoch 169/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8338 - val_loss: 1.8582\n",
      "Epoch 170/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8272 - val_loss: 1.8377\n",
      "Epoch 171/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8260 - val_loss: 1.8146\n",
      "Epoch 172/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8246 - val_loss: 2.0217\n",
      "Epoch 173/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8196 - val_loss: 1.8412\n",
      "Epoch 174/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8188 - val_loss: 1.9624\n",
      "Epoch 175/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8216 - val_loss: 1.8268\n",
      "Epoch 176/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8228 - val_loss: 1.7694\n",
      "Epoch 177/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8249 - val_loss: 1.8592\n",
      "Epoch 178/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8244 - val_loss: 1.7941\n",
      "Epoch 179/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8257 - val_loss: 1.8880\n",
      "Epoch 180/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8188 - val_loss: 1.8193\n",
      "Epoch 181/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8144 - val_loss: 1.9000\n",
      "Epoch 182/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8189 - val_loss: 1.8076\n",
      "Epoch 183/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8063 - val_loss: 1.9031\n",
      "Epoch 184/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8128 - val_loss: 1.8256\n",
      "Epoch 185/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8170 - val_loss: 1.8145\n",
      "Epoch 186/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8121 - val_loss: 1.8089\n",
      "Epoch 187/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8121 - val_loss: 1.7811\n",
      "Epoch 188/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8164 - val_loss: 1.7709\n",
      "Epoch 189/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8159 - val_loss: 1.8035\n",
      "Epoch 190/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8053 - val_loss: 1.9854\n",
      "Epoch 191/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8185 - val_loss: 1.7939\n",
      "Epoch 192/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8103 - val_loss: 1.8296\n",
      "Epoch 193/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8048 - val_loss: 1.8071\n",
      "Epoch 194/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8034 - val_loss: 1.8423\n",
      "Epoch 195/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8042 - val_loss: 1.7747\n",
      "Epoch 196/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8040 - val_loss: 1.8308\n",
      "Epoch 197/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8139 - val_loss: 1.8118\n",
      "Epoch 198/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8054 - val_loss: 1.7986\n",
      "Epoch 199/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8110 - val_loss: 1.8327\n",
      "Epoch 200/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8080 - val_loss: 1.7638\n",
      "Epoch 201/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8096 - val_loss: 1.7743\n",
      "Epoch 202/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7997 - val_loss: 1.9064\n",
      "Epoch 203/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8021 - val_loss: 1.7730\n",
      "Epoch 204/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8024 - val_loss: 1.8747\n",
      "Epoch 205/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7977 - val_loss: 1.7907\n",
      "Epoch 206/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7987 - val_loss: 1.7756\n",
      "Epoch 207/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7989 - val_loss: 1.8574\n",
      "Epoch 208/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7955 - val_loss: 1.7797\n",
      "Epoch 209/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7932 - val_loss: 1.8112\n",
      "Epoch 210/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7958 - val_loss: 1.7834\n",
      "Epoch 211/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8050 - val_loss: 2.0071\n",
      "Epoch 212/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7999 - val_loss: 1.8048\n",
      "Epoch 213/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7914 - val_loss: 1.8740\n",
      "Epoch 214/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7936 - val_loss: 1.8161\n",
      "Epoch 215/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8054 - val_loss: 1.7371\n",
      "Epoch 216/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7970 - val_loss: 1.8443\n",
      "Epoch 217/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7918 - val_loss: 1.8095\n",
      "Epoch 218/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7907 - val_loss: 1.8294\n",
      "Epoch 219/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7951 - val_loss: 1.8408\n",
      "Epoch 220/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7866 - val_loss: 1.7859\n",
      "Epoch 221/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7957 - val_loss: 1.8113\n",
      "Epoch 222/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7948 - val_loss: 1.8331\n",
      "Epoch 223/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7955 - val_loss: 1.9284\n",
      "Epoch 224/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7938 - val_loss: 1.8556\n",
      "Epoch 225/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7866 - val_loss: 1.7758\n",
      "Epoch 226/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7898 - val_loss: 1.8616\n",
      "Epoch 227/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7849 - val_loss: 1.8611\n",
      "Epoch 228/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7903 - val_loss: 1.9142\n",
      "Epoch 229/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7928 - val_loss: 1.7739\n",
      "Epoch 230/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7802 - val_loss: 1.8127\n",
      "Epoch 231/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7817 - val_loss: 1.7277\n",
      "Epoch 232/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7830 - val_loss: 1.7999\n",
      "Epoch 233/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7825 - val_loss: 1.7625\n",
      "Epoch 234/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7783 - val_loss: 1.8763\n",
      "Epoch 235/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7876 - val_loss: 1.7724\n",
      "Epoch 236/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7811 - val_loss: 1.8024\n",
      "Epoch 237/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7797 - val_loss: 1.8224\n",
      "Epoch 238/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7881 - val_loss: 1.8469\n",
      "Epoch 239/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7764 - val_loss: 1.7825\n",
      "Epoch 240/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7789 - val_loss: 1.8647\n",
      "Epoch 241/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7728 - val_loss: 1.8360\n",
      "Epoch 242/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7767 - val_loss: 1.7996\n",
      "Epoch 243/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7747 - val_loss: 1.8042\n",
      "Epoch 244/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7748 - val_loss: 1.7522\n",
      "Epoch 245/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7787 - val_loss: 1.7360\n",
      "Epoch 246/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7738 - val_loss: 1.8442\n",
      "Epoch 247/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7784 - val_loss: 1.8507\n",
      "Epoch 248/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7746 - val_loss: 1.8253\n",
      "Epoch 249/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7753 - val_loss: 1.8109\n",
      "Epoch 250/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7716 - val_loss: 1.7925\n",
      "Epoch 251/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7699 - val_loss: 1.7748\n",
      "Epoch 252/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7643 - val_loss: 1.7810\n",
      "Epoch 253/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7715 - val_loss: 1.8641\n",
      "Epoch 254/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7710 - val_loss: 1.7657\n",
      "Epoch 255/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7770 - val_loss: 1.8872\n",
      "Epoch 256/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7744 - val_loss: 1.7588\n",
      "Epoch 257/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7705 - val_loss: 1.7519\n",
      "Epoch 258/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7655 - val_loss: 1.7218\n",
      "Epoch 259/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7583 - val_loss: 1.8205\n",
      "Epoch 260/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7756 - val_loss: 2.0120\n",
      "Epoch 261/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7657 - val_loss: 1.7759\n",
      "Epoch 262/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7604 - val_loss: 1.7690\n",
      "Epoch 263/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7656 - val_loss: 1.7792\n",
      "Epoch 264/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7618 - val_loss: 1.7661\n",
      "Epoch 265/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7596 - val_loss: 1.7683\n",
      "Epoch 266/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7606 - val_loss: 1.7734\n",
      "Epoch 267/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7613 - val_loss: 1.7683\n",
      "Epoch 268/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7591 - val_loss: 1.8267\n",
      "Epoch 269/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7596 - val_loss: 1.7888\n",
      "Epoch 270/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7585 - val_loss: 1.7900\n",
      "Epoch 271/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7615 - val_loss: 1.8209\n",
      "Epoch 272/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7621 - val_loss: 1.7405\n",
      "Epoch 273/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7588 - val_loss: 1.7352\n",
      "Epoch 274/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7599 - val_loss: 1.7510\n",
      "Epoch 275/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7537 - val_loss: 1.7111\n",
      "Epoch 276/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7550 - val_loss: 1.7399\n",
      "Epoch 277/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7510 - val_loss: 1.7691\n",
      "Epoch 278/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7568 - val_loss: 1.7333\n",
      "Epoch 279/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7563 - val_loss: 1.7245\n",
      "Epoch 280/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7546 - val_loss: 1.8059\n",
      "Epoch 281/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7480 - val_loss: 1.8035\n",
      "Epoch 282/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7499 - val_loss: 1.7802\n",
      "Epoch 283/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7572 - val_loss: 1.8748\n",
      "Epoch 284/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7488 - val_loss: 1.9217\n",
      "Epoch 285/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7491 - val_loss: 1.7798\n",
      "Epoch 286/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7615 - val_loss: 1.7434\n",
      "Epoch 287/500\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.7421 - val_loss: 1.6981\n",
      "Epoch 288/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7525 - val_loss: 1.7477\n",
      "Epoch 289/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7569 - val_loss: 1.7218\n",
      "Epoch 290/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7466 - val_loss: 1.8029\n",
      "Epoch 291/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7439 - val_loss: 1.7758\n",
      "Epoch 292/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7504 - val_loss: 1.7567\n",
      "Epoch 293/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7520 - val_loss: 1.7419\n",
      "Epoch 294/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7513 - val_loss: 1.7866\n",
      "Epoch 295/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7429 - val_loss: 1.8820\n",
      "Epoch 296/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7483 - val_loss: 1.8209\n",
      "Epoch 297/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7421 - val_loss: 1.8392\n",
      "Epoch 298/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7418 - val_loss: 1.7776\n",
      "Epoch 299/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7552 - val_loss: 1.7488\n",
      "Epoch 300/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7453 - val_loss: 1.7415\n",
      "Epoch 301/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7404 - val_loss: 1.7736\n",
      "Epoch 302/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7449 - val_loss: 2.0046\n",
      "Epoch 303/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7476 - val_loss: 1.7639\n",
      "Epoch 304/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7376 - val_loss: 1.8143\n",
      "Epoch 305/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7413 - val_loss: 1.7669\n",
      "Epoch 306/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7413 - val_loss: 1.7755\n",
      "Epoch 307/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7338 - val_loss: 1.7418\n",
      "Epoch 308/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7453 - val_loss: 1.7739\n",
      "Epoch 309/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7437 - val_loss: 1.7851\n",
      "Epoch 310/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7333 - val_loss: 1.7093\n",
      "Epoch 311/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7384 - val_loss: 1.7729\n",
      "Epoch 312/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7463 - val_loss: 1.8676\n",
      "Epoch 313/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7330 - val_loss: 1.8400\n",
      "Epoch 314/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7376 - val_loss: 1.8105\n",
      "Epoch 315/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7402 - val_loss: 1.7412\n",
      "Epoch 316/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7380 - val_loss: 1.7235\n",
      "Epoch 317/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7385 - val_loss: 1.7125\n",
      "Epoch 318/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7376 - val_loss: 1.8150\n",
      "Epoch 319/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7335 - val_loss: 1.7188\n",
      "Epoch 320/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7429 - val_loss: 1.7332\n",
      "Epoch 321/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7304 - val_loss: 1.7135\n",
      "Epoch 322/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7423 - val_loss: 1.7650\n",
      "Epoch 323/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7400 - val_loss: 1.7311\n",
      "Epoch 324/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7338 - val_loss: 1.7501\n",
      "Epoch 325/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7420 - val_loss: 1.8065\n",
      "Epoch 326/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7346 - val_loss: 1.8497\n",
      "Epoch 327/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7346 - val_loss: 1.7409\n",
      "Epoch 328/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7335 - val_loss: 1.7676\n",
      "Epoch 329/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7343 - val_loss: 1.7136\n",
      "Epoch 330/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7303 - val_loss: 1.7610\n",
      "Epoch 331/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7409 - val_loss: 1.8044\n",
      "Epoch 332/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7389 - val_loss: 1.9053\n",
      "Epoch 333/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7321 - val_loss: 1.8209\n",
      "Epoch 334/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7324 - val_loss: 1.7452\n",
      "Epoch 335/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7266 - val_loss: 1.8580\n",
      "Epoch 336/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7348 - val_loss: 1.7427\n",
      "Epoch 337/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7317 - val_loss: 1.7668\n",
      "Epoch 338/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7407 - val_loss: 1.7058\n",
      "Epoch 339/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7298 - val_loss: 1.7816\n",
      "Epoch 340/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7262 - val_loss: 1.7542\n",
      "Epoch 341/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7290 - val_loss: 1.7874\n",
      "Epoch 342/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7304 - val_loss: 1.8353\n",
      "Epoch 343/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7318 - val_loss: 1.7390\n",
      "Epoch 344/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7253 - val_loss: 1.7260\n",
      "Epoch 345/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7261 - val_loss: 1.7170\n",
      "Epoch 346/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7334 - val_loss: 1.8533\n",
      "Epoch 347/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7243 - val_loss: 1.7717\n",
      "Epoch 348/500\n",
      "1728/1728 [==============================] - 9s 5ms/step - loss: 1.7297 - val_loss: 1.7227\n",
      "Epoch 349/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7283 - val_loss: 1.7093\n",
      "Epoch 350/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7227 - val_loss: 1.8016\n",
      "Epoch 351/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7302 - val_loss: 1.7535\n",
      "Epoch 352/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7209 - val_loss: 1.8831\n",
      "Epoch 353/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7322 - val_loss: 1.7443\n",
      "Epoch 354/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7231 - val_loss: 1.8058\n",
      "Epoch 355/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7260 - val_loss: 1.7432\n",
      "Epoch 356/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7209 - val_loss: 1.7141\n",
      "Epoch 357/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7278 - val_loss: 1.7810\n",
      "Epoch 358/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7191 - val_loss: 1.7728\n",
      "Epoch 359/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7330 - val_loss: 1.7529\n",
      "Epoch 360/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7210 - val_loss: 1.7545\n",
      "Epoch 361/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7199 - val_loss: 1.7513\n",
      "Epoch 362/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7207 - val_loss: 1.8145\n",
      "Epoch 363/500\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.7234 - val_loss: 1.7275\n",
      "Epoch 364/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7215 - val_loss: 1.7560\n",
      "Epoch 365/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7311 - val_loss: 1.7895\n",
      "Epoch 366/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7245 - val_loss: 1.7692\n",
      "Epoch 367/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7209 - val_loss: 1.7820\n",
      "Epoch 368/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7183 - val_loss: 1.7383\n",
      "Epoch 369/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7283 - val_loss: 1.6983\n",
      "Epoch 370/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7185 - val_loss: 1.7156\n",
      "Epoch 371/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7200 - val_loss: 1.7928\n",
      "Epoch 372/500\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.7219 - val_loss: 1.7899\n",
      "Epoch 373/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7197 - val_loss: 1.7223\n",
      "Epoch 374/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7215 - val_loss: 1.7663\n",
      "Epoch 375/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7246 - val_loss: 1.7684\n",
      "Epoch 376/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7127 - val_loss: 1.7079\n",
      "Epoch 377/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7194 - val_loss: 1.7469\n",
      "Epoch 378/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7224 - val_loss: 1.7243\n",
      "Epoch 379/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7204 - val_loss: 1.7707\n",
      "Epoch 380/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7182 - val_loss: 1.7462\n",
      "Epoch 381/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7218 - val_loss: 1.7609\n",
      "Epoch 382/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7152 - val_loss: 1.7356\n",
      "Epoch 383/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7174 - val_loss: 1.7155\n",
      "Epoch 384/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7178 - val_loss: 1.9141\n",
      "Epoch 385/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7192 - val_loss: 1.7496\n",
      "Epoch 386/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7190 - val_loss: 1.7051\n",
      "Epoch 387/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7142 - val_loss: 1.7456\n",
      "Epoch 388/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7158 - val_loss: 1.7914\n",
      "Epoch 389/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7161 - val_loss: 1.7368\n",
      "Epoch 390/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7107 - val_loss: 1.6806\n",
      "Epoch 391/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7091 - val_loss: 1.7635\n",
      "Epoch 392/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7154 - val_loss: 1.7762\n",
      "Epoch 393/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7179 - val_loss: 1.7550\n",
      "Epoch 394/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7101 - val_loss: 1.7129\n",
      "Epoch 395/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7067 - val_loss: 1.8265\n",
      "Epoch 396/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7166 - val_loss: 1.6897\n",
      "Epoch 397/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7034 - val_loss: 1.7099\n",
      "Epoch 398/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7037 - val_loss: 1.7390\n",
      "Epoch 399/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7083 - val_loss: 1.7001\n",
      "Epoch 400/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7139 - val_loss: 1.7441\n",
      "Epoch 401/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7121 - val_loss: 1.7817\n",
      "Epoch 402/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7103 - val_loss: 1.7330\n",
      "Epoch 403/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7043 - val_loss: 1.6895\n",
      "Epoch 404/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7066 - val_loss: 1.7382\n",
      "Epoch 405/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7075 - val_loss: 1.7593\n",
      "Epoch 406/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7035 - val_loss: 1.6867\n",
      "Epoch 407/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7059 - val_loss: 1.7216\n",
      "Epoch 408/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7054 - val_loss: 1.8097\n",
      "Epoch 409/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7090 - val_loss: 1.7722\n",
      "Epoch 410/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7095 - val_loss: 1.9234\n",
      "Epoch 411/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7037 - val_loss: 1.6969\n",
      "Epoch 412/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7028 - val_loss: 1.7016\n",
      "Epoch 413/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7033 - val_loss: 1.7423\n",
      "Epoch 414/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7148 - val_loss: 1.7067\n",
      "Epoch 415/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6993 - val_loss: 1.6996\n",
      "Epoch 416/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7030 - val_loss: 1.7478\n",
      "Epoch 417/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7089 - val_loss: 1.6675\n",
      "Epoch 418/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7018 - val_loss: 1.7132\n",
      "Epoch 419/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6972 - val_loss: 1.7131\n",
      "Epoch 420/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7004 - val_loss: 1.7230\n",
      "Epoch 421/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7082 - val_loss: 1.7640\n",
      "Epoch 422/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7116 - val_loss: 1.7307\n",
      "Epoch 423/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6987 - val_loss: 1.7144\n",
      "Epoch 424/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7031 - val_loss: 1.6838\n",
      "Epoch 425/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7029 - val_loss: 1.6884\n",
      "Epoch 426/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7016 - val_loss: 1.6732\n",
      "Epoch 427/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7068 - val_loss: 1.7805\n",
      "Epoch 428/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7094 - val_loss: 1.7029\n",
      "Epoch 429/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7060 - val_loss: 1.7317\n",
      "Epoch 430/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7033 - val_loss: 1.6936\n",
      "Epoch 431/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6991 - val_loss: 1.7539\n",
      "Epoch 432/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7039 - val_loss: 1.7204\n",
      "Epoch 433/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7071 - val_loss: 1.7679\n",
      "Epoch 434/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6959 - val_loss: 1.6851\n",
      "Epoch 435/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7000 - val_loss: 1.7092\n",
      "Epoch 436/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7006 - val_loss: 1.7722\n",
      "Epoch 437/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7026 - val_loss: 1.7437\n",
      "Epoch 438/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6969 - val_loss: 1.8388\n",
      "Epoch 439/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6956 - val_loss: 1.6900\n",
      "Epoch 440/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7085 - val_loss: 1.8046\n",
      "Epoch 441/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6928 - val_loss: 1.6986\n",
      "Epoch 442/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6913 - val_loss: 1.6862\n",
      "Epoch 443/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7019 - val_loss: 1.7599\n",
      "Epoch 444/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6984 - val_loss: 1.7277\n",
      "Epoch 445/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7019 - val_loss: 1.8056\n",
      "Epoch 446/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6947 - val_loss: 1.7581\n",
      "Epoch 447/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6895 - val_loss: 1.7567\n",
      "Epoch 448/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6961 - val_loss: 1.7016\n",
      "Epoch 449/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7056 - val_loss: 1.8050\n",
      "Epoch 450/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6988 - val_loss: 1.7616\n",
      "Epoch 451/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6922 - val_loss: 1.8374\n",
      "Epoch 452/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6933 - val_loss: 1.7025\n",
      "Epoch 453/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6942 - val_loss: 1.7201\n",
      "Epoch 454/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6948 - val_loss: 1.6949\n",
      "Epoch 455/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6892 - val_loss: 1.7580\n",
      "Epoch 456/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6985 - val_loss: 1.7390\n",
      "Epoch 457/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6911 - val_loss: 1.7115\n",
      "Epoch 458/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6986 - val_loss: 1.7266\n",
      "Epoch 459/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6970 - val_loss: 1.8641\n",
      "Epoch 460/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6867 - val_loss: 1.7926\n",
      "Epoch 461/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6964 - val_loss: 1.8494\n",
      "Epoch 462/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6915 - val_loss: 1.6992\n",
      "Epoch 463/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6872 - val_loss: 1.7275\n",
      "Epoch 464/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6924 - val_loss: 1.7441\n",
      "Epoch 465/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6937 - val_loss: 1.6865\n",
      "Epoch 466/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6902 - val_loss: 1.6663\n",
      "Epoch 467/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6902 - val_loss: 1.6916\n",
      "Epoch 468/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6888 - val_loss: 1.6929\n",
      "Epoch 469/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7003 - val_loss: 1.6926\n",
      "Epoch 470/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6911 - val_loss: 1.7125\n",
      "Epoch 471/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6897 - val_loss: 1.7168\n",
      "Epoch 472/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6958 - val_loss: 1.6887\n",
      "Epoch 473/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6874 - val_loss: 1.7351\n",
      "Epoch 474/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6908 - val_loss: 1.7123\n",
      "Epoch 475/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6896 - val_loss: 1.6933\n",
      "Epoch 476/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6941 - val_loss: 1.7183\n",
      "Epoch 477/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6852 - val_loss: 1.6556\n",
      "Epoch 478/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6886 - val_loss: 1.6928\n",
      "Epoch 479/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6873 - val_loss: 1.7934\n",
      "Epoch 480/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6863 - val_loss: 1.7766\n",
      "Epoch 481/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6901 - val_loss: 1.6730\n",
      "Epoch 482/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6778 - val_loss: 1.7405\n",
      "Epoch 483/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6820 - val_loss: 1.7232\n",
      "Epoch 484/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6875 - val_loss: 1.6715\n",
      "Epoch 485/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6905 - val_loss: 1.7847\n",
      "Epoch 486/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6859 - val_loss: 1.6581\n",
      "Epoch 487/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6810 - val_loss: 1.6964\n",
      "Epoch 488/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6855 - val_loss: 1.7602\n",
      "Epoch 489/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6820 - val_loss: 1.6881\n",
      "Epoch 490/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6843 - val_loss: 1.7668\n",
      "Epoch 491/500\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6818 - val_loss: 1.6692\n",
      "Epoch 492/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6836 - val_loss: 1.8428\n",
      "Epoch 493/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6852 - val_loss: 1.7765\n",
      "Epoch 494/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6815 - val_loss: 1.7569\n",
      "Epoch 495/500\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6868 - val_loss: 1.7960\n",
      "Epoch 496/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6786 - val_loss: 1.7409\n",
      "Epoch 497/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6809 - val_loss: 1.7120\n",
      "Epoch 498/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6734 - val_loss: 1.6869\n",
      "Epoch 499/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6863 - val_loss: 1.7115\n",
      "Epoch 500/500\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6795 - val_loss: 1.7307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7306646953638947\n",
      "0.9501702448933367\n",
      "Epoch 1/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 8.5203 - val_loss: 4.0567\n",
      "Epoch 2/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 4.9045 - val_loss: 5.8170\n",
      "Epoch 3/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 4.4450 - val_loss: 5.3851\n",
      "Epoch 4/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 4.2699 - val_loss: 3.6851\n",
      "Epoch 5/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 3.7767 - val_loss: 3.4129\n",
      "Epoch 6/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 3.3512 - val_loss: 3.3417\n",
      "Epoch 7/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 3.2509 - val_loss: 2.9496\n",
      "Epoch 8/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 3.0973 - val_loss: 2.9704\n",
      "Epoch 9/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 3.0195 - val_loss: 2.8579\n",
      "Epoch 10/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.8972 - val_loss: 2.6415\n",
      "Epoch 11/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.7888 - val_loss: 2.7706\n",
      "Epoch 12/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.7144 - val_loss: 2.5430\n",
      "Epoch 13/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.6012 - val_loss: 2.6959\n",
      "Epoch 14/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.5537 - val_loss: 2.4560\n",
      "Epoch 15/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.5125 - val_loss: 2.4585\n",
      "Epoch 16/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.4473 - val_loss: 2.4046\n",
      "Epoch 17/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.4344 - val_loss: 2.4662\n",
      "Epoch 18/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.4384 - val_loss: 2.4461\n",
      "Epoch 19/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.3956 - val_loss: 2.3355\n",
      "Epoch 20/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.3660 - val_loss: 2.3947\n",
      "Epoch 21/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.3592 - val_loss: 2.4220\n",
      "Epoch 22/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.3109 - val_loss: 2.1965\n",
      "Epoch 23/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.3145 - val_loss: 2.4428\n",
      "Epoch 24/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.2457 - val_loss: 2.1715\n",
      "Epoch 25/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.2385 - val_loss: 2.3131\n",
      "Epoch 26/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.2261 - val_loss: 2.6571\n",
      "Epoch 27/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1833 - val_loss: 2.1312\n",
      "Epoch 28/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1694 - val_loss: 2.1520\n",
      "Epoch 29/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1814 - val_loss: 2.1474\n",
      "Epoch 30/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1293 - val_loss: 2.1393\n",
      "Epoch 31/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1413 - val_loss: 2.0507\n",
      "Epoch 32/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 2.1287 - val_loss: 2.6583\n",
      "Epoch 33/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1112 - val_loss: 2.1819\n",
      "Epoch 34/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0928 - val_loss: 2.1121\n",
      "Epoch 35/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0649 - val_loss: 2.0808\n",
      "Epoch 36/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0660 - val_loss: 2.0915\n",
      "Epoch 37/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0553 - val_loss: 2.0020\n",
      "Epoch 38/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0582 - val_loss: 2.0906\n",
      "Epoch 39/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0399 - val_loss: 1.9282\n",
      "Epoch 40/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0371 - val_loss: 2.1253\n",
      "Epoch 41/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0398 - val_loss: 2.1077\n",
      "Epoch 42/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0158 - val_loss: 1.9728\n",
      "Epoch 43/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0048 - val_loss: 2.2049\n",
      "Epoch 44/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9977 - val_loss: 2.0639\n",
      "Epoch 45/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.0279 - val_loss: 1.9508\n",
      "Epoch 46/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0048 - val_loss: 2.1125\n",
      "Epoch 47/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9868 - val_loss: 1.9448\n",
      "Epoch 48/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9748 - val_loss: 1.9295\n",
      "Epoch 49/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9746 - val_loss: 2.0762\n",
      "Epoch 50/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9741 - val_loss: 2.0369\n",
      "Epoch 51/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9655 - val_loss: 2.0164\n",
      "Epoch 52/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9565 - val_loss: 2.0054\n",
      "Epoch 53/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9565 - val_loss: 1.9728\n",
      "Epoch 54/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9586 - val_loss: 2.0005\n",
      "Epoch 55/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9560 - val_loss: 1.9337\n",
      "Epoch 56/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9538 - val_loss: 1.9291\n",
      "Epoch 57/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9459 - val_loss: 1.8684\n",
      "Epoch 58/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.9403 - val_loss: 1.8983\n",
      "Epoch 59/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9292 - val_loss: 1.8663\n",
      "Epoch 60/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9245 - val_loss: 1.9440\n",
      "Epoch 61/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9282 - val_loss: 1.8960\n",
      "Epoch 62/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9069 - val_loss: 1.8755\n",
      "Epoch 63/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9174 - val_loss: 1.8971\n",
      "Epoch 64/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8923 - val_loss: 1.9051\n",
      "Epoch 65/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8950 - val_loss: 1.8950\n",
      "Epoch 66/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8941 - val_loss: 1.8473\n",
      "Epoch 67/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8817 - val_loss: 1.9032\n",
      "Epoch 68/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8715 - val_loss: 1.8675\n",
      "Epoch 69/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8851 - val_loss: 1.8157\n",
      "Epoch 70/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8732 - val_loss: 1.8301\n",
      "Epoch 71/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8629 - val_loss: 1.9457\n",
      "Epoch 72/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8655 - val_loss: 2.1184\n",
      "Epoch 73/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8660 - val_loss: 1.9271\n",
      "Epoch 74/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8563 - val_loss: 1.8808\n",
      "Epoch 75/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8576 - val_loss: 1.8842\n",
      "Epoch 76/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8513 - val_loss: 1.9145\n",
      "Epoch 77/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8540 - val_loss: 1.8395\n",
      "Epoch 78/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8272 - val_loss: 1.8783\n",
      "Epoch 79/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8340 - val_loss: 1.7958\n",
      "Epoch 80/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8322 - val_loss: 1.8329\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8472 - val_loss: 1.8502\n",
      "Epoch 82/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8280 - val_loss: 1.9792\n",
      "Epoch 83/500\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.8273 - val_loss: 1.8630\n",
      "Epoch 84/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8089 - val_loss: 1.8307\n",
      "Epoch 85/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8348 - val_loss: 2.1703\n",
      "Epoch 86/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8114 - val_loss: 1.8024\n",
      "Epoch 87/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8048 - val_loss: 1.8320\n",
      "Epoch 88/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8090 - val_loss: 1.7616\n",
      "Epoch 89/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7981 - val_loss: 1.8257\n",
      "Epoch 90/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7921 - val_loss: 1.8331\n",
      "Epoch 91/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7906 - val_loss: 1.8720\n",
      "Epoch 92/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7913 - val_loss: 1.7383\n",
      "Epoch 93/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7827 - val_loss: 1.7726\n",
      "Epoch 94/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7917 - val_loss: 1.8009\n",
      "Epoch 95/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7867 - val_loss: 1.7700\n",
      "Epoch 96/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7838 - val_loss: 1.8059\n",
      "Epoch 97/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7667 - val_loss: 1.7500\n",
      "Epoch 98/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7765 - val_loss: 1.7377\n",
      "Epoch 99/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7657 - val_loss: 2.0394\n",
      "Epoch 100/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7721 - val_loss: 1.7606\n",
      "Epoch 101/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7705 - val_loss: 1.7745\n",
      "Epoch 102/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7682 - val_loss: 1.7584\n",
      "Epoch 103/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7718 - val_loss: 1.7724\n",
      "Epoch 104/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7610 - val_loss: 1.8838\n",
      "Epoch 105/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7672 - val_loss: 1.7975\n",
      "Epoch 106/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7652 - val_loss: 1.7527\n",
      "Epoch 107/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7507 - val_loss: 1.7564\n",
      "Epoch 108/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7557 - val_loss: 1.7017\n",
      "Epoch 109/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7455 - val_loss: 1.8458\n",
      "Epoch 110/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7406 - val_loss: 1.7566\n",
      "Epoch 111/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7457 - val_loss: 1.7293\n",
      "Epoch 112/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7402 - val_loss: 1.6915\n",
      "Epoch 113/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7429 - val_loss: 1.8478\n",
      "Epoch 114/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7567 - val_loss: 1.6887\n",
      "Epoch 115/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7349 - val_loss: 1.7268\n",
      "Epoch 116/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7359 - val_loss: 1.6936\n",
      "Epoch 117/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7205 - val_loss: 1.7633\n",
      "Epoch 118/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7266 - val_loss: 1.7216\n",
      "Epoch 119/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7374 - val_loss: 1.7210\n",
      "Epoch 120/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7275 - val_loss: 1.8230\n",
      "Epoch 121/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7259 - val_loss: 1.8283\n",
      "Epoch 122/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7226 - val_loss: 1.7924\n",
      "Epoch 123/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7437 - val_loss: 1.7494\n",
      "Epoch 124/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7218 - val_loss: 1.7078\n",
      "Epoch 125/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7152 - val_loss: 1.7690\n",
      "Epoch 126/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7189 - val_loss: 1.7483\n",
      "Epoch 127/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7030 - val_loss: 1.6951\n",
      "Epoch 128/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7134 - val_loss: 1.6820\n",
      "Epoch 129/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7161 - val_loss: 1.6971\n",
      "Epoch 130/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7048 - val_loss: 1.7522\n",
      "Epoch 131/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7119 - val_loss: 1.8066\n",
      "Epoch 132/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7096 - val_loss: 1.6708\n",
      "Epoch 133/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7063 - val_loss: 1.9878\n",
      "Epoch 134/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6980 - val_loss: 1.7048\n",
      "Epoch 135/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7045 - val_loss: 1.7196\n",
      "Epoch 136/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6971 - val_loss: 1.7577\n",
      "Epoch 137/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7004 - val_loss: 1.6552\n",
      "Epoch 138/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6928 - val_loss: 1.7276\n",
      "Epoch 139/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6995 - val_loss: 1.7057\n",
      "Epoch 140/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6986 - val_loss: 1.6612\n",
      "Epoch 141/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6851 - val_loss: 1.6296\n",
      "Epoch 142/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6785 - val_loss: 1.7127\n",
      "Epoch 143/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6832 - val_loss: 1.6602\n",
      "Epoch 144/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6871 - val_loss: 1.6635\n",
      "Epoch 145/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6732 - val_loss: 1.6905\n",
      "Epoch 146/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6741 - val_loss: 1.7015\n",
      "Epoch 147/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6819 - val_loss: 1.7077\n",
      "Epoch 148/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6753 - val_loss: 1.7729\n",
      "Epoch 149/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6603 - val_loss: 1.6732\n",
      "Epoch 150/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6712 - val_loss: 1.6972\n",
      "Epoch 151/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6604 - val_loss: 1.7316\n",
      "Epoch 152/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6779 - val_loss: 1.6841\n",
      "Epoch 153/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6725 - val_loss: 1.6654\n",
      "Epoch 154/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6648 - val_loss: 1.6469\n",
      "Epoch 155/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6580 - val_loss: 1.6533\n",
      "Epoch 156/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6680 - val_loss: 1.6534\n",
      "Epoch 157/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6573 - val_loss: 1.6295\n",
      "Epoch 158/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6707 - val_loss: 1.8830\n",
      "Epoch 159/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6627 - val_loss: 1.7750\n",
      "Epoch 160/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6703 - val_loss: 1.7871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6511 - val_loss: 1.6596\n",
      "Epoch 162/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6611 - val_loss: 1.6178\n",
      "Epoch 163/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6510 - val_loss: 1.7869\n",
      "Epoch 164/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6581 - val_loss: 1.6765\n",
      "Epoch 165/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6543 - val_loss: 1.6622\n",
      "Epoch 166/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6539 - val_loss: 1.6852\n",
      "Epoch 167/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6471 - val_loss: 1.7081\n",
      "Epoch 168/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6478 - val_loss: 1.6743\n",
      "Epoch 169/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6389 - val_loss: 1.6120\n",
      "Epoch 170/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6513 - val_loss: 1.6950\n",
      "Epoch 171/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6498 - val_loss: 1.6747\n",
      "Epoch 172/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6389 - val_loss: 1.6419\n",
      "Epoch 173/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6437 - val_loss: 1.6132\n",
      "Epoch 174/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6364 - val_loss: 1.6951\n",
      "Epoch 175/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6395 - val_loss: 1.7243\n",
      "Epoch 176/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6468 - val_loss: 1.6295\n",
      "Epoch 177/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6349 - val_loss: 1.6372\n",
      "Epoch 178/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6383 - val_loss: 1.6851\n",
      "Epoch 179/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6395 - val_loss: 1.7373\n",
      "Epoch 180/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6263 - val_loss: 1.6592\n",
      "Epoch 181/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6421 - val_loss: 1.7025\n",
      "Epoch 182/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6298 - val_loss: 1.8077\n",
      "Epoch 183/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6298 - val_loss: 1.6680\n",
      "Epoch 184/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6314 - val_loss: 1.7477\n",
      "Epoch 185/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6445 - val_loss: 1.7132\n",
      "Epoch 186/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6225 - val_loss: 1.5922\n",
      "Epoch 187/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6200 - val_loss: 1.7018\n",
      "Epoch 188/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6323 - val_loss: 1.7854\n",
      "Epoch 189/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6228 - val_loss: 1.6078\n",
      "Epoch 190/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6232 - val_loss: 1.6560\n",
      "Epoch 191/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6216 - val_loss: 1.6841\n",
      "Epoch 192/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6345 - val_loss: 1.6731\n",
      "Epoch 193/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6173 - val_loss: 1.6206\n",
      "Epoch 194/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6153 - val_loss: 1.7114\n",
      "Epoch 195/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6220 - val_loss: 1.6118\n",
      "Epoch 196/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6235 - val_loss: 1.5866\n",
      "Epoch 197/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6132 - val_loss: 1.6314\n",
      "Epoch 198/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6114 - val_loss: 1.5865\n",
      "Epoch 199/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6172 - val_loss: 1.6107\n",
      "Epoch 200/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6128 - val_loss: 1.6208\n",
      "Epoch 201/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6053 - val_loss: 1.6333\n",
      "Epoch 202/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6148 - val_loss: 1.5667\n",
      "Epoch 203/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6143 - val_loss: 1.6640\n",
      "Epoch 204/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6009 - val_loss: 1.6387\n",
      "Epoch 205/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6140 - val_loss: 1.5787\n",
      "Epoch 206/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6100 - val_loss: 1.5892\n",
      "Epoch 207/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6086 - val_loss: 1.6052\n",
      "Epoch 208/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6129 - val_loss: 1.6456\n",
      "Epoch 209/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6118 - val_loss: 1.5853\n",
      "Epoch 210/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6091 - val_loss: 1.6698\n",
      "Epoch 211/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5989 - val_loss: 1.6345\n",
      "Epoch 212/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6114 - val_loss: 1.6697\n",
      "Epoch 213/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6048 - val_loss: 1.6996\n",
      "Epoch 214/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6082 - val_loss: 1.8220\n",
      "Epoch 215/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6060 - val_loss: 1.5762\n",
      "Epoch 216/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5928 - val_loss: 1.6508\n",
      "Epoch 217/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5998 - val_loss: 1.5979\n",
      "Epoch 218/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6005 - val_loss: 1.6445\n",
      "Epoch 219/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5971 - val_loss: 1.5654\n",
      "Epoch 220/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6056 - val_loss: 1.6523\n",
      "Epoch 221/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5986 - val_loss: 1.6527\n",
      "Epoch 222/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5922 - val_loss: 1.6174\n",
      "Epoch 223/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5958 - val_loss: 1.6017\n",
      "Epoch 224/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5888 - val_loss: 1.7200\n",
      "Epoch 225/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5948 - val_loss: 1.6221\n",
      "Epoch 226/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5982 - val_loss: 1.7002\n",
      "Epoch 227/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5872 - val_loss: 1.5917\n",
      "Epoch 228/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5878 - val_loss: 1.6226\n",
      "Epoch 229/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5988 - val_loss: 1.5721\n",
      "Epoch 230/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5987 - val_loss: 1.5843\n",
      "Epoch 231/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5869 - val_loss: 1.6031\n",
      "Epoch 232/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5904 - val_loss: 1.5909\n",
      "Epoch 233/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5925 - val_loss: 1.6544\n",
      "Epoch 234/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5869 - val_loss: 1.6294\n",
      "Epoch 235/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5873 - val_loss: 1.6387\n",
      "Epoch 236/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5795 - val_loss: 1.7090\n",
      "Epoch 237/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5897 - val_loss: 1.5788\n",
      "Epoch 238/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5860 - val_loss: 1.5801\n",
      "Epoch 239/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5775 - val_loss: 1.6589\n",
      "Epoch 240/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5842 - val_loss: 1.7175\n",
      "Epoch 241/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5838 - val_loss: 1.5871\n",
      "Epoch 242/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5754 - val_loss: 1.5582\n",
      "Epoch 243/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5785 - val_loss: 1.6248\n",
      "Epoch 244/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5848 - val_loss: 1.5891\n",
      "Epoch 245/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5785 - val_loss: 1.6047\n",
      "Epoch 246/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5734 - val_loss: 1.6000\n",
      "Epoch 247/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5763 - val_loss: 1.6217\n",
      "Epoch 248/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5699 - val_loss: 1.6182\n",
      "Epoch 249/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5814 - val_loss: 1.5628\n",
      "Epoch 250/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5700 - val_loss: 1.6741\n",
      "Epoch 251/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5682 - val_loss: 1.6243\n",
      "Epoch 252/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5748 - val_loss: 1.6320\n",
      "Epoch 253/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5781 - val_loss: 1.6121\n",
      "Epoch 254/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5800 - val_loss: 1.6253\n",
      "Epoch 255/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5674 - val_loss: 1.6472\n",
      "Epoch 256/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5654 - val_loss: 1.6839\n",
      "Epoch 257/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5670 - val_loss: 1.5774\n",
      "Epoch 258/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5536 - val_loss: 1.7245\n",
      "Epoch 259/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5653 - val_loss: 1.5865\n",
      "Epoch 260/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5650 - val_loss: 1.6477\n",
      "Epoch 261/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5656 - val_loss: 1.5182\n",
      "Epoch 262/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5648 - val_loss: 1.5757\n",
      "Epoch 263/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5609 - val_loss: 1.5671\n",
      "Epoch 264/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5636 - val_loss: 1.5506\n",
      "Epoch 265/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5584 - val_loss: 1.6053\n",
      "Epoch 266/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5590 - val_loss: 1.6430\n",
      "Epoch 267/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5555 - val_loss: 1.5261\n",
      "Epoch 268/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5570 - val_loss: 1.5807\n",
      "Epoch 269/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5537 - val_loss: 1.5811\n",
      "Epoch 270/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5637 - val_loss: 1.6584\n",
      "Epoch 271/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5668 - val_loss: 1.5453\n",
      "Epoch 272/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5647 - val_loss: 1.6010\n",
      "Epoch 273/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5505 - val_loss: 1.6244\n",
      "Epoch 274/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5598 - val_loss: 1.5776\n",
      "Epoch 275/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5609 - val_loss: 1.5361\n",
      "Epoch 276/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5527 - val_loss: 1.5905\n",
      "Epoch 277/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5457 - val_loss: 1.6022\n",
      "Epoch 278/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5583 - val_loss: 1.5807\n",
      "Epoch 279/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5513 - val_loss: 1.5760\n",
      "Epoch 280/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5494 - val_loss: 1.5771\n",
      "Epoch 281/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5560 - val_loss: 1.5856\n",
      "Epoch 282/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5568 - val_loss: 1.5980\n",
      "Epoch 283/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5565 - val_loss: 1.6143\n",
      "Epoch 284/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5429 - val_loss: 1.6078\n",
      "Epoch 285/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5466 - val_loss: 1.5453\n",
      "Epoch 286/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5385 - val_loss: 1.6487\n",
      "Epoch 287/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5507 - val_loss: 1.5859\n",
      "Epoch 288/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5396 - val_loss: 1.6016\n",
      "Epoch 289/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5374 - val_loss: 1.5973\n",
      "Epoch 290/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5391 - val_loss: 1.5391\n",
      "Epoch 291/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5472 - val_loss: 1.6140\n",
      "Epoch 292/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5444 - val_loss: 1.6657\n",
      "Epoch 293/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5550 - val_loss: 1.5945\n",
      "Epoch 294/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5370 - val_loss: 1.5535\n",
      "Epoch 295/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5422 - val_loss: 1.5445\n",
      "Epoch 296/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5405 - val_loss: 1.5561\n",
      "Epoch 297/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5430 - val_loss: 1.6263\n",
      "Epoch 298/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5433 - val_loss: 1.5676\n",
      "Epoch 299/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5395 - val_loss: 1.6789\n",
      "Epoch 300/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5476 - val_loss: 1.6055\n",
      "Epoch 301/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5307 - val_loss: 1.5692\n",
      "Epoch 302/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5358 - val_loss: 1.5486\n",
      "Epoch 303/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5367 - val_loss: 1.5063\n",
      "Epoch 304/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5292 - val_loss: 1.5620\n",
      "Epoch 305/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5333 - val_loss: 1.5218\n",
      "Epoch 306/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5358 - val_loss: 1.5698\n",
      "Epoch 307/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5314 - val_loss: 1.5577\n",
      "Epoch 308/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5277 - val_loss: 1.5649\n",
      "Epoch 309/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5299 - val_loss: 1.5578\n",
      "Epoch 310/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5224 - val_loss: 1.5590\n",
      "Epoch 311/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5357 - val_loss: 1.5454\n",
      "Epoch 312/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5295 - val_loss: 1.6313\n",
      "Epoch 313/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5205 - val_loss: 1.5198\n",
      "Epoch 314/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5310 - val_loss: 1.6203\n",
      "Epoch 315/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5216 - val_loss: 1.5630\n",
      "Epoch 316/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5305 - val_loss: 1.5166\n",
      "Epoch 317/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5203 - val_loss: 1.5094\n",
      "Epoch 318/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5139 - val_loss: 1.5461\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5227 - val_loss: 1.5645\n",
      "Epoch 320/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5225 - val_loss: 1.5556\n",
      "Epoch 321/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5232 - val_loss: 1.5551\n",
      "Epoch 322/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5200 - val_loss: 1.6030\n",
      "Epoch 323/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5197 - val_loss: 1.5727\n",
      "Epoch 324/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5238 - val_loss: 1.5540\n",
      "Epoch 325/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5274 - val_loss: 1.5547\n",
      "Epoch 326/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5120 - val_loss: 1.5082\n",
      "Epoch 327/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5094 - val_loss: 1.5460\n",
      "Epoch 328/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5142 - val_loss: 1.5805\n",
      "Epoch 329/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5238 - val_loss: 1.5949\n",
      "Epoch 330/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5144 - val_loss: 1.5204\n",
      "Epoch 331/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5097 - val_loss: 1.5467\n",
      "Epoch 332/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5142 - val_loss: 1.5102\n",
      "Epoch 333/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5152 - val_loss: 1.5915\n",
      "Epoch 334/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5178 - val_loss: 1.5429\n",
      "Epoch 335/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5229 - val_loss: 1.5631\n",
      "Epoch 336/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5130 - val_loss: 1.5004\n",
      "Epoch 337/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5108 - val_loss: 1.6135\n",
      "Epoch 338/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5147 - val_loss: 1.5342\n",
      "Epoch 339/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5156 - val_loss: 1.4908\n",
      "Epoch 340/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5095 - val_loss: 1.5985\n",
      "Epoch 341/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5010 - val_loss: 1.4980\n",
      "Epoch 342/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5073 - val_loss: 1.5542\n",
      "Epoch 343/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5073 - val_loss: 1.5946\n",
      "Epoch 344/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5098 - val_loss: 1.5300\n",
      "Epoch 345/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5027 - val_loss: 1.4671\n",
      "Epoch 346/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5086 - val_loss: 1.5600\n",
      "Epoch 347/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4965 - val_loss: 1.5240\n",
      "Epoch 348/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5205 - val_loss: 1.5768\n",
      "Epoch 349/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5117 - val_loss: 1.5310\n",
      "Epoch 350/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5081 - val_loss: 1.5754\n",
      "Epoch 351/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4986 - val_loss: 1.6271\n",
      "Epoch 352/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5170 - val_loss: 1.5278\n",
      "Epoch 353/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5070 - val_loss: 1.4829\n",
      "Epoch 354/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4976 - val_loss: 1.5275\n",
      "Epoch 355/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5137 - val_loss: 1.4934\n",
      "Epoch 356/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4938 - val_loss: 1.5631\n",
      "Epoch 357/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4984 - val_loss: 1.5197\n",
      "Epoch 358/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5093 - val_loss: 1.4836\n",
      "Epoch 359/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4942 - val_loss: 1.4790\n",
      "Epoch 360/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4968 - val_loss: 1.5388\n",
      "Epoch 361/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5066 - val_loss: 1.5412\n",
      "Epoch 362/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4949 - val_loss: 1.4880\n",
      "Epoch 363/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5069 - val_loss: 1.4957\n",
      "Epoch 364/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5018 - val_loss: 1.5662\n",
      "Epoch 365/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4938 - val_loss: 1.6284\n",
      "Epoch 366/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5035 - val_loss: 1.5061\n",
      "Epoch 367/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4966 - val_loss: 1.5088\n",
      "Epoch 368/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4988 - val_loss: 1.5099\n",
      "Epoch 369/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4955 - val_loss: 1.4804\n",
      "Epoch 370/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5069 - val_loss: 1.5084\n",
      "Epoch 371/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4902 - val_loss: 1.5076\n",
      "Epoch 372/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5018 - val_loss: 1.6484\n",
      "Epoch 373/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4973 - val_loss: 1.5084\n",
      "Epoch 374/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4933 - val_loss: 1.5837\n",
      "Epoch 375/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5013 - val_loss: 1.5638\n",
      "Epoch 376/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4917 - val_loss: 1.5148\n",
      "Epoch 377/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4902 - val_loss: 1.5271\n",
      "Epoch 378/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4968 - val_loss: 1.4907\n",
      "Epoch 379/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4981 - val_loss: 1.4965\n",
      "Epoch 380/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5007 - val_loss: 1.5365\n",
      "Epoch 381/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4941 - val_loss: 1.4942\n",
      "Epoch 382/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4964 - val_loss: 1.5667\n",
      "Epoch 383/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4889 - val_loss: 1.5846\n",
      "Epoch 384/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4908 - val_loss: 1.5997\n",
      "Epoch 385/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4957 - val_loss: 1.4817\n",
      "Epoch 386/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4831 - val_loss: 1.5237\n",
      "Epoch 387/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4930 - val_loss: 1.5518\n",
      "Epoch 388/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4896 - val_loss: 1.5782\n",
      "Epoch 389/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4970 - val_loss: 1.4949\n",
      "Epoch 390/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4905 - val_loss: 1.4910\n",
      "Epoch 391/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4937 - val_loss: 1.5247\n",
      "Epoch 392/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4936 - val_loss: 1.4696\n",
      "Epoch 393/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4890 - val_loss: 1.4948\n",
      "Epoch 394/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4831 - val_loss: 1.5780\n",
      "Epoch 395/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4982 - val_loss: 1.5518\n",
      "Epoch 396/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4917 - val_loss: 1.4616\n",
      "Epoch 397/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4862 - val_loss: 1.6574\n",
      "Epoch 398/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4872 - val_loss: 1.4898\n",
      "Epoch 399/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4828 - val_loss: 1.4852\n",
      "Epoch 400/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4904 - val_loss: 1.5548\n",
      "Epoch 401/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4810 - val_loss: 1.5326\n",
      "Epoch 402/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4802 - val_loss: 1.4675\n",
      "Epoch 403/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4874 - val_loss: 1.5835\n",
      "Epoch 404/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4790 - val_loss: 1.5721\n",
      "Epoch 405/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4908 - val_loss: 1.5468\n",
      "Epoch 406/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4760 - val_loss: 1.4759\n",
      "Epoch 407/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4754 - val_loss: 1.4870\n",
      "Epoch 408/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4857 - val_loss: 1.5241\n",
      "Epoch 409/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4873 - val_loss: 1.4659\n",
      "Epoch 410/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4792 - val_loss: 1.5024\n",
      "Epoch 411/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4841 - val_loss: 1.5030\n",
      "Epoch 412/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4823 - val_loss: 1.4902\n",
      "Epoch 413/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4756 - val_loss: 1.5119\n",
      "Epoch 414/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4838 - val_loss: 1.5024\n",
      "Epoch 415/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4876 - val_loss: 1.5027\n",
      "Epoch 416/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4923 - val_loss: 1.5495\n",
      "Epoch 417/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4750 - val_loss: 1.5052\n",
      "Epoch 418/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4731 - val_loss: 1.4550\n",
      "Epoch 419/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4779 - val_loss: 1.5169\n",
      "Epoch 420/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4753 - val_loss: 1.6157\n",
      "Epoch 421/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4778 - val_loss: 1.5614\n",
      "Epoch 422/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4909 - val_loss: 1.4517\n",
      "Epoch 423/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4734 - val_loss: 1.5270\n",
      "Epoch 424/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4744 - val_loss: 1.5510\n",
      "Epoch 425/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4850 - val_loss: 1.4582\n",
      "Epoch 426/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4721 - val_loss: 1.5137\n",
      "Epoch 427/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4751 - val_loss: 1.5079\n",
      "Epoch 428/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4746 - val_loss: 1.4603\n",
      "Epoch 429/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4866 - val_loss: 1.5411\n",
      "Epoch 430/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4777 - val_loss: 1.5941\n",
      "Epoch 431/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4766 - val_loss: 1.4947\n",
      "Epoch 432/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4775 - val_loss: 1.4709\n",
      "Epoch 433/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4717 - val_loss: 1.6196\n",
      "Epoch 434/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4859 - val_loss: 1.5409\n",
      "Epoch 435/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4770 - val_loss: 1.4498\n",
      "Epoch 436/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4741 - val_loss: 1.4957\n",
      "Epoch 437/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4756 - val_loss: 1.5104\n",
      "Epoch 438/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4765 - val_loss: 1.4628\n",
      "Epoch 439/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4670 - val_loss: 1.5201\n",
      "Epoch 440/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4727 - val_loss: 1.4732\n",
      "Epoch 441/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4701 - val_loss: 1.4940\n",
      "Epoch 442/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4691 - val_loss: 1.5396\n",
      "Epoch 443/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4713 - val_loss: 1.5019\n",
      "Epoch 444/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4725 - val_loss: 1.4775\n",
      "Epoch 445/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4738 - val_loss: 1.5069\n",
      "Epoch 446/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4655 - val_loss: 1.5018\n",
      "Epoch 447/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4647 - val_loss: 1.4789\n",
      "Epoch 448/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4680 - val_loss: 1.4755\n",
      "Epoch 449/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4719 - val_loss: 1.5408\n",
      "Epoch 450/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4606 - val_loss: 1.4753\n",
      "Epoch 451/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4721 - val_loss: 1.5073\n",
      "Epoch 452/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4752 - val_loss: 1.5566\n",
      "Epoch 453/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4635 - val_loss: 1.5513\n",
      "Epoch 454/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4836 - val_loss: 1.4579\n",
      "Epoch 455/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4732 - val_loss: 1.5257\n",
      "Epoch 456/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4703 - val_loss: 1.4771\n",
      "Epoch 457/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4675 - val_loss: 1.5365\n",
      "Epoch 458/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4622 - val_loss: 1.4536\n",
      "Epoch 459/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4600 - val_loss: 1.5363\n",
      "Epoch 460/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4726 - val_loss: 1.5562\n",
      "Epoch 461/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4677 - val_loss: 1.5157\n",
      "Epoch 462/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4672 - val_loss: 1.5533\n",
      "Epoch 463/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4735 - val_loss: 1.5141\n",
      "Epoch 464/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4648 - val_loss: 1.4998\n",
      "Epoch 465/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4762 - val_loss: 1.4488\n",
      "Epoch 466/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4535 - val_loss: 1.4712\n",
      "Epoch 467/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4783 - val_loss: 1.5053\n",
      "Epoch 468/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4555 - val_loss: 1.5409\n",
      "Epoch 469/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4579 - val_loss: 1.5175\n",
      "Epoch 470/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4596 - val_loss: 1.4538\n",
      "Epoch 471/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4630 - val_loss: 1.6426\n",
      "Epoch 472/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4617 - val_loss: 1.4580\n",
      "Epoch 473/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4598 - val_loss: 1.4795\n",
      "Epoch 474/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4578 - val_loss: 1.4978\n",
      "Epoch 475/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4550 - val_loss: 1.5153\n",
      "Epoch 476/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4650 - val_loss: 1.5586\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4576 - val_loss: 1.4733\n",
      "Epoch 478/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4637 - val_loss: 1.5296\n",
      "Epoch 479/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4611 - val_loss: 1.5047\n",
      "Epoch 480/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4709 - val_loss: 1.4855\n",
      "Epoch 481/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4620 - val_loss: 1.5555\n",
      "Epoch 482/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4573 - val_loss: 1.5016\n",
      "Epoch 483/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4626 - val_loss: 1.4681\n",
      "Epoch 484/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4617 - val_loss: 1.4870\n",
      "Epoch 485/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4571 - val_loss: 1.4682\n",
      "Epoch 486/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4609 - val_loss: 1.4893\n",
      "Epoch 487/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4535 - val_loss: 1.5275\n",
      "Epoch 488/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4526 - val_loss: 1.4287\n",
      "Epoch 489/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4499 - val_loss: 1.5110\n",
      "Epoch 490/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4617 - val_loss: 1.5377\n",
      "Epoch 491/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4581 - val_loss: 1.5328\n",
      "Epoch 492/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4499 - val_loss: 1.5834\n",
      "Epoch 493/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4626 - val_loss: 1.5913\n",
      "Epoch 494/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4573 - val_loss: 1.6841\n",
      "Epoch 495/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4630 - val_loss: 1.5181\n",
      "Epoch 496/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4563 - val_loss: 1.5257\n",
      "Epoch 497/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4574 - val_loss: 1.4766\n",
      "Epoch 498/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4558 - val_loss: 1.5338\n",
      "Epoch 499/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4578 - val_loss: 1.5065\n",
      "Epoch 500/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4549 - val_loss: 1.4988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4987921657391323\n",
      "0.96483997728315\n",
      "Epoch 1/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 8.5015 - val_loss: 4.1636\n",
      "Epoch 2/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 5.5755 - val_loss: 8.5603\n",
      "Epoch 3/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.8817 - val_loss: 4.4850\n",
      "Epoch 4/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.6611 - val_loss: 4.1999\n",
      "Epoch 5/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.5343 - val_loss: 4.4610\n",
      "Epoch 6/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.2452 - val_loss: 3.3540\n",
      "Epoch 7/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.7293 - val_loss: 3.2970\n",
      "Epoch 8/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 3.5208 - val_loss: 3.9812\n",
      "Epoch 9/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.4023 - val_loss: 4.0727\n",
      "Epoch 10/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.2926 - val_loss: 2.9713\n",
      "Epoch 11/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.1504 - val_loss: 3.1896\n",
      "Epoch 12/500\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 3.1395 - val_loss: 3.1326\n",
      "Epoch 13/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.9988 - val_loss: 3.0237\n",
      "Epoch 14/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 3.0050 - val_loss: 2.9483\n",
      "Epoch 15/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.9053 - val_loss: 2.7806\n",
      "Epoch 16/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.8187 - val_loss: 2.6298\n",
      "Epoch 17/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.7982 - val_loss: 2.5872\n",
      "Epoch 18/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.7294 - val_loss: 2.8258\n",
      "Epoch 19/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.6703 - val_loss: 2.5935\n",
      "Epoch 20/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.6732 - val_loss: 2.5396\n",
      "Epoch 21/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.6292 - val_loss: 2.7532\n",
      "Epoch 22/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.5816 - val_loss: 2.6538\n",
      "Epoch 23/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.5609 - val_loss: 2.4600\n",
      "Epoch 24/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.5192 - val_loss: 3.1349\n",
      "Epoch 25/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4779 - val_loss: 2.4273\n",
      "Epoch 26/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4532 - val_loss: 2.4101\n",
      "Epoch 27/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4121 - val_loss: 2.3911\n",
      "Epoch 28/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4208 - val_loss: 2.3318\n",
      "Epoch 29/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.3813 - val_loss: 2.3044\n",
      "Epoch 30/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.3423 - val_loss: 2.2774\n",
      "Epoch 31/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.3375 - val_loss: 2.3095\n",
      "Epoch 32/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.3217 - val_loss: 2.3494\n",
      "Epoch 33/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.2798 - val_loss: 2.2707\n",
      "Epoch 34/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.2552 - val_loss: 2.2751\n",
      "Epoch 35/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.2335 - val_loss: 2.2733\n",
      "Epoch 36/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.2348 - val_loss: 2.2843\n",
      "Epoch 37/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1967 - val_loss: 2.3074\n",
      "Epoch 38/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2034 - val_loss: 2.3130\n",
      "Epoch 39/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1608 - val_loss: 2.1332\n",
      "Epoch 40/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1343 - val_loss: 2.3801\n",
      "Epoch 41/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1513 - val_loss: 2.0819\n",
      "Epoch 42/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1460 - val_loss: 2.2260\n",
      "Epoch 43/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1197 - val_loss: 2.1720\n",
      "Epoch 44/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0892 - val_loss: 2.0802\n",
      "Epoch 45/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1197 - val_loss: 2.1074\n",
      "Epoch 46/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0818 - val_loss: 2.0548\n",
      "Epoch 47/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0688 - val_loss: 2.1202\n",
      "Epoch 48/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0438 - val_loss: 2.0880\n",
      "Epoch 49/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0367 - val_loss: 2.0665\n",
      "Epoch 50/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0179 - val_loss: 1.9904\n",
      "Epoch 51/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0181 - val_loss: 2.1244\n",
      "Epoch 52/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0097 - val_loss: 1.9891\n",
      "Epoch 53/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0013 - val_loss: 2.0486\n",
      "Epoch 54/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9708 - val_loss: 1.9191\n",
      "Epoch 55/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9809 - val_loss: 2.2368\n",
      "Epoch 56/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9597 - val_loss: 1.9297\n",
      "Epoch 57/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9421 - val_loss: 2.0320\n",
      "Epoch 58/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9361 - val_loss: 2.0348\n",
      "Epoch 59/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9212 - val_loss: 1.9217\n",
      "Epoch 60/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9224 - val_loss: 1.9030\n",
      "Epoch 61/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9210 - val_loss: 1.9087\n",
      "Epoch 62/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9125 - val_loss: 1.8382\n",
      "Epoch 63/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8836 - val_loss: 1.9509\n",
      "Epoch 64/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8943 - val_loss: 1.9287\n",
      "Epoch 65/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8941 - val_loss: 1.8890\n",
      "Epoch 66/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8928 - val_loss: 1.8371\n",
      "Epoch 67/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8973 - val_loss: 1.8472\n",
      "Epoch 68/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8805 - val_loss: 1.8384\n",
      "Epoch 69/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8634 - val_loss: 1.8088\n",
      "Epoch 70/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8694 - val_loss: 1.9388\n",
      "Epoch 71/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8534 - val_loss: 1.9479\n",
      "Epoch 72/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8505 - val_loss: 1.9370\n",
      "Epoch 73/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8661 - val_loss: 1.8354\n",
      "Epoch 74/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8441 - val_loss: 1.9422\n",
      "Epoch 75/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8365 - val_loss: 1.8601\n",
      "Epoch 76/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8295 - val_loss: 1.9356\n",
      "Epoch 77/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8228 - val_loss: 1.8786\n",
      "Epoch 78/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8266 - val_loss: 1.8149\n",
      "Epoch 79/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8231 - val_loss: 1.7788\n",
      "Epoch 80/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8181 - val_loss: 1.8525\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8096 - val_loss: 1.9294\n",
      "Epoch 82/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8094 - val_loss: 1.8753\n",
      "Epoch 83/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8068 - val_loss: 1.8126\n",
      "Epoch 84/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8068 - val_loss: 1.8217\n",
      "Epoch 85/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7998 - val_loss: 1.9081\n",
      "Epoch 86/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7835 - val_loss: 1.7970\n",
      "Epoch 87/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7931 - val_loss: 1.7630\n",
      "Epoch 88/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7894 - val_loss: 1.8091\n",
      "Epoch 89/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7790 - val_loss: 1.8224\n",
      "Epoch 90/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7853 - val_loss: 1.7965\n",
      "Epoch 91/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7811 - val_loss: 1.7309\n",
      "Epoch 92/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7718 - val_loss: 1.7737\n",
      "Epoch 93/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7570 - val_loss: 1.7877\n",
      "Epoch 94/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7665 - val_loss: 1.7458\n",
      "Epoch 95/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7475 - val_loss: 1.7964\n",
      "Epoch 96/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7471 - val_loss: 1.8690\n",
      "Epoch 97/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7604 - val_loss: 1.7439\n",
      "Epoch 98/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7294 - val_loss: 1.7680\n",
      "Epoch 99/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7295 - val_loss: 1.7152\n",
      "Epoch 100/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7399 - val_loss: 1.7409\n",
      "Epoch 101/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7419 - val_loss: 1.7495\n",
      "Epoch 102/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7402 - val_loss: 1.7638\n",
      "Epoch 103/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7434 - val_loss: 1.7848\n",
      "Epoch 104/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7195 - val_loss: 1.7868\n",
      "Epoch 105/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7190 - val_loss: 1.6907\n",
      "Epoch 106/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7235 - val_loss: 1.7128\n",
      "Epoch 107/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7174 - val_loss: 1.7354\n",
      "Epoch 108/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7041 - val_loss: 1.7419\n",
      "Epoch 109/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7084 - val_loss: 1.8706\n",
      "Epoch 110/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7094 - val_loss: 1.7487\n",
      "Epoch 111/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7098 - val_loss: 1.6765\n",
      "Epoch 112/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6930 - val_loss: 1.7629\n",
      "Epoch 113/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6897 - val_loss: 1.7484\n",
      "Epoch 114/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6924 - val_loss: 1.6919\n",
      "Epoch 115/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6881 - val_loss: 1.7316\n",
      "Epoch 116/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6871 - val_loss: 1.7050\n",
      "Epoch 117/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6918 - val_loss: 1.8006\n",
      "Epoch 118/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6715 - val_loss: 1.6787\n",
      "Epoch 119/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6869 - val_loss: 1.7256\n",
      "Epoch 120/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6733 - val_loss: 1.8717\n",
      "Epoch 121/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6788 - val_loss: 1.6470\n",
      "Epoch 122/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6626 - val_loss: 1.6533\n",
      "Epoch 123/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6560 - val_loss: 1.7553\n",
      "Epoch 124/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6705 - val_loss: 1.6911\n",
      "Epoch 125/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6503 - val_loss: 1.7053\n",
      "Epoch 126/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6579 - val_loss: 1.7501\n",
      "Epoch 127/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6646 - val_loss: 1.7392\n",
      "Epoch 128/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6570 - val_loss: 1.6364\n",
      "Epoch 129/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6374 - val_loss: 1.7261\n",
      "Epoch 130/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6472 - val_loss: 1.6091\n",
      "Epoch 131/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6449 - val_loss: 1.6581\n",
      "Epoch 132/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6504 - val_loss: 1.6642\n",
      "Epoch 133/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6322 - val_loss: 1.6665\n",
      "Epoch 134/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6442 - val_loss: 1.6711\n",
      "Epoch 135/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6455 - val_loss: 1.6416\n",
      "Epoch 136/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6261 - val_loss: 1.6497\n",
      "Epoch 137/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6376 - val_loss: 1.6312\n",
      "Epoch 138/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6184 - val_loss: 1.6436\n",
      "Epoch 139/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6289 - val_loss: 1.6237\n",
      "Epoch 140/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6209 - val_loss: 1.5992\n",
      "Epoch 141/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6216 - val_loss: 1.6980\n",
      "Epoch 142/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6077 - val_loss: 1.6453\n",
      "Epoch 143/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6187 - val_loss: 1.6602\n",
      "Epoch 144/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6093 - val_loss: 1.6061\n",
      "Epoch 145/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6138 - val_loss: 1.6364\n",
      "Epoch 146/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5981 - val_loss: 1.6641\n",
      "Epoch 147/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6136 - val_loss: 1.6379\n",
      "Epoch 148/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6062 - val_loss: 1.7294\n",
      "Epoch 149/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6094 - val_loss: 1.7527\n",
      "Epoch 150/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6162 - val_loss: 1.7415\n",
      "Epoch 151/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6021 - val_loss: 1.6114\n",
      "Epoch 152/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6053 - val_loss: 1.6181\n",
      "Epoch 153/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5971 - val_loss: 1.8097\n",
      "Epoch 154/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6109 - val_loss: 1.6264\n",
      "Epoch 155/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6037 - val_loss: 1.7684\n",
      "Epoch 156/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5866 - val_loss: 1.5890\n",
      "Epoch 157/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5823 - val_loss: 1.6505\n",
      "Epoch 158/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6022 - val_loss: 1.5992\n",
      "Epoch 159/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5988 - val_loss: 1.7000\n",
      "Epoch 160/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5732 - val_loss: 1.6654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5865 - val_loss: 1.6046\n",
      "Epoch 162/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5857 - val_loss: 1.7063\n",
      "Epoch 163/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5772 - val_loss: 1.6235\n",
      "Epoch 164/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5720 - val_loss: 1.5834\n",
      "Epoch 165/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5847 - val_loss: 1.6247\n",
      "Epoch 166/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5728 - val_loss: 1.6342\n",
      "Epoch 167/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5612 - val_loss: 1.5695\n",
      "Epoch 168/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5703 - val_loss: 1.6077\n",
      "Epoch 169/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5808 - val_loss: 1.5458\n",
      "Epoch 170/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5666 - val_loss: 1.6378\n",
      "Epoch 171/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5723 - val_loss: 1.5715\n",
      "Epoch 172/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5754 - val_loss: 1.6937\n",
      "Epoch 173/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5730 - val_loss: 1.6225\n",
      "Epoch 174/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5583 - val_loss: 1.6046\n",
      "Epoch 175/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5672 - val_loss: 1.6266\n",
      "Epoch 176/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5526 - val_loss: 1.5735\n",
      "Epoch 177/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5419 - val_loss: 1.5974\n",
      "Epoch 178/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5526 - val_loss: 1.6230\n",
      "Epoch 179/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5550 - val_loss: 1.6090\n",
      "Epoch 180/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5642 - val_loss: 1.5766\n",
      "Epoch 181/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5479 - val_loss: 1.5974\n",
      "Epoch 182/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5559 - val_loss: 1.5487\n",
      "Epoch 183/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5552 - val_loss: 1.6548\n",
      "Epoch 184/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5565 - val_loss: 1.5274\n",
      "Epoch 185/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5463 - val_loss: 1.5953\n",
      "Epoch 186/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5406 - val_loss: 1.5384\n",
      "Epoch 187/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5414 - val_loss: 1.5393\n",
      "Epoch 188/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5371 - val_loss: 1.5823\n",
      "Epoch 189/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5459 - val_loss: 1.5466\n",
      "Epoch 190/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5455 - val_loss: 1.5373\n",
      "Epoch 191/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5371 - val_loss: 1.5282\n",
      "Epoch 192/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5424 - val_loss: 1.5337\n",
      "Epoch 193/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5379 - val_loss: 1.5591\n",
      "Epoch 194/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5391 - val_loss: 1.6248\n",
      "Epoch 195/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5387 - val_loss: 1.6108\n",
      "Epoch 196/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5325 - val_loss: 1.5315\n",
      "Epoch 197/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5358 - val_loss: 1.5981\n",
      "Epoch 198/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5274 - val_loss: 1.6200\n",
      "Epoch 199/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5180 - val_loss: 1.5463\n",
      "Epoch 200/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5235 - val_loss: 1.5616\n",
      "Epoch 201/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5247 - val_loss: 1.5223\n",
      "Epoch 202/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5370 - val_loss: 1.6486\n",
      "Epoch 203/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5194 - val_loss: 1.5535\n",
      "Epoch 204/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5250 - val_loss: 1.5549\n",
      "Epoch 205/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5122 - val_loss: 1.5195\n",
      "Epoch 206/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5185 - val_loss: 1.5894\n",
      "Epoch 207/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5123 - val_loss: 1.6085\n",
      "Epoch 208/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5145 - val_loss: 1.5299\n",
      "Epoch 209/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5215 - val_loss: 1.5687\n",
      "Epoch 210/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5067 - val_loss: 1.4953\n",
      "Epoch 211/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5142 - val_loss: 1.5527\n",
      "Epoch 212/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5087 - val_loss: 1.5241\n",
      "Epoch 213/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5052 - val_loss: 1.5468\n",
      "Epoch 214/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5095 - val_loss: 1.5781\n",
      "Epoch 215/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5042 - val_loss: 1.5997\n",
      "Epoch 216/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5116 - val_loss: 1.5612\n",
      "Epoch 217/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5098 - val_loss: 1.5807\n",
      "Epoch 218/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4968 - val_loss: 1.5137\n",
      "Epoch 219/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5019 - val_loss: 1.5756\n",
      "Epoch 220/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4995 - val_loss: 1.5077\n",
      "Epoch 221/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5069 - val_loss: 1.5503\n",
      "Epoch 222/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5001 - val_loss: 1.5705\n",
      "Epoch 223/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5046 - val_loss: 1.5394\n",
      "Epoch 224/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5120 - val_loss: 1.5786\n",
      "Epoch 225/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5061 - val_loss: 1.5427\n",
      "Epoch 226/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4930 - val_loss: 1.5656\n",
      "Epoch 227/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5014 - val_loss: 1.5131\n",
      "Epoch 228/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4906 - val_loss: 1.5097\n",
      "Epoch 229/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4917 - val_loss: 1.5812\n",
      "Epoch 230/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4937 - val_loss: 1.5452\n",
      "Epoch 231/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4758 - val_loss: 1.5119\n",
      "Epoch 232/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4980 - val_loss: 1.5706\n",
      "Epoch 233/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4900 - val_loss: 1.6791\n",
      "Epoch 234/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5002 - val_loss: 1.5410\n",
      "Epoch 235/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4939 - val_loss: 1.5355\n",
      "Epoch 236/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4826 - val_loss: 1.5259\n",
      "Epoch 237/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4881 - val_loss: 1.5523\n",
      "Epoch 238/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4792 - val_loss: 1.6601\n",
      "Epoch 239/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4838 - val_loss: 1.4666\n",
      "Epoch 240/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4821 - val_loss: 1.5511\n",
      "Epoch 241/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4854 - val_loss: 1.5307\n",
      "Epoch 242/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4810 - val_loss: 1.5609\n",
      "Epoch 243/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4757 - val_loss: 1.5006\n",
      "Epoch 244/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4838 - val_loss: 1.5484\n",
      "Epoch 245/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4859 - val_loss: 1.5339\n",
      "Epoch 246/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4845 - val_loss: 1.4577\n",
      "Epoch 247/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4633 - val_loss: 1.4964\n",
      "Epoch 248/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4721 - val_loss: 1.5259\n",
      "Epoch 249/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4685 - val_loss: 1.5659\n",
      "Epoch 250/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4726 - val_loss: 1.4559\n",
      "Epoch 251/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4647 - val_loss: 1.5341\n",
      "Epoch 252/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4656 - val_loss: 1.5180\n",
      "Epoch 253/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4741 - val_loss: 1.5482\n",
      "Epoch 254/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4581 - val_loss: 1.4590\n",
      "Epoch 255/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4671 - val_loss: 1.5516\n",
      "Epoch 256/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4718 - val_loss: 1.4894\n",
      "Epoch 257/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4651 - val_loss: 1.5171\n",
      "Epoch 258/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4657 - val_loss: 1.5676\n",
      "Epoch 259/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4688 - val_loss: 1.5141\n",
      "Epoch 260/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4606 - val_loss: 1.5215\n",
      "Epoch 261/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4587 - val_loss: 1.5534\n",
      "Epoch 262/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4715 - val_loss: 1.5292\n",
      "Epoch 263/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4582 - val_loss: 1.4927\n",
      "Epoch 264/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4707 - val_loss: 1.5305\n",
      "Epoch 265/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4576 - val_loss: 1.5404\n",
      "Epoch 266/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4640 - val_loss: 1.4666\n",
      "Epoch 267/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4472 - val_loss: 1.6162\n",
      "Epoch 268/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4599 - val_loss: 1.5030\n",
      "Epoch 269/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4484 - val_loss: 1.4806\n",
      "Epoch 270/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4580 - val_loss: 1.4678\n",
      "Epoch 271/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4682 - val_loss: 1.4877\n",
      "Epoch 272/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4550 - val_loss: 1.5272\n",
      "Epoch 273/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4562 - val_loss: 1.4903\n",
      "Epoch 274/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4434 - val_loss: 1.4947\n",
      "Epoch 275/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4513 - val_loss: 1.5222\n",
      "Epoch 276/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4482 - val_loss: 1.4780\n",
      "Epoch 277/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4478 - val_loss: 1.4869\n",
      "Epoch 278/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4490 - val_loss: 1.4730\n",
      "Epoch 279/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4467 - val_loss: 1.5014\n",
      "Epoch 280/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4380 - val_loss: 1.4818\n",
      "Epoch 281/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4445 - val_loss: 1.4542\n",
      "Epoch 282/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4368 - val_loss: 1.4907\n",
      "Epoch 283/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4454 - val_loss: 1.5431\n",
      "Epoch 284/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4376 - val_loss: 1.4960\n",
      "Epoch 285/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4472 - val_loss: 1.5086\n",
      "Epoch 286/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4347 - val_loss: 1.4950\n",
      "Epoch 287/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4382 - val_loss: 1.5423\n",
      "Epoch 288/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4548 - val_loss: 1.6164\n",
      "Epoch 289/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4500 - val_loss: 1.5453\n",
      "Epoch 290/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4247 - val_loss: 1.4418\n",
      "Epoch 291/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4381 - val_loss: 1.4392\n",
      "Epoch 292/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4403 - val_loss: 1.4878\n",
      "Epoch 293/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4379 - val_loss: 1.5204\n",
      "Epoch 294/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4308 - val_loss: 1.5059\n",
      "Epoch 295/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4413 - val_loss: 1.5589\n",
      "Epoch 296/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4287 - val_loss: 1.5173\n",
      "Epoch 297/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4404 - val_loss: 1.6265\n",
      "Epoch 298/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4302 - val_loss: 1.4412\n",
      "Epoch 299/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4259 - val_loss: 1.4914\n",
      "Epoch 300/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4300 - val_loss: 1.5174\n",
      "Epoch 301/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4295 - val_loss: 1.5706\n",
      "Epoch 302/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4319 - val_loss: 1.5013\n",
      "Epoch 303/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4383 - val_loss: 1.4840\n",
      "Epoch 304/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4221 - val_loss: 1.4709\n",
      "Epoch 305/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4226 - val_loss: 1.4983\n",
      "Epoch 306/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4319 - val_loss: 1.5098\n",
      "Epoch 307/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4215 - val_loss: 1.5084\n",
      "Epoch 308/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4206 - val_loss: 1.4996\n",
      "Epoch 309/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4233 - val_loss: 1.4565\n",
      "Epoch 310/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4236 - val_loss: 1.4578\n",
      "Epoch 311/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4134 - val_loss: 1.4715\n",
      "Epoch 312/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4298 - val_loss: 1.4422\n",
      "Epoch 313/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4187 - val_loss: 1.4898\n",
      "Epoch 314/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4253 - val_loss: 1.4943\n",
      "Epoch 315/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4156 - val_loss: 1.5379\n",
      "Epoch 316/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4281 - val_loss: 1.4593\n",
      "Epoch 317/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4164 - val_loss: 1.4343\n",
      "Epoch 318/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4250 - val_loss: 1.4472\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4160 - val_loss: 1.4064\n",
      "Epoch 320/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4162 - val_loss: 1.4951\n",
      "Epoch 321/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4189 - val_loss: 1.4591\n",
      "Epoch 322/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4134 - val_loss: 1.4537\n",
      "Epoch 323/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4166 - val_loss: 1.4780\n",
      "Epoch 324/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4185 - val_loss: 1.4742\n",
      "Epoch 325/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4260 - val_loss: 1.4977\n",
      "Epoch 326/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4130 - val_loss: 1.5014\n",
      "Epoch 327/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4157 - val_loss: 1.4824\n",
      "Epoch 328/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4142 - val_loss: 1.5772\n",
      "Epoch 329/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4148 - val_loss: 1.5117\n",
      "Epoch 330/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4193 - val_loss: 1.4844\n",
      "Epoch 331/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4066 - val_loss: 1.5195\n",
      "Epoch 332/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4173 - val_loss: 1.4099\n",
      "Epoch 333/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4114 - val_loss: 1.4472\n",
      "Epoch 334/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4073 - val_loss: 1.5062\n",
      "Epoch 335/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3994 - val_loss: 1.4657\n",
      "Epoch 336/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4058 - val_loss: 1.4925\n",
      "Epoch 337/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4058 - val_loss: 1.4595\n",
      "Epoch 338/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4102 - val_loss: 1.4387\n",
      "Epoch 339/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4161 - val_loss: 1.4951\n",
      "Epoch 340/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4029 - val_loss: 1.4379\n",
      "Epoch 341/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4129 - val_loss: 1.4461\n",
      "Epoch 342/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4053 - val_loss: 1.4598\n",
      "Epoch 343/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4061 - val_loss: 1.4635\n",
      "Epoch 344/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4054 - val_loss: 1.4273\n",
      "Epoch 345/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4010 - val_loss: 1.4469\n",
      "Epoch 346/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4069 - val_loss: 1.4355\n",
      "Epoch 347/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3979 - val_loss: 1.5311\n",
      "Epoch 348/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4011 - val_loss: 1.4679\n",
      "Epoch 349/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4015 - val_loss: 1.5343\n",
      "Epoch 350/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3953 - val_loss: 1.4372\n",
      "Epoch 351/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3911 - val_loss: 1.4589\n",
      "Epoch 352/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3993 - val_loss: 1.4675\n",
      "Epoch 353/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4005 - val_loss: 1.4960\n",
      "Epoch 354/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3963 - val_loss: 1.4735\n",
      "Epoch 355/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3915 - val_loss: 1.4265\n",
      "Epoch 356/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4008 - val_loss: 1.4117\n",
      "Epoch 357/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4026 - val_loss: 1.4364\n",
      "Epoch 358/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3926 - val_loss: 1.5276\n",
      "Epoch 359/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3903 - val_loss: 1.5334\n",
      "Epoch 360/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3948 - val_loss: 1.4190\n",
      "Epoch 361/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4069 - val_loss: 1.4356\n",
      "Epoch 362/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3910 - val_loss: 1.4819\n",
      "Epoch 363/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3961 - val_loss: 1.4260\n",
      "Epoch 364/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3834 - val_loss: 1.3868\n",
      "Epoch 365/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3978 - val_loss: 1.4561\n",
      "Epoch 366/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3946 - val_loss: 1.4271\n",
      "Epoch 367/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3936 - val_loss: 1.4453\n",
      "Epoch 368/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3926 - val_loss: 1.5118\n",
      "Epoch 369/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3916 - val_loss: 1.4687\n",
      "Epoch 370/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3871 - val_loss: 1.4521\n",
      "Epoch 371/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3929 - val_loss: 1.4181\n",
      "Epoch 372/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3914 - val_loss: 1.4343\n",
      "Epoch 373/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3870 - val_loss: 1.4487\n",
      "Epoch 374/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3970 - val_loss: 1.3754\n",
      "Epoch 375/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3811 - val_loss: 1.4542\n",
      "Epoch 376/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3910 - val_loss: 1.4333\n",
      "Epoch 377/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3838 - val_loss: 1.4509\n",
      "Epoch 378/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3839 - val_loss: 1.4439\n",
      "Epoch 379/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3839 - val_loss: 1.4835\n",
      "Epoch 380/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3917 - val_loss: 1.4224\n",
      "Epoch 381/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3829 - val_loss: 1.4108\n",
      "Epoch 382/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3870 - val_loss: 1.4193\n",
      "Epoch 383/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3808 - val_loss: 1.4462\n",
      "Epoch 384/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3822 - val_loss: 1.5047\n",
      "Epoch 385/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3853 - val_loss: 1.4212\n",
      "Epoch 386/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3764 - val_loss: 1.4400\n",
      "Epoch 387/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3752 - val_loss: 1.4448\n",
      "Epoch 388/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3900 - val_loss: 1.4356\n",
      "Epoch 389/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3700 - val_loss: 1.4008\n",
      "Epoch 390/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3883 - val_loss: 1.4437\n",
      "Epoch 391/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3783 - val_loss: 1.4677\n",
      "Epoch 392/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3712 - val_loss: 1.4162\n",
      "Epoch 393/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3881 - val_loss: 1.4146\n",
      "Epoch 394/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3686 - val_loss: 1.3899\n",
      "Epoch 395/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3789 - val_loss: 1.4283\n",
      "Epoch 396/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3703 - val_loss: 1.4007\n",
      "Epoch 397/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3737 - val_loss: 1.4649\n",
      "Epoch 398/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3715 - val_loss: 1.4051\n",
      "Epoch 399/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3789 - val_loss: 1.4185\n",
      "Epoch 400/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3813 - val_loss: 1.4592\n",
      "Epoch 401/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3801 - val_loss: 1.4280\n",
      "Epoch 402/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3601 - val_loss: 1.3909\n",
      "Epoch 403/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3846 - val_loss: 1.4884\n",
      "Epoch 404/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3804 - val_loss: 1.4658\n",
      "Epoch 405/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3724 - val_loss: 1.4300\n",
      "Epoch 406/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3777 - val_loss: 1.4234\n",
      "Epoch 407/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3729 - val_loss: 1.3523\n",
      "Epoch 408/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3786 - val_loss: 1.4780\n",
      "Epoch 409/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3607 - val_loss: 1.4862\n",
      "Epoch 410/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3727 - val_loss: 1.5095\n",
      "Epoch 411/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3675 - val_loss: 1.3888\n",
      "Epoch 412/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3703 - val_loss: 1.4186\n",
      "Epoch 413/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3653 - val_loss: 1.4149\n",
      "Epoch 414/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3688 - val_loss: 1.4150\n",
      "Epoch 415/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3617 - val_loss: 1.5321\n",
      "Epoch 416/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3722 - val_loss: 1.4576\n",
      "Epoch 417/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3718 - val_loss: 1.4886\n",
      "Epoch 418/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3655 - val_loss: 1.4293\n",
      "Epoch 419/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3689 - val_loss: 1.4015\n",
      "Epoch 420/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3656 - val_loss: 1.3970\n",
      "Epoch 421/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3540 - val_loss: 1.4015\n",
      "Epoch 422/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3663 - val_loss: 1.4623\n",
      "Epoch 423/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3737 - val_loss: 1.3997\n",
      "Epoch 424/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3668 - val_loss: 1.4701\n",
      "Epoch 425/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3681 - val_loss: 1.4844\n",
      "Epoch 426/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3634 - val_loss: 1.4132\n",
      "Epoch 427/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3532 - val_loss: 1.4508\n",
      "Epoch 428/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3681 - val_loss: 1.4584\n",
      "Epoch 429/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3577 - val_loss: 1.4288\n",
      "Epoch 430/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3646 - val_loss: 1.4347\n",
      "Epoch 431/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3708 - val_loss: 1.3661\n",
      "Epoch 432/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3695 - val_loss: 1.4050\n",
      "Epoch 433/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3554 - val_loss: 1.3849\n",
      "Epoch 434/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3503 - val_loss: 1.3951\n",
      "Epoch 435/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3553 - val_loss: 1.4273\n",
      "Epoch 436/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3692 - val_loss: 1.3884\n",
      "Epoch 437/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3734 - val_loss: 1.3938\n",
      "Epoch 438/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3562 - val_loss: 1.4401\n",
      "Epoch 439/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3540 - val_loss: 1.4193\n",
      "Epoch 440/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3534 - val_loss: 1.4898\n",
      "Epoch 441/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3602 - val_loss: 1.4508\n",
      "Epoch 442/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3671 - val_loss: 1.3607\n",
      "Epoch 443/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3622 - val_loss: 1.4132\n",
      "Epoch 444/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3587 - val_loss: 1.4369\n",
      "Epoch 445/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3574 - val_loss: 1.4021\n",
      "Epoch 446/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3533 - val_loss: 1.4477\n",
      "Epoch 447/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3615 - val_loss: 1.3808\n",
      "Epoch 448/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3517 - val_loss: 1.3905\n",
      "Epoch 449/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3535 - val_loss: 1.4323\n",
      "Epoch 450/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3548 - val_loss: 1.3682\n",
      "Epoch 451/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3520 - val_loss: 1.3737\n",
      "Epoch 452/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3577 - val_loss: 1.3628\n",
      "Epoch 453/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3480 - val_loss: 1.3601\n",
      "Epoch 454/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3533 - val_loss: 1.4210\n",
      "Epoch 455/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3717 - val_loss: 1.4247\n",
      "Epoch 456/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3517 - val_loss: 1.4194\n",
      "Epoch 457/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3559 - val_loss: 1.4398\n",
      "Epoch 458/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3473 - val_loss: 1.4093\n",
      "Epoch 459/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3482 - val_loss: 1.3705\n",
      "Epoch 460/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3479 - val_loss: 1.4370\n",
      "Epoch 461/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3455 - val_loss: 1.4501\n",
      "Epoch 462/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3481 - val_loss: 1.4531\n",
      "Epoch 463/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3426 - val_loss: 1.4170\n",
      "Epoch 464/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3434 - val_loss: 1.4460\n",
      "Epoch 465/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3449 - val_loss: 1.4416\n",
      "Epoch 466/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3540 - val_loss: 1.3657\n",
      "Epoch 467/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3463 - val_loss: 1.4473\n",
      "Epoch 468/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3448 - val_loss: 1.4221\n",
      "Epoch 469/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3487 - val_loss: 1.3602\n",
      "Epoch 470/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3364 - val_loss: 1.4189\n",
      "Epoch 471/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3548 - val_loss: 1.3485\n",
      "Epoch 472/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3438 - val_loss: 1.3586\n",
      "Epoch 473/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3426 - val_loss: 1.3513\n",
      "Epoch 474/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3493 - val_loss: 1.4358\n",
      "Epoch 475/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3492 - val_loss: 1.4067\n",
      "Epoch 476/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3523 - val_loss: 1.4236\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3426 - val_loss: 1.3633\n",
      "Epoch 478/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3393 - val_loss: 1.4247\n",
      "Epoch 479/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3442 - val_loss: 1.4817\n",
      "Epoch 480/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3444 - val_loss: 1.3888\n",
      "Epoch 481/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3424 - val_loss: 1.4000\n",
      "Epoch 482/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3464 - val_loss: 1.4514\n",
      "Epoch 483/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3473 - val_loss: 1.4400\n",
      "Epoch 484/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3495 - val_loss: 1.3994\n",
      "Epoch 485/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3326 - val_loss: 1.3955\n",
      "Epoch 486/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3331 - val_loss: 1.3969\n",
      "Epoch 487/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3430 - val_loss: 1.4097\n",
      "Epoch 488/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3372 - val_loss: 1.4692\n",
      "Epoch 489/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3391 - val_loss: 1.3432\n",
      "Epoch 490/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3334 - val_loss: 1.3411\n",
      "Epoch 491/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3359 - val_loss: 1.4280\n",
      "Epoch 492/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3377 - val_loss: 1.3979\n",
      "Epoch 493/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3394 - val_loss: 1.3774\n",
      "Epoch 494/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3411 - val_loss: 1.3356\n",
      "Epoch 495/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3482 - val_loss: 1.4289\n",
      "Epoch 496/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3367 - val_loss: 1.4280\n",
      "Epoch 497/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3417 - val_loss: 1.3695\n",
      "Epoch 498/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3497 - val_loss: 1.3363\n",
      "Epoch 499/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3316 - val_loss: 1.4211\n",
      "Epoch 500/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3386 - val_loss: 1.3914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3914454879043225\n",
      "0.9711139617569924\n",
      "Epoch 1/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 10.9676 - val_loss: 4.4209\n",
      "Epoch 2/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 5.6418 - val_loss: 4.9061\n",
      "Epoch 3/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.8396 - val_loss: 3.9659\n",
      "Epoch 4/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.5007 - val_loss: 4.5319\n",
      "Epoch 5/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.4130 - val_loss: 4.2218\n",
      "Epoch 6/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.3690 - val_loss: 4.4415\n",
      "Epoch 7/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.3520 - val_loss: 3.6545\n",
      "Epoch 8/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.8951 - val_loss: 4.1172\n",
      "Epoch 9/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.7979 - val_loss: 3.4361\n",
      "Epoch 10/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.4893 - val_loss: 3.7652\n",
      "Epoch 11/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.4802 - val_loss: 3.9998\n",
      "Epoch 12/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.3019 - val_loss: 2.9059\n",
      "Epoch 13/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.1515 - val_loss: 3.4596\n",
      "Epoch 14/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.0228 - val_loss: 2.8501\n",
      "Epoch 15/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.0853 - val_loss: 2.7873\n",
      "Epoch 16/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.9696 - val_loss: 2.7886\n",
      "Epoch 17/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.8984 - val_loss: 2.6712\n",
      "Epoch 18/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.7831 - val_loss: 2.7245\n",
      "Epoch 19/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.7841 - val_loss: 2.7756\n",
      "Epoch 20/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.7354 - val_loss: 2.6251\n",
      "Epoch 21/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.6841 - val_loss: 2.6287\n",
      "Epoch 22/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.5887 - val_loss: 2.4447\n",
      "Epoch 23/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.5368 - val_loss: 2.4308\n",
      "Epoch 24/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.5364 - val_loss: 2.4746\n",
      "Epoch 25/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4988 - val_loss: 2.4693\n",
      "Epoch 26/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5108 - val_loss: 2.3835\n",
      "Epoch 27/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.4567 - val_loss: 2.4081\n",
      "Epoch 28/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.4023 - val_loss: 2.6713\n",
      "Epoch 29/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.4075 - val_loss: 2.4015\n",
      "Epoch 30/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3599 - val_loss: 2.3591\n",
      "Epoch 31/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3731 - val_loss: 2.2999\n",
      "Epoch 32/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3213 - val_loss: 2.2437\n",
      "Epoch 33/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3138 - val_loss: 2.4960\n",
      "Epoch 34/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.2705 - val_loss: 2.2789\n",
      "Epoch 35/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.2625 - val_loss: 2.2611\n",
      "Epoch 36/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.2545 - val_loss: 2.1464\n",
      "Epoch 37/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.2348 - val_loss: 2.2240\n",
      "Epoch 38/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1948 - val_loss: 2.5367\n",
      "Epoch 39/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1669 - val_loss: 2.1283\n",
      "Epoch 40/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1559 - val_loss: 2.1594\n",
      "Epoch 41/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1199 - val_loss: 2.0450\n",
      "Epoch 42/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1179 - val_loss: 2.1155\n",
      "Epoch 43/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1261 - val_loss: 2.1332\n",
      "Epoch 44/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0876 - val_loss: 2.0087\n",
      "Epoch 45/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0874 - val_loss: 2.0321\n",
      "Epoch 46/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0716 - val_loss: 2.0206\n",
      "Epoch 47/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0660 - val_loss: 2.1897\n",
      "Epoch 48/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0643 - val_loss: 1.9875\n",
      "Epoch 49/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.0692 - val_loss: 2.0310\n",
      "Epoch 50/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0272 - val_loss: 2.3187\n",
      "Epoch 51/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0333 - val_loss: 2.2942\n",
      "Epoch 52/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0402 - val_loss: 2.4872\n",
      "Epoch 53/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0131 - val_loss: 1.9878\n",
      "Epoch 54/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9980 - val_loss: 1.9800\n",
      "Epoch 55/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0233 - val_loss: 2.0857\n",
      "Epoch 56/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9975 - val_loss: 2.0386\n",
      "Epoch 57/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9936 - val_loss: 2.0034\n",
      "Epoch 58/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9959 - val_loss: 2.0409\n",
      "Epoch 59/500\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.9892 - val_loss: 2.0413\n",
      "Epoch 60/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9545 - val_loss: 2.0131\n",
      "Epoch 61/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9740 - val_loss: 1.9688\n",
      "Epoch 62/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9585 - val_loss: 2.0085\n",
      "Epoch 63/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9469 - val_loss: 1.9755\n",
      "Epoch 64/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9489 - val_loss: 1.9086\n",
      "Epoch 65/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9233 - val_loss: 1.8754\n",
      "Epoch 66/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9259 - val_loss: 2.0510\n",
      "Epoch 67/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9184 - val_loss: 1.8889\n",
      "Epoch 68/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8923 - val_loss: 1.8712\n",
      "Epoch 69/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9044 - val_loss: 1.9613\n",
      "Epoch 70/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8936 - val_loss: 1.8758\n",
      "Epoch 71/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8960 - val_loss: 1.8858\n",
      "Epoch 72/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8816 - val_loss: 1.9615\n",
      "Epoch 73/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8756 - val_loss: 1.8564\n",
      "Epoch 74/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8758 - val_loss: 1.9087\n",
      "Epoch 75/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.8760 - val_loss: 1.8454\n",
      "Epoch 76/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8658 - val_loss: 2.0687\n",
      "Epoch 77/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8637 - val_loss: 1.9250\n",
      "Epoch 78/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8498 - val_loss: 1.8532\n",
      "Epoch 79/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8307 - val_loss: 1.8712\n",
      "Epoch 80/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8273 - val_loss: 1.8162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8261 - val_loss: 1.8185\n",
      "Epoch 82/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8214 - val_loss: 1.8539\n",
      "Epoch 83/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8229 - val_loss: 1.9042\n",
      "Epoch 84/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8080 - val_loss: 1.9007\n",
      "Epoch 85/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8383 - val_loss: 1.8416\n",
      "Epoch 86/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8038 - val_loss: 1.8629\n",
      "Epoch 87/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8176 - val_loss: 1.9222\n",
      "Epoch 88/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8151 - val_loss: 1.7634\n",
      "Epoch 89/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7985 - val_loss: 1.8187\n",
      "Epoch 90/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7946 - val_loss: 1.8208\n",
      "Epoch 91/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7866 - val_loss: 1.8300\n",
      "Epoch 92/500\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.7943 - val_loss: 1.7932\n",
      "Epoch 93/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7852 - val_loss: 1.7386\n",
      "Epoch 94/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7887 - val_loss: 1.7974\n",
      "Epoch 95/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7627 - val_loss: 1.8049\n",
      "Epoch 96/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7580 - val_loss: 1.7866\n",
      "Epoch 97/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7705 - val_loss: 1.9086\n",
      "Epoch 98/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7516 - val_loss: 1.9228\n",
      "Epoch 99/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7537 - val_loss: 1.7342\n",
      "Epoch 100/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7477 - val_loss: 1.7845\n",
      "Epoch 101/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7703 - val_loss: 1.8229\n",
      "Epoch 102/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7531 - val_loss: 1.7854\n",
      "Epoch 103/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7517 - val_loss: 1.8602\n",
      "Epoch 104/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7433 - val_loss: 1.7553\n",
      "Epoch 105/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7413 - val_loss: 1.7280\n",
      "Epoch 106/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7469 - val_loss: 1.7724\n",
      "Epoch 107/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7275 - val_loss: 1.7029\n",
      "Epoch 108/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7278 - val_loss: 1.7817\n",
      "Epoch 109/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7247 - val_loss: 1.7219\n",
      "Epoch 110/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7068 - val_loss: 1.6974\n",
      "Epoch 111/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7333 - val_loss: 1.7979\n",
      "Epoch 112/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7030 - val_loss: 1.8320\n",
      "Epoch 113/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7015 - val_loss: 1.7634\n",
      "Epoch 114/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6978 - val_loss: 1.8178\n",
      "Epoch 115/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6949 - val_loss: 1.7249\n",
      "Epoch 116/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7033 - val_loss: 1.6589\n",
      "Epoch 117/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6892 - val_loss: 1.6941\n",
      "Epoch 118/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6849 - val_loss: 1.7624\n",
      "Epoch 119/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6946 - val_loss: 1.7578\n",
      "Epoch 120/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6877 - val_loss: 1.7250\n",
      "Epoch 121/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6815 - val_loss: 1.7067\n",
      "Epoch 122/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6655 - val_loss: 1.6504\n",
      "Epoch 123/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6617 - val_loss: 1.6994\n",
      "Epoch 124/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6655 - val_loss: 1.6465\n",
      "Epoch 125/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.6624 - val_loss: 1.6228\n",
      "Epoch 126/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6693 - val_loss: 1.6753\n",
      "Epoch 127/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6505 - val_loss: 1.6897\n",
      "Epoch 128/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6651 - val_loss: 1.7155\n",
      "Epoch 129/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6629 - val_loss: 1.6770\n",
      "Epoch 130/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6368 - val_loss: 1.7195\n",
      "Epoch 131/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6558 - val_loss: 1.7252\n",
      "Epoch 132/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6406 - val_loss: 1.6520\n",
      "Epoch 133/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6373 - val_loss: 1.8240\n",
      "Epoch 134/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6376 - val_loss: 1.6433\n",
      "Epoch 135/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6404 - val_loss: 1.6579\n",
      "Epoch 136/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6196 - val_loss: 1.6971\n",
      "Epoch 137/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6421 - val_loss: 1.6550\n",
      "Epoch 138/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6234 - val_loss: 1.6402\n",
      "Epoch 139/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6308 - val_loss: 1.6219\n",
      "Epoch 140/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6208 - val_loss: 1.6958\n",
      "Epoch 141/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6259 - val_loss: 1.6824\n",
      "Epoch 142/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6210 - val_loss: 1.6024\n",
      "Epoch 143/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6116 - val_loss: 1.6185\n",
      "Epoch 144/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6145 - val_loss: 1.6002\n",
      "Epoch 145/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6428 - val_loss: 1.6983\n",
      "Epoch 146/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6070 - val_loss: 1.6104\n",
      "Epoch 147/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6096 - val_loss: 1.6528\n",
      "Epoch 148/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5993 - val_loss: 1.5922\n",
      "Epoch 149/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5890 - val_loss: 1.6450\n",
      "Epoch 150/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5942 - val_loss: 1.6326\n",
      "Epoch 151/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5941 - val_loss: 1.6154\n",
      "Epoch 152/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5977 - val_loss: 1.5934\n",
      "Epoch 153/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5917 - val_loss: 1.5810\n",
      "Epoch 154/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5933 - val_loss: 1.5973\n",
      "Epoch 155/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5791 - val_loss: 1.6072\n",
      "Epoch 156/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5764 - val_loss: 1.6096\n",
      "Epoch 157/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5919 - val_loss: 1.6173\n",
      "Epoch 158/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5920 - val_loss: 1.5367\n",
      "Epoch 159/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5645 - val_loss: 1.5841\n",
      "Epoch 160/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5859 - val_loss: 1.6268\n",
      "Epoch 161/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5718 - val_loss: 1.6036\n",
      "Epoch 162/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5756 - val_loss: 1.6194\n",
      "Epoch 163/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5713 - val_loss: 1.5834\n",
      "Epoch 164/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5626 - val_loss: 1.5651\n",
      "Epoch 165/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5555 - val_loss: 1.7095\n",
      "Epoch 166/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5719 - val_loss: 1.6479\n",
      "Epoch 167/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5634 - val_loss: 1.6593\n",
      "Epoch 168/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5654 - val_loss: 1.6008\n",
      "Epoch 169/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5610 - val_loss: 1.5232\n",
      "Epoch 170/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5430 - val_loss: 1.6510\n",
      "Epoch 171/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5617 - val_loss: 1.6344\n",
      "Epoch 172/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5610 - val_loss: 1.6382\n",
      "Epoch 173/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5511 - val_loss: 1.7341\n",
      "Epoch 174/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5472 - val_loss: 1.5775\n",
      "Epoch 175/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5394 - val_loss: 1.6095\n",
      "Epoch 176/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5382 - val_loss: 1.5711\n",
      "Epoch 177/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5324 - val_loss: 1.5284\n",
      "Epoch 178/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5510 - val_loss: 1.5635\n",
      "Epoch 179/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5421 - val_loss: 1.6595\n",
      "Epoch 180/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5477 - val_loss: 1.5702\n",
      "Epoch 181/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5254 - val_loss: 1.5954\n",
      "Epoch 182/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5368 - val_loss: 1.5981\n",
      "Epoch 183/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5324 - val_loss: 1.5596\n",
      "Epoch 184/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5368 - val_loss: 1.5455\n",
      "Epoch 185/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5224 - val_loss: 1.5327\n",
      "Epoch 186/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5272 - val_loss: 1.5984\n",
      "Epoch 187/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5276 - val_loss: 1.5435\n",
      "Epoch 188/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5297 - val_loss: 1.6171\n",
      "Epoch 189/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5225 - val_loss: 1.6354\n",
      "Epoch 190/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5261 - val_loss: 1.5552\n",
      "Epoch 191/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5221 - val_loss: 1.6516\n",
      "Epoch 192/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5175 - val_loss: 1.5461\n",
      "Epoch 193/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5185 - val_loss: 1.5904\n",
      "Epoch 194/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5257 - val_loss: 1.5646\n",
      "Epoch 195/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5133 - val_loss: 1.5906\n",
      "Epoch 196/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5213 - val_loss: 1.5896\n",
      "Epoch 197/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5028 - val_loss: 1.6078\n",
      "Epoch 198/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5156 - val_loss: 1.5314\n",
      "Epoch 199/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5031 - val_loss: 1.6121\n",
      "Epoch 200/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5124 - val_loss: 1.4926\n",
      "Epoch 201/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5073 - val_loss: 1.5315\n",
      "Epoch 202/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4977 - val_loss: 1.5250\n",
      "Epoch 203/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5074 - val_loss: 1.5144\n",
      "Epoch 204/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5185 - val_loss: 1.5023\n",
      "Epoch 205/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4918 - val_loss: 1.5047\n",
      "Epoch 206/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5052 - val_loss: 1.5182\n",
      "Epoch 207/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4813 - val_loss: 1.4973\n",
      "Epoch 208/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4991 - val_loss: 1.5340\n",
      "Epoch 209/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4915 - val_loss: 1.5331\n",
      "Epoch 210/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5044 - val_loss: 1.5555\n",
      "Epoch 211/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5058 - val_loss: 1.5951\n",
      "Epoch 212/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4912 - val_loss: 1.5012\n",
      "Epoch 213/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4925 - val_loss: 1.5066\n",
      "Epoch 214/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4958 - val_loss: 1.5128\n",
      "Epoch 215/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4737 - val_loss: 1.5451\n",
      "Epoch 216/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4939 - val_loss: 1.6037\n",
      "Epoch 217/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4885 - val_loss: 1.5574\n",
      "Epoch 218/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4834 - val_loss: 1.4857\n",
      "Epoch 219/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4793 - val_loss: 1.4741\n",
      "Epoch 220/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4748 - val_loss: 1.4629\n",
      "Epoch 221/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4803 - val_loss: 1.4595\n",
      "Epoch 222/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4870 - val_loss: 1.6281\n",
      "Epoch 223/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4735 - val_loss: 1.4944\n",
      "Epoch 224/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4812 - val_loss: 1.5003\n",
      "Epoch 225/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4705 - val_loss: 1.5284\n",
      "Epoch 226/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4779 - val_loss: 1.5527\n",
      "Epoch 227/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4683 - val_loss: 1.5148\n",
      "Epoch 228/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4589 - val_loss: 1.5917\n",
      "Epoch 229/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4554 - val_loss: 1.5195\n",
      "Epoch 230/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4675 - val_loss: 1.5438\n",
      "Epoch 231/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4717 - val_loss: 1.4545\n",
      "Epoch 232/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4627 - val_loss: 1.5548\n",
      "Epoch 233/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4684 - val_loss: 1.5994\n",
      "Epoch 234/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4594 - val_loss: 1.5611\n",
      "Epoch 235/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4553 - val_loss: 1.4701\n",
      "Epoch 236/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4697 - val_loss: 1.6026\n",
      "Epoch 237/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4550 - val_loss: 1.5205\n",
      "Epoch 238/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4487 - val_loss: 1.5294\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4706 - val_loss: 1.4740\n",
      "Epoch 240/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4573 - val_loss: 1.5395\n",
      "Epoch 241/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4525 - val_loss: 1.4822\n",
      "Epoch 242/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4535 - val_loss: 1.5113\n",
      "Epoch 243/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4563 - val_loss: 1.4768\n",
      "Epoch 244/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4495 - val_loss: 1.4231\n",
      "Epoch 245/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4683 - val_loss: 1.4543\n",
      "Epoch 246/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4552 - val_loss: 1.5437\n",
      "Epoch 247/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4497 - val_loss: 1.4326\n",
      "Epoch 248/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4402 - val_loss: 1.4695\n",
      "Epoch 249/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4369 - val_loss: 1.4806\n",
      "Epoch 250/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4507 - val_loss: 1.4970\n",
      "Epoch 251/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4451 - val_loss: 1.4295\n",
      "Epoch 252/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4485 - val_loss: 1.4590\n",
      "Epoch 253/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4430 - val_loss: 1.4936\n",
      "Epoch 254/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4313 - val_loss: 1.5424\n",
      "Epoch 255/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4460 - val_loss: 1.5616\n",
      "Epoch 256/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4284 - val_loss: 1.5894\n",
      "Epoch 257/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4401 - val_loss: 1.4529\n",
      "Epoch 258/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4308 - val_loss: 1.4265\n",
      "Epoch 259/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4360 - val_loss: 1.4515\n",
      "Epoch 260/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4378 - val_loss: 1.4593\n",
      "Epoch 261/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4406 - val_loss: 1.4760\n",
      "Epoch 262/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4397 - val_loss: 1.5037\n",
      "Epoch 263/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4357 - val_loss: 1.4801\n",
      "Epoch 264/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4235 - val_loss: 1.4376\n",
      "Epoch 265/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4302 - val_loss: 1.4318\n",
      "Epoch 266/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4236 - val_loss: 1.4950\n",
      "Epoch 267/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4465 - val_loss: 1.4895\n",
      "Epoch 268/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4298 - val_loss: 1.4188\n",
      "Epoch 269/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4197 - val_loss: 1.4585\n",
      "Epoch 270/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4258 - val_loss: 1.4805\n",
      "Epoch 271/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4297 - val_loss: 1.4328\n",
      "Epoch 272/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4202 - val_loss: 1.4709\n",
      "Epoch 273/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4256 - val_loss: 1.4191\n",
      "Epoch 274/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4336 - val_loss: 1.5229\n",
      "Epoch 275/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4109 - val_loss: 1.5088\n",
      "Epoch 276/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4274 - val_loss: 1.4232\n",
      "Epoch 277/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4124 - val_loss: 1.4622\n",
      "Epoch 278/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4155 - val_loss: 1.4318\n",
      "Epoch 279/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4141 - val_loss: 1.4102\n",
      "Epoch 280/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4096 - val_loss: 1.4577\n",
      "Epoch 281/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4219 - val_loss: 1.4348\n",
      "Epoch 282/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4253 - val_loss: 1.4322\n",
      "Epoch 283/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4155 - val_loss: 1.4679\n",
      "Epoch 284/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4173 - val_loss: 1.4173\n",
      "Epoch 285/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4187 - val_loss: 1.4561\n",
      "Epoch 286/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4098 - val_loss: 1.3824\n",
      "Epoch 287/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4067 - val_loss: 1.4213\n",
      "Epoch 288/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4140 - val_loss: 1.4358\n",
      "Epoch 289/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4115 - val_loss: 1.4393\n",
      "Epoch 290/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4121 - val_loss: 1.4242\n",
      "Epoch 291/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4105 - val_loss: 1.4370\n",
      "Epoch 292/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4063 - val_loss: 1.4380\n",
      "Epoch 293/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4035 - val_loss: 1.4599\n",
      "Epoch 294/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3950 - val_loss: 1.4188\n",
      "Epoch 295/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4129 - val_loss: 1.5560\n",
      "Epoch 296/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4019 - val_loss: 1.4104\n",
      "Epoch 297/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4049 - val_loss: 1.4470\n",
      "Epoch 298/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4048 - val_loss: 1.4404\n",
      "Epoch 299/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4031 - val_loss: 1.4422\n",
      "Epoch 300/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4042 - val_loss: 1.5183\n",
      "Epoch 301/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4034 - val_loss: 1.4137\n",
      "Epoch 302/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4052 - val_loss: 1.4091\n",
      "Epoch 303/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4051 - val_loss: 1.4357\n",
      "Epoch 304/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4029 - val_loss: 1.4289\n",
      "Epoch 305/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4014 - val_loss: 1.4517\n",
      "Epoch 306/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3954 - val_loss: 1.4048\n",
      "Epoch 307/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3838 - val_loss: 1.4396\n",
      "Epoch 308/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3994 - val_loss: 1.4625\n",
      "Epoch 309/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3831 - val_loss: 1.4855\n",
      "Epoch 310/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3970 - val_loss: 1.4438\n",
      "Epoch 311/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3975 - val_loss: 1.4182\n",
      "Epoch 312/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3782 - val_loss: 1.4729\n",
      "Epoch 313/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3995 - val_loss: 1.4438\n",
      "Epoch 314/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3923 - val_loss: 1.5024\n",
      "Epoch 315/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3936 - val_loss: 1.4223\n",
      "Epoch 316/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3887 - val_loss: 1.4134\n",
      "Epoch 317/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3915 - val_loss: 1.4262\n",
      "Epoch 318/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3963 - val_loss: 1.4529\n",
      "Epoch 319/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3903 - val_loss: 1.4473\n",
      "Epoch 320/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3791 - val_loss: 1.4451\n",
      "Epoch 321/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3836 - val_loss: 1.4476\n",
      "Epoch 322/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3923 - val_loss: 1.4112\n",
      "Epoch 323/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3832 - val_loss: 1.5751\n",
      "Epoch 324/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3905 - val_loss: 1.4006\n",
      "Epoch 325/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3738 - val_loss: 1.4979\n",
      "Epoch 326/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3866 - val_loss: 1.4244\n",
      "Epoch 327/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3813 - val_loss: 1.4742\n",
      "Epoch 328/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3816 - val_loss: 1.4003\n",
      "Epoch 329/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3656 - val_loss: 1.4212\n",
      "Epoch 330/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3816 - val_loss: 1.4144\n",
      "Epoch 331/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3801 - val_loss: 1.4949\n",
      "Epoch 332/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3740 - val_loss: 1.4326\n",
      "Epoch 333/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3858 - val_loss: 1.4234\n",
      "Epoch 334/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3702 - val_loss: 1.4230\n",
      "Epoch 335/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3745 - val_loss: 1.4321\n",
      "Epoch 336/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3799 - val_loss: 1.4751\n",
      "Epoch 337/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3803 - val_loss: 1.4266\n",
      "Epoch 338/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3704 - val_loss: 1.4275\n",
      "Epoch 339/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3760 - val_loss: 1.4052\n",
      "Epoch 340/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3692 - val_loss: 1.4690\n",
      "Epoch 341/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3847 - val_loss: 1.3839\n",
      "Epoch 342/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3779 - val_loss: 1.4473\n",
      "Epoch 343/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3701 - val_loss: 1.4699\n",
      "Epoch 344/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3767 - val_loss: 1.4896\n",
      "Epoch 345/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3756 - val_loss: 1.3668\n",
      "Epoch 346/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3733 - val_loss: 1.3759\n",
      "Epoch 347/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3610 - val_loss: 1.4051\n",
      "Epoch 348/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3634 - val_loss: 1.4837\n",
      "Epoch 349/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3588 - val_loss: 1.4283\n",
      "Epoch 350/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3574 - val_loss: 1.4020\n",
      "Epoch 351/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3912 - val_loss: 1.4278\n",
      "Epoch 352/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3658 - val_loss: 1.4912\n",
      "Epoch 353/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3631 - val_loss: 1.4069\n",
      "Epoch 354/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3625 - val_loss: 1.4259\n",
      "Epoch 355/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3790 - val_loss: 1.3699\n",
      "Epoch 356/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3600 - val_loss: 1.4112\n",
      "Epoch 357/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3717 - val_loss: 1.4263\n",
      "Epoch 358/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3600 - val_loss: 1.3392\n",
      "Epoch 359/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3525 - val_loss: 1.3828\n",
      "Epoch 360/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3751 - val_loss: 1.4458\n",
      "Epoch 361/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3637 - val_loss: 1.3843\n",
      "Epoch 362/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3518 - val_loss: 1.4094\n",
      "Epoch 363/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3654 - val_loss: 1.3937\n",
      "Epoch 364/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3586 - val_loss: 1.3850\n",
      "Epoch 365/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3591 - val_loss: 1.4942\n",
      "Epoch 366/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3674 - val_loss: 1.4255\n",
      "Epoch 367/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3604 - val_loss: 1.4198\n",
      "Epoch 368/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3510 - val_loss: 1.4206\n",
      "Epoch 369/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3573 - val_loss: 1.4095\n",
      "Epoch 370/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3584 - val_loss: 1.3764\n",
      "Epoch 371/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3610 - val_loss: 1.4782\n",
      "Epoch 372/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3525 - val_loss: 1.4356\n",
      "Epoch 373/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3577 - val_loss: 1.3729\n",
      "Epoch 374/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3517 - val_loss: 1.4088\n",
      "Epoch 375/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3594 - val_loss: 1.3718\n",
      "Epoch 376/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3586 - val_loss: 1.3405\n",
      "Epoch 377/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3506 - val_loss: 1.4299\n",
      "Epoch 378/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3548 - val_loss: 1.3746\n",
      "Epoch 379/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3488 - val_loss: 1.4263\n",
      "Epoch 380/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3563 - val_loss: 1.3745\n",
      "Epoch 381/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3415 - val_loss: 1.4362\n",
      "Epoch 382/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3557 - val_loss: 1.4401\n",
      "Epoch 383/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3546 - val_loss: 1.4188\n",
      "Epoch 384/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3487 - val_loss: 1.4038\n",
      "Epoch 385/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3496 - val_loss: 1.3737\n",
      "Epoch 386/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3467 - val_loss: 1.3567\n",
      "Epoch 387/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3487 - val_loss: 1.3988\n",
      "Epoch 388/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3423 - val_loss: 1.3889\n",
      "Epoch 389/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3482 - val_loss: 1.3876\n",
      "Epoch 390/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3457 - val_loss: 1.4101\n",
      "Epoch 391/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3572 - val_loss: 1.4035\n",
      "Epoch 392/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3441 - val_loss: 1.3524\n",
      "Epoch 393/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3401 - val_loss: 1.4139\n",
      "Epoch 394/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3466 - val_loss: 1.4636\n",
      "Epoch 395/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3589 - val_loss: 1.4388\n",
      "Epoch 396/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3412 - val_loss: 1.3422\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3430 - val_loss: 1.3741\n",
      "Epoch 398/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3467 - val_loss: 1.4448\n",
      "Epoch 399/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3389 - val_loss: 1.3756\n",
      "Epoch 400/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3309 - val_loss: 1.3978\n",
      "Epoch 401/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3455 - val_loss: 1.3720\n",
      "Epoch 402/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3305 - val_loss: 1.3765\n",
      "Epoch 403/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3455 - val_loss: 1.3520\n",
      "Epoch 404/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3337 - val_loss: 1.3987\n",
      "Epoch 405/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3396 - val_loss: 1.3620\n",
      "Epoch 406/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3387 - val_loss: 1.3702\n",
      "Epoch 407/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3350 - val_loss: 1.3624\n",
      "Epoch 408/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3278 - val_loss: 1.3639\n",
      "Epoch 409/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3311 - val_loss: 1.3686\n",
      "Epoch 410/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3396 - val_loss: 1.4153\n",
      "Epoch 411/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3565 - val_loss: 1.3962\n",
      "Epoch 412/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3326 - val_loss: 1.3461\n",
      "Epoch 413/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3263 - val_loss: 1.3400\n",
      "Epoch 414/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3273 - val_loss: 1.3416\n",
      "Epoch 415/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3263 - val_loss: 1.3453\n",
      "Epoch 416/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3400 - val_loss: 1.4692\n",
      "Epoch 417/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3335 - val_loss: 1.4094\n",
      "Epoch 418/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3295 - val_loss: 1.3729\n",
      "Epoch 419/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3311 - val_loss: 1.4366\n",
      "Epoch 420/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3386 - val_loss: 1.3205\n",
      "Epoch 421/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3379 - val_loss: 1.3729\n",
      "Epoch 422/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3319 - val_loss: 1.3911\n",
      "Epoch 423/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3315 - val_loss: 1.3581\n",
      "Epoch 424/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3420 - val_loss: 1.3545\n",
      "Epoch 425/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3329 - val_loss: 1.3828\n",
      "Epoch 426/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3333 - val_loss: 1.3945\n",
      "Epoch 427/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3259 - val_loss: 1.3613\n",
      "Epoch 428/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3215 - val_loss: 1.3373\n",
      "Epoch 429/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3358 - val_loss: 1.3961\n",
      "Epoch 430/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3284 - val_loss: 1.3346\n",
      "Epoch 431/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3271 - val_loss: 1.3602\n",
      "Epoch 432/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3180 - val_loss: 1.3792\n",
      "Epoch 433/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3223 - val_loss: 1.3694\n",
      "Epoch 434/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3257 - val_loss: 1.3283\n",
      "Epoch 435/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3227 - val_loss: 1.4302\n",
      "Epoch 436/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3220 - val_loss: 1.3287\n",
      "Epoch 437/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3139 - val_loss: 1.3145\n",
      "Epoch 438/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3315 - val_loss: 1.4376\n",
      "Epoch 439/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3285 - val_loss: 1.3695\n",
      "Epoch 440/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3212 - val_loss: 1.3659\n",
      "Epoch 441/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3238 - val_loss: 1.4206\n",
      "Epoch 442/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3294 - val_loss: 1.3683\n",
      "Epoch 443/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3126 - val_loss: 1.4282\n",
      "Epoch 444/500\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.3309 - val_loss: 1.3311\n",
      "Epoch 445/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3176 - val_loss: 1.3594\n",
      "Epoch 446/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3229 - val_loss: 1.3538\n",
      "Epoch 447/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3195 - val_loss: 1.3933\n",
      "Epoch 448/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3253 - val_loss: 1.3491\n",
      "Epoch 449/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3076 - val_loss: 1.3388\n",
      "Epoch 450/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3256 - val_loss: 1.3192\n",
      "Epoch 451/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3165 - val_loss: 1.3802\n",
      "Epoch 452/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3218 - val_loss: 1.3607\n",
      "Epoch 453/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3158 - val_loss: 1.4207\n",
      "Epoch 454/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3294 - val_loss: 1.3654\n",
      "Epoch 455/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3147 - val_loss: 1.3583\n",
      "Epoch 456/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3075 - val_loss: 1.3445\n",
      "Epoch 457/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3152 - val_loss: 1.3186\n",
      "Epoch 458/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3109 - val_loss: 1.3702\n",
      "Epoch 459/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3121 - val_loss: 1.4111\n",
      "Epoch 460/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3095 - val_loss: 1.4093\n",
      "Epoch 461/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3147 - val_loss: 1.3446\n",
      "Epoch 462/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3068 - val_loss: 1.3297\n",
      "Epoch 463/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3110 - val_loss: 1.3473\n",
      "Epoch 464/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3183 - val_loss: 1.3382\n",
      "Epoch 465/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3175 - val_loss: 1.3612\n",
      "Epoch 466/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3059 - val_loss: 1.3759\n",
      "Epoch 467/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3067 - val_loss: 1.3662\n",
      "Epoch 468/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3221 - val_loss: 1.3742\n",
      "Epoch 469/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3036 - val_loss: 1.3465\n",
      "Epoch 470/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3080 - val_loss: 1.3012\n",
      "Epoch 471/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3112 - val_loss: 1.3201\n",
      "Epoch 472/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3254 - val_loss: 1.3677\n",
      "Epoch 473/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3182 - val_loss: 1.3318\n",
      "Epoch 474/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3138 - val_loss: 1.3704\n",
      "Epoch 475/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3071 - val_loss: 1.4023\n",
      "Epoch 476/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3045 - val_loss: 1.3512\n",
      "Epoch 477/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3140 - val_loss: 1.3282\n",
      "Epoch 478/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3024 - val_loss: 1.3432\n",
      "Epoch 479/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3182 - val_loss: 1.4625\n",
      "Epoch 480/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3097 - val_loss: 1.3888\n",
      "Epoch 481/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2963 - val_loss: 1.2987\n",
      "Epoch 482/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3075 - val_loss: 1.2980\n",
      "Epoch 483/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3035 - val_loss: 1.4366\n",
      "Epoch 484/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3015 - val_loss: 1.3842\n",
      "Epoch 485/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3030 - val_loss: 1.3556\n",
      "Epoch 486/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3129 - val_loss: 1.3928\n",
      "Epoch 487/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2985 - val_loss: 1.3580\n",
      "Epoch 488/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3022 - val_loss: 1.4581\n",
      "Epoch 489/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2976 - val_loss: 1.3303\n",
      "Epoch 490/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3059 - val_loss: 1.3922\n",
      "Epoch 491/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3145 - val_loss: 1.3700\n",
      "Epoch 492/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3077 - val_loss: 1.3801\n",
      "Epoch 493/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3052 - val_loss: 1.3113\n",
      "Epoch 494/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2966 - val_loss: 1.4349\n",
      "Epoch 495/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2906 - val_loss: 1.3827\n",
      "Epoch 496/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2926 - val_loss: 1.3289\n",
      "Epoch 497/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3034 - val_loss: 1.3180\n",
      "Epoch 498/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3136 - val_loss: 1.3619\n",
      "Epoch 499/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2977 - val_loss: 1.3420\n",
      "Epoch 500/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2973 - val_loss: 1.4627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4626626916044165\n",
      "0.969285996531378\n",
      "Epoch 1/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 12.1535 - val_loss: 5.9690\n",
      "Epoch 2/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 6.3841 - val_loss: 7.3649\n",
      "Epoch 3/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 4.6589 - val_loss: 7.5215\n",
      "Epoch 4/500\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 4.8815 - val_loss: 4.2616\n",
      "Epoch 5/500\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 4.3696 - val_loss: 9.3889\n",
      "Epoch 6/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 4.4851 - val_loss: 4.3932\n",
      "Epoch 7/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 4.7940 - val_loss: 3.5759\n",
      "Epoch 8/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 4.6123 - val_loss: 3.8566\n",
      "Epoch 9/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 3.6124 - val_loss: 3.2641\n",
      "Epoch 10/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.5432 - val_loss: 4.3438\n",
      "Epoch 11/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.5602 - val_loss: 3.4580\n",
      "Epoch 12/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.4201 - val_loss: 3.1721\n",
      "Epoch 13/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.4343 - val_loss: 4.7514\n",
      "Epoch 14/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.2598 - val_loss: 3.0339\n",
      "Epoch 15/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 3.0667 - val_loss: 3.2983\n",
      "Epoch 16/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.1747 - val_loss: 2.9520\n",
      "Epoch 17/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.9949 - val_loss: 2.8474\n",
      "Epoch 18/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 3.0406 - val_loss: 2.9264\n",
      "Epoch 19/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.9786 - val_loss: 3.3611\n",
      "Epoch 20/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.8443 - val_loss: 2.7011\n",
      "Epoch 21/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.7857 - val_loss: 2.6174\n",
      "Epoch 22/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.7485 - val_loss: 2.8866\n",
      "Epoch 23/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.7519 - val_loss: 2.5775\n",
      "Epoch 24/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.7083 - val_loss: 2.5175\n",
      "Epoch 25/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.7112 - val_loss: 2.5541\n",
      "Epoch 26/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 2.6335 - val_loss: 2.5820\n",
      "Epoch 27/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.6136 - val_loss: 2.7225\n",
      "Epoch 28/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.5912 - val_loss: 2.5318\n",
      "Epoch 29/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.5651 - val_loss: 2.4088\n",
      "Epoch 30/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.5395 - val_loss: 2.6002\n",
      "Epoch 31/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.4963 - val_loss: 2.5685\n",
      "Epoch 32/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.5120 - val_loss: 2.3581\n",
      "Epoch 33/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.4623 - val_loss: 2.6680\n",
      "Epoch 34/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.4375 - val_loss: 2.3397\n",
      "Epoch 35/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4499 - val_loss: 2.3750\n",
      "Epoch 36/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4141 - val_loss: 2.3338\n",
      "Epoch 37/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.3902 - val_loss: 2.5128\n",
      "Epoch 38/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.4241 - val_loss: 2.2778\n",
      "Epoch 39/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.3565 - val_loss: 2.3415\n",
      "Epoch 40/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.3437 - val_loss: 2.4807\n",
      "Epoch 41/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.3166 - val_loss: 2.3068\n",
      "Epoch 42/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.3022 - val_loss: 2.2425\n",
      "Epoch 43/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2838 - val_loss: 2.2951\n",
      "Epoch 44/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 2.2813 - val_loss: 2.7103\n",
      "Epoch 45/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.2581 - val_loss: 2.2170\n",
      "Epoch 46/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.2791 - val_loss: 2.1894\n",
      "Epoch 47/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.2489 - val_loss: 2.6720\n",
      "Epoch 48/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.2173 - val_loss: 2.1582\n",
      "Epoch 49/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.2185 - val_loss: 2.2312\n",
      "Epoch 50/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.2126 - val_loss: 2.1704\n",
      "Epoch 51/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.2175 - val_loss: 2.1522\n",
      "Epoch 52/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.1537 - val_loss: 2.0912\n",
      "Epoch 53/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.1419 - val_loss: 2.3312\n",
      "Epoch 54/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.1593 - val_loss: 2.1759\n",
      "Epoch 55/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.1056 - val_loss: 2.1530\n",
      "Epoch 56/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.1246 - val_loss: 2.0662\n",
      "Epoch 57/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.1106 - val_loss: 2.0496\n",
      "Epoch 58/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0850 - val_loss: 2.0725\n",
      "Epoch 59/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0755 - val_loss: 2.1064\n",
      "Epoch 60/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0833 - val_loss: 2.2188\n",
      "Epoch 61/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 2.0409 - val_loss: 2.0769\n",
      "Epoch 62/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0498 - val_loss: 2.0552\n",
      "Epoch 63/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0712 - val_loss: 2.0368\n",
      "Epoch 64/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0262 - val_loss: 1.9925\n",
      "Epoch 65/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0086 - val_loss: 2.0602\n",
      "Epoch 66/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0190 - val_loss: 1.9740\n",
      "Epoch 67/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0106 - val_loss: 1.9507\n",
      "Epoch 68/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0088 - val_loss: 1.9958\n",
      "Epoch 69/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.0042 - val_loss: 2.0018\n",
      "Epoch 70/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9930 - val_loss: 1.9769\n",
      "Epoch 71/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9721 - val_loss: 2.0539\n",
      "Epoch 72/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9927 - val_loss: 1.9667\n",
      "Epoch 73/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9747 - val_loss: 1.9910\n",
      "Epoch 74/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9987 - val_loss: 1.9318\n",
      "Epoch 75/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9446 - val_loss: 1.8941\n",
      "Epoch 76/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.9607 - val_loss: 1.9457\n",
      "Epoch 77/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9691 - val_loss: 1.8972\n",
      "Epoch 78/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9514 - val_loss: 1.9275\n",
      "Epoch 79/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.9367 - val_loss: 1.8893\n",
      "Epoch 80/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9291 - val_loss: 1.9577\n",
      "Epoch 81/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.9333 - val_loss: 2.0686\n",
      "Epoch 82/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.9246 - val_loss: 1.8792\n",
      "Epoch 83/500\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.8982 - val_loss: 1.8785\n",
      "Epoch 84/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8969 - val_loss: 1.9733\n",
      "Epoch 85/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8992 - val_loss: 1.9446\n",
      "Epoch 86/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.9015 - val_loss: 2.0625\n",
      "Epoch 87/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8886 - val_loss: 1.8888\n",
      "Epoch 88/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8953 - val_loss: 1.9258\n",
      "Epoch 89/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8804 - val_loss: 1.8548\n",
      "Epoch 90/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8926 - val_loss: 1.8802\n",
      "Epoch 91/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8654 - val_loss: 1.8954\n",
      "Epoch 92/500\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.8516 - val_loss: 1.9425\n",
      "Epoch 93/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8607 - val_loss: 1.9858\n",
      "Epoch 94/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8396 - val_loss: 1.8619\n",
      "Epoch 95/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8673 - val_loss: 1.8543\n",
      "Epoch 96/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.8413 - val_loss: 1.8480\n",
      "Epoch 97/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8390 - val_loss: 1.8895\n",
      "Epoch 98/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8128 - val_loss: 1.8053\n",
      "Epoch 99/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8245 - val_loss: 1.8451\n",
      "Epoch 100/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8180 - val_loss: 1.9137\n",
      "Epoch 101/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.8049 - val_loss: 1.7732\n",
      "Epoch 102/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8159 - val_loss: 1.8644\n",
      "Epoch 103/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7990 - val_loss: 1.8149\n",
      "Epoch 104/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7989 - val_loss: 1.7648\n",
      "Epoch 105/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7914 - val_loss: 1.7875\n",
      "Epoch 106/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7775 - val_loss: 1.7848\n",
      "Epoch 107/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7752 - val_loss: 1.7171\n",
      "Epoch 108/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7620 - val_loss: 1.7730\n",
      "Epoch 109/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7832 - val_loss: 1.7628\n",
      "Epoch 110/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7714 - val_loss: 1.8586\n",
      "Epoch 111/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7725 - val_loss: 1.7412\n",
      "Epoch 112/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7717 - val_loss: 1.8395\n",
      "Epoch 113/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.7642 - val_loss: 1.8589\n",
      "Epoch 114/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7402 - val_loss: 1.8142\n",
      "Epoch 115/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7479 - val_loss: 1.6854\n",
      "Epoch 116/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7328 - val_loss: 1.9046\n",
      "Epoch 117/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7279 - val_loss: 1.7474\n",
      "Epoch 118/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7310 - val_loss: 1.7042\n",
      "Epoch 119/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7248 - val_loss: 1.7370\n",
      "Epoch 120/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7146 - val_loss: 1.7743\n",
      "Epoch 121/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7203 - val_loss: 1.7985\n",
      "Epoch 122/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7303 - val_loss: 1.7564\n",
      "Epoch 123/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7132 - val_loss: 1.7025\n",
      "Epoch 124/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7088 - val_loss: 1.7824\n",
      "Epoch 125/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7026 - val_loss: 1.7044\n",
      "Epoch 126/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7178 - val_loss: 1.7502\n",
      "Epoch 127/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7193 - val_loss: 1.7392\n",
      "Epoch 128/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6958 - val_loss: 1.7233\n",
      "Epoch 129/500\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7048 - val_loss: 1.7088\n",
      "Epoch 130/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.6909 - val_loss: 1.7570\n",
      "Epoch 131/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.6900 - val_loss: 1.6683\n",
      "Epoch 132/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6888 - val_loss: 1.7554\n",
      "Epoch 133/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7028 - val_loss: 1.7717\n",
      "Epoch 134/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6733 - val_loss: 1.6784\n",
      "Epoch 135/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6901 - val_loss: 1.6668\n",
      "Epoch 136/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6805 - val_loss: 1.6833\n",
      "Epoch 137/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6929 - val_loss: 1.6600\n",
      "Epoch 138/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6830 - val_loss: 1.7001\n",
      "Epoch 139/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6597 - val_loss: 1.6327\n",
      "Epoch 140/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6733 - val_loss: 1.7460\n",
      "Epoch 141/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6754 - val_loss: 1.7146\n",
      "Epoch 142/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6651 - val_loss: 1.6859\n",
      "Epoch 143/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6544 - val_loss: 1.6495\n",
      "Epoch 144/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6552 - val_loss: 1.6607\n",
      "Epoch 145/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6543 - val_loss: 1.8045\n",
      "Epoch 146/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.6601 - val_loss: 1.7008\n",
      "Epoch 147/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.6644 - val_loss: 1.6428\n",
      "Epoch 148/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6365 - val_loss: 1.6550\n",
      "Epoch 149/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6750 - val_loss: 1.7422\n",
      "Epoch 150/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6398 - val_loss: 1.6594\n",
      "Epoch 151/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6289 - val_loss: 1.7547\n",
      "Epoch 152/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6482 - val_loss: 1.6511\n",
      "Epoch 153/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6457 - val_loss: 1.6612\n",
      "Epoch 154/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6300 - val_loss: 1.6497\n",
      "Epoch 155/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6327 - val_loss: 1.6374\n",
      "Epoch 156/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6418 - val_loss: 1.6568\n",
      "Epoch 157/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6293 - val_loss: 1.6611\n",
      "Epoch 158/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6316 - val_loss: 1.6402\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6382 - val_loss: 1.6329\n",
      "Epoch 160/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6301 - val_loss: 1.6922\n",
      "Epoch 161/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6472 - val_loss: 1.6894\n",
      "Epoch 162/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.6176 - val_loss: 1.7318\n",
      "Epoch 163/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6188 - val_loss: 1.8103\n",
      "Epoch 164/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6337 - val_loss: 1.6134\n",
      "Epoch 165/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6247 - val_loss: 1.6178\n",
      "Epoch 166/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6164 - val_loss: 1.6629\n",
      "Epoch 167/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6011 - val_loss: 1.7519\n",
      "Epoch 168/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6068 - val_loss: 1.6056\n",
      "Epoch 169/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6087 - val_loss: 1.6993\n",
      "Epoch 170/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6013 - val_loss: 1.6960\n",
      "Epoch 171/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6089 - val_loss: 1.6723\n",
      "Epoch 172/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6065 - val_loss: 1.5991\n",
      "Epoch 173/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5992 - val_loss: 1.7226\n",
      "Epoch 174/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6079 - val_loss: 1.6162\n",
      "Epoch 175/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6008 - val_loss: 1.5930\n",
      "Epoch 176/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5898 - val_loss: 1.6940\n",
      "Epoch 177/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.5862 - val_loss: 1.6200\n",
      "Epoch 178/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.5944 - val_loss: 1.6216\n",
      "Epoch 179/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5982 - val_loss: 1.6055\n",
      "Epoch 180/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5805 - val_loss: 1.7012\n",
      "Epoch 181/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5932 - val_loss: 1.6301\n",
      "Epoch 182/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5815 - val_loss: 1.6418\n",
      "Epoch 183/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5740 - val_loss: 1.5975\n",
      "Epoch 184/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5849 - val_loss: 1.5867\n",
      "Epoch 185/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5889 - val_loss: 1.6573\n",
      "Epoch 186/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5702 - val_loss: 1.6634\n",
      "Epoch 187/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5778 - val_loss: 1.6182\n",
      "Epoch 188/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5625 - val_loss: 1.5968\n",
      "Epoch 189/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5644 - val_loss: 1.5864\n",
      "Epoch 190/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5771 - val_loss: 1.6287\n",
      "Epoch 191/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5605 - val_loss: 1.6017\n",
      "Epoch 192/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5743 - val_loss: 1.5688\n",
      "Epoch 193/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.5698 - val_loss: 1.6102\n",
      "Epoch 194/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.5560 - val_loss: 1.6627\n",
      "Epoch 195/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5665 - val_loss: 1.6194\n",
      "Epoch 196/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5644 - val_loss: 1.6534\n",
      "Epoch 197/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5539 - val_loss: 1.6626\n",
      "Epoch 198/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5541 - val_loss: 1.5825\n",
      "Epoch 199/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5466 - val_loss: 1.6291\n",
      "Epoch 200/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5643 - val_loss: 1.5569\n",
      "Epoch 201/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5491 - val_loss: 1.5430\n",
      "Epoch 202/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5406 - val_loss: 1.6527\n",
      "Epoch 203/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5513 - val_loss: 1.5775\n",
      "Epoch 204/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5474 - val_loss: 1.5791\n",
      "Epoch 205/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5444 - val_loss: 1.6214\n",
      "Epoch 206/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5548 - val_loss: 1.5538\n",
      "Epoch 207/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5321 - val_loss: 1.6421\n",
      "Epoch 208/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5431 - val_loss: 1.5308\n",
      "Epoch 209/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.5480 - val_loss: 1.5362\n",
      "Epoch 210/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5474 - val_loss: 1.5686\n",
      "Epoch 211/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5369 - val_loss: 1.6286\n",
      "Epoch 212/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5217 - val_loss: 1.5196\n",
      "Epoch 213/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5352 - val_loss: 1.5613\n",
      "Epoch 214/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5382 - val_loss: 1.5632\n",
      "Epoch 215/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5263 - val_loss: 1.5275\n",
      "Epoch 216/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5257 - val_loss: 1.6058\n",
      "Epoch 217/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5298 - val_loss: 1.5773\n",
      "Epoch 218/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5401 - val_loss: 1.5902\n",
      "Epoch 219/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5551 - val_loss: 1.5853\n",
      "Epoch 220/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5315 - val_loss: 1.5677\n",
      "Epoch 221/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5176 - val_loss: 1.5595\n",
      "Epoch 222/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5153 - val_loss: 1.5278\n",
      "Epoch 223/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5142 - val_loss: 1.5883\n",
      "Epoch 224/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5292 - val_loss: 1.5378\n",
      "Epoch 225/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.5196 - val_loss: 1.5138\n",
      "Epoch 226/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.5127 - val_loss: 1.5336\n",
      "Epoch 227/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5124 - val_loss: 1.5859\n",
      "Epoch 228/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5319 - val_loss: 1.5335\n",
      "Epoch 229/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5138 - val_loss: 1.5316\n",
      "Epoch 230/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5195 - val_loss: 1.5645\n",
      "Epoch 231/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5221 - val_loss: 1.5349\n",
      "Epoch 232/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5015 - val_loss: 1.5250\n",
      "Epoch 233/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5035 - val_loss: 1.5516\n",
      "Epoch 234/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5100 - val_loss: 1.5080\n",
      "Epoch 235/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4984 - val_loss: 1.5098\n",
      "Epoch 236/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5106 - val_loss: 1.4950\n",
      "Epoch 237/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4968 - val_loss: 1.5943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5036 - val_loss: 1.6061\n",
      "Epoch 239/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5112 - val_loss: 1.5392\n",
      "Epoch 240/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.5008 - val_loss: 1.5285\n",
      "Epoch 241/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.4989 - val_loss: 1.5303\n",
      "Epoch 242/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4980 - val_loss: 1.5294\n",
      "Epoch 243/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5064 - val_loss: 1.6876\n",
      "Epoch 244/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5075 - val_loss: 1.5859\n",
      "Epoch 245/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4931 - val_loss: 1.4966\n",
      "Epoch 246/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.4915 - val_loss: 1.5135\n",
      "Epoch 247/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4985 - val_loss: 1.5431\n",
      "Epoch 248/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4987 - val_loss: 1.5617\n",
      "Epoch 249/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5086 - val_loss: 1.5893\n",
      "Epoch 250/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4911 - val_loss: 1.5125\n",
      "Epoch 251/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4913 - val_loss: 1.5188\n",
      "Epoch 252/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4877 - val_loss: 1.5426\n",
      "Epoch 253/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4789 - val_loss: 1.5401\n",
      "Epoch 254/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4901 - val_loss: 1.4920\n",
      "Epoch 255/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4822 - val_loss: 1.4819\n",
      "Epoch 256/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.4915 - val_loss: 1.5248\n",
      "Epoch 257/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4803 - val_loss: 1.4945\n",
      "Epoch 258/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4836 - val_loss: 1.5306\n",
      "Epoch 259/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4964 - val_loss: 1.5463\n",
      "Epoch 260/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4821 - val_loss: 1.5455\n",
      "Epoch 261/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4776 - val_loss: 1.5530\n",
      "Epoch 262/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4824 - val_loss: 1.5353\n",
      "Epoch 263/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4777 - val_loss: 1.4931\n",
      "Epoch 264/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4650 - val_loss: 1.4907\n",
      "Epoch 265/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4806 - val_loss: 1.5856\n",
      "Epoch 266/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4729 - val_loss: 1.5562\n",
      "Epoch 267/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4855 - val_loss: 1.4934\n",
      "Epoch 268/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4777 - val_loss: 1.5116\n",
      "Epoch 269/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4612 - val_loss: 1.5140\n",
      "Epoch 270/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4774 - val_loss: 1.5998\n",
      "Epoch 271/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4567 - val_loss: 1.5218\n",
      "Epoch 272/500\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.4740 - val_loss: 1.4975\n",
      "Epoch 273/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4693 - val_loss: 1.5900\n",
      "Epoch 274/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4676 - val_loss: 1.4701\n",
      "Epoch 275/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4609 - val_loss: 1.4657\n",
      "Epoch 276/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4713 - val_loss: 1.5006\n",
      "Epoch 277/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4693 - val_loss: 1.5136\n",
      "Epoch 278/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4685 - val_loss: 1.5125\n",
      "Epoch 279/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4563 - val_loss: 1.4542\n",
      "Epoch 280/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4608 - val_loss: 1.4772\n",
      "Epoch 281/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4724 - val_loss: 1.4592\n",
      "Epoch 282/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4490 - val_loss: 1.5018\n",
      "Epoch 283/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4581 - val_loss: 1.4699\n",
      "Epoch 284/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4653 - val_loss: 1.4920\n",
      "Epoch 285/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4561 - val_loss: 1.4863\n",
      "Epoch 286/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4458 - val_loss: 1.4537\n",
      "Epoch 287/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.4592 - val_loss: 1.5412\n",
      "Epoch 288/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.4498 - val_loss: 1.5456\n",
      "Epoch 289/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4421 - val_loss: 1.5084\n",
      "Epoch 290/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4507 - val_loss: 1.4508\n",
      "Epoch 291/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4441 - val_loss: 1.4824\n",
      "Epoch 292/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4484 - val_loss: 1.4257\n",
      "Epoch 293/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4399 - val_loss: 1.4775\n",
      "Epoch 294/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4465 - val_loss: 1.5154\n",
      "Epoch 295/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4357 - val_loss: 1.4689\n",
      "Epoch 296/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4351 - val_loss: 1.4805\n",
      "Epoch 297/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4550 - val_loss: 1.4607\n",
      "Epoch 298/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4410 - val_loss: 1.5101\n",
      "Epoch 299/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4381 - val_loss: 1.4843\n",
      "Epoch 300/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4503 - val_loss: 1.4569\n",
      "Epoch 301/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4464 - val_loss: 1.4894\n",
      "Epoch 302/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4393 - val_loss: 1.4859\n",
      "Epoch 303/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.4379 - val_loss: 1.5017\n",
      "Epoch 304/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4418 - val_loss: 1.5342\n",
      "Epoch 305/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4322 - val_loss: 1.4820\n",
      "Epoch 306/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4367 - val_loss: 1.4703\n",
      "Epoch 307/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4226 - val_loss: 1.5382\n",
      "Epoch 308/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4331 - val_loss: 1.5163\n",
      "Epoch 309/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4384 - val_loss: 1.5176\n",
      "Epoch 310/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4335 - val_loss: 1.4923\n",
      "Epoch 311/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4293 - val_loss: 1.4776\n",
      "Epoch 312/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4263 - val_loss: 1.4513\n",
      "Epoch 313/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4330 - val_loss: 1.5660\n",
      "Epoch 314/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4342 - val_loss: 1.4555\n",
      "Epoch 315/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4285 - val_loss: 1.4310\n",
      "Epoch 316/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4204 - val_loss: 1.4502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4189 - val_loss: 1.4814\n",
      "Epoch 318/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4229 - val_loss: 1.4855\n",
      "Epoch 319/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.4252 - val_loss: 1.6670\n",
      "Epoch 320/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4263 - val_loss: 1.4545\n",
      "Epoch 321/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4291 - val_loss: 1.4550\n",
      "Epoch 322/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4148 - val_loss: 1.4808\n",
      "Epoch 323/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4174 - val_loss: 1.5601\n",
      "Epoch 324/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4212 - val_loss: 1.4726\n",
      "Epoch 325/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4282 - val_loss: 1.5132\n",
      "Epoch 326/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4236 - val_loss: 1.4520\n",
      "Epoch 327/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4117 - val_loss: 1.5173\n",
      "Epoch 328/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4075 - val_loss: 1.4738\n",
      "Epoch 329/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4300 - val_loss: 1.4414\n",
      "Epoch 330/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4157 - val_loss: 1.4667\n",
      "Epoch 331/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4210 - val_loss: 1.5101\n",
      "Epoch 332/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4096 - val_loss: 1.4639\n",
      "Epoch 333/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4097 - val_loss: 1.4094\n",
      "Epoch 334/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4103 - val_loss: 1.4715\n",
      "Epoch 335/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.4114 - val_loss: 1.5112\n",
      "Epoch 336/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4138 - val_loss: 1.4670\n",
      "Epoch 337/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4109 - val_loss: 1.4860\n",
      "Epoch 338/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4166 - val_loss: 1.4472\n",
      "Epoch 339/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4062 - val_loss: 1.4224\n",
      "Epoch 340/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4159 - val_loss: 1.4627\n",
      "Epoch 341/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3972 - val_loss: 1.4446\n",
      "Epoch 342/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4059 - val_loss: 1.4166\n",
      "Epoch 343/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4083 - val_loss: 1.4887\n",
      "Epoch 344/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3972 - val_loss: 1.3976\n",
      "Epoch 345/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4070 - val_loss: 1.4527\n",
      "Epoch 346/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4033 - val_loss: 1.4195\n",
      "Epoch 347/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4066 - val_loss: 1.4729\n",
      "Epoch 348/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4009 - val_loss: 1.4789\n",
      "Epoch 349/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4087 - val_loss: 1.4289\n",
      "Epoch 350/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3975 - val_loss: 1.4514\n",
      "Epoch 351/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3993 - val_loss: 1.4978\n",
      "Epoch 352/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3999 - val_loss: 1.4349\n",
      "Epoch 353/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3994 - val_loss: 1.4755\n",
      "Epoch 354/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3888 - val_loss: 1.4564\n",
      "Epoch 355/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3926 - val_loss: 1.4450\n",
      "Epoch 356/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3932 - val_loss: 1.4292\n",
      "Epoch 357/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3919 - val_loss: 1.5101\n",
      "Epoch 358/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4063 - val_loss: 1.4509\n",
      "Epoch 359/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3999 - val_loss: 1.4321\n",
      "Epoch 360/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3965 - val_loss: 1.4571\n",
      "Epoch 361/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3902 - val_loss: 1.4342\n",
      "Epoch 362/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3907 - val_loss: 1.4260\n",
      "Epoch 363/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3802 - val_loss: 1.4580\n",
      "Epoch 364/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3887 - val_loss: 1.4084\n",
      "Epoch 365/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3995 - val_loss: 1.4603\n",
      "Epoch 366/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3897 - val_loss: 1.4086\n",
      "Epoch 367/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.4105 - val_loss: 1.5000\n",
      "Epoch 368/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3974 - val_loss: 1.4385\n",
      "Epoch 369/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3787 - val_loss: 1.4074\n",
      "Epoch 370/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3899 - val_loss: 1.4169\n",
      "Epoch 371/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3728 - val_loss: 1.4159\n",
      "Epoch 372/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3858 - val_loss: 1.5093\n",
      "Epoch 373/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4005 - val_loss: 1.4039\n",
      "Epoch 374/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3890 - val_loss: 1.5023\n",
      "Epoch 375/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3861 - val_loss: 1.3891\n",
      "Epoch 376/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3895 - val_loss: 1.4431\n",
      "Epoch 377/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3736 - val_loss: 1.3725\n",
      "Epoch 378/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3986 - val_loss: 1.3890\n",
      "Epoch 379/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3859 - val_loss: 1.4098\n",
      "Epoch 380/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3800 - val_loss: 1.3742\n",
      "Epoch 381/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3815 - val_loss: 1.4414\n",
      "Epoch 382/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3835 - val_loss: 1.4208\n",
      "Epoch 383/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3993 - val_loss: 1.3982\n",
      "Epoch 384/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3704 - val_loss: 1.3884\n",
      "Epoch 385/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3825 - val_loss: 1.3748\n",
      "Epoch 386/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3710 - val_loss: 1.4064\n",
      "Epoch 387/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3734 - val_loss: 1.4107\n",
      "Epoch 388/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3738 - val_loss: 1.3969\n",
      "Epoch 389/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3736 - val_loss: 1.4367\n",
      "Epoch 390/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3777 - val_loss: 1.4173\n",
      "Epoch 391/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3723 - val_loss: 1.5118\n",
      "Epoch 392/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3831 - val_loss: 1.3960\n",
      "Epoch 393/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3804 - val_loss: 1.4083\n",
      "Epoch 394/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3853 - val_loss: 1.4351\n",
      "Epoch 395/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3678 - val_loss: 1.4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3714 - val_loss: 1.4592\n",
      "Epoch 397/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3644 - val_loss: 1.3899\n",
      "Epoch 398/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3649 - val_loss: 1.4189\n",
      "Epoch 399/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3647 - val_loss: 1.3942\n",
      "Epoch 400/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3724 - val_loss: 1.4028\n",
      "Epoch 401/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3558 - val_loss: 1.4652\n",
      "Epoch 402/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3699 - val_loss: 1.4063\n",
      "Epoch 403/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3769 - val_loss: 1.4310\n",
      "Epoch 404/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3754 - val_loss: 1.3996\n",
      "Epoch 405/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3600 - val_loss: 1.3776\n",
      "Epoch 406/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3681 - val_loss: 1.4798\n",
      "Epoch 407/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3713 - val_loss: 1.4757\n",
      "Epoch 408/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3698 - val_loss: 1.4207\n",
      "Epoch 409/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3527 - val_loss: 1.4278\n",
      "Epoch 410/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3665 - val_loss: 1.3803\n",
      "Epoch 411/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3566 - val_loss: 1.4167\n",
      "Epoch 412/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3559 - val_loss: 1.4701\n",
      "Epoch 413/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3665 - val_loss: 1.3885\n",
      "Epoch 414/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3614 - val_loss: 1.4747\n",
      "Epoch 415/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3545 - val_loss: 1.3813\n",
      "Epoch 416/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3513 - val_loss: 1.3920\n",
      "Epoch 417/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3658 - val_loss: 1.3725\n",
      "Epoch 418/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3452 - val_loss: 1.3850\n",
      "Epoch 419/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3585 - val_loss: 1.4108\n",
      "Epoch 420/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3609 - val_loss: 1.4394\n",
      "Epoch 421/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3550 - val_loss: 1.3954\n",
      "Epoch 422/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3625 - val_loss: 1.3814\n",
      "Epoch 423/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3611 - val_loss: 1.4360\n",
      "Epoch 424/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3604 - val_loss: 1.4706\n",
      "Epoch 425/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3596 - val_loss: 1.4335\n",
      "Epoch 426/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3565 - val_loss: 1.4168\n",
      "Epoch 427/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3515 - val_loss: 1.4363\n",
      "Epoch 428/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3654 - val_loss: 1.4502\n",
      "Epoch 429/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3608 - val_loss: 1.3657\n",
      "Epoch 430/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3494 - val_loss: 1.3873\n",
      "Epoch 431/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3482 - val_loss: 1.3895\n",
      "Epoch 432/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3469 - val_loss: 1.4192\n",
      "Epoch 433/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3424 - val_loss: 1.4342\n",
      "Epoch 434/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3467 - val_loss: 1.4135\n",
      "Epoch 435/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3530 - val_loss: 1.4082\n",
      "Epoch 436/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3627 - val_loss: 1.4232\n",
      "Epoch 437/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3416 - val_loss: 1.3835\n",
      "Epoch 438/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3474 - val_loss: 1.5117\n",
      "Epoch 439/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3530 - val_loss: 1.4305\n",
      "Epoch 440/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3510 - val_loss: 1.4546\n",
      "Epoch 441/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3394 - val_loss: 1.3364\n",
      "Epoch 442/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3460 - val_loss: 1.3625\n",
      "Epoch 443/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3363 - val_loss: 1.4038\n",
      "Epoch 444/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3434 - val_loss: 1.3563\n",
      "Epoch 445/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3367 - val_loss: 1.3914\n",
      "Epoch 446/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3380 - val_loss: 1.3579\n",
      "Epoch 447/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3524 - val_loss: 1.3960\n",
      "Epoch 448/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3460 - val_loss: 1.4226\n",
      "Epoch 449/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3438 - val_loss: 1.4958\n",
      "Epoch 450/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3479 - val_loss: 1.3673\n",
      "Epoch 451/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3454 - val_loss: 1.3840\n",
      "Epoch 452/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3289 - val_loss: 1.3653\n",
      "Epoch 453/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3384 - val_loss: 1.4116\n",
      "Epoch 454/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3464 - val_loss: 1.3582\n",
      "Epoch 455/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3410 - val_loss: 1.4222\n",
      "Epoch 456/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3426 - val_loss: 1.3574\n",
      "Epoch 457/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3491 - val_loss: 1.4076\n",
      "Epoch 458/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3351 - val_loss: 1.3857\n",
      "Epoch 459/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3309 - val_loss: 1.4555\n",
      "Epoch 460/500\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3577 - val_loss: 1.4624\n",
      "Epoch 461/500\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.3361 - val_loss: 1.4084\n",
      "Epoch 462/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3272 - val_loss: 1.3537\n",
      "Epoch 463/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3365 - val_loss: 1.3858\n",
      "Epoch 464/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3341 - val_loss: 1.4054\n",
      "Epoch 465/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3399 - val_loss: 1.4108\n",
      "Epoch 466/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3263 - val_loss: 1.3278\n",
      "Epoch 467/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3372 - val_loss: 1.4080\n",
      "Epoch 468/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3273 - val_loss: 1.3953\n",
      "Epoch 469/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3316 - val_loss: 1.4021\n",
      "Epoch 470/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3307 - val_loss: 1.3596\n",
      "Epoch 471/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3342 - val_loss: 1.4371\n",
      "Epoch 472/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3300 - val_loss: 1.5148\n",
      "Epoch 473/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3371 - val_loss: 1.3820\n",
      "Epoch 474/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3262 - val_loss: 1.3651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3320 - val_loss: 1.3907\n",
      "Epoch 476/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3254 - val_loss: 1.3327\n",
      "Epoch 477/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3343 - val_loss: 1.4162\n",
      "Epoch 478/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3391 - val_loss: 1.4487\n",
      "Epoch 479/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3329 - val_loss: 1.3530\n",
      "Epoch 480/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3294 - val_loss: 1.3956\n",
      "Epoch 481/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3331 - val_loss: 1.3494\n",
      "Epoch 482/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3235 - val_loss: 1.4033\n",
      "Epoch 483/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3275 - val_loss: 1.3756\n",
      "Epoch 484/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3262 - val_loss: 1.3422\n",
      "Epoch 485/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3264 - val_loss: 1.4046\n",
      "Epoch 486/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3286 - val_loss: 1.3705\n",
      "Epoch 487/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3170 - val_loss: 1.3789\n",
      "Epoch 488/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3387 - val_loss: 1.3122\n",
      "Epoch 489/500\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3179 - val_loss: 1.3587\n",
      "Epoch 490/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3304 - val_loss: 1.3679\n",
      "Epoch 491/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3251 - val_loss: 1.4109\n",
      "Epoch 492/500\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3260 - val_loss: 1.3826\n",
      "Epoch 493/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3154 - val_loss: 1.3618\n",
      "Epoch 494/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3246 - val_loss: 1.3622\n",
      "Epoch 495/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3296 - val_loss: 1.4115\n",
      "Epoch 496/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3285 - val_loss: 1.3638\n",
      "Epoch 497/500\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3249 - val_loss: 1.3539\n",
      "Epoch 498/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3262 - val_loss: 1.3434\n",
      "Epoch 499/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3267 - val_loss: 1.3640\n",
      "Epoch 500/500\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3140 - val_loss: 1.3798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3797889843336213\n",
      "0.9720065688362883\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 12.9497 - val_loss: 16.3766\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 6.9623 - val_loss: 4.8636\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 5.1911 - val_loss: 4.5141\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.8028 - val_loss: 5.9760\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.5447 - val_loss: 3.9113\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 4.5615 - val_loss: 3.9475\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 5.0026 - val_loss: 4.0380\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 4.2196 - val_loss: 3.8333\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.1736 - val_loss: 4.5117\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.9696 - val_loss: 3.6548\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.6927 - val_loss: 3.3306\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.5591 - val_loss: 3.2457\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.6598 - val_loss: 3.1984\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.7946 - val_loss: 5.4848\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.2422 - val_loss: 3.4211\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.6501 - val_loss: 3.2408\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.4063 - val_loss: 5.7195\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.4922 - val_loss: 3.3969\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.2454 - val_loss: 3.5304\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.2461 - val_loss: 2.9953\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.0914 - val_loss: 2.8867\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 3.0297 - val_loss: 3.3014\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.0475 - val_loss: 2.8775\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.0394 - val_loss: 2.7154\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.9752 - val_loss: 2.6884\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.8548 - val_loss: 2.7001\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7732 - val_loss: 2.6488\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.8539 - val_loss: 2.8481\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7530 - val_loss: 2.6655\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.6517 - val_loss: 2.6735\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7691 - val_loss: 2.7294\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7219 - val_loss: 2.6094\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.6219 - val_loss: 2.4404\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.6099 - val_loss: 2.7796\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.5923 - val_loss: 2.6291\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5114 - val_loss: 2.5186\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5566 - val_loss: 2.4335\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 2.5256 - val_loss: 2.3620\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4506 - val_loss: 2.4801\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4527 - val_loss: 2.4797\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4414 - val_loss: 2.5768\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4316 - val_loss: 2.4414\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4570 - val_loss: 2.3971\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3981 - val_loss: 2.4144\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3592 - val_loss: 2.4721\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3606 - val_loss: 2.5480\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3340 - val_loss: 2.7448\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3380 - val_loss: 2.3923\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.3376 - val_loss: 2.2661\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3064 - val_loss: 2.2167\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2873 - val_loss: 2.2443\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2786 - val_loss: 2.3265\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3134 - val_loss: 2.3973\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 2.2145 - val_loss: 2.2643\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.2614 - val_loss: 2.1984\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2412 - val_loss: 2.2260\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2098 - val_loss: 2.2938\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2349 - val_loss: 2.1201\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1895 - val_loss: 2.2121\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1796 - val_loss: 2.1250\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1556 - val_loss: 2.1357\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1408 - val_loss: 2.1161\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1585 - val_loss: 2.1993\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1166 - val_loss: 2.1013\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0922 - val_loss: 2.0881\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0995 - val_loss: 2.0699\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0722 - val_loss: 2.0925\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0807 - val_loss: 2.0260\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1125 - val_loss: 2.0289\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 2.0504 - val_loss: 2.0068\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.0589 - val_loss: 1.9735\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0548 - val_loss: 1.9451\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0147 - val_loss: 1.9931\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9908 - val_loss: 2.0731\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9911 - val_loss: 2.1129\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9925 - val_loss: 1.9912\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9775 - val_loss: 2.0119\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.9860 - val_loss: 1.9718\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9803 - val_loss: 1.9270\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.9698 - val_loss: 1.9813\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9529 - val_loss: 2.0435\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9337 - val_loss: 2.0277\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9606 - val_loss: 1.9189\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9356 - val_loss: 1.9261\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9208 - val_loss: 2.0033\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.8989 - val_loss: 1.8771\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9133 - val_loss: 1.8925\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8957 - val_loss: 1.9400\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9115 - val_loss: 2.0623\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9032 - val_loss: 1.9311\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8892 - val_loss: 1.8593\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8732 - val_loss: 1.9869\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8648 - val_loss: 1.8401\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8528 - val_loss: 1.8636\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8761 - val_loss: 1.8416\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8637 - val_loss: 1.8357\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8507 - val_loss: 1.8731\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.8606 - val_loss: 1.9212\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.8508 - val_loss: 1.9281\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8603 - val_loss: 1.8355\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8345 - val_loss: 1.8591\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.8323 - val_loss: 1.8072\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.8216 - val_loss: 1.8373\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8194 - val_loss: 1.8063\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8101 - val_loss: 1.7798\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7899 - val_loss: 1.8575\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8059 - val_loss: 1.7966\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7730 - val_loss: 1.7234\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7791 - val_loss: 1.7724\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7595 - val_loss: 1.7415\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7778 - val_loss: 1.9274\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7657 - val_loss: 1.7774\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7675 - val_loss: 1.8753\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7655 - val_loss: 1.7479\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7502 - val_loss: 1.7464\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7455 - val_loss: 1.9060\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7526 - val_loss: 1.7901\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.7481 - val_loss: 1.7327\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7369 - val_loss: 1.7339\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7274 - val_loss: 1.7183\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7145 - val_loss: 1.7861\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7468 - val_loss: 1.7291\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7236 - val_loss: 1.6955\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7107 - val_loss: 1.7408\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7273 - val_loss: 1.7363\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7042 - val_loss: 1.6896\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6937 - val_loss: 1.6779\n",
      "Epoch 128/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6978 - val_loss: 1.7558\n",
      "Epoch 129/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6919 - val_loss: 1.7357\n",
      "Epoch 130/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6913 - val_loss: 1.7349\n",
      "Epoch 131/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6846 - val_loss: 1.6560\n",
      "Epoch 132/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6653 - val_loss: 1.6649\n",
      "Epoch 133/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6954 - val_loss: 1.6993\n",
      "Epoch 134/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6749 - val_loss: 1.7169\n",
      "Epoch 135/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.6679 - val_loss: 1.6926\n",
      "Epoch 136/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6860 - val_loss: 1.6548\n",
      "Epoch 137/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6553 - val_loss: 1.6852\n",
      "Epoch 138/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6559 - val_loss: 1.6903\n",
      "Epoch 139/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6648 - val_loss: 1.6923\n",
      "Epoch 140/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6506 - val_loss: 1.6513\n",
      "Epoch 141/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6475 - val_loss: 1.6643\n",
      "Epoch 142/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6309 - val_loss: 1.6517\n",
      "Epoch 143/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6450 - val_loss: 1.6484\n",
      "Epoch 144/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6218 - val_loss: 1.6479\n",
      "Epoch 145/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6188 - val_loss: 1.6400\n",
      "Epoch 146/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6307 - val_loss: 1.6684\n",
      "Epoch 147/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6301 - val_loss: 1.7022\n",
      "Epoch 148/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6072 - val_loss: 1.6348\n",
      "Epoch 149/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6176 - val_loss: 1.7281\n",
      "Epoch 150/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6026 - val_loss: 1.6025\n",
      "Epoch 151/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.6062 - val_loss: 1.6654\n",
      "Epoch 152/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6208 - val_loss: 1.5975\n",
      "Epoch 153/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5916 - val_loss: 1.6036\n",
      "Epoch 154/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6087 - val_loss: 1.7110\n",
      "Epoch 155/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6001 - val_loss: 1.5758\n",
      "Epoch 156/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5766 - val_loss: 1.6431\n",
      "Epoch 157/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5868 - val_loss: 1.5914\n",
      "Epoch 158/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5943 - val_loss: 1.6303\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5797 - val_loss: 1.6388\n",
      "Epoch 160/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5902 - val_loss: 1.5750\n",
      "Epoch 161/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5743 - val_loss: 1.5717\n",
      "Epoch 162/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5793 - val_loss: 1.6252\n",
      "Epoch 163/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5773 - val_loss: 1.6271\n",
      "Epoch 164/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5797 - val_loss: 1.6062\n",
      "Epoch 165/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5879 - val_loss: 1.5720\n",
      "Epoch 166/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5640 - val_loss: 1.5874\n",
      "Epoch 167/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5589 - val_loss: 1.5821\n",
      "Epoch 168/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5863 - val_loss: 1.5941\n",
      "Epoch 169/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5504 - val_loss: 1.6724\n",
      "Epoch 170/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5658 - val_loss: 1.6750\n",
      "Epoch 171/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5688 - val_loss: 1.6094\n",
      "Epoch 172/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5441 - val_loss: 1.6167\n",
      "Epoch 173/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5521 - val_loss: 1.5692\n",
      "Epoch 174/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5413 - val_loss: 1.5490\n",
      "Epoch 175/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5310 - val_loss: 1.5456\n",
      "Epoch 176/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5431 - val_loss: 1.6035\n",
      "Epoch 177/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5410 - val_loss: 1.6096\n",
      "Epoch 178/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5297 - val_loss: 1.7340\n",
      "Epoch 179/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5386 - val_loss: 1.5812\n",
      "Epoch 180/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5443 - val_loss: 1.5601\n",
      "Epoch 181/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5550 - val_loss: 1.6480\n",
      "Epoch 182/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5269 - val_loss: 1.5432\n",
      "Epoch 183/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.5307 - val_loss: 1.6095\n",
      "Epoch 184/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5298 - val_loss: 1.5845\n",
      "Epoch 185/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.5309 - val_loss: 1.6379\n",
      "Epoch 186/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5265 - val_loss: 1.5711\n",
      "Epoch 187/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.5359 - val_loss: 1.5758\n",
      "Epoch 188/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5460 - val_loss: 1.5664\n",
      "Epoch 189/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.5220 - val_loss: 1.5125\n",
      "Epoch 190/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4939 - val_loss: 1.5063\n",
      "Epoch 191/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5210 - val_loss: 1.5531\n",
      "Epoch 192/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5159 - val_loss: 1.5338\n",
      "Epoch 193/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5163 - val_loss: 1.5064\n",
      "Epoch 194/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5048 - val_loss: 1.5044\n",
      "Epoch 195/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4959 - val_loss: 1.5698\n",
      "Epoch 196/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.5082 - val_loss: 1.5185\n",
      "Epoch 197/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.5162 - val_loss: 1.5135\n",
      "Epoch 198/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.5062 - val_loss: 1.5869\n",
      "Epoch 199/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4991 - val_loss: 1.5612\n",
      "Epoch 200/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4832 - val_loss: 1.5282\n",
      "Epoch 201/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5101 - val_loss: 1.5965\n",
      "Epoch 202/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.5018 - val_loss: 1.5478\n",
      "Epoch 203/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4973 - val_loss: 1.5265\n",
      "Epoch 204/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.5051 - val_loss: 1.5294\n",
      "Epoch 205/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4912 - val_loss: 1.5595\n",
      "Epoch 206/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 1.4972 - val_loss: 1.5296\n",
      "Epoch 207/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4925 - val_loss: 1.5236\n",
      "Epoch 208/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4828 - val_loss: 1.4925\n",
      "Epoch 209/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4926 - val_loss: 1.5648\n",
      "Epoch 210/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 1.4792 - val_loss: 1.4789\n",
      "Epoch 211/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 1.4842 - val_loss: 1.7265\n",
      "Epoch 212/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4792 - val_loss: 1.5161\n",
      "Epoch 213/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4897 - val_loss: 1.5006\n",
      "Epoch 214/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4672 - val_loss: 1.4906\n",
      "Epoch 215/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4756 - val_loss: 1.5544\n",
      "Epoch 216/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4618 - val_loss: 1.4842\n",
      "Epoch 217/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4693 - val_loss: 1.5003\n",
      "Epoch 218/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4765 - val_loss: 1.5471\n",
      "Epoch 219/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4814 - val_loss: 1.5687\n",
      "Epoch 220/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4571 - val_loss: 1.5284\n",
      "Epoch 221/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4591 - val_loss: 1.5170\n",
      "Epoch 222/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4822 - val_loss: 1.5117\n",
      "Epoch 223/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 1.4609 - val_loss: 1.5115\n",
      "Epoch 224/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4611 - val_loss: 1.4805\n",
      "Epoch 225/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4451 - val_loss: 1.5278\n",
      "Epoch 226/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4603 - val_loss: 1.5105\n",
      "Epoch 227/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4664 - val_loss: 1.4908\n",
      "Epoch 228/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4563 - val_loss: 1.4792\n",
      "Epoch 229/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4491 - val_loss: 1.4864\n",
      "Epoch 230/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 1.4652 - val_loss: 1.5014\n",
      "Epoch 231/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4517 - val_loss: 1.4753\n",
      "Epoch 232/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4540 - val_loss: 1.4628\n",
      "Epoch 233/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4537 - val_loss: 1.4858\n",
      "Epoch 234/500\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 1.4369 - val_loss: 1.4663\n",
      "Epoch 235/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 1.4641 - val_loss: 1.4909\n",
      "Epoch 236/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 1.4516 - val_loss: 1.5855\n",
      "Epoch 237/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.4420 - val_loss: 1.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4513 - val_loss: 1.4762\n",
      "Epoch 239/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4473 - val_loss: 1.4253\n",
      "Epoch 240/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4352 - val_loss: 1.4737\n",
      "Epoch 241/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4309 - val_loss: 1.4380\n",
      "Epoch 242/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4459 - val_loss: 1.4694\n",
      "Epoch 243/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4286 - val_loss: 1.5265\n",
      "Epoch 244/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4516 - val_loss: 1.5662\n",
      "Epoch 245/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4229 - val_loss: 1.5147\n",
      "Epoch 246/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4441 - val_loss: 1.5301\n",
      "Epoch 247/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4176 - val_loss: 1.4476\n",
      "Epoch 248/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4346 - val_loss: 1.4308\n",
      "Epoch 249/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4267 - val_loss: 1.4230\n",
      "Epoch 250/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4278 - val_loss: 1.4498\n",
      "Epoch 251/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4222 - val_loss: 1.5310\n",
      "Epoch 252/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4165 - val_loss: 1.4317\n",
      "Epoch 253/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4434 - val_loss: 1.4897\n",
      "Epoch 254/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4238 - val_loss: 1.5518\n",
      "Epoch 255/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4210 - val_loss: 1.4685\n",
      "Epoch 256/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4062 - val_loss: 1.4573\n",
      "Epoch 257/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4115 - val_loss: 1.4082\n",
      "Epoch 258/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4200 - val_loss: 1.5104\n",
      "Epoch 259/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4103 - val_loss: 1.4400\n",
      "Epoch 260/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4054 - val_loss: 1.4547\n",
      "Epoch 261/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4134 - val_loss: 1.4311\n",
      "Epoch 262/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4029 - val_loss: 1.4342\n",
      "Epoch 263/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4159 - val_loss: 1.4302\n",
      "Epoch 264/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4118 - val_loss: 1.4529\n",
      "Epoch 265/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4132 - val_loss: 1.4262\n",
      "Epoch 266/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4029 - val_loss: 1.4266\n",
      "Epoch 267/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4098 - val_loss: 1.4324\n",
      "Epoch 268/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4129 - val_loss: 1.4453\n",
      "Epoch 269/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4014 - val_loss: 1.4467\n",
      "Epoch 270/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4093 - val_loss: 1.4788\n",
      "Epoch 271/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3995 - val_loss: 1.4715\n",
      "Epoch 272/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3974 - val_loss: 1.4513\n",
      "Epoch 273/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3978 - val_loss: 1.4122\n",
      "Epoch 274/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3883 - val_loss: 1.4528\n",
      "Epoch 275/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3915 - val_loss: 1.4514\n",
      "Epoch 276/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3948 - val_loss: 1.4651\n",
      "Epoch 277/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4036 - val_loss: 1.3947\n",
      "Epoch 278/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3892 - val_loss: 1.3958\n",
      "Epoch 279/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3780 - val_loss: 1.4359\n",
      "Epoch 280/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3807 - val_loss: 1.3938\n",
      "Epoch 281/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3774 - val_loss: 1.4773\n",
      "Epoch 282/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3816 - val_loss: 1.4439\n",
      "Epoch 283/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3824 - val_loss: 1.3860\n",
      "Epoch 284/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3823 - val_loss: 1.4402\n",
      "Epoch 285/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3821 - val_loss: 1.4398\n",
      "Epoch 286/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3815 - val_loss: 1.3835\n",
      "Epoch 287/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3721 - val_loss: 1.4584\n",
      "Epoch 288/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3872 - val_loss: 1.4796\n",
      "Epoch 289/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3725 - val_loss: 1.4262\n",
      "Epoch 290/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3806 - val_loss: 1.4345\n",
      "Epoch 291/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3602 - val_loss: 1.4008\n",
      "Epoch 292/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3701 - val_loss: 1.5684\n",
      "Epoch 293/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3839 - val_loss: 1.3619\n",
      "Epoch 294/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3704 - val_loss: 1.4481\n",
      "Epoch 295/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3703 - val_loss: 1.4228\n",
      "Epoch 296/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3764 - val_loss: 1.4116\n",
      "Epoch 297/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3754 - val_loss: 1.3784\n",
      "Epoch 298/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3812 - val_loss: 1.3926\n",
      "Epoch 299/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3710 - val_loss: 1.4730\n",
      "Epoch 300/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.3658 - val_loss: 1.4920\n",
      "Epoch 301/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3661 - val_loss: 1.4323\n",
      "Epoch 302/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3723 - val_loss: 1.4239\n",
      "Epoch 303/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3638 - val_loss: 1.4127\n",
      "Epoch 304/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3718 - val_loss: 1.3923\n",
      "Epoch 305/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3641 - val_loss: 1.4027\n",
      "Epoch 306/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3781 - val_loss: 1.4336\n",
      "Epoch 307/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3563 - val_loss: 1.3998\n",
      "Epoch 308/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3455 - val_loss: 1.4160\n",
      "Epoch 309/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3706 - val_loss: 1.4424\n",
      "Epoch 310/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3716 - val_loss: 1.4074\n",
      "Epoch 311/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3584 - val_loss: 1.3355\n",
      "Epoch 312/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3481 - val_loss: 1.4031\n",
      "Epoch 313/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3556 - val_loss: 1.3916\n",
      "Epoch 314/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3484 - val_loss: 1.3841\n",
      "Epoch 315/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3715 - val_loss: 1.3760\n",
      "Epoch 316/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3510 - val_loss: 1.4154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3483 - val_loss: 1.4962\n",
      "Epoch 318/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3417 - val_loss: 1.3920\n",
      "Epoch 319/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3559 - val_loss: 1.4048\n",
      "Epoch 320/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3478 - val_loss: 1.4002\n",
      "Epoch 321/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3571 - val_loss: 1.4257\n",
      "Epoch 322/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3451 - val_loss: 1.5031\n",
      "Epoch 323/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3378 - val_loss: 1.3998\n",
      "Epoch 324/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3345 - val_loss: 1.3674\n",
      "Epoch 325/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3564 - val_loss: 1.3681\n",
      "Epoch 326/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3562 - val_loss: 1.4105\n",
      "Epoch 327/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3556 - val_loss: 1.4136\n",
      "Epoch 328/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3511 - val_loss: 1.3812\n",
      "Epoch 329/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3467 - val_loss: 1.4614\n",
      "Epoch 330/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3538 - val_loss: 1.3575\n",
      "Epoch 331/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3518 - val_loss: 1.3561\n",
      "Epoch 332/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3400 - val_loss: 1.3985\n",
      "Epoch 333/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3338 - val_loss: 1.3705\n",
      "Epoch 334/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3310 - val_loss: 1.3642\n",
      "Epoch 335/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3318 - val_loss: 1.4492\n",
      "Epoch 336/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3458 - val_loss: 1.3725\n",
      "Epoch 337/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3527 - val_loss: 1.3612\n",
      "Epoch 338/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3284 - val_loss: 1.3333\n",
      "Epoch 339/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3384 - val_loss: 1.4282\n",
      "Epoch 340/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3334 - val_loss: 1.3711\n",
      "Epoch 341/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3484 - val_loss: 1.4153\n",
      "Epoch 342/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3290 - val_loss: 1.4215\n",
      "Epoch 343/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3272 - val_loss: 1.4115\n",
      "Epoch 344/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3318 - val_loss: 1.3524\n",
      "Epoch 345/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3408 - val_loss: 1.3677\n",
      "Epoch 346/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3276 - val_loss: 1.3500\n",
      "Epoch 347/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3270 - val_loss: 1.3849\n",
      "Epoch 348/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3358 - val_loss: 1.4087\n",
      "Epoch 349/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3220 - val_loss: 1.4562\n",
      "Epoch 350/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3285 - val_loss: 1.3607\n",
      "Epoch 351/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3427 - val_loss: 1.3926\n",
      "Epoch 352/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3221 - val_loss: 1.3633\n",
      "Epoch 353/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3275 - val_loss: 1.3826\n",
      "Epoch 354/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3285 - val_loss: 1.3583\n",
      "Epoch 355/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3233 - val_loss: 1.3396\n",
      "Epoch 356/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3268 - val_loss: 1.3882\n",
      "Epoch 357/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3349 - val_loss: 1.3698\n",
      "Epoch 358/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3204 - val_loss: 1.3413\n",
      "Epoch 359/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3054 - val_loss: 1.3809\n",
      "Epoch 360/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3208 - val_loss: 1.3427\n",
      "Epoch 361/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3106 - val_loss: 1.3907\n",
      "Epoch 362/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3181 - val_loss: 1.3923\n",
      "Epoch 363/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3134 - val_loss: 1.4175\n",
      "Epoch 364/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3220 - val_loss: 1.3218\n",
      "Epoch 365/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3112 - val_loss: 1.3938\n",
      "Epoch 366/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3118 - val_loss: 1.3432\n",
      "Epoch 367/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3068 - val_loss: 1.3780\n",
      "Epoch 368/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3270 - val_loss: 1.3373\n",
      "Epoch 369/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3216 - val_loss: 1.4263\n",
      "Epoch 370/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3151 - val_loss: 1.3660\n",
      "Epoch 371/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3065 - val_loss: 1.3645\n",
      "Epoch 372/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3084 - val_loss: 1.3490\n",
      "Epoch 373/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3087 - val_loss: 1.4448\n",
      "Epoch 374/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3224 - val_loss: 1.4024\n",
      "Epoch 375/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3084 - val_loss: 1.3818\n",
      "Epoch 376/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3164 - val_loss: 1.3573\n",
      "Epoch 377/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3121 - val_loss: 1.3535\n",
      "Epoch 378/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3049 - val_loss: 1.3321\n",
      "Epoch 379/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3084 - val_loss: 1.3963\n",
      "Epoch 380/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3097 - val_loss: 1.3616\n",
      "Epoch 381/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3138 - val_loss: 1.3769\n",
      "Epoch 382/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3101 - val_loss: 1.3331\n",
      "Epoch 383/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3088 - val_loss: 1.3536\n",
      "Epoch 384/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3087 - val_loss: 1.3664\n",
      "Epoch 385/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3022 - val_loss: 1.4782\n",
      "Epoch 386/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2950 - val_loss: 1.3892\n",
      "Epoch 387/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3127 - val_loss: 1.3555\n",
      "Epoch 388/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.3018 - val_loss: 1.4399\n",
      "Epoch 389/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3026 - val_loss: 1.3257\n",
      "Epoch 390/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3097 - val_loss: 1.3841\n",
      "Epoch 391/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3079 - val_loss: 1.3319\n",
      "Epoch 392/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2965 - val_loss: 1.3568\n",
      "Epoch 393/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2979 - val_loss: 1.4000\n",
      "Epoch 394/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2981 - val_loss: 1.3824\n",
      "Epoch 395/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2971 - val_loss: 1.4146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2897 - val_loss: 1.3484\n",
      "Epoch 397/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2944 - val_loss: 1.3342\n",
      "Epoch 398/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3001 - val_loss: 1.3912\n",
      "Epoch 399/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2862 - val_loss: 1.3838\n",
      "Epoch 400/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3076 - val_loss: 1.3440\n",
      "Epoch 401/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2966 - val_loss: 1.3537\n",
      "Epoch 402/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3089 - val_loss: 1.4744\n",
      "Epoch 403/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2880 - val_loss: 1.3640\n",
      "Epoch 404/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2962 - val_loss: 1.4299\n",
      "Epoch 405/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2823 - val_loss: 1.3797\n",
      "Epoch 406/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2922 - val_loss: 1.3095\n",
      "Epoch 407/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2892 - val_loss: 1.3550\n",
      "Epoch 408/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2871 - val_loss: 1.3435\n",
      "Epoch 409/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2967 - val_loss: 1.3980\n",
      "Epoch 410/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2964 - val_loss: 1.3328\n",
      "Epoch 411/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2800 - val_loss: 1.3965\n",
      "Epoch 412/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2954 - val_loss: 1.3309\n",
      "Epoch 413/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2946 - val_loss: 1.3232\n",
      "Epoch 414/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2859 - val_loss: 1.4115\n",
      "Epoch 415/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2916 - val_loss: 1.3611\n",
      "Epoch 416/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2779 - val_loss: 1.4511\n",
      "Epoch 417/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2835 - val_loss: 1.3481\n",
      "Epoch 418/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2783 - val_loss: 1.3433\n",
      "Epoch 419/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2780 - val_loss: 1.3581\n",
      "Epoch 420/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2955 - val_loss: 1.3481\n",
      "Epoch 421/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2882 - val_loss: 1.3842\n",
      "Epoch 422/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2775 - val_loss: 1.3711\n",
      "Epoch 423/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2730 - val_loss: 1.3300\n",
      "Epoch 424/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2830 - val_loss: 1.3653\n",
      "Epoch 425/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2849 - val_loss: 1.3582\n",
      "Epoch 426/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2751 - val_loss: 1.3395\n",
      "Epoch 427/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2920 - val_loss: 1.3407\n",
      "Epoch 428/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2753 - val_loss: 1.3288\n",
      "Epoch 429/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2818 - val_loss: 1.3140\n",
      "Epoch 430/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3017 - val_loss: 1.3222\n",
      "Epoch 431/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2757 - val_loss: 1.3158\n",
      "Epoch 432/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2837 - val_loss: 1.2894\n",
      "Epoch 433/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2764 - val_loss: 1.3262\n",
      "Epoch 434/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2776 - val_loss: 1.2842\n",
      "Epoch 435/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2666 - val_loss: 1.3181\n",
      "Epoch 436/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2679 - val_loss: 1.2818\n",
      "Epoch 437/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2722 - val_loss: 1.4033\n",
      "Epoch 438/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2742 - val_loss: 1.3211\n",
      "Epoch 439/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2683 - val_loss: 1.3164\n",
      "Epoch 440/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2803 - val_loss: 1.3002\n",
      "Epoch 441/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2712 - val_loss: 1.3223\n",
      "Epoch 442/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2781 - val_loss: 1.3218\n",
      "Epoch 443/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2740 - val_loss: 1.3565\n",
      "Epoch 444/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2711 - val_loss: 1.3068\n",
      "Epoch 445/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2689 - val_loss: 1.2680\n",
      "Epoch 446/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2846 - val_loss: 1.3525\n",
      "Epoch 447/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2737 - val_loss: 1.2924\n",
      "Epoch 448/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2758 - val_loss: 1.3237\n",
      "Epoch 449/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2570 - val_loss: 1.2868\n",
      "Epoch 450/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2662 - val_loss: 1.2663\n",
      "Epoch 451/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2670 - val_loss: 1.2926\n",
      "Epoch 452/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2683 - val_loss: 1.3136\n",
      "Epoch 453/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2709 - val_loss: 1.3274\n",
      "Epoch 454/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2730 - val_loss: 1.3330\n",
      "Epoch 455/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2699 - val_loss: 1.2955\n",
      "Epoch 456/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2440 - val_loss: 1.2813\n",
      "Epoch 457/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2613 - val_loss: 1.4274\n",
      "Epoch 458/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2722 - val_loss: 1.3862\n",
      "Epoch 459/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2723 - val_loss: 1.3204\n",
      "Epoch 460/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2748 - val_loss: 1.3925\n",
      "Epoch 461/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2752 - val_loss: 1.3282\n",
      "Epoch 462/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2652 - val_loss: 1.3284\n",
      "Epoch 463/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2700 - val_loss: 1.3488\n",
      "Epoch 464/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2610 - val_loss: 1.3678\n",
      "Epoch 465/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2944 - val_loss: 1.3578\n",
      "Epoch 466/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2634 - val_loss: 1.3120\n",
      "Epoch 467/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2471 - val_loss: 1.3226\n",
      "Epoch 468/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2532 - val_loss: 1.2829\n",
      "Epoch 469/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2630 - val_loss: 1.3164\n",
      "Epoch 470/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2612 - val_loss: 1.2899\n",
      "Epoch 471/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2505 - val_loss: 1.3134\n",
      "Epoch 472/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2493 - val_loss: 1.2997\n",
      "Epoch 473/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2603 - val_loss: 1.2870\n",
      "Epoch 474/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2509 - val_loss: 1.3186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2615 - val_loss: 1.2807\n",
      "Epoch 476/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2655 - val_loss: 1.2875\n",
      "Epoch 477/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2597 - val_loss: 1.2611\n",
      "Epoch 478/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2449 - val_loss: 1.2742\n",
      "Epoch 479/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2565 - val_loss: 1.2871\n",
      "Epoch 480/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2592 - val_loss: 1.3488\n",
      "Epoch 481/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2520 - val_loss: 1.2823\n",
      "Epoch 482/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2564 - val_loss: 1.3235\n",
      "Epoch 483/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2628 - val_loss: 1.3080\n",
      "Epoch 484/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2550 - val_loss: 1.3053\n",
      "Epoch 485/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2583 - val_loss: 1.3536\n",
      "Epoch 486/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2498 - val_loss: 1.3742\n",
      "Epoch 487/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2618 - val_loss: 1.2997\n",
      "Epoch 488/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2582 - val_loss: 1.3124\n",
      "Epoch 489/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2569 - val_loss: 1.3528\n",
      "Epoch 490/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2345 - val_loss: 1.3011\n",
      "Epoch 491/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2539 - val_loss: 1.3320\n",
      "Epoch 492/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2448 - val_loss: 1.3401\n",
      "Epoch 493/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2476 - val_loss: 1.2830\n",
      "Epoch 494/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2537 - val_loss: 1.2926\n",
      "Epoch 495/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2640 - val_loss: 1.3551\n",
      "Epoch 496/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2505 - val_loss: 1.3311\n",
      "Epoch 497/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2431 - val_loss: 1.2947\n",
      "Epoch 498/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2366 - val_loss: 1.2803\n",
      "Epoch 499/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2364 - val_loss: 1.3059\n",
      "Epoch 500/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2644 - val_loss: 1.2859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2859053921528094\n",
      "0.975503762091122\n",
      "Epoch 1/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 6.3345 - val_loss: 4.3762\n",
      "Epoch 2/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 4.5065 - val_loss: 5.3379\n",
      "Epoch 3/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 4.0916 - val_loss: 5.6172\n",
      "Epoch 4/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 3.3162 - val_loss: 3.0279\n",
      "Epoch 5/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 3.0742 - val_loss: 2.9794\n",
      "Epoch 6/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.8605 - val_loss: 2.6298\n",
      "Epoch 7/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.7444 - val_loss: 2.7325\n",
      "Epoch 8/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.6503 - val_loss: 2.5648\n",
      "Epoch 9/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.5750 - val_loss: 2.7638\n",
      "Epoch 10/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.5528 - val_loss: 2.3743\n",
      "Epoch 11/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.4990 - val_loss: 2.3779\n",
      "Epoch 12/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.4954 - val_loss: 2.4352\n",
      "Epoch 13/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.4530 - val_loss: 3.0125\n",
      "Epoch 14/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.4576 - val_loss: 2.4445\n",
      "Epoch 15/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.4319 - val_loss: 2.2877\n",
      "Epoch 16/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.3943 - val_loss: 2.5412\n",
      "Epoch 17/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.3793 - val_loss: 2.2309\n",
      "Epoch 18/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.3460 - val_loss: 2.3516\n",
      "Epoch 19/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.3335 - val_loss: 2.2092\n",
      "Epoch 20/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2959 - val_loss: 2.3643\n",
      "Epoch 21/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2565 - val_loss: 2.3626\n",
      "Epoch 22/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2520 - val_loss: 2.1770\n",
      "Epoch 23/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2150 - val_loss: 2.2334\n",
      "Epoch 24/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1948 - val_loss: 2.1098\n",
      "Epoch 25/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1839 - val_loss: 2.1771\n",
      "Epoch 26/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1698 - val_loss: 2.0967\n",
      "Epoch 27/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1640 - val_loss: 2.0772\n",
      "Epoch 28/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1407 - val_loss: 2.1360\n",
      "Epoch 29/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1503 - val_loss: 2.2924\n",
      "Epoch 30/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1250 - val_loss: 2.0307\n",
      "Epoch 31/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1222 - val_loss: 2.1573\n",
      "Epoch 32/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0991 - val_loss: 2.1580\n",
      "Epoch 33/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0930 - val_loss: 1.9907\n",
      "Epoch 34/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0914 - val_loss: 1.9922\n",
      "Epoch 35/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1003 - val_loss: 2.1373\n",
      "Epoch 36/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0728 - val_loss: 2.0197\n",
      "Epoch 37/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0653 - val_loss: 2.0781\n",
      "Epoch 38/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0741 - val_loss: 1.9638\n",
      "Epoch 39/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0514 - val_loss: 2.2686\n",
      "Epoch 40/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0631 - val_loss: 2.0745\n",
      "Epoch 41/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0572 - val_loss: 1.9745\n",
      "Epoch 42/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0394 - val_loss: 2.0059\n",
      "Epoch 43/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0394 - val_loss: 1.9971\n",
      "Epoch 44/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0499 - val_loss: 1.9725\n",
      "Epoch 45/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0303 - val_loss: 1.9604\n",
      "Epoch 46/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0285 - val_loss: 2.0477\n",
      "Epoch 47/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0157 - val_loss: 2.0475\n",
      "Epoch 48/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0352 - val_loss: 2.1243\n",
      "Epoch 49/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0224 - val_loss: 2.1252\n",
      "Epoch 50/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0028 - val_loss: 2.0924\n",
      "Epoch 51/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0145 - val_loss: 2.0502\n",
      "Epoch 52/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0037 - val_loss: 2.0676\n",
      "Epoch 53/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9927 - val_loss: 2.2139\n",
      "Epoch 54/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0083 - val_loss: 2.0470\n",
      "Epoch 55/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9880 - val_loss: 2.0832\n",
      "Epoch 56/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9875 - val_loss: 2.2185\n",
      "Epoch 57/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9742 - val_loss: 1.9449\n",
      "Epoch 58/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9780 - val_loss: 2.0133\n",
      "Epoch 59/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9705 - val_loss: 2.0158\n",
      "Epoch 60/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9607 - val_loss: 2.3145\n",
      "Epoch 61/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9703 - val_loss: 1.8809\n",
      "Epoch 62/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9607 - val_loss: 2.1777\n",
      "Epoch 63/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9511 - val_loss: 1.8975\n",
      "Epoch 64/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9588 - val_loss: 1.8767\n",
      "Epoch 65/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9519 - val_loss: 1.9561\n",
      "Epoch 66/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9533 - val_loss: 1.8751\n",
      "Epoch 67/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9515 - val_loss: 1.9205\n",
      "Epoch 68/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9489 - val_loss: 1.9696\n",
      "Epoch 69/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9491 - val_loss: 1.9734\n",
      "Epoch 70/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9458 - val_loss: 1.8835\n",
      "Epoch 71/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9459 - val_loss: 1.8482\n",
      "Epoch 72/700\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.9319 - val_loss: 1.9366\n",
      "Epoch 73/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9398 - val_loss: 1.9074\n",
      "Epoch 74/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9247 - val_loss: 1.9172\n",
      "Epoch 75/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9258 - val_loss: 1.8898\n",
      "Epoch 76/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9164 - val_loss: 1.9419\n",
      "Epoch 77/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9121 - val_loss: 1.9005\n",
      "Epoch 78/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9124 - val_loss: 1.9290\n",
      "Epoch 79/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9135 - val_loss: 1.9135\n",
      "Epoch 80/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9051 - val_loss: 1.9034\n",
      "Epoch 81/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9122 - val_loss: 1.9316\n",
      "Epoch 82/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9014 - val_loss: 1.8863\n",
      "Epoch 83/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9029 - val_loss: 1.8489\n",
      "Epoch 84/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8982 - val_loss: 1.9108\n",
      "Epoch 85/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8956 - val_loss: 2.1482\n",
      "Epoch 86/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8990 - val_loss: 1.9470\n",
      "Epoch 87/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8934 - val_loss: 1.8680\n",
      "Epoch 88/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8933 - val_loss: 1.8725\n",
      "Epoch 89/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8951 - val_loss: 1.8456\n",
      "Epoch 90/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8809 - val_loss: 1.8998\n",
      "Epoch 91/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8837 - val_loss: 1.8811\n",
      "Epoch 92/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8853 - val_loss: 1.9072\n",
      "Epoch 93/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8867 - val_loss: 1.8541\n",
      "Epoch 94/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8671 - val_loss: 1.8380\n",
      "Epoch 95/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8798 - val_loss: 1.9705\n",
      "Epoch 96/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8726 - val_loss: 1.8836\n",
      "Epoch 97/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8769 - val_loss: 1.9579\n",
      "Epoch 98/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8694 - val_loss: 1.8082\n",
      "Epoch 99/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8675 - val_loss: 1.8701\n",
      "Epoch 100/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8750 - val_loss: 1.8458\n",
      "Epoch 101/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8690 - val_loss: 1.8847\n",
      "Epoch 102/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8693 - val_loss: 1.8917\n",
      "Epoch 103/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8670 - val_loss: 1.8606\n",
      "Epoch 104/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8603 - val_loss: 1.8378\n",
      "Epoch 105/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8725 - val_loss: 2.0638\n",
      "Epoch 106/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8574 - val_loss: 1.8185\n",
      "Epoch 107/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8545 - val_loss: 1.9177\n",
      "Epoch 108/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8535 - val_loss: 1.8599\n",
      "Epoch 109/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8597 - val_loss: 1.8447\n",
      "Epoch 110/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8406 - val_loss: 1.8367\n",
      "Epoch 111/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8399 - val_loss: 2.0186\n",
      "Epoch 112/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8468 - val_loss: 1.8883\n",
      "Epoch 113/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8502 - val_loss: 1.9537\n",
      "Epoch 114/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8464 - val_loss: 1.8113\n",
      "Epoch 115/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8409 - val_loss: 1.8498\n",
      "Epoch 116/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8374 - val_loss: 1.8386\n",
      "Epoch 117/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8367 - val_loss: 1.8523\n",
      "Epoch 118/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8390 - val_loss: 1.8250\n",
      "Epoch 119/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8304 - val_loss: 1.8337\n",
      "Epoch 120/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8335 - val_loss: 1.8187\n",
      "Epoch 121/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8329 - val_loss: 1.8301\n",
      "Epoch 122/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8296 - val_loss: 1.8523\n",
      "Epoch 123/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8273 - val_loss: 1.7930\n",
      "Epoch 124/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8277 - val_loss: 1.8218\n",
      "Epoch 125/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8330 - val_loss: 1.8326\n",
      "Epoch 126/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8226 - val_loss: 1.9082\n",
      "Epoch 127/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8174 - val_loss: 1.9249\n",
      "Epoch 128/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8196 - val_loss: 1.7776\n",
      "Epoch 129/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8220 - val_loss: 1.8078\n",
      "Epoch 130/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8216 - val_loss: 1.7871\n",
      "Epoch 131/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8160 - val_loss: 1.8141\n",
      "Epoch 132/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8247 - val_loss: 1.8294\n",
      "Epoch 133/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8147 - val_loss: 1.8086\n",
      "Epoch 134/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8135 - val_loss: 1.7642\n",
      "Epoch 135/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8111 - val_loss: 1.8617\n",
      "Epoch 136/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8089 - val_loss: 1.8263\n",
      "Epoch 137/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8090 - val_loss: 2.0481\n",
      "Epoch 138/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8095 - val_loss: 2.0857\n",
      "Epoch 139/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8122 - val_loss: 1.8321\n",
      "Epoch 140/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8132 - val_loss: 1.8832\n",
      "Epoch 141/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8083 - val_loss: 1.7676\n",
      "Epoch 142/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8076 - val_loss: 1.7686\n",
      "Epoch 143/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8007 - val_loss: 1.8792\n",
      "Epoch 144/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7972 - val_loss: 1.7842\n",
      "Epoch 145/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7964 - val_loss: 1.8153\n",
      "Epoch 146/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7977 - val_loss: 1.9017\n",
      "Epoch 147/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8035 - val_loss: 1.7930\n",
      "Epoch 148/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8000 - val_loss: 1.7756\n",
      "Epoch 149/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7961 - val_loss: 1.8042\n",
      "Epoch 150/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7966 - val_loss: 1.7896\n",
      "Epoch 151/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7993 - val_loss: 1.7600\n",
      "Epoch 152/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7918 - val_loss: 1.7610\n",
      "Epoch 153/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7854 - val_loss: 1.8387\n",
      "Epoch 154/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7869 - val_loss: 1.8343\n",
      "Epoch 155/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7887 - val_loss: 1.8164\n",
      "Epoch 156/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7818 - val_loss: 1.7654\n",
      "Epoch 157/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7796 - val_loss: 1.7954\n",
      "Epoch 158/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7869 - val_loss: 1.8134\n",
      "Epoch 159/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7883 - val_loss: 1.7713\n",
      "Epoch 160/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7771 - val_loss: 1.8247\n",
      "Epoch 161/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7826 - val_loss: 1.7926\n",
      "Epoch 162/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7819 - val_loss: 1.7743\n",
      "Epoch 163/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7775 - val_loss: 1.7811\n",
      "Epoch 164/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7796 - val_loss: 1.7840\n",
      "Epoch 165/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7750 - val_loss: 1.8287\n",
      "Epoch 166/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7763 - val_loss: 1.9156\n",
      "Epoch 167/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7766 - val_loss: 1.7409\n",
      "Epoch 168/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7802 - val_loss: 1.7617\n",
      "Epoch 169/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7708 - val_loss: 1.8173\n",
      "Epoch 170/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7756 - val_loss: 1.7318\n",
      "Epoch 171/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7730 - val_loss: 1.8499\n",
      "Epoch 172/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7661 - val_loss: 1.8949\n",
      "Epoch 173/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7641 - val_loss: 1.7680\n",
      "Epoch 174/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7693 - val_loss: 1.8848\n",
      "Epoch 175/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7698 - val_loss: 1.7613\n",
      "Epoch 176/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7784 - val_loss: 1.7860\n",
      "Epoch 177/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7655 - val_loss: 1.7464\n",
      "Epoch 178/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7691 - val_loss: 1.9177\n",
      "Epoch 179/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7625 - val_loss: 1.8505\n",
      "Epoch 180/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7584 - val_loss: 1.8727\n",
      "Epoch 181/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7696 - val_loss: 1.7704\n",
      "Epoch 182/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7678 - val_loss: 1.7775\n",
      "Epoch 183/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7658 - val_loss: 1.8243\n",
      "Epoch 184/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7536 - val_loss: 1.8908\n",
      "Epoch 185/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7506 - val_loss: 1.7755\n",
      "Epoch 186/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7511 - val_loss: 1.7670\n",
      "Epoch 187/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7616 - val_loss: 1.8300\n",
      "Epoch 188/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7555 - val_loss: 1.7672\n",
      "Epoch 189/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7517 - val_loss: 1.8822\n",
      "Epoch 190/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7501 - val_loss: 1.8456\n",
      "Epoch 191/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7427 - val_loss: 1.8912\n",
      "Epoch 192/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7569 - val_loss: 1.8057\n",
      "Epoch 193/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7525 - val_loss: 1.7681\n",
      "Epoch 194/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7535 - val_loss: 1.7592\n",
      "Epoch 195/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7487 - val_loss: 1.7392\n",
      "Epoch 196/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7550 - val_loss: 1.7834\n",
      "Epoch 197/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7488 - val_loss: 1.8466\n",
      "Epoch 198/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7338 - val_loss: 1.8007\n",
      "Epoch 199/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7468 - val_loss: 1.7228\n",
      "Epoch 200/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7492 - val_loss: 1.7457\n",
      "Epoch 201/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7398 - val_loss: 1.7317\n",
      "Epoch 202/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7400 - val_loss: 1.6879\n",
      "Epoch 203/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7365 - val_loss: 1.8013\n",
      "Epoch 204/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7364 - val_loss: 1.7837\n",
      "Epoch 205/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7434 - val_loss: 1.7931\n",
      "Epoch 206/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7384 - val_loss: 1.8286\n",
      "Epoch 207/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7408 - val_loss: 1.7066\n",
      "Epoch 208/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7410 - val_loss: 1.7359\n",
      "Epoch 209/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7344 - val_loss: 1.7980\n",
      "Epoch 210/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7343 - val_loss: 1.7344\n",
      "Epoch 211/700\n",
      "1728/1728 [==============================] - 9s 5ms/step - loss: 1.7331 - val_loss: 1.7379\n",
      "Epoch 212/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7265 - val_loss: 1.7419\n",
      "Epoch 213/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7391 - val_loss: 1.7248\n",
      "Epoch 214/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7296 - val_loss: 1.7633\n",
      "Epoch 215/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7362 - val_loss: 1.8293\n",
      "Epoch 216/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7272 - val_loss: 1.7624\n",
      "Epoch 217/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7283 - val_loss: 1.7016\n",
      "Epoch 218/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7240 - val_loss: 1.7255\n",
      "Epoch 219/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7274 - val_loss: 1.7154\n",
      "Epoch 220/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7295 - val_loss: 1.8060\n",
      "Epoch 221/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7323 - val_loss: 1.7794\n",
      "Epoch 222/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7271 - val_loss: 1.8069\n",
      "Epoch 223/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7308 - val_loss: 1.7226\n",
      "Epoch 224/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7231 - val_loss: 1.7299\n",
      "Epoch 225/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7176 - val_loss: 1.7300\n",
      "Epoch 226/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7197 - val_loss: 1.7276\n",
      "Epoch 227/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7147 - val_loss: 1.7807\n",
      "Epoch 228/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7247 - val_loss: 1.7763\n",
      "Epoch 229/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7171 - val_loss: 1.7919\n",
      "Epoch 230/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7196 - val_loss: 1.7263\n",
      "Epoch 231/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7182 - val_loss: 1.6772\n",
      "Epoch 232/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7228 - val_loss: 1.7316\n",
      "Epoch 233/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7126 - val_loss: 1.7952\n",
      "Epoch 234/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7197 - val_loss: 1.7236\n",
      "Epoch 235/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7189 - val_loss: 1.7865\n",
      "Epoch 236/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7136 - val_loss: 1.7185\n",
      "Epoch 237/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7204 - val_loss: 1.7825\n",
      "Epoch 238/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7234 - val_loss: 1.8810\n",
      "Epoch 239/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7218 - val_loss: 1.7179\n",
      "Epoch 240/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7164 - val_loss: 1.7570\n",
      "Epoch 241/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7139 - val_loss: 1.7455\n",
      "Epoch 242/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7149 - val_loss: 1.7190\n",
      "Epoch 243/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7171 - val_loss: 1.9277\n",
      "Epoch 244/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7144 - val_loss: 1.7795\n",
      "Epoch 245/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7170 - val_loss: 1.6902\n",
      "Epoch 246/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7177 - val_loss: 1.7604\n",
      "Epoch 247/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7175 - val_loss: 1.7267\n",
      "Epoch 248/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7129 - val_loss: 1.7458\n",
      "Epoch 249/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7131 - val_loss: 1.8319\n",
      "Epoch 250/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7131 - val_loss: 1.7628\n",
      "Epoch 251/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7106 - val_loss: 1.7630\n",
      "Epoch 252/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7148 - val_loss: 1.7377\n",
      "Epoch 253/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7084 - val_loss: 1.7522\n",
      "Epoch 254/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6996 - val_loss: 1.7257\n",
      "Epoch 255/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7111 - val_loss: 1.6907\n",
      "Epoch 256/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7086 - val_loss: 1.6742\n",
      "Epoch 257/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7061 - val_loss: 1.7594\n",
      "Epoch 258/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7111 - val_loss: 1.6526\n",
      "Epoch 259/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7063 - val_loss: 1.7324\n",
      "Epoch 260/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7068 - val_loss: 1.6860\n",
      "Epoch 261/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7069 - val_loss: 1.7339\n",
      "Epoch 262/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7044 - val_loss: 1.7277\n",
      "Epoch 263/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7072 - val_loss: 1.8505\n",
      "Epoch 264/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7075 - val_loss: 1.7642\n",
      "Epoch 265/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7012 - val_loss: 1.7073\n",
      "Epoch 266/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7050 - val_loss: 1.7123\n",
      "Epoch 267/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7050 - val_loss: 1.7567\n",
      "Epoch 268/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7011 - val_loss: 1.7159\n",
      "Epoch 269/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6940 - val_loss: 1.7466\n",
      "Epoch 270/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6992 - val_loss: 1.8088\n",
      "Epoch 271/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7008 - val_loss: 1.6853\n",
      "Epoch 272/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6949 - val_loss: 1.7087\n",
      "Epoch 273/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7010 - val_loss: 1.7284\n",
      "Epoch 274/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6945 - val_loss: 1.7821\n",
      "Epoch 275/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7017 - val_loss: 1.7034\n",
      "Epoch 276/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6990 - val_loss: 1.6868\n",
      "Epoch 277/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6965 - val_loss: 1.6835\n",
      "Epoch 278/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6978 - val_loss: 1.7388\n",
      "Epoch 279/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6902 - val_loss: 1.6518\n",
      "Epoch 280/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6945 - val_loss: 1.7610\n",
      "Epoch 281/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6908 - val_loss: 1.7458\n",
      "Epoch 282/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7073 - val_loss: 1.7397\n",
      "Epoch 283/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6925 - val_loss: 1.7407\n",
      "Epoch 284/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6933 - val_loss: 1.7825\n",
      "Epoch 285/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6975 - val_loss: 1.6698\n",
      "Epoch 286/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6943 - val_loss: 1.6915\n",
      "Epoch 287/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6958 - val_loss: 1.7190\n",
      "Epoch 288/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6957 - val_loss: 1.7632\n",
      "Epoch 289/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7092 - val_loss: 1.7551\n",
      "Epoch 290/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6925 - val_loss: 1.7012\n",
      "Epoch 291/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6953 - val_loss: 1.8054\n",
      "Epoch 292/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6889 - val_loss: 1.7421\n",
      "Epoch 293/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6977 - val_loss: 1.6996\n",
      "Epoch 294/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6845 - val_loss: 1.7176\n",
      "Epoch 295/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6925 - val_loss: 1.7422\n",
      "Epoch 296/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6908 - val_loss: 2.0148\n",
      "Epoch 297/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6905 - val_loss: 1.6987\n",
      "Epoch 298/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6919 - val_loss: 1.7334\n",
      "Epoch 299/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6935 - val_loss: 1.7229\n",
      "Epoch 300/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6934 - val_loss: 1.7183\n",
      "Epoch 301/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6917 - val_loss: 1.6992\n",
      "Epoch 302/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6920 - val_loss: 1.7229\n",
      "Epoch 303/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6918 - val_loss: 1.6779\n",
      "Epoch 304/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6811 - val_loss: 1.7098\n",
      "Epoch 305/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6880 - val_loss: 1.7066\n",
      "Epoch 306/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6789 - val_loss: 1.6957\n",
      "Epoch 307/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6833 - val_loss: 1.7194\n",
      "Epoch 308/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6823 - val_loss: 1.7052\n",
      "Epoch 309/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6903 - val_loss: 1.7181\n",
      "Epoch 310/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6883 - val_loss: 1.7902\n",
      "Epoch 311/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6841 - val_loss: 1.7266\n",
      "Epoch 312/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6826 - val_loss: 1.7047\n",
      "Epoch 313/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.6808 - val_loss: 1.7185\n",
      "Epoch 314/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6927 - val_loss: 1.6734\n",
      "Epoch 315/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6815 - val_loss: 1.7419\n",
      "Epoch 316/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6838 - val_loss: 1.6654\n",
      "Epoch 317/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6830 - val_loss: 1.6809\n",
      "Epoch 318/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6847 - val_loss: 1.6642\n",
      "Epoch 319/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6829 - val_loss: 1.7286\n",
      "Epoch 320/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6888 - val_loss: 1.7751\n",
      "Epoch 321/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6803 - val_loss: 1.6610\n",
      "Epoch 322/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6815 - val_loss: 1.7511\n",
      "Epoch 323/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6860 - val_loss: 1.6536\n",
      "Epoch 324/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6836 - val_loss: 1.6596\n",
      "Epoch 325/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6863 - val_loss: 1.6477\n",
      "Epoch 326/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6794 - val_loss: 1.7159\n",
      "Epoch 327/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6805 - val_loss: 1.6502\n",
      "Epoch 328/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6735 - val_loss: 1.6711\n",
      "Epoch 329/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6754 - val_loss: 1.7358\n",
      "Epoch 330/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6732 - val_loss: 1.6881\n",
      "Epoch 331/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6822 - val_loss: 1.7540\n",
      "Epoch 332/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6800 - val_loss: 1.6660\n",
      "Epoch 333/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6756 - val_loss: 1.7655\n",
      "Epoch 334/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6778 - val_loss: 1.7034\n",
      "Epoch 335/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6802 - val_loss: 1.6758\n",
      "Epoch 336/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6680 - val_loss: 1.8429\n",
      "Epoch 337/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6811 - val_loss: 1.6379\n",
      "Epoch 338/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6703 - val_loss: 1.6770\n",
      "Epoch 339/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6740 - val_loss: 1.6602\n",
      "Epoch 340/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6748 - val_loss: 1.6924\n",
      "Epoch 341/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6771 - val_loss: 1.7736\n",
      "Epoch 342/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6637 - val_loss: 1.7609\n",
      "Epoch 343/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6759 - val_loss: 1.6597\n",
      "Epoch 344/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6763 - val_loss: 1.7425\n",
      "Epoch 345/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6815 - val_loss: 1.6934\n",
      "Epoch 346/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6711 - val_loss: 1.6591\n",
      "Epoch 347/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6704 - val_loss: 1.7920\n",
      "Epoch 348/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6792 - val_loss: 1.6693\n",
      "Epoch 349/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6711 - val_loss: 1.6860\n",
      "Epoch 350/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6789 - val_loss: 1.6524\n",
      "Epoch 351/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6800 - val_loss: 1.7034\n",
      "Epoch 352/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6723 - val_loss: 1.6542\n",
      "Epoch 353/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6727 - val_loss: 1.6904\n",
      "Epoch 354/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6784 - val_loss: 1.8517\n",
      "Epoch 355/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6754 - val_loss: 1.7350\n",
      "Epoch 356/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6669 - val_loss: 1.6531\n",
      "Epoch 357/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6771 - val_loss: 1.7661\n",
      "Epoch 358/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6691 - val_loss: 1.7193\n",
      "Epoch 359/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6810 - val_loss: 1.7973\n",
      "Epoch 360/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6721 - val_loss: 1.7555\n",
      "Epoch 361/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6664 - val_loss: 1.7020\n",
      "Epoch 362/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6674 - val_loss: 1.7997\n",
      "Epoch 363/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6652 - val_loss: 1.6429\n",
      "Epoch 364/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6738 - val_loss: 1.7692\n",
      "Epoch 365/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6677 - val_loss: 1.7009\n",
      "Epoch 366/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6724 - val_loss: 1.7080\n",
      "Epoch 367/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6691 - val_loss: 1.7185\n",
      "Epoch 368/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6678 - val_loss: 1.7545\n",
      "Epoch 369/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6646 - val_loss: 1.7005\n",
      "Epoch 370/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6677 - val_loss: 1.6334\n",
      "Epoch 371/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6698 - val_loss: 1.7341\n",
      "Epoch 372/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6724 - val_loss: 1.6600\n",
      "Epoch 373/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6684 - val_loss: 1.7022\n",
      "Epoch 374/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6627 - val_loss: 1.6605\n",
      "Epoch 375/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6571 - val_loss: 1.6858\n",
      "Epoch 376/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6625 - val_loss: 1.6418\n",
      "Epoch 377/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6648 - val_loss: 1.6591\n",
      "Epoch 378/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6613 - val_loss: 1.6729\n",
      "Epoch 379/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6588 - val_loss: 1.6646\n",
      "Epoch 380/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6651 - val_loss: 1.6686\n",
      "Epoch 381/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6696 - val_loss: 1.8539\n",
      "Epoch 382/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6626 - val_loss: 1.7746\n",
      "Epoch 383/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6677 - val_loss: 1.7109\n",
      "Epoch 384/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6623 - val_loss: 1.7540\n",
      "Epoch 385/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6627 - val_loss: 1.6983\n",
      "Epoch 386/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6634 - val_loss: 1.6659\n",
      "Epoch 387/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6581 - val_loss: 1.6713\n",
      "Epoch 388/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6665 - val_loss: 1.7896\n",
      "Epoch 389/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6597 - val_loss: 1.7674\n",
      "Epoch 390/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6672 - val_loss: 1.8684\n",
      "Epoch 391/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6600 - val_loss: 1.6744\n",
      "Epoch 392/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6600 - val_loss: 1.6728\n",
      "Epoch 393/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6587 - val_loss: 1.6832\n",
      "Epoch 394/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6566 - val_loss: 1.7553\n",
      "Epoch 395/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6542 - val_loss: 1.6697\n",
      "Epoch 396/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6576 - val_loss: 1.7500\n",
      "Epoch 397/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6549 - val_loss: 1.6437\n",
      "Epoch 398/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6612 - val_loss: 1.6695\n",
      "Epoch 399/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6545 - val_loss: 1.6817\n",
      "Epoch 400/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6564 - val_loss: 1.6851\n",
      "Epoch 401/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6487 - val_loss: 1.6752\n",
      "Epoch 402/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6596 - val_loss: 1.6640\n",
      "Epoch 403/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6576 - val_loss: 1.7159\n",
      "Epoch 404/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6576 - val_loss: 1.6792\n",
      "Epoch 405/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6601 - val_loss: 1.7798\n",
      "Epoch 406/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6591 - val_loss: 1.6575\n",
      "Epoch 407/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6567 - val_loss: 1.6750\n",
      "Epoch 408/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6469 - val_loss: 1.6496\n",
      "Epoch 409/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6597 - val_loss: 1.7640\n",
      "Epoch 410/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6523 - val_loss: 1.6859\n",
      "Epoch 411/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6622 - val_loss: 1.6463\n",
      "Epoch 412/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6492 - val_loss: 1.6909\n",
      "Epoch 413/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6548 - val_loss: 1.6568\n",
      "Epoch 414/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6492 - val_loss: 1.7334\n",
      "Epoch 415/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6549 - val_loss: 1.6368\n",
      "Epoch 416/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6538 - val_loss: 1.6943\n",
      "Epoch 417/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6546 - val_loss: 1.6593\n",
      "Epoch 418/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6537 - val_loss: 1.7195\n",
      "Epoch 419/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6501 - val_loss: 1.6816\n",
      "Epoch 420/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6517 - val_loss: 1.6369\n",
      "Epoch 421/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6575 - val_loss: 1.7207\n",
      "Epoch 422/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6502 - val_loss: 1.6692\n",
      "Epoch 423/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6519 - val_loss: 1.6533\n",
      "Epoch 424/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6445 - val_loss: 1.7162\n",
      "Epoch 425/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6534 - val_loss: 1.6673\n",
      "Epoch 426/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6520 - val_loss: 1.6753\n",
      "Epoch 427/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6471 - val_loss: 1.6822\n",
      "Epoch 428/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6456 - val_loss: 1.7387\n",
      "Epoch 429/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6507 - val_loss: 1.6420\n",
      "Epoch 430/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6470 - val_loss: 1.6500\n",
      "Epoch 431/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6435 - val_loss: 1.6635\n",
      "Epoch 432/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6465 - val_loss: 1.7014\n",
      "Epoch 433/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6509 - val_loss: 1.6361\n",
      "Epoch 434/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6499 - val_loss: 1.7197\n",
      "Epoch 435/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6538 - val_loss: 1.6350\n",
      "Epoch 436/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6479 - val_loss: 1.7150\n",
      "Epoch 437/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6509 - val_loss: 1.6323\n",
      "Epoch 438/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6495 - val_loss: 1.6209\n",
      "Epoch 439/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6429 - val_loss: 1.7907\n",
      "Epoch 440/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6463 - val_loss: 1.7025\n",
      "Epoch 441/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6465 - val_loss: 1.6802\n",
      "Epoch 442/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6435 - val_loss: 1.7105\n",
      "Epoch 443/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6531 - val_loss: 1.6428\n",
      "Epoch 444/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6429 - val_loss: 1.6551\n",
      "Epoch 445/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6427 - val_loss: 1.7303\n",
      "Epoch 446/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6394 - val_loss: 1.6646\n",
      "Epoch 447/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6378 - val_loss: 1.6582\n",
      "Epoch 448/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6485 - val_loss: 1.6531\n",
      "Epoch 449/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6455 - val_loss: 1.6318\n",
      "Epoch 450/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6414 - val_loss: 1.7622\n",
      "Epoch 451/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6419 - val_loss: 1.6851\n",
      "Epoch 452/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6432 - val_loss: 1.6940\n",
      "Epoch 453/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6418 - val_loss: 1.6654\n",
      "Epoch 454/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6407 - val_loss: 1.7812\n",
      "Epoch 455/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6436 - val_loss: 1.7550\n",
      "Epoch 456/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6398 - val_loss: 1.6042\n",
      "Epoch 457/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6404 - val_loss: 1.6201\n",
      "Epoch 458/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6413 - val_loss: 1.6752\n",
      "Epoch 459/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6461 - val_loss: 1.6508\n",
      "Epoch 460/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6433 - val_loss: 1.6848\n",
      "Epoch 461/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6434 - val_loss: 1.6579\n",
      "Epoch 462/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6446 - val_loss: 1.6861\n",
      "Epoch 463/700\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6445 - val_loss: 1.6792\n",
      "Epoch 464/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6376 - val_loss: 1.6494\n",
      "Epoch 465/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6369 - val_loss: 1.6229\n",
      "Epoch 466/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6413 - val_loss: 1.7038\n",
      "Epoch 467/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6393 - val_loss: 1.7211\n",
      "Epoch 468/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6396 - val_loss: 1.8168\n",
      "Epoch 469/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6403 - val_loss: 1.6155\n",
      "Epoch 470/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6425 - val_loss: 1.7136\n",
      "Epoch 471/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6416 - val_loss: 1.6340\n",
      "Epoch 472/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6486 - val_loss: 1.6407\n",
      "Epoch 473/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6360 - val_loss: 1.6392\n",
      "Epoch 474/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6369 - val_loss: 1.6169\n",
      "Epoch 475/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6380 - val_loss: 1.6907\n",
      "Epoch 476/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6418 - val_loss: 1.6287\n",
      "Epoch 477/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6373 - val_loss: 1.6558\n",
      "Epoch 478/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6408 - val_loss: 1.6871\n",
      "Epoch 479/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6424 - val_loss: 1.7152\n",
      "Epoch 480/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6404 - val_loss: 1.6971\n",
      "Epoch 481/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6308 - val_loss: 1.6355\n",
      "Epoch 482/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6400 - val_loss: 1.7235\n",
      "Epoch 483/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6336 - val_loss: 1.6265\n",
      "Epoch 484/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6395 - val_loss: 1.6664\n",
      "Epoch 485/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6339 - val_loss: 1.6173\n",
      "Epoch 486/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6377 - val_loss: 1.6615\n",
      "Epoch 487/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6286 - val_loss: 1.6486\n",
      "Epoch 488/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6324 - val_loss: 1.6331\n",
      "Epoch 489/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6454 - val_loss: 1.7564\n",
      "Epoch 490/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6427 - val_loss: 1.8118\n",
      "Epoch 491/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6356 - val_loss: 1.6507\n",
      "Epoch 492/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6383 - val_loss: 1.6354\n",
      "Epoch 493/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6386 - val_loss: 1.6892\n",
      "Epoch 494/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6409 - val_loss: 1.7304\n",
      "Epoch 495/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6379 - val_loss: 1.6977\n",
      "Epoch 496/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6456 - val_loss: 1.6923\n",
      "Epoch 497/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6317 - val_loss: 1.7299\n",
      "Epoch 498/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6385 - val_loss: 1.7192\n",
      "Epoch 499/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6310 - val_loss: 1.6476\n",
      "Epoch 500/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6339 - val_loss: 1.6173\n",
      "Epoch 501/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6309 - val_loss: 1.7583\n",
      "Epoch 502/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6301 - val_loss: 1.6274\n",
      "Epoch 503/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6323 - val_loss: 1.6608\n",
      "Epoch 504/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6342 - val_loss: 1.6400\n",
      "Epoch 505/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6284 - val_loss: 1.7551\n",
      "Epoch 506/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6370 - val_loss: 1.6689\n",
      "Epoch 507/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6314 - val_loss: 1.6964\n",
      "Epoch 508/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6314 - val_loss: 1.6680\n",
      "Epoch 509/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6349 - val_loss: 1.7492\n",
      "Epoch 510/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6308 - val_loss: 1.7159\n",
      "Epoch 511/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6347 - val_loss: 1.6121\n",
      "Epoch 512/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6304 - val_loss: 1.6553\n",
      "Epoch 513/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6338 - val_loss: 1.6449\n",
      "Epoch 514/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6340 - val_loss: 1.6610\n",
      "Epoch 515/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6327 - val_loss: 1.7076\n",
      "Epoch 516/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6282 - val_loss: 1.7532\n",
      "Epoch 517/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6323 - val_loss: 1.6681\n",
      "Epoch 518/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6336 - val_loss: 1.6870\n",
      "Epoch 519/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6265 - val_loss: 1.6436\n",
      "Epoch 520/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6313 - val_loss: 1.6755\n",
      "Epoch 521/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6327 - val_loss: 1.6405\n",
      "Epoch 522/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6325 - val_loss: 1.7476\n",
      "Epoch 523/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6226 - val_loss: 1.6590\n",
      "Epoch 524/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6303 - val_loss: 1.6468\n",
      "Epoch 525/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6235 - val_loss: 1.6227\n",
      "Epoch 526/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6271 - val_loss: 1.6722\n",
      "Epoch 527/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6307 - val_loss: 1.6782\n",
      "Epoch 528/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6285 - val_loss: 1.6489\n",
      "Epoch 529/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6246 - val_loss: 1.6080\n",
      "Epoch 530/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6260 - val_loss: 1.6687\n",
      "Epoch 531/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6370 - val_loss: 1.7984\n",
      "Epoch 532/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6295 - val_loss: 1.6322\n",
      "Epoch 533/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6249 - val_loss: 1.6089\n",
      "Epoch 534/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6226 - val_loss: 1.6597\n",
      "Epoch 535/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6345 - val_loss: 1.6506\n",
      "Epoch 536/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6257 - val_loss: 1.7967\n",
      "Epoch 537/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6216 - val_loss: 1.6749\n",
      "Epoch 538/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6277 - val_loss: 1.7339\n",
      "Epoch 539/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6300 - val_loss: 1.6087\n",
      "Epoch 540/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6273 - val_loss: 1.6584\n",
      "Epoch 541/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6229 - val_loss: 1.6410\n",
      "Epoch 542/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6289 - val_loss: 1.7451\n",
      "Epoch 543/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6224 - val_loss: 1.5905\n",
      "Epoch 544/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6289 - val_loss: 1.6804\n",
      "Epoch 545/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6230 - val_loss: 1.6893\n",
      "Epoch 546/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6224 - val_loss: 1.7793\n",
      "Epoch 547/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6297 - val_loss: 1.6393\n",
      "Epoch 548/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6251 - val_loss: 1.7806\n",
      "Epoch 549/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6272 - val_loss: 1.6967\n",
      "Epoch 550/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6295 - val_loss: 1.6595\n",
      "Epoch 551/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6315 - val_loss: 1.6757\n",
      "Epoch 552/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6298 - val_loss: 1.6104\n",
      "Epoch 553/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6191 - val_loss: 1.6693\n",
      "Epoch 554/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6200 - val_loss: 1.6880\n",
      "Epoch 555/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6270 - val_loss: 1.6105\n",
      "Epoch 556/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6210 - val_loss: 1.6632\n",
      "Epoch 557/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6288 - val_loss: 1.6136\n",
      "Epoch 558/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6246 - val_loss: 1.6352\n",
      "Epoch 559/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6213 - val_loss: 1.7518\n",
      "Epoch 560/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6285 - val_loss: 1.6409\n",
      "Epoch 561/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6171 - val_loss: 1.6504\n",
      "Epoch 562/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6269 - val_loss: 1.6937\n",
      "Epoch 563/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6238 - val_loss: 1.8794\n",
      "Epoch 564/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6224 - val_loss: 1.6315\n",
      "Epoch 565/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6208 - val_loss: 1.6351\n",
      "Epoch 566/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6223 - val_loss: 1.6005\n",
      "Epoch 567/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6246 - val_loss: 1.6819\n",
      "Epoch 568/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6255 - val_loss: 1.6559\n",
      "Epoch 569/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6187 - val_loss: 1.6793\n",
      "Epoch 570/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6299 - val_loss: 1.6896\n",
      "Epoch 571/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6222 - val_loss: 1.6857\n",
      "Epoch 572/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6262 - val_loss: 1.7299\n",
      "Epoch 573/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6184 - val_loss: 1.6047\n",
      "Epoch 574/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6226 - val_loss: 1.6812\n",
      "Epoch 575/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6234 - val_loss: 1.6457\n",
      "Epoch 576/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6291 - val_loss: 1.6178\n",
      "Epoch 577/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6220 - val_loss: 1.5725\n",
      "Epoch 578/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6206 - val_loss: 1.7207\n",
      "Epoch 579/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6192 - val_loss: 1.5972\n",
      "Epoch 580/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6186 - val_loss: 1.6073\n",
      "Epoch 581/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6226 - val_loss: 1.6541\n",
      "Epoch 582/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6244 - val_loss: 1.6973\n",
      "Epoch 583/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6156 - val_loss: 1.6381\n",
      "Epoch 584/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6312 - val_loss: 1.5904\n",
      "Epoch 585/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6113 - val_loss: 1.6488\n",
      "Epoch 586/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6136 - val_loss: 1.6561\n",
      "Epoch 587/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6149 - val_loss: 1.6273\n",
      "Epoch 588/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6205 - val_loss: 1.6767\n",
      "Epoch 589/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6224 - val_loss: 1.6292\n",
      "Epoch 590/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6187 - val_loss: 1.6181\n",
      "Epoch 591/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6234 - val_loss: 1.6045\n",
      "Epoch 592/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6204 - val_loss: 1.6507\n",
      "Epoch 593/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6235 - val_loss: 1.7708\n",
      "Epoch 594/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6193 - val_loss: 1.6547\n",
      "Epoch 595/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6230 - val_loss: 1.6554\n",
      "Epoch 596/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6158 - val_loss: 1.6388\n",
      "Epoch 597/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6186 - val_loss: 1.6778\n",
      "Epoch 598/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6168 - val_loss: 1.5974\n",
      "Epoch 599/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6213 - val_loss: 1.6688\n",
      "Epoch 600/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6162 - val_loss: 1.6511\n",
      "Epoch 601/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6209 - val_loss: 1.6509\n",
      "Epoch 602/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6227 - val_loss: 1.6000\n",
      "Epoch 603/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6237 - val_loss: 1.6378\n",
      "Epoch 604/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6195 - val_loss: 1.6772\n",
      "Epoch 605/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6176 - val_loss: 1.6623\n",
      "Epoch 606/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6148 - val_loss: 1.6396\n",
      "Epoch 607/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6192 - val_loss: 1.7184\n",
      "Epoch 608/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6171 - val_loss: 1.6909\n",
      "Epoch 609/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6153 - val_loss: 1.6889\n",
      "Epoch 610/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6149 - val_loss: 1.7477\n",
      "Epoch 611/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6166 - val_loss: 1.6261\n",
      "Epoch 612/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6175 - val_loss: 1.8071\n",
      "Epoch 613/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6140 - val_loss: 1.6304\n",
      "Epoch 614/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6219 - val_loss: 1.6190\n",
      "Epoch 615/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6229 - val_loss: 1.6350\n",
      "Epoch 616/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6158 - val_loss: 1.5825\n",
      "Epoch 617/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6232 - val_loss: 1.6256\n",
      "Epoch 618/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6238 - val_loss: 1.5671\n",
      "Epoch 619/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6170 - val_loss: 1.7082\n",
      "Epoch 620/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6133 - val_loss: 1.6195\n",
      "Epoch 621/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6184 - val_loss: 1.6873\n",
      "Epoch 622/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6105 - val_loss: 1.6273\n",
      "Epoch 623/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6171 - val_loss: 1.7076\n",
      "Epoch 624/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6191 - val_loss: 1.6050\n",
      "Epoch 625/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6147 - val_loss: 1.6036\n",
      "Epoch 626/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6127 - val_loss: 1.7042\n",
      "Epoch 627/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6144 - val_loss: 1.5868\n",
      "Epoch 628/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6174 - val_loss: 1.6256\n",
      "Epoch 629/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6085 - val_loss: 1.6386\n",
      "Epoch 630/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6156 - val_loss: 1.5915\n",
      "Epoch 631/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6164 - val_loss: 1.6125\n",
      "Epoch 632/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6113 - val_loss: 1.7183\n",
      "Epoch 633/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6069 - val_loss: 1.6241\n",
      "Epoch 634/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6114 - val_loss: 1.6754\n",
      "Epoch 635/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6150 - val_loss: 1.6409\n",
      "Epoch 636/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6111 - val_loss: 1.6040\n",
      "Epoch 637/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6070 - val_loss: 1.6613\n",
      "Epoch 638/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6092 - val_loss: 1.6536\n",
      "Epoch 639/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6096 - val_loss: 1.6264\n",
      "Epoch 640/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6151 - val_loss: 1.6308\n",
      "Epoch 641/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6121 - val_loss: 1.6418\n",
      "Epoch 642/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6091 - val_loss: 1.6038\n",
      "Epoch 643/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6052 - val_loss: 1.6443\n",
      "Epoch 644/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6161 - val_loss: 1.8098\n",
      "Epoch 645/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6159 - val_loss: 1.7050\n",
      "Epoch 646/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6159 - val_loss: 1.6032\n",
      "Epoch 647/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6123 - val_loss: 1.7023\n",
      "Epoch 648/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6144 - val_loss: 1.6576\n",
      "Epoch 649/700\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6095 - val_loss: 1.6108\n",
      "Epoch 650/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6154 - val_loss: 1.7040\n",
      "Epoch 651/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6062 - val_loss: 1.6184\n",
      "Epoch 652/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6019 - val_loss: 1.6718\n",
      "Epoch 653/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6154 - val_loss: 1.6360\n",
      "Epoch 654/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6123 - val_loss: 1.6764\n",
      "Epoch 655/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6109 - val_loss: 1.6153\n",
      "Epoch 656/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6120 - val_loss: 1.6413\n",
      "Epoch 657/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6091 - val_loss: 1.6314\n",
      "Epoch 658/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6114 - val_loss: 1.6352\n",
      "Epoch 659/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6107 - val_loss: 1.7012\n",
      "Epoch 660/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6104 - val_loss: 1.6227\n",
      "Epoch 661/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6101 - val_loss: 1.6280\n",
      "Epoch 662/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6120 - val_loss: 1.6447\n",
      "Epoch 663/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6156 - val_loss: 1.7409\n",
      "Epoch 664/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6035 - val_loss: 1.6053\n",
      "Epoch 665/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6075 - val_loss: 1.6884\n",
      "Epoch 666/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6135 - val_loss: 1.8087\n",
      "Epoch 667/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6046 - val_loss: 1.6049\n",
      "Epoch 668/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6018 - val_loss: 1.6171\n",
      "Epoch 669/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6153 - val_loss: 1.6679\n",
      "Epoch 670/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6163 - val_loss: 1.6095\n",
      "Epoch 671/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.5998 - val_loss: 1.7286\n",
      "Epoch 672/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6136 - val_loss: 1.6489\n",
      "Epoch 673/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.5997 - val_loss: 1.6291\n",
      "Epoch 674/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6034 - val_loss: 1.6254\n",
      "Epoch 675/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6023 - val_loss: 1.6668\n",
      "Epoch 676/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6074 - val_loss: 1.6178\n",
      "Epoch 677/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6054 - val_loss: 1.6061\n",
      "Epoch 678/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6072 - val_loss: 1.7380\n",
      "Epoch 679/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6075 - val_loss: 1.6614\n",
      "Epoch 680/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6066 - val_loss: 1.6023\n",
      "Epoch 681/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6055 - val_loss: 1.6130\n",
      "Epoch 682/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6026 - val_loss: 1.6328\n",
      "Epoch 683/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6035 - val_loss: 1.5766\n",
      "Epoch 684/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.5988 - val_loss: 1.7010\n",
      "Epoch 685/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6033 - val_loss: 1.5975\n",
      "Epoch 686/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6106 - val_loss: 1.6167\n",
      "Epoch 687/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6016 - val_loss: 1.6095\n",
      "Epoch 688/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.5998 - val_loss: 1.6114\n",
      "Epoch 689/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6007 - val_loss: 1.6286\n",
      "Epoch 690/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6042 - val_loss: 1.7078\n",
      "Epoch 691/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6013 - val_loss: 1.5946\n",
      "Epoch 692/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6014 - val_loss: 1.7018\n",
      "Epoch 693/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6026 - val_loss: 1.6089\n",
      "Epoch 694/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6034 - val_loss: 1.6367\n",
      "Epoch 695/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6001 - val_loss: 1.6182\n",
      "Epoch 696/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.5990 - val_loss: 1.6754\n",
      "Epoch 697/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6022 - val_loss: 1.6425\n",
      "Epoch 698/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5945 - val_loss: 1.6499\n",
      "Epoch 699/700\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6042 - val_loss: 1.5865\n",
      "Epoch 700/700\n",
      "1728/1728 [==============================] - 5s 3ms/step - loss: 1.6024 - val_loss: 1.6095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.609481814794664\n",
      "0.960460571735543\n",
      "Epoch 1/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 8.5919 - val_loss: 6.3431\n",
      "Epoch 2/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 4.6957 - val_loss: 4.1284\n",
      "Epoch 3/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 4.6393 - val_loss: 4.0395\n",
      "Epoch 4/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 4.3754 - val_loss: 5.6308\n",
      "Epoch 5/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 4.1894 - val_loss: 4.0937\n",
      "Epoch 6/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 4.0651 - val_loss: 3.9920\n",
      "Epoch 7/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 3.4396 - val_loss: 3.0696\n",
      "Epoch 8/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 3.1817 - val_loss: 3.0490\n",
      "Epoch 9/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 3.0088 - val_loss: 3.4093\n",
      "Epoch 10/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.9266 - val_loss: 3.0184\n",
      "Epoch 11/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.9031 - val_loss: 3.0759\n",
      "Epoch 12/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.8084 - val_loss: 2.6274\n",
      "Epoch 13/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.7258 - val_loss: 2.7054\n",
      "Epoch 14/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.6460 - val_loss: 2.6094\n",
      "Epoch 15/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.5668 - val_loss: 2.8027\n",
      "Epoch 16/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.5301 - val_loss: 2.4400\n",
      "Epoch 17/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.5040 - val_loss: 2.3630\n",
      "Epoch 18/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.4613 - val_loss: 2.4429\n",
      "Epoch 19/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.4427 - val_loss: 3.0546\n",
      "Epoch 20/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.4012 - val_loss: 2.3464\n",
      "Epoch 21/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.4009 - val_loss: 2.4532\n",
      "Epoch 22/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3675 - val_loss: 2.3241\n",
      "Epoch 23/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3362 - val_loss: 2.2657\n",
      "Epoch 24/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3151 - val_loss: 2.5094\n",
      "Epoch 25/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2820 - val_loss: 2.2016\n",
      "Epoch 26/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.2761 - val_loss: 2.3072\n",
      "Epoch 27/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2471 - val_loss: 2.1811\n",
      "Epoch 28/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2097 - val_loss: 2.1793\n",
      "Epoch 29/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1880 - val_loss: 2.1164\n",
      "Epoch 30/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1647 - val_loss: 2.0891\n",
      "Epoch 31/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1369 - val_loss: 2.1602\n",
      "Epoch 32/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1235 - val_loss: 2.0858\n",
      "Epoch 33/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1036 - val_loss: 2.0758\n",
      "Epoch 34/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.0828 - val_loss: 2.0436\n",
      "Epoch 35/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0895 - val_loss: 2.0294\n",
      "Epoch 36/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0759 - val_loss: 2.0146\n",
      "Epoch 37/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0574 - val_loss: 1.9798\n",
      "Epoch 38/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0625 - val_loss: 2.1410\n",
      "Epoch 39/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0444 - val_loss: 2.0398\n",
      "Epoch 40/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0346 - val_loss: 1.9758\n",
      "Epoch 41/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0293 - val_loss: 1.9607\n",
      "Epoch 42/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0273 - val_loss: 1.9515\n",
      "Epoch 43/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0114 - val_loss: 2.0096\n",
      "Epoch 44/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9972 - val_loss: 1.8989\n",
      "Epoch 45/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9931 - val_loss: 1.9485\n",
      "Epoch 46/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9858 - val_loss: 2.0756\n",
      "Epoch 47/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9814 - val_loss: 2.0597\n",
      "Epoch 48/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9785 - val_loss: 2.1313\n",
      "Epoch 49/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9633 - val_loss: 1.9939\n",
      "Epoch 50/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9752 - val_loss: 1.9201\n",
      "Epoch 51/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9596 - val_loss: 1.9405\n",
      "Epoch 52/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9556 - val_loss: 2.0868\n",
      "Epoch 53/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9502 - val_loss: 1.9076\n",
      "Epoch 54/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9447 - val_loss: 2.0204\n",
      "Epoch 55/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9321 - val_loss: 1.9189\n",
      "Epoch 56/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9231 - val_loss: 1.8695\n",
      "Epoch 57/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9028 - val_loss: 1.8840\n",
      "Epoch 58/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9151 - val_loss: 1.8496\n",
      "Epoch 59/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9134 - val_loss: 1.8490\n",
      "Epoch 60/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9006 - val_loss: 1.8812\n",
      "Epoch 61/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8922 - val_loss: 1.9404\n",
      "Epoch 62/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9117 - val_loss: 1.8546\n",
      "Epoch 63/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8837 - val_loss: 1.8394\n",
      "Epoch 64/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8919 - val_loss: 1.8529\n",
      "Epoch 65/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8918 - val_loss: 1.8553\n",
      "Epoch 66/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8663 - val_loss: 1.9066\n",
      "Epoch 67/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8804 - val_loss: 1.9485\n",
      "Epoch 68/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8699 - val_loss: 1.8462\n",
      "Epoch 69/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8838 - val_loss: 1.9302\n",
      "Epoch 70/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8623 - val_loss: 1.8848\n",
      "Epoch 71/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8742 - val_loss: 1.8323\n",
      "Epoch 72/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8497 - val_loss: 1.8386\n",
      "Epoch 73/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8496 - val_loss: 1.8613\n",
      "Epoch 74/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8494 - val_loss: 1.8351\n",
      "Epoch 75/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8539 - val_loss: 1.8210\n",
      "Epoch 76/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8487 - val_loss: 1.8775\n",
      "Epoch 77/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8409 - val_loss: 1.8830\n",
      "Epoch 78/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8236 - val_loss: 1.9284\n",
      "Epoch 79/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8236 - val_loss: 1.7372\n",
      "Epoch 80/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8307 - val_loss: 2.0027\n",
      "Epoch 81/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8179 - val_loss: 1.8285\n",
      "Epoch 82/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8132 - val_loss: 1.8812\n",
      "Epoch 83/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8037 - val_loss: 1.8584\n",
      "Epoch 84/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8074 - val_loss: 1.7742\n",
      "Epoch 85/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7997 - val_loss: 1.8077\n",
      "Epoch 86/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7954 - val_loss: 1.8400\n",
      "Epoch 87/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7970 - val_loss: 1.7653\n",
      "Epoch 88/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7935 - val_loss: 1.9197\n",
      "Epoch 89/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7907 - val_loss: 1.8231\n",
      "Epoch 90/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7881 - val_loss: 1.7802\n",
      "Epoch 91/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7847 - val_loss: 1.7103\n",
      "Epoch 92/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7678 - val_loss: 1.7859\n",
      "Epoch 93/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7646 - val_loss: 1.8053\n",
      "Epoch 94/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7850 - val_loss: 1.7861\n",
      "Epoch 95/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7651 - val_loss: 1.8398\n",
      "Epoch 96/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7654 - val_loss: 1.7704\n",
      "Epoch 97/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7714 - val_loss: 1.8195\n",
      "Epoch 98/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7653 - val_loss: 1.8100\n",
      "Epoch 99/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7476 - val_loss: 1.7570\n",
      "Epoch 100/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7673 - val_loss: 1.7158\n",
      "Epoch 101/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7465 - val_loss: 1.7223\n",
      "Epoch 102/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7501 - val_loss: 1.7859\n",
      "Epoch 103/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7494 - val_loss: 1.7361\n",
      "Epoch 104/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7545 - val_loss: 1.7038\n",
      "Epoch 105/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7470 - val_loss: 1.8443\n",
      "Epoch 106/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7338 - val_loss: 1.7407\n",
      "Epoch 107/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7368 - val_loss: 1.6955\n",
      "Epoch 108/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7364 - val_loss: 1.7912\n",
      "Epoch 109/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7290 - val_loss: 1.7958\n",
      "Epoch 110/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7307 - val_loss: 1.9108\n",
      "Epoch 111/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7191 - val_loss: 1.7238\n",
      "Epoch 112/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7284 - val_loss: 1.7452\n",
      "Epoch 113/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7093 - val_loss: 1.7684\n",
      "Epoch 114/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7321 - val_loss: 1.8052\n",
      "Epoch 115/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7079 - val_loss: 1.8394\n",
      "Epoch 116/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7377 - val_loss: 1.7562\n",
      "Epoch 117/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7057 - val_loss: 1.7932\n",
      "Epoch 118/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7077 - val_loss: 1.7676\n",
      "Epoch 119/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7040 - val_loss: 1.6948\n",
      "Epoch 120/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6986 - val_loss: 1.7254\n",
      "Epoch 121/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7018 - val_loss: 1.7740\n",
      "Epoch 122/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7034 - val_loss: 1.7032\n",
      "Epoch 123/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6863 - val_loss: 1.7752\n",
      "Epoch 124/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7072 - val_loss: 1.7568\n",
      "Epoch 125/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6940 - val_loss: 1.7508\n",
      "Epoch 126/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6876 - val_loss: 1.6316\n",
      "Epoch 127/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6829 - val_loss: 1.8660\n",
      "Epoch 128/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6872 - val_loss: 1.7856\n",
      "Epoch 129/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6816 - val_loss: 1.6629\n",
      "Epoch 130/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6895 - val_loss: 1.7035\n",
      "Epoch 131/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6588 - val_loss: 1.6449\n",
      "Epoch 132/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6732 - val_loss: 1.7148\n",
      "Epoch 133/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6686 - val_loss: 1.6736\n",
      "Epoch 134/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6599 - val_loss: 1.6579\n",
      "Epoch 135/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6593 - val_loss: 1.6963\n",
      "Epoch 136/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6651 - val_loss: 1.8521\n",
      "Epoch 137/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6627 - val_loss: 1.6908\n",
      "Epoch 138/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6676 - val_loss: 1.6615\n",
      "Epoch 139/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6606 - val_loss: 1.6655\n",
      "Epoch 140/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6435 - val_loss: 1.6289\n",
      "Epoch 141/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6433 - val_loss: 1.6530\n",
      "Epoch 142/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6577 - val_loss: 1.6898\n",
      "Epoch 143/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6447 - val_loss: 1.6350\n",
      "Epoch 144/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6395 - val_loss: 1.6603\n",
      "Epoch 145/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6568 - val_loss: 1.7345\n",
      "Epoch 146/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6471 - val_loss: 1.7874\n",
      "Epoch 147/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6343 - val_loss: 1.6724\n",
      "Epoch 148/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6398 - val_loss: 1.6093\n",
      "Epoch 149/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6334 - val_loss: 1.6303\n",
      "Epoch 150/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6344 - val_loss: 1.6758\n",
      "Epoch 151/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6281 - val_loss: 1.6190\n",
      "Epoch 152/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6357 - val_loss: 1.9131\n",
      "Epoch 153/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6336 - val_loss: 1.6248\n",
      "Epoch 154/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6383 - val_loss: 1.6794\n",
      "Epoch 155/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6231 - val_loss: 1.6903\n",
      "Epoch 156/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6360 - val_loss: 1.7204\n",
      "Epoch 157/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6350 - val_loss: 1.6683\n",
      "Epoch 158/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6242 - val_loss: 1.7134\n",
      "Epoch 159/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6268 - val_loss: 1.6151\n",
      "Epoch 160/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6213 - val_loss: 1.6382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6198 - val_loss: 1.6518\n",
      "Epoch 162/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6203 - val_loss: 1.6203\n",
      "Epoch 163/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6197 - val_loss: 1.6787\n",
      "Epoch 164/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6178 - val_loss: 1.6059\n",
      "Epoch 165/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6161 - val_loss: 1.6805\n",
      "Epoch 166/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6100 - val_loss: 1.7155\n",
      "Epoch 167/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6050 - val_loss: 1.6516\n",
      "Epoch 168/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6036 - val_loss: 1.6379\n",
      "Epoch 169/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6008 - val_loss: 1.7187\n",
      "Epoch 170/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5956 - val_loss: 1.9051\n",
      "Epoch 171/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5996 - val_loss: 1.6268\n",
      "Epoch 172/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6008 - val_loss: 1.6229\n",
      "Epoch 173/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6039 - val_loss: 1.5675\n",
      "Epoch 174/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6006 - val_loss: 1.6508\n",
      "Epoch 175/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5950 - val_loss: 1.5891\n",
      "Epoch 176/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5878 - val_loss: 1.6264\n",
      "Epoch 177/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5975 - val_loss: 1.6596\n",
      "Epoch 178/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5900 - val_loss: 1.7598\n",
      "Epoch 179/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5915 - val_loss: 1.5541\n",
      "Epoch 180/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5714 - val_loss: 1.5639\n",
      "Epoch 181/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5793 - val_loss: 1.6046\n",
      "Epoch 182/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5857 - val_loss: 1.5757\n",
      "Epoch 183/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5907 - val_loss: 1.5764\n",
      "Epoch 184/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5740 - val_loss: 1.5734\n",
      "Epoch 185/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5832 - val_loss: 1.6377\n",
      "Epoch 186/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5784 - val_loss: 1.5632\n",
      "Epoch 187/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5795 - val_loss: 1.7801\n",
      "Epoch 188/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5739 - val_loss: 1.5695\n",
      "Epoch 189/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5825 - val_loss: 1.5620\n",
      "Epoch 190/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5613 - val_loss: 1.5159\n",
      "Epoch 191/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5657 - val_loss: 1.5384\n",
      "Epoch 192/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5599 - val_loss: 1.6542\n",
      "Epoch 193/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5794 - val_loss: 1.6708\n",
      "Epoch 194/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5636 - val_loss: 1.5472\n",
      "Epoch 195/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5656 - val_loss: 1.6343\n",
      "Epoch 196/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5734 - val_loss: 1.6779\n",
      "Epoch 197/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5595 - val_loss: 1.5413\n",
      "Epoch 198/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5583 - val_loss: 1.5693\n",
      "Epoch 199/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5594 - val_loss: 1.6406\n",
      "Epoch 200/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5624 - val_loss: 1.6276\n",
      "Epoch 201/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5575 - val_loss: 1.5913\n",
      "Epoch 202/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5542 - val_loss: 1.5939\n",
      "Epoch 203/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5546 - val_loss: 1.8048\n",
      "Epoch 204/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5569 - val_loss: 1.6173\n",
      "Epoch 205/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5553 - val_loss: 1.5819\n",
      "Epoch 206/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5512 - val_loss: 1.5405\n",
      "Epoch 207/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5455 - val_loss: 1.6158\n",
      "Epoch 208/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5541 - val_loss: 1.6127\n",
      "Epoch 209/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5456 - val_loss: 1.7038\n",
      "Epoch 210/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5438 - val_loss: 1.6055\n",
      "Epoch 211/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5454 - val_loss: 1.6210\n",
      "Epoch 212/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5407 - val_loss: 1.5764\n",
      "Epoch 213/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5442 - val_loss: 1.6358\n",
      "Epoch 214/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5499 - val_loss: 1.6654\n",
      "Epoch 215/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5295 - val_loss: 1.5891\n",
      "Epoch 216/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5422 - val_loss: 1.6099\n",
      "Epoch 217/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5316 - val_loss: 1.5327\n",
      "Epoch 218/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5456 - val_loss: 1.6055\n",
      "Epoch 219/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5390 - val_loss: 1.5725\n",
      "Epoch 220/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5348 - val_loss: 1.5945\n",
      "Epoch 221/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5326 - val_loss: 1.4923\n",
      "Epoch 222/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5284 - val_loss: 1.6382\n",
      "Epoch 223/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5261 - val_loss: 1.5375\n",
      "Epoch 224/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5294 - val_loss: 1.5651\n",
      "Epoch 225/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5293 - val_loss: 1.5424\n",
      "Epoch 226/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5216 - val_loss: 1.4985\n",
      "Epoch 227/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5263 - val_loss: 1.6264\n",
      "Epoch 228/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5281 - val_loss: 1.6403\n",
      "Epoch 229/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5185 - val_loss: 1.5586\n",
      "Epoch 230/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5277 - val_loss: 1.5994\n",
      "Epoch 231/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5235 - val_loss: 1.5682\n",
      "Epoch 232/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5161 - val_loss: 1.6227\n",
      "Epoch 233/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5228 - val_loss: 1.5130\n",
      "Epoch 234/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5185 - val_loss: 1.5943\n",
      "Epoch 235/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5181 - val_loss: 1.5686\n",
      "Epoch 236/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5217 - val_loss: 1.6122\n",
      "Epoch 237/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5111 - val_loss: 1.5702\n",
      "Epoch 238/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5135 - val_loss: 1.5676\n",
      "Epoch 239/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5118 - val_loss: 1.5792\n",
      "Epoch 240/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5148 - val_loss: 1.6192\n",
      "Epoch 241/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5123 - val_loss: 1.5588\n",
      "Epoch 242/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5035 - val_loss: 1.5275\n",
      "Epoch 243/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5062 - val_loss: 1.5482\n",
      "Epoch 244/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5131 - val_loss: 1.5698\n",
      "Epoch 245/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5110 - val_loss: 1.6015\n",
      "Epoch 246/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5080 - val_loss: 1.5359\n",
      "Epoch 247/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5069 - val_loss: 1.5369\n",
      "Epoch 248/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5124 - val_loss: 1.5365\n",
      "Epoch 249/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5046 - val_loss: 1.5507\n",
      "Epoch 250/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4995 - val_loss: 1.5559\n",
      "Epoch 251/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5078 - val_loss: 1.5080\n",
      "Epoch 252/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5061 - val_loss: 1.5770\n",
      "Epoch 253/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5004 - val_loss: 1.5448\n",
      "Epoch 254/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5071 - val_loss: 1.5349\n",
      "Epoch 255/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4988 - val_loss: 1.4982\n",
      "Epoch 256/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5060 - val_loss: 1.5901\n",
      "Epoch 257/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4953 - val_loss: 1.5629\n",
      "Epoch 258/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4992 - val_loss: 1.4758\n",
      "Epoch 259/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4941 - val_loss: 1.5338\n",
      "Epoch 260/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4984 - val_loss: 1.5691\n",
      "Epoch 261/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4946 - val_loss: 1.5326\n",
      "Epoch 262/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5027 - val_loss: 1.5162\n",
      "Epoch 263/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4838 - val_loss: 1.4992\n",
      "Epoch 264/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4936 - val_loss: 1.5197\n",
      "Epoch 265/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4974 - val_loss: 1.5051\n",
      "Epoch 266/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4879 - val_loss: 1.5068\n",
      "Epoch 267/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4948 - val_loss: 1.5605\n",
      "Epoch 268/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4929 - val_loss: 1.4985\n",
      "Epoch 269/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4973 - val_loss: 1.5082\n",
      "Epoch 270/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4866 - val_loss: 1.4617\n",
      "Epoch 271/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4877 - val_loss: 1.5089\n",
      "Epoch 272/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4930 - val_loss: 1.6359\n",
      "Epoch 273/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4997 - val_loss: 1.5041\n",
      "Epoch 274/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4814 - val_loss: 1.4956\n",
      "Epoch 275/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4815 - val_loss: 1.5517\n",
      "Epoch 276/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4969 - val_loss: 1.5065\n",
      "Epoch 277/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5001 - val_loss: 1.6110\n",
      "Epoch 278/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4877 - val_loss: 1.6237\n",
      "Epoch 279/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4863 - val_loss: 1.5711\n",
      "Epoch 280/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4778 - val_loss: 1.4757\n",
      "Epoch 281/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4887 - val_loss: 1.4788\n",
      "Epoch 282/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4821 - val_loss: 1.5299\n",
      "Epoch 283/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4830 - val_loss: 1.6281\n",
      "Epoch 284/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4840 - val_loss: 1.5340\n",
      "Epoch 285/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4845 - val_loss: 1.5411\n",
      "Epoch 286/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4818 - val_loss: 1.4841\n",
      "Epoch 287/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4747 - val_loss: 1.4947\n",
      "Epoch 288/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4779 - val_loss: 1.4875\n",
      "Epoch 289/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4802 - val_loss: 1.4905\n",
      "Epoch 290/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4791 - val_loss: 1.4630\n",
      "Epoch 291/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4799 - val_loss: 1.5355\n",
      "Epoch 292/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4888 - val_loss: 1.5092\n",
      "Epoch 293/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4780 - val_loss: 1.5288\n",
      "Epoch 294/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4697 - val_loss: 1.4759\n",
      "Epoch 295/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4793 - val_loss: 1.4804\n",
      "Epoch 296/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4772 - val_loss: 1.5274\n",
      "Epoch 297/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4770 - val_loss: 1.5629\n",
      "Epoch 298/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4874 - val_loss: 1.4808\n",
      "Epoch 299/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4707 - val_loss: 1.5215\n",
      "Epoch 300/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4679 - val_loss: 1.5673\n",
      "Epoch 301/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4746 - val_loss: 1.4782\n",
      "Epoch 302/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4773 - val_loss: 1.6130\n",
      "Epoch 303/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4718 - val_loss: 1.5089\n",
      "Epoch 304/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4658 - val_loss: 1.4758\n",
      "Epoch 305/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4758 - val_loss: 1.4434\n",
      "Epoch 306/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4648 - val_loss: 1.5058\n",
      "Epoch 307/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4635 - val_loss: 1.4349\n",
      "Epoch 308/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4665 - val_loss: 1.5305\n",
      "Epoch 309/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4738 - val_loss: 1.4947\n",
      "Epoch 310/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4703 - val_loss: 1.5091\n",
      "Epoch 311/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4681 - val_loss: 1.6014\n",
      "Epoch 312/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4728 - val_loss: 1.4760\n",
      "Epoch 313/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4658 - val_loss: 1.4628\n",
      "Epoch 314/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4606 - val_loss: 1.4981\n",
      "Epoch 315/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4687 - val_loss: 1.4744\n",
      "Epoch 316/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4577 - val_loss: 1.4697\n",
      "Epoch 317/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4602 - val_loss: 1.5263\n",
      "Epoch 318/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4530 - val_loss: 1.4738\n",
      "Epoch 319/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4633 - val_loss: 1.5415\n",
      "Epoch 320/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4661 - val_loss: 1.4939\n",
      "Epoch 321/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4598 - val_loss: 1.4832\n",
      "Epoch 322/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4606 - val_loss: 1.5433\n",
      "Epoch 323/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4640 - val_loss: 1.5531\n",
      "Epoch 324/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4493 - val_loss: 1.5350\n",
      "Epoch 325/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4655 - val_loss: 1.4978\n",
      "Epoch 326/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4606 - val_loss: 1.5562\n",
      "Epoch 327/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4537 - val_loss: 1.5045\n",
      "Epoch 328/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4503 - val_loss: 1.4467\n",
      "Epoch 329/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4569 - val_loss: 1.5460\n",
      "Epoch 330/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4658 - val_loss: 1.5624\n",
      "Epoch 331/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4484 - val_loss: 1.5153\n",
      "Epoch 332/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4444 - val_loss: 1.4963\n",
      "Epoch 333/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4528 - val_loss: 1.5685\n",
      "Epoch 334/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4550 - val_loss: 1.5293\n",
      "Epoch 335/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4519 - val_loss: 1.5008\n",
      "Epoch 336/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4479 - val_loss: 1.5532\n",
      "Epoch 337/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4533 - val_loss: 1.5099\n",
      "Epoch 338/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4580 - val_loss: 1.4901\n",
      "Epoch 339/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4426 - val_loss: 1.4523\n",
      "Epoch 340/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4571 - val_loss: 1.5903\n",
      "Epoch 341/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4538 - val_loss: 1.4712\n",
      "Epoch 342/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4458 - val_loss: 1.5782\n",
      "Epoch 343/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4387 - val_loss: 1.4579\n",
      "Epoch 344/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4461 - val_loss: 1.5008\n",
      "Epoch 345/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4420 - val_loss: 1.5714\n",
      "Epoch 346/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4540 - val_loss: 1.4650\n",
      "Epoch 347/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4460 - val_loss: 1.4565\n",
      "Epoch 348/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4432 - val_loss: 1.5219\n",
      "Epoch 349/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4454 - val_loss: 1.4776\n",
      "Epoch 350/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4501 - val_loss: 1.5157\n",
      "Epoch 351/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4424 - val_loss: 1.4831\n",
      "Epoch 352/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4475 - val_loss: 1.4327\n",
      "Epoch 353/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4317 - val_loss: 1.4587\n",
      "Epoch 354/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4392 - val_loss: 1.5767\n",
      "Epoch 355/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4373 - val_loss: 1.5189\n",
      "Epoch 356/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4349 - val_loss: 1.5068\n",
      "Epoch 357/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4418 - val_loss: 1.4840\n",
      "Epoch 358/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4388 - val_loss: 1.5181\n",
      "Epoch 359/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4389 - val_loss: 1.5310\n",
      "Epoch 360/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4351 - val_loss: 1.4676\n",
      "Epoch 361/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4320 - val_loss: 1.4783\n",
      "Epoch 362/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4341 - val_loss: 1.4799\n",
      "Epoch 363/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4477 - val_loss: 1.4915\n",
      "Epoch 364/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4361 - val_loss: 1.4443\n",
      "Epoch 365/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4432 - val_loss: 1.5195\n",
      "Epoch 366/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4299 - val_loss: 1.4429\n",
      "Epoch 367/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4357 - val_loss: 1.4718\n",
      "Epoch 368/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4383 - val_loss: 1.5014\n",
      "Epoch 369/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4343 - val_loss: 1.4963\n",
      "Epoch 370/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4343 - val_loss: 1.4526\n",
      "Epoch 371/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4274 - val_loss: 1.4567\n",
      "Epoch 372/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4339 - val_loss: 1.4269\n",
      "Epoch 373/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4330 - val_loss: 1.4392\n",
      "Epoch 374/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4302 - val_loss: 1.4583\n",
      "Epoch 375/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4339 - val_loss: 1.4816\n",
      "Epoch 376/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4377 - val_loss: 1.5182\n",
      "Epoch 377/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4225 - val_loss: 1.5428\n",
      "Epoch 378/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4276 - val_loss: 1.4441\n",
      "Epoch 379/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4233 - val_loss: 1.5387\n",
      "Epoch 380/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4299 - val_loss: 1.5023\n",
      "Epoch 381/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4163 - val_loss: 1.4413\n",
      "Epoch 382/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4208 - val_loss: 1.4705\n",
      "Epoch 383/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4204 - val_loss: 1.4528\n",
      "Epoch 384/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4270 - val_loss: 1.4545\n",
      "Epoch 385/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4291 - val_loss: 1.5243\n",
      "Epoch 386/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4335 - val_loss: 1.4685\n",
      "Epoch 387/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4290 - val_loss: 1.4833\n",
      "Epoch 388/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4157 - val_loss: 1.4407\n",
      "Epoch 389/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4274 - val_loss: 1.4327\n",
      "Epoch 390/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4187 - val_loss: 1.4330\n",
      "Epoch 391/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4274 - val_loss: 1.4887\n",
      "Epoch 392/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4132 - val_loss: 1.4866\n",
      "Epoch 393/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4299 - val_loss: 1.5089\n",
      "Epoch 394/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4277 - val_loss: 1.4591\n",
      "Epoch 395/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4149 - val_loss: 1.4963\n",
      "Epoch 396/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4199 - val_loss: 1.4910\n",
      "Epoch 397/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4200 - val_loss: 1.3956\n",
      "Epoch 398/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4235 - val_loss: 1.4654\n",
      "Epoch 399/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4338 - val_loss: 1.4804\n",
      "Epoch 400/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4191 - val_loss: 1.5368\n",
      "Epoch 401/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4186 - val_loss: 1.4450\n",
      "Epoch 402/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4233 - val_loss: 1.4460\n",
      "Epoch 403/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4150 - val_loss: 1.4279\n",
      "Epoch 404/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4117 - val_loss: 1.4560\n",
      "Epoch 405/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4223 - val_loss: 1.4673\n",
      "Epoch 406/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4217 - val_loss: 1.4321\n",
      "Epoch 407/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4224 - val_loss: 1.4487\n",
      "Epoch 408/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4209 - val_loss: 1.4565\n",
      "Epoch 409/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4141 - val_loss: 1.4203\n",
      "Epoch 410/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4108 - val_loss: 1.4405\n",
      "Epoch 411/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4241 - val_loss: 1.4769\n",
      "Epoch 412/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4200 - val_loss: 1.4586\n",
      "Epoch 413/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4233 - val_loss: 1.4607\n",
      "Epoch 414/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4055 - val_loss: 1.4698\n",
      "Epoch 415/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4094 - val_loss: 1.4317\n",
      "Epoch 416/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4194 - val_loss: 1.4596\n",
      "Epoch 417/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4112 - val_loss: 1.4966\n",
      "Epoch 418/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4193 - val_loss: 1.4601\n",
      "Epoch 419/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4106 - val_loss: 1.5809\n",
      "Epoch 420/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4132 - val_loss: 1.4410\n",
      "Epoch 421/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4115 - val_loss: 1.4159\n",
      "Epoch 422/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4159 - val_loss: 1.4219\n",
      "Epoch 423/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4058 - val_loss: 1.4542\n",
      "Epoch 424/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4115 - val_loss: 1.5070\n",
      "Epoch 425/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4162 - val_loss: 1.4849\n",
      "Epoch 426/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4144 - val_loss: 1.4428\n",
      "Epoch 427/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4095 - val_loss: 1.4426\n",
      "Epoch 428/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4145 - val_loss: 1.4027\n",
      "Epoch 429/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4145 - val_loss: 1.4254\n",
      "Epoch 430/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4030 - val_loss: 1.4564\n",
      "Epoch 431/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4158 - val_loss: 1.4757\n",
      "Epoch 432/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4021 - val_loss: 1.4416\n",
      "Epoch 433/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4059 - val_loss: 1.4570\n",
      "Epoch 434/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4020 - val_loss: 1.4826\n",
      "Epoch 435/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4004 - val_loss: 1.4094\n",
      "Epoch 436/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4016 - val_loss: 1.4411\n",
      "Epoch 437/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3986 - val_loss: 1.4632\n",
      "Epoch 438/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4100 - val_loss: 1.4492\n",
      "Epoch 439/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4127 - val_loss: 1.4314\n",
      "Epoch 440/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4008 - val_loss: 1.4493\n",
      "Epoch 441/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4065 - val_loss: 1.4123\n",
      "Epoch 442/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4065 - val_loss: 1.4168\n",
      "Epoch 443/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3964 - val_loss: 1.4157\n",
      "Epoch 444/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4038 - val_loss: 1.4517\n",
      "Epoch 445/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4049 - val_loss: 1.4772\n",
      "Epoch 446/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4014 - val_loss: 1.4598\n",
      "Epoch 447/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4029 - val_loss: 1.3751\n",
      "Epoch 448/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3987 - val_loss: 1.4250\n",
      "Epoch 449/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3945 - val_loss: 1.4646\n",
      "Epoch 450/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4040 - val_loss: 1.3909\n",
      "Epoch 451/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4032 - val_loss: 1.4085\n",
      "Epoch 452/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4013 - val_loss: 1.4481\n",
      "Epoch 453/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3986 - val_loss: 1.4401\n",
      "Epoch 454/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4002 - val_loss: 1.4512\n",
      "Epoch 455/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3953 - val_loss: 1.4104\n",
      "Epoch 456/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3922 - val_loss: 1.4677\n",
      "Epoch 457/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3969 - val_loss: 1.4187\n",
      "Epoch 458/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4037 - val_loss: 1.3931\n",
      "Epoch 459/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3853 - val_loss: 1.3942\n",
      "Epoch 460/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3977 - val_loss: 1.3950\n",
      "Epoch 461/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3953 - val_loss: 1.4503\n",
      "Epoch 462/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3977 - val_loss: 1.4422\n",
      "Epoch 463/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3994 - val_loss: 1.4579\n",
      "Epoch 464/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3906 - val_loss: 1.4133\n",
      "Epoch 465/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3992 - val_loss: 1.4988\n",
      "Epoch 466/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3871 - val_loss: 1.4484\n",
      "Epoch 467/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3938 - val_loss: 1.5418\n",
      "Epoch 468/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3961 - val_loss: 1.4342\n",
      "Epoch 469/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4002 - val_loss: 1.5066\n",
      "Epoch 470/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3882 - val_loss: 1.4815\n",
      "Epoch 471/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3883 - val_loss: 1.4720\n",
      "Epoch 472/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4040 - val_loss: 1.3936\n",
      "Epoch 473/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3887 - val_loss: 1.4155\n",
      "Epoch 474/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3995 - val_loss: 1.5020\n",
      "Epoch 475/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3857 - val_loss: 1.4704\n",
      "Epoch 476/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3893 - val_loss: 1.3804\n",
      "Epoch 477/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3862 - val_loss: 1.4343\n",
      "Epoch 478/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3928 - val_loss: 1.3660\n",
      "Epoch 479/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3914 - val_loss: 1.4164\n",
      "Epoch 480/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4002 - val_loss: 1.4015\n",
      "Epoch 481/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3858 - val_loss: 1.4223\n",
      "Epoch 482/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3934 - val_loss: 1.4694\n",
      "Epoch 483/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3942 - val_loss: 1.4047\n",
      "Epoch 484/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3803 - val_loss: 1.4506\n",
      "Epoch 485/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3901 - val_loss: 1.5691\n",
      "Epoch 486/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3867 - val_loss: 1.4284\n",
      "Epoch 487/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3901 - val_loss: 1.4101\n",
      "Epoch 488/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3852 - val_loss: 1.3696\n",
      "Epoch 489/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3999 - val_loss: 1.4560\n",
      "Epoch 490/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3819 - val_loss: 1.4709\n",
      "Epoch 491/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3942 - val_loss: 1.4187\n",
      "Epoch 492/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3969 - val_loss: 1.3917\n",
      "Epoch 493/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3956 - val_loss: 1.4302\n",
      "Epoch 494/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3958 - val_loss: 1.4151\n",
      "Epoch 495/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3871 - val_loss: 1.4300\n",
      "Epoch 496/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3805 - val_loss: 1.4695\n",
      "Epoch 497/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3938 - val_loss: 1.3673\n",
      "Epoch 498/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3872 - val_loss: 1.4282\n",
      "Epoch 499/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3895 - val_loss: 1.4385\n",
      "Epoch 500/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3877 - val_loss: 1.4534\n",
      "Epoch 501/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3856 - val_loss: 1.4447\n",
      "Epoch 502/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3762 - val_loss: 1.3858\n",
      "Epoch 503/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4001 - val_loss: 1.4152\n",
      "Epoch 504/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3837 - val_loss: 1.4302\n",
      "Epoch 505/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3880 - val_loss: 1.4005\n",
      "Epoch 506/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3862 - val_loss: 1.4731\n",
      "Epoch 507/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3923 - val_loss: 1.4449\n",
      "Epoch 508/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3815 - val_loss: 1.3918\n",
      "Epoch 509/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3803 - val_loss: 1.4506\n",
      "Epoch 510/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3851 - val_loss: 1.3985\n",
      "Epoch 511/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3911 - val_loss: 1.4330\n",
      "Epoch 512/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3803 - val_loss: 1.4109\n",
      "Epoch 513/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3767 - val_loss: 1.4114\n",
      "Epoch 514/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3780 - val_loss: 1.4447\n",
      "Epoch 515/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3894 - val_loss: 1.3993\n",
      "Epoch 516/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3887 - val_loss: 1.4648\n",
      "Epoch 517/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3790 - val_loss: 1.5775\n",
      "Epoch 518/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3753 - val_loss: 1.3865\n",
      "Epoch 519/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3866 - val_loss: 1.4483\n",
      "Epoch 520/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3882 - val_loss: 1.4284\n",
      "Epoch 521/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3833 - val_loss: 1.4226\n",
      "Epoch 522/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3921 - val_loss: 1.4215\n",
      "Epoch 523/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3755 - val_loss: 1.4164\n",
      "Epoch 524/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3723 - val_loss: 1.4139\n",
      "Epoch 525/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3893 - val_loss: 1.4319\n",
      "Epoch 526/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3794 - val_loss: 1.4695\n",
      "Epoch 527/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3802 - val_loss: 1.4655\n",
      "Epoch 528/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3809 - val_loss: 1.4266\n",
      "Epoch 529/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3746 - val_loss: 1.4068\n",
      "Epoch 530/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3905 - val_loss: 1.4297\n",
      "Epoch 531/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3821 - val_loss: 1.4923\n",
      "Epoch 532/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3830 - val_loss: 1.4041\n",
      "Epoch 533/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3749 - val_loss: 1.4108\n",
      "Epoch 534/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3834 - val_loss: 1.4353\n",
      "Epoch 535/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3796 - val_loss: 1.4199\n",
      "Epoch 536/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3819 - val_loss: 1.4175\n",
      "Epoch 537/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3791 - val_loss: 1.4192\n",
      "Epoch 538/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3781 - val_loss: 1.4045\n",
      "Epoch 539/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3780 - val_loss: 1.4331\n",
      "Epoch 540/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3720 - val_loss: 1.3875\n",
      "Epoch 541/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3798 - val_loss: 1.5171\n",
      "Epoch 542/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3787 - val_loss: 1.4894\n",
      "Epoch 543/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3686 - val_loss: 1.4208\n",
      "Epoch 544/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3721 - val_loss: 1.4430\n",
      "Epoch 545/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3816 - val_loss: 1.3948\n",
      "Epoch 546/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3745 - val_loss: 1.4304\n",
      "Epoch 547/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3758 - val_loss: 1.3939\n",
      "Epoch 548/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3775 - val_loss: 1.4203\n",
      "Epoch 549/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3779 - val_loss: 1.5108\n",
      "Epoch 550/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3693 - val_loss: 1.4024\n",
      "Epoch 551/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3760 - val_loss: 1.3946\n",
      "Epoch 552/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3757 - val_loss: 1.3877\n",
      "Epoch 553/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3661 - val_loss: 1.4047\n",
      "Epoch 554/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3766 - val_loss: 1.4578\n",
      "Epoch 555/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3722 - val_loss: 1.4149\n",
      "Epoch 556/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3767 - val_loss: 1.4285\n",
      "Epoch 557/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3791 - val_loss: 1.5111\n",
      "Epoch 558/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3746 - val_loss: 1.3725\n",
      "Epoch 559/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3758 - val_loss: 1.4176\n",
      "Epoch 560/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3736 - val_loss: 1.3712\n",
      "Epoch 561/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3664 - val_loss: 1.4592\n",
      "Epoch 562/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3671 - val_loss: 1.4038\n",
      "Epoch 563/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3670 - val_loss: 1.4259\n",
      "Epoch 564/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3743 - val_loss: 1.5145\n",
      "Epoch 565/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3633 - val_loss: 1.3666\n",
      "Epoch 566/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3679 - val_loss: 1.4060\n",
      "Epoch 567/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3680 - val_loss: 1.5564\n",
      "Epoch 568/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3691 - val_loss: 1.4007\n",
      "Epoch 569/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3744 - val_loss: 1.4287\n",
      "Epoch 570/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3696 - val_loss: 1.4352\n",
      "Epoch 571/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3694 - val_loss: 1.4199\n",
      "Epoch 572/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3685 - val_loss: 1.4214\n",
      "Epoch 573/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3706 - val_loss: 1.4031\n",
      "Epoch 574/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3711 - val_loss: 1.3934\n",
      "Epoch 575/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3679 - val_loss: 1.3825\n",
      "Epoch 576/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3723 - val_loss: 1.3848\n",
      "Epoch 577/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3634 - val_loss: 1.4205\n",
      "Epoch 578/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3692 - val_loss: 1.3989\n",
      "Epoch 579/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3678 - val_loss: 1.4718\n",
      "Epoch 580/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3760 - val_loss: 1.3674\n",
      "Epoch 581/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3686 - val_loss: 1.3427\n",
      "Epoch 582/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3663 - val_loss: 1.4127\n",
      "Epoch 583/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3720 - val_loss: 1.4003\n",
      "Epoch 584/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3684 - val_loss: 1.4171\n",
      "Epoch 585/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3684 - val_loss: 1.3802\n",
      "Epoch 586/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3598 - val_loss: 1.4025\n",
      "Epoch 587/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3620 - val_loss: 1.5223\n",
      "Epoch 588/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3660 - val_loss: 1.4328\n",
      "Epoch 589/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3653 - val_loss: 1.4084\n",
      "Epoch 590/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3607 - val_loss: 1.4139\n",
      "Epoch 591/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3625 - val_loss: 1.3938\n",
      "Epoch 592/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3661 - val_loss: 1.4012\n",
      "Epoch 593/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3681 - val_loss: 1.4239\n",
      "Epoch 594/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3658 - val_loss: 1.3988\n",
      "Epoch 595/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3652 - val_loss: 1.3777\n",
      "Epoch 596/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3633 - val_loss: 1.4894\n",
      "Epoch 597/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3637 - val_loss: 1.4051\n",
      "Epoch 598/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3612 - val_loss: 1.4447\n",
      "Epoch 599/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3637 - val_loss: 1.3780\n",
      "Epoch 600/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3606 - val_loss: 1.3942\n",
      "Epoch 601/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3633 - val_loss: 1.3497\n",
      "Epoch 602/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3560 - val_loss: 1.4031\n",
      "Epoch 603/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3691 - val_loss: 1.3632\n",
      "Epoch 604/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3573 - val_loss: 1.3800\n",
      "Epoch 605/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3591 - val_loss: 1.3667\n",
      "Epoch 606/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3627 - val_loss: 1.3862\n",
      "Epoch 607/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3563 - val_loss: 1.3949\n",
      "Epoch 608/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3596 - val_loss: 1.3477\n",
      "Epoch 609/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3643 - val_loss: 1.3965\n",
      "Epoch 610/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3602 - val_loss: 1.4318\n",
      "Epoch 611/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3710 - val_loss: 1.4642\n",
      "Epoch 612/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3606 - val_loss: 1.3950\n",
      "Epoch 613/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3597 - val_loss: 1.5029\n",
      "Epoch 614/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3575 - val_loss: 1.3792\n",
      "Epoch 615/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3561 - val_loss: 1.4181\n",
      "Epoch 616/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3610 - val_loss: 1.4910\n",
      "Epoch 617/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3559 - val_loss: 1.4339\n",
      "Epoch 618/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3670 - val_loss: 1.3826\n",
      "Epoch 619/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3652 - val_loss: 1.3888\n",
      "Epoch 620/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3643 - val_loss: 1.3633\n",
      "Epoch 621/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3530 - val_loss: 1.3643\n",
      "Epoch 622/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3621 - val_loss: 1.4198\n",
      "Epoch 623/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3575 - val_loss: 1.3885\n",
      "Epoch 624/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3649 - val_loss: 1.3965\n",
      "Epoch 625/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3505 - val_loss: 1.3920\n",
      "Epoch 626/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3575 - val_loss: 1.4251\n",
      "Epoch 627/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3584 - val_loss: 1.4304\n",
      "Epoch 628/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3531 - val_loss: 1.3893\n",
      "Epoch 629/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3537 - val_loss: 1.3631\n",
      "Epoch 630/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3588 - val_loss: 1.4311\n",
      "Epoch 631/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3537 - val_loss: 1.4264\n",
      "Epoch 632/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3525 - val_loss: 1.3863\n",
      "Epoch 633/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3595 - val_loss: 1.4246\n",
      "Epoch 634/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3660 - val_loss: 1.3952\n",
      "Epoch 635/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3494 - val_loss: 1.4242\n",
      "Epoch 636/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3551 - val_loss: 1.4361\n",
      "Epoch 637/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3523 - val_loss: 1.4058\n",
      "Epoch 638/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3448 - val_loss: 1.3914\n",
      "Epoch 639/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3604 - val_loss: 1.3801\n",
      "Epoch 640/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3585 - val_loss: 1.4546\n",
      "Epoch 641/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3462 - val_loss: 1.4289\n",
      "Epoch 642/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3661 - val_loss: 1.3624\n",
      "Epoch 643/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3539 - val_loss: 1.3852\n",
      "Epoch 644/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3526 - val_loss: 1.4256\n",
      "Epoch 645/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3627 - val_loss: 1.3319\n",
      "Epoch 646/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3573 - val_loss: 1.5154\n",
      "Epoch 647/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3518 - val_loss: 1.3804\n",
      "Epoch 648/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3553 - val_loss: 1.4088\n",
      "Epoch 649/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3524 - val_loss: 1.3625\n",
      "Epoch 650/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3499 - val_loss: 1.3979\n",
      "Epoch 651/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3517 - val_loss: 1.3943\n",
      "Epoch 652/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3586 - val_loss: 1.4328\n",
      "Epoch 653/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3583 - val_loss: 1.3981\n",
      "Epoch 654/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3588 - val_loss: 1.4476\n",
      "Epoch 655/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3515 - val_loss: 1.3849\n",
      "Epoch 656/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3563 - val_loss: 1.3782\n",
      "Epoch 657/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3594 - val_loss: 1.4310\n",
      "Epoch 658/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3434 - val_loss: 1.3868\n",
      "Epoch 659/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3508 - val_loss: 1.4345\n",
      "Epoch 660/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3490 - val_loss: 1.3535\n",
      "Epoch 661/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3456 - val_loss: 1.3949\n",
      "Epoch 662/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3483 - val_loss: 1.4081\n",
      "Epoch 663/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3524 - val_loss: 1.3915\n",
      "Epoch 664/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3454 - val_loss: 1.4130\n",
      "Epoch 665/700\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3549 - val_loss: 1.4069\n",
      "Epoch 666/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3536 - val_loss: 1.3612\n",
      "Epoch 667/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3494 - val_loss: 1.3701\n",
      "Epoch 668/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3441 - val_loss: 1.3923\n",
      "Epoch 669/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3520 - val_loss: 1.3869\n",
      "Epoch 670/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3529 - val_loss: 1.4276\n",
      "Epoch 671/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3448 - val_loss: 1.3609\n",
      "Epoch 672/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3360 - val_loss: 1.4467\n",
      "Epoch 673/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3532 - val_loss: 1.4527\n",
      "Epoch 674/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3493 - val_loss: 1.3524\n",
      "Epoch 675/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3451 - val_loss: 1.3440\n",
      "Epoch 676/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3492 - val_loss: 1.3857\n",
      "Epoch 677/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3560 - val_loss: 1.3646\n",
      "Epoch 678/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3508 - val_loss: 1.3479\n",
      "Epoch 679/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3549 - val_loss: 1.3391\n",
      "Epoch 680/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3454 - val_loss: 1.4456\n",
      "Epoch 681/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3356 - val_loss: 1.5107\n",
      "Epoch 682/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3590 - val_loss: 1.4163\n",
      "Epoch 683/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3513 - val_loss: 1.4221\n",
      "Epoch 684/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3507 - val_loss: 1.3750\n",
      "Epoch 685/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3447 - val_loss: 1.3470\n",
      "Epoch 686/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3409 - val_loss: 1.4113\n",
      "Epoch 687/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3545 - val_loss: 1.3773\n",
      "Epoch 688/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3406 - val_loss: 1.4628\n",
      "Epoch 689/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3483 - val_loss: 1.3954\n",
      "Epoch 690/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3434 - val_loss: 1.4783\n",
      "Epoch 691/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3512 - val_loss: 1.4006\n",
      "Epoch 692/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3419 - val_loss: 1.3642\n",
      "Epoch 693/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3451 - val_loss: 1.4046\n",
      "Epoch 694/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3407 - val_loss: 1.4001\n",
      "Epoch 695/700\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3403 - val_loss: 1.4277\n",
      "Epoch 696/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3424 - val_loss: 1.4455\n",
      "Epoch 697/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3433 - val_loss: 1.3760\n",
      "Epoch 698/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3534 - val_loss: 1.3347\n",
      "Epoch 699/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3502 - val_loss: 1.4264\n",
      "Epoch 700/700\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3377 - val_loss: 1.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.380042593718246\n",
      "0.9719515262877162\n",
      "Epoch 1/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 8.4175 - val_loss: 10.1551\n",
      "Epoch 2/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 4.6142 - val_loss: 4.0050\n",
      "Epoch 3/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 5.1367 - val_loss: 4.5430\n",
      "Epoch 4/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 4.3551 - val_loss: 3.9124\n",
      "Epoch 5/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 4.2995 - val_loss: 4.0131\n",
      "Epoch 6/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 3.9897 - val_loss: 3.9784\n",
      "Epoch 7/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 3.4931 - val_loss: 3.0081\n",
      "Epoch 8/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 3.4341 - val_loss: 3.0342\n",
      "Epoch 9/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.2339 - val_loss: 4.2703\n",
      "Epoch 10/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 3.1008 - val_loss: 2.9502\n",
      "Epoch 11/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 3.1122 - val_loss: 2.9296\n",
      "Epoch 12/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 3.0199 - val_loss: 3.2089\n",
      "Epoch 13/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.9166 - val_loss: 2.9613\n",
      "Epoch 14/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.8426 - val_loss: 2.6678\n",
      "Epoch 15/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.7681 - val_loss: 2.8409\n",
      "Epoch 16/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.7221 - val_loss: 2.5711\n",
      "Epoch 17/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.6420 - val_loss: 3.0338\n",
      "Epoch 18/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.6216 - val_loss: 2.5371\n",
      "Epoch 19/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.5547 - val_loss: 3.0451\n",
      "Epoch 20/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.5172 - val_loss: 2.5073\n",
      "Epoch 21/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4857 - val_loss: 2.7414\n",
      "Epoch 22/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4407 - val_loss: 2.4167\n",
      "Epoch 23/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4219 - val_loss: 2.3285\n",
      "Epoch 24/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4070 - val_loss: 2.5235\n",
      "Epoch 25/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.3975 - val_loss: 2.3041\n",
      "Epoch 26/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.3459 - val_loss: 2.2750\n",
      "Epoch 27/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.3370 - val_loss: 2.2707\n",
      "Epoch 28/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.2981 - val_loss: 2.2234\n",
      "Epoch 29/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.2988 - val_loss: 2.2227\n",
      "Epoch 30/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.2407 - val_loss: 2.2554\n",
      "Epoch 31/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.2416 - val_loss: 2.1587\n",
      "Epoch 32/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.2308 - val_loss: 2.1015\n",
      "Epoch 33/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1782 - val_loss: 2.2418\n",
      "Epoch 34/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1740 - val_loss: 2.1017\n",
      "Epoch 35/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1616 - val_loss: 2.0910\n",
      "Epoch 36/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1218 - val_loss: 2.1668\n",
      "Epoch 37/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1224 - val_loss: 2.1323\n",
      "Epoch 38/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1023 - val_loss: 2.2480\n",
      "Epoch 39/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0859 - val_loss: 2.0430\n",
      "Epoch 40/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0860 - val_loss: 1.9733\n",
      "Epoch 41/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0732 - val_loss: 2.0428\n",
      "Epoch 42/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0700 - val_loss: 2.0303\n",
      "Epoch 43/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0515 - val_loss: 2.0797\n",
      "Epoch 44/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0389 - val_loss: 2.0242\n",
      "Epoch 45/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0304 - val_loss: 2.0016\n",
      "Epoch 46/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0268 - val_loss: 2.0839\n",
      "Epoch 47/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0026 - val_loss: 2.0221\n",
      "Epoch 48/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0035 - val_loss: 2.1718\n",
      "Epoch 49/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0056 - val_loss: 2.0699\n",
      "Epoch 50/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9806 - val_loss: 1.9843\n",
      "Epoch 51/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9651 - val_loss: 2.0146\n",
      "Epoch 52/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9735 - val_loss: 1.9390\n",
      "Epoch 53/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9564 - val_loss: 1.8974\n",
      "Epoch 54/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9464 - val_loss: 1.9385\n",
      "Epoch 55/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9413 - val_loss: 1.9328\n",
      "Epoch 56/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9404 - val_loss: 2.0085\n",
      "Epoch 57/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9441 - val_loss: 1.8924\n",
      "Epoch 58/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9260 - val_loss: 1.8765\n",
      "Epoch 59/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9352 - val_loss: 1.9540\n",
      "Epoch 60/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9187 - val_loss: 1.9990\n",
      "Epoch 61/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9100 - val_loss: 1.9032\n",
      "Epoch 62/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9161 - val_loss: 1.8632\n",
      "Epoch 63/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9050 - val_loss: 1.9282\n",
      "Epoch 64/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9073 - val_loss: 1.8873\n",
      "Epoch 65/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8949 - val_loss: 1.8356\n",
      "Epoch 66/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8915 - val_loss: 1.8646\n",
      "Epoch 67/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8838 - val_loss: 2.0060\n",
      "Epoch 68/700\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.8918 - val_loss: 1.9064\n",
      "Epoch 69/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8703 - val_loss: 1.8819\n",
      "Epoch 70/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8747 - val_loss: 2.0881\n",
      "Epoch 71/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8594 - val_loss: 1.8883\n",
      "Epoch 72/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8533 - val_loss: 1.9174\n",
      "Epoch 73/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8586 - val_loss: 1.8287\n",
      "Epoch 74/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8538 - val_loss: 1.8694\n",
      "Epoch 75/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8511 - val_loss: 1.8462\n",
      "Epoch 76/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8485 - val_loss: 1.8573\n",
      "Epoch 77/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8392 - val_loss: 1.9374\n",
      "Epoch 78/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8268 - val_loss: 1.8119\n",
      "Epoch 79/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8332 - val_loss: 1.8354\n",
      "Epoch 80/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8210 - val_loss: 1.8347\n",
      "Epoch 81/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8107 - val_loss: 1.7726\n",
      "Epoch 82/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8193 - val_loss: 1.8368\n",
      "Epoch 83/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8212 - val_loss: 1.7929\n",
      "Epoch 84/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8063 - val_loss: 1.8193\n",
      "Epoch 85/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8079 - val_loss: 1.8086\n",
      "Epoch 86/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7916 - val_loss: 1.8665\n",
      "Epoch 87/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8095 - val_loss: 2.0749\n",
      "Epoch 88/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7974 - val_loss: 1.7562\n",
      "Epoch 89/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7891 - val_loss: 1.7749\n",
      "Epoch 90/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7877 - val_loss: 1.8821\n",
      "Epoch 91/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7836 - val_loss: 1.8160\n",
      "Epoch 92/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7879 - val_loss: 1.8149\n",
      "Epoch 93/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7846 - val_loss: 1.9109\n",
      "Epoch 94/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7574 - val_loss: 1.7706\n",
      "Epoch 95/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7641 - val_loss: 1.9387\n",
      "Epoch 96/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7656 - val_loss: 1.8066\n",
      "Epoch 97/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7575 - val_loss: 1.9425\n",
      "Epoch 98/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7637 - val_loss: 1.7831\n",
      "Epoch 99/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7460 - val_loss: 1.7336\n",
      "Epoch 100/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7477 - val_loss: 1.7798\n",
      "Epoch 101/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7503 - val_loss: 1.7325\n",
      "Epoch 102/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7297 - val_loss: 1.8232\n",
      "Epoch 103/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7566 - val_loss: 1.7829\n",
      "Epoch 104/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7504 - val_loss: 1.7557\n",
      "Epoch 105/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7544 - val_loss: 1.7012\n",
      "Epoch 106/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7346 - val_loss: 1.7313\n",
      "Epoch 107/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7405 - val_loss: 1.8174\n",
      "Epoch 108/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7420 - val_loss: 1.7092\n",
      "Epoch 109/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7205 - val_loss: 1.7540\n",
      "Epoch 110/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7262 - val_loss: 1.7882\n",
      "Epoch 111/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7220 - val_loss: 1.7492\n",
      "Epoch 112/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7185 - val_loss: 1.8652\n",
      "Epoch 113/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7313 - val_loss: 1.7324\n",
      "Epoch 114/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7167 - val_loss: 1.7869\n",
      "Epoch 115/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7174 - val_loss: 1.7435\n",
      "Epoch 116/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7135 - val_loss: 1.7633\n",
      "Epoch 117/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7189 - val_loss: 1.7240\n",
      "Epoch 118/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7011 - val_loss: 1.6661\n",
      "Epoch 119/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7122 - val_loss: 1.8334\n",
      "Epoch 120/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6928 - val_loss: 1.7386\n",
      "Epoch 121/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7097 - val_loss: 1.7302\n",
      "Epoch 122/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6864 - val_loss: 1.6748\n",
      "Epoch 123/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6904 - val_loss: 1.6970\n",
      "Epoch 124/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6902 - val_loss: 1.6925\n",
      "Epoch 125/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6936 - val_loss: 1.7832\n",
      "Epoch 126/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6792 - val_loss: 1.7633\n",
      "Epoch 127/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6825 - val_loss: 1.7053\n",
      "Epoch 128/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6886 - val_loss: 1.6463\n",
      "Epoch 129/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6788 - val_loss: 1.8074\n",
      "Epoch 130/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6813 - val_loss: 1.7070\n",
      "Epoch 131/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6769 - val_loss: 1.7341\n",
      "Epoch 132/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6860 - val_loss: 1.7219\n",
      "Epoch 133/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6791 - val_loss: 1.6821\n",
      "Epoch 134/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6632 - val_loss: 1.6849\n",
      "Epoch 135/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6832 - val_loss: 1.8467\n",
      "Epoch 136/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6667 - val_loss: 1.6577\n",
      "Epoch 137/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6542 - val_loss: 1.6406\n",
      "Epoch 138/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6558 - val_loss: 1.6855\n",
      "Epoch 139/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6559 - val_loss: 1.6687\n",
      "Epoch 140/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6525 - val_loss: 1.7103\n",
      "Epoch 141/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6636 - val_loss: 1.6407\n",
      "Epoch 142/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6597 - val_loss: 1.6590\n",
      "Epoch 143/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6576 - val_loss: 1.6348\n",
      "Epoch 144/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6439 - val_loss: 1.6954\n",
      "Epoch 145/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6527 - val_loss: 1.6300\n",
      "Epoch 146/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6425 - val_loss: 1.7193\n",
      "Epoch 147/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6397 - val_loss: 1.7313\n",
      "Epoch 148/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6415 - val_loss: 1.6957\n",
      "Epoch 149/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6404 - val_loss: 1.6850\n",
      "Epoch 150/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6326 - val_loss: 1.6191\n",
      "Epoch 151/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6304 - val_loss: 1.6616\n",
      "Epoch 152/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6201 - val_loss: 1.6531\n",
      "Epoch 153/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6261 - val_loss: 1.6611\n",
      "Epoch 154/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6269 - val_loss: 1.6625\n",
      "Epoch 155/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6425 - val_loss: 1.6677\n",
      "Epoch 156/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6319 - val_loss: 1.6507\n",
      "Epoch 157/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6074 - val_loss: 1.6595\n",
      "Epoch 158/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6112 - val_loss: 1.8453\n",
      "Epoch 159/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6320 - val_loss: 1.6606\n",
      "Epoch 160/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6230 - val_loss: 1.6716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6196 - val_loss: 1.6596\n",
      "Epoch 162/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6107 - val_loss: 1.6134\n",
      "Epoch 163/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5956 - val_loss: 1.6774\n",
      "Epoch 164/700\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6171 - val_loss: 1.6374\n",
      "Epoch 165/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6036 - val_loss: 1.7478\n",
      "Epoch 166/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6177 - val_loss: 1.6030\n",
      "Epoch 167/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5960 - val_loss: 1.6357\n",
      "Epoch 168/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6086 - val_loss: 1.6804\n",
      "Epoch 169/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5990 - val_loss: 1.6469\n",
      "Epoch 170/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6143 - val_loss: 1.6536\n",
      "Epoch 171/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6124 - val_loss: 1.6618\n",
      "Epoch 172/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5967 - val_loss: 1.7594\n",
      "Epoch 173/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6104 - val_loss: 1.6858\n",
      "Epoch 174/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6051 - val_loss: 1.6167\n",
      "Epoch 175/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5881 - val_loss: 1.5923\n",
      "Epoch 176/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5976 - val_loss: 1.6917\n",
      "Epoch 177/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5940 - val_loss: 1.6394\n",
      "Epoch 178/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5994 - val_loss: 1.6085\n",
      "Epoch 179/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5958 - val_loss: 1.6251\n",
      "Epoch 180/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5830 - val_loss: 1.6324\n",
      "Epoch 181/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5939 - val_loss: 1.6031\n",
      "Epoch 182/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5957 - val_loss: 1.6317\n",
      "Epoch 183/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5928 - val_loss: 1.6654\n",
      "Epoch 184/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5755 - val_loss: 1.5826\n",
      "Epoch 185/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5753 - val_loss: 1.6617\n",
      "Epoch 186/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5773 - val_loss: 1.6266\n",
      "Epoch 187/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5885 - val_loss: 1.6556\n",
      "Epoch 188/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5731 - val_loss: 1.5708\n",
      "Epoch 189/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5780 - val_loss: 1.6555\n",
      "Epoch 190/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5747 - val_loss: 1.6039\n",
      "Epoch 191/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5727 - val_loss: 1.6494\n",
      "Epoch 192/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5692 - val_loss: 1.6161\n",
      "Epoch 193/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5715 - val_loss: 1.6642\n",
      "Epoch 194/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5653 - val_loss: 1.5828\n",
      "Epoch 195/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5609 - val_loss: 1.6358\n",
      "Epoch 196/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5791 - val_loss: 1.6723\n",
      "Epoch 197/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5689 - val_loss: 1.5790\n",
      "Epoch 198/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5794 - val_loss: 1.6043\n",
      "Epoch 199/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5680 - val_loss: 1.5981\n",
      "Epoch 200/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5650 - val_loss: 1.6625\n",
      "Epoch 201/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5639 - val_loss: 1.6441\n",
      "Epoch 202/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5494 - val_loss: 1.6015\n",
      "Epoch 203/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5553 - val_loss: 1.5691\n",
      "Epoch 204/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5451 - val_loss: 1.6252\n",
      "Epoch 205/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5594 - val_loss: 1.5498\n",
      "Epoch 206/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5532 - val_loss: 1.6152\n",
      "Epoch 207/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5474 - val_loss: 1.5983\n",
      "Epoch 208/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5534 - val_loss: 1.5604\n",
      "Epoch 209/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5588 - val_loss: 1.6079\n",
      "Epoch 210/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5558 - val_loss: 1.5833\n",
      "Epoch 211/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5401 - val_loss: 1.5932\n",
      "Epoch 212/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5560 - val_loss: 1.5913\n",
      "Epoch 213/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5454 - val_loss: 1.6393\n",
      "Epoch 214/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5480 - val_loss: 1.5490\n",
      "Epoch 215/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5446 - val_loss: 1.5386\n",
      "Epoch 216/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5439 - val_loss: 1.6902\n",
      "Epoch 217/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5506 - val_loss: 1.6489\n",
      "Epoch 218/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5412 - val_loss: 1.5586\n",
      "Epoch 219/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5198 - val_loss: 1.5972\n",
      "Epoch 220/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5253 - val_loss: 1.5680\n",
      "Epoch 221/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5399 - val_loss: 1.5463\n",
      "Epoch 222/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5268 - val_loss: 1.6271\n",
      "Epoch 223/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5450 - val_loss: 1.4998\n",
      "Epoch 224/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5334 - val_loss: 1.6327\n",
      "Epoch 225/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5381 - val_loss: 1.5482\n",
      "Epoch 226/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5354 - val_loss: 1.6153\n",
      "Epoch 227/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5348 - val_loss: 1.5865\n",
      "Epoch 228/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5289 - val_loss: 1.6125\n",
      "Epoch 229/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5263 - val_loss: 1.5491\n",
      "Epoch 230/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5304 - val_loss: 1.5814\n",
      "Epoch 231/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5276 - val_loss: 1.5521\n",
      "Epoch 232/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5303 - val_loss: 1.6440\n",
      "Epoch 233/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5307 - val_loss: 1.5644\n",
      "Epoch 234/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5263 - val_loss: 1.5291\n",
      "Epoch 235/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5178 - val_loss: 1.6029\n",
      "Epoch 236/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5187 - val_loss: 1.6224\n",
      "Epoch 237/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5195 - val_loss: 1.5668\n",
      "Epoch 238/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5198 - val_loss: 1.5108\n",
      "Epoch 239/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5212 - val_loss: 1.5075\n",
      "Epoch 240/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5256 - val_loss: 1.5433\n",
      "Epoch 241/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5237 - val_loss: 1.5610\n",
      "Epoch 242/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5132 - val_loss: 1.4764\n",
      "Epoch 243/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5150 - val_loss: 1.4947\n",
      "Epoch 244/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5190 - val_loss: 1.5133\n",
      "Epoch 245/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5046 - val_loss: 1.5139\n",
      "Epoch 246/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5218 - val_loss: 1.5414\n",
      "Epoch 247/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5091 - val_loss: 1.5231\n",
      "Epoch 248/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5058 - val_loss: 1.4872\n",
      "Epoch 249/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5099 - val_loss: 1.5760\n",
      "Epoch 250/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5141 - val_loss: 1.5464\n",
      "Epoch 251/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5087 - val_loss: 1.4917\n",
      "Epoch 252/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5223 - val_loss: 1.4953\n",
      "Epoch 253/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5108 - val_loss: 1.6198\n",
      "Epoch 254/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5034 - val_loss: 1.5493\n",
      "Epoch 255/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5069 - val_loss: 1.5804\n",
      "Epoch 256/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5057 - val_loss: 1.5937\n",
      "Epoch 257/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5154 - val_loss: 1.5757\n",
      "Epoch 258/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5088 - val_loss: 1.5976\n",
      "Epoch 259/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5012 - val_loss: 1.5378\n",
      "Epoch 260/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5038 - val_loss: 1.6015\n",
      "Epoch 261/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4997 - val_loss: 1.4998\n",
      "Epoch 262/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4975 - val_loss: 1.5659\n",
      "Epoch 263/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4918 - val_loss: 1.5443\n",
      "Epoch 264/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4976 - val_loss: 1.5451\n",
      "Epoch 265/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4894 - val_loss: 1.5187\n",
      "Epoch 266/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4838 - val_loss: 1.5136\n",
      "Epoch 267/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4931 - val_loss: 1.5572\n",
      "Epoch 268/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4945 - val_loss: 1.5063\n",
      "Epoch 269/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4970 - val_loss: 1.5155\n",
      "Epoch 270/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4801 - val_loss: 1.5028\n",
      "Epoch 271/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4847 - val_loss: 1.5144\n",
      "Epoch 272/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4704 - val_loss: 1.5446\n",
      "Epoch 273/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4924 - val_loss: 1.5287\n",
      "Epoch 274/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4777 - val_loss: 1.5681\n",
      "Epoch 275/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4815 - val_loss: 1.4909\n",
      "Epoch 276/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4896 - val_loss: 1.5107\n",
      "Epoch 277/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4874 - val_loss: 1.5466\n",
      "Epoch 278/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4809 - val_loss: 1.5095\n",
      "Epoch 279/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4843 - val_loss: 1.6224\n",
      "Epoch 280/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4830 - val_loss: 1.5282\n",
      "Epoch 281/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4825 - val_loss: 1.5232\n",
      "Epoch 282/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4887 - val_loss: 1.5221\n",
      "Epoch 283/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4801 - val_loss: 1.5015\n",
      "Epoch 284/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4826 - val_loss: 1.4577\n",
      "Epoch 285/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4687 - val_loss: 1.5521\n",
      "Epoch 286/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4857 - val_loss: 1.5121\n",
      "Epoch 287/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4771 - val_loss: 1.5395\n",
      "Epoch 288/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4800 - val_loss: 1.5524\n",
      "Epoch 289/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4685 - val_loss: 1.5271\n",
      "Epoch 290/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4661 - val_loss: 1.4477\n",
      "Epoch 291/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4640 - val_loss: 1.5540\n",
      "Epoch 292/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4856 - val_loss: 1.4668\n",
      "Epoch 293/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4784 - val_loss: 1.5031\n",
      "Epoch 294/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4716 - val_loss: 1.5459\n",
      "Epoch 295/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4713 - val_loss: 1.5371\n",
      "Epoch 296/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4637 - val_loss: 1.4970\n",
      "Epoch 297/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4527 - val_loss: 1.4997\n",
      "Epoch 298/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4718 - val_loss: 1.5058\n",
      "Epoch 299/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4714 - val_loss: 1.4800\n",
      "Epoch 300/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4691 - val_loss: 1.5502\n",
      "Epoch 301/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4647 - val_loss: 1.5258\n",
      "Epoch 302/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4620 - val_loss: 1.4422\n",
      "Epoch 303/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4682 - val_loss: 1.4856\n",
      "Epoch 304/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4718 - val_loss: 1.4968\n",
      "Epoch 305/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4620 - val_loss: 1.4934\n",
      "Epoch 306/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4639 - val_loss: 1.5582\n",
      "Epoch 307/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4609 - val_loss: 1.5473\n",
      "Epoch 308/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4612 - val_loss: 1.5198\n",
      "Epoch 309/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4607 - val_loss: 1.4994\n",
      "Epoch 310/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4647 - val_loss: 1.5108\n",
      "Epoch 311/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4703 - val_loss: 1.5107\n",
      "Epoch 312/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4486 - val_loss: 1.5247\n",
      "Epoch 313/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4595 - val_loss: 1.4797\n",
      "Epoch 314/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4537 - val_loss: 1.4769\n",
      "Epoch 315/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4597 - val_loss: 1.4721\n",
      "Epoch 316/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4598 - val_loss: 1.4747\n",
      "Epoch 317/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4573 - val_loss: 1.5309\n",
      "Epoch 318/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4537 - val_loss: 1.4928\n",
      "Epoch 319/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4539 - val_loss: 1.4579\n",
      "Epoch 320/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4461 - val_loss: 1.4721\n",
      "Epoch 321/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4503 - val_loss: 1.4895\n",
      "Epoch 322/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4567 - val_loss: 1.4648\n",
      "Epoch 323/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4540 - val_loss: 1.5424\n",
      "Epoch 324/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4435 - val_loss: 1.4445\n",
      "Epoch 325/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4515 - val_loss: 1.5064\n",
      "Epoch 326/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4525 - val_loss: 1.4901\n",
      "Epoch 327/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4506 - val_loss: 1.5303\n",
      "Epoch 328/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4493 - val_loss: 1.4496\n",
      "Epoch 329/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4353 - val_loss: 1.4423\n",
      "Epoch 330/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4467 - val_loss: 1.7534\n",
      "Epoch 331/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4560 - val_loss: 1.4252\n",
      "Epoch 332/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4293 - val_loss: 1.4891\n",
      "Epoch 333/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4423 - val_loss: 1.5024\n",
      "Epoch 334/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4431 - val_loss: 1.4674\n",
      "Epoch 335/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4638 - val_loss: 1.4917\n",
      "Epoch 336/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4419 - val_loss: 1.4373\n",
      "Epoch 337/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4379 - val_loss: 1.5082\n",
      "Epoch 338/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4333 - val_loss: 1.4326\n",
      "Epoch 339/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4438 - val_loss: 1.4011\n",
      "Epoch 340/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4380 - val_loss: 1.4837\n",
      "Epoch 341/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4334 - val_loss: 1.4877\n",
      "Epoch 342/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4385 - val_loss: 1.5165\n",
      "Epoch 343/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4359 - val_loss: 1.4447\n",
      "Epoch 344/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4331 - val_loss: 1.5210\n",
      "Epoch 345/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4475 - val_loss: 1.5015\n",
      "Epoch 346/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4398 - val_loss: 1.4630\n",
      "Epoch 347/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4447 - val_loss: 1.5151\n",
      "Epoch 348/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4378 - val_loss: 1.5709\n",
      "Epoch 349/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4301 - val_loss: 1.4772\n",
      "Epoch 350/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4439 - val_loss: 1.5482\n",
      "Epoch 351/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4436 - val_loss: 1.4630\n",
      "Epoch 352/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4398 - val_loss: 1.4634\n",
      "Epoch 353/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4318 - val_loss: 1.5946\n",
      "Epoch 354/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4336 - val_loss: 1.4732\n",
      "Epoch 355/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4333 - val_loss: 1.4927\n",
      "Epoch 356/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4360 - val_loss: 1.4558\n",
      "Epoch 357/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4271 - val_loss: 1.4555\n",
      "Epoch 358/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4316 - val_loss: 1.4778\n",
      "Epoch 359/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4213 - val_loss: 1.5414\n",
      "Epoch 360/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4250 - val_loss: 1.4676\n",
      "Epoch 361/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4244 - val_loss: 1.4129\n",
      "Epoch 362/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4210 - val_loss: 1.4596\n",
      "Epoch 363/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4234 - val_loss: 1.4287\n",
      "Epoch 364/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4288 - val_loss: 1.4403\n",
      "Epoch 365/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4184 - val_loss: 1.5650\n",
      "Epoch 366/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4348 - val_loss: 1.4902\n",
      "Epoch 367/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4364 - val_loss: 1.4249\n",
      "Epoch 368/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4273 - val_loss: 1.4362\n",
      "Epoch 369/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4136 - val_loss: 1.4959\n",
      "Epoch 370/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4167 - val_loss: 1.4391\n",
      "Epoch 371/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4180 - val_loss: 1.4547\n",
      "Epoch 372/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4194 - val_loss: 1.4299\n",
      "Epoch 373/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4212 - val_loss: 1.4978\n",
      "Epoch 374/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4247 - val_loss: 1.5053\n",
      "Epoch 375/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4112 - val_loss: 1.4081\n",
      "Epoch 376/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4155 - val_loss: 1.4600\n",
      "Epoch 377/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4282 - val_loss: 1.4715\n",
      "Epoch 378/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4134 - val_loss: 1.4685\n",
      "Epoch 379/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4243 - val_loss: 1.5272\n",
      "Epoch 380/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4155 - val_loss: 1.4178\n",
      "Epoch 381/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4086 - val_loss: 1.5184\n",
      "Epoch 382/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4122 - val_loss: 1.4796\n",
      "Epoch 383/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4137 - val_loss: 1.4018\n",
      "Epoch 384/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4180 - val_loss: 1.4192\n",
      "Epoch 385/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4104 - val_loss: 1.4720\n",
      "Epoch 386/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4153 - val_loss: 1.4399\n",
      "Epoch 387/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4217 - val_loss: 1.5455\n",
      "Epoch 388/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3983 - val_loss: 1.5063\n",
      "Epoch 389/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4178 - val_loss: 1.4806\n",
      "Epoch 390/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4157 - val_loss: 1.4857\n",
      "Epoch 391/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4077 - val_loss: 1.4502\n",
      "Epoch 392/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4084 - val_loss: 1.4329\n",
      "Epoch 393/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4018 - val_loss: 1.5061\n",
      "Epoch 394/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4183 - val_loss: 1.4855\n",
      "Epoch 395/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4045 - val_loss: 1.4397\n",
      "Epoch 396/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4086 - val_loss: 1.4655\n",
      "Epoch 397/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4017 - val_loss: 1.4373\n",
      "Epoch 398/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4093 - val_loss: 1.5193\n",
      "Epoch 399/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4058 - val_loss: 1.4070\n",
      "Epoch 400/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4132 - val_loss: 1.4457\n",
      "Epoch 401/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4093 - val_loss: 1.4476\n",
      "Epoch 402/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4124 - val_loss: 1.4566\n",
      "Epoch 403/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3992 - val_loss: 1.4174\n",
      "Epoch 404/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4073 - val_loss: 1.4178\n",
      "Epoch 405/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4106 - val_loss: 1.4366\n",
      "Epoch 406/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4044 - val_loss: 1.4838\n",
      "Epoch 407/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3990 - val_loss: 1.4366\n",
      "Epoch 408/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4034 - val_loss: 1.4599\n",
      "Epoch 409/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4062 - val_loss: 1.4709\n",
      "Epoch 410/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4113 - val_loss: 1.4643\n",
      "Epoch 411/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4022 - val_loss: 1.4729\n",
      "Epoch 412/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4011 - val_loss: 1.4284\n",
      "Epoch 413/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3920 - val_loss: 1.3757\n",
      "Epoch 414/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4031 - val_loss: 1.4407\n",
      "Epoch 415/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3935 - val_loss: 1.5098\n",
      "Epoch 416/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4023 - val_loss: 1.4281\n",
      "Epoch 417/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4135 - val_loss: 1.4925\n",
      "Epoch 418/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3923 - val_loss: 1.5231\n",
      "Epoch 419/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4000 - val_loss: 1.4915\n",
      "Epoch 420/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3955 - val_loss: 1.4223\n",
      "Epoch 421/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3928 - val_loss: 1.4556\n",
      "Epoch 422/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3941 - val_loss: 1.4499\n",
      "Epoch 423/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3946 - val_loss: 1.4178\n",
      "Epoch 424/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3903 - val_loss: 1.4780\n",
      "Epoch 425/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3944 - val_loss: 1.4742\n",
      "Epoch 426/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4000 - val_loss: 1.4534\n",
      "Epoch 427/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4006 - val_loss: 1.3896\n",
      "Epoch 428/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3907 - val_loss: 1.4571\n",
      "Epoch 429/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3902 - val_loss: 1.4711\n",
      "Epoch 430/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3944 - val_loss: 1.4499\n",
      "Epoch 431/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4069 - val_loss: 1.4025\n",
      "Epoch 432/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3881 - val_loss: 1.4153\n",
      "Epoch 433/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3907 - val_loss: 1.4616\n",
      "Epoch 434/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4015 - val_loss: 1.4636\n",
      "Epoch 435/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3928 - val_loss: 1.5172\n",
      "Epoch 436/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3850 - val_loss: 1.4510\n",
      "Epoch 437/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3932 - val_loss: 1.4635\n",
      "Epoch 438/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3902 - val_loss: 1.5093\n",
      "Epoch 439/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3935 - val_loss: 1.4704\n",
      "Epoch 440/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3844 - val_loss: 1.4466\n",
      "Epoch 441/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3889 - val_loss: 1.4501\n",
      "Epoch 442/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3948 - val_loss: 1.4512\n",
      "Epoch 443/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3960 - val_loss: 1.4363\n",
      "Epoch 444/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3858 - val_loss: 1.3970\n",
      "Epoch 445/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3877 - val_loss: 1.4251\n",
      "Epoch 446/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4048 - val_loss: 1.4884\n",
      "Epoch 447/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3791 - val_loss: 1.4749\n",
      "Epoch 448/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3907 - val_loss: 1.3999\n",
      "Epoch 449/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3753 - val_loss: 1.4211\n",
      "Epoch 450/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3800 - val_loss: 1.4345\n",
      "Epoch 451/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3924 - val_loss: 1.4003\n",
      "Epoch 452/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3814 - val_loss: 1.4027\n",
      "Epoch 453/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3982 - val_loss: 1.4227\n",
      "Epoch 454/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3893 - val_loss: 1.5358\n",
      "Epoch 455/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3919 - val_loss: 1.4847\n",
      "Epoch 456/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3785 - val_loss: 1.4047\n",
      "Epoch 457/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3808 - val_loss: 1.5375\n",
      "Epoch 458/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3819 - val_loss: 1.4029\n",
      "Epoch 459/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3792 - val_loss: 1.4210\n",
      "Epoch 460/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3794 - val_loss: 1.3987\n",
      "Epoch 461/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3872 - val_loss: 1.4025\n",
      "Epoch 462/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3830 - val_loss: 1.4816\n",
      "Epoch 463/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3932 - val_loss: 1.5200\n",
      "Epoch 464/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3770 - val_loss: 1.3912\n",
      "Epoch 465/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3881 - val_loss: 1.4792\n",
      "Epoch 466/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3839 - val_loss: 1.4291\n",
      "Epoch 467/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3747 - val_loss: 1.4358\n",
      "Epoch 468/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3889 - val_loss: 1.4438\n",
      "Epoch 469/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3720 - val_loss: 1.4129\n",
      "Epoch 470/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3917 - val_loss: 1.4364\n",
      "Epoch 471/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3791 - val_loss: 1.4178\n",
      "Epoch 472/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3826 - val_loss: 1.4563\n",
      "Epoch 473/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3776 - val_loss: 1.5359\n",
      "Epoch 474/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3845 - val_loss: 1.4222\n",
      "Epoch 475/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3746 - val_loss: 1.3788\n",
      "Epoch 476/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3663 - val_loss: 1.4070\n",
      "Epoch 477/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3784 - val_loss: 1.4119\n",
      "Epoch 478/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3750 - val_loss: 1.4095\n",
      "Epoch 479/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3683 - val_loss: 1.4293\n",
      "Epoch 480/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3695 - val_loss: 1.4558\n",
      "Epoch 481/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3778 - val_loss: 1.4259\n",
      "Epoch 482/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3798 - val_loss: 1.4876\n",
      "Epoch 483/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3860 - val_loss: 1.3907\n",
      "Epoch 484/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3812 - val_loss: 1.4749\n",
      "Epoch 485/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3681 - val_loss: 1.4899\n",
      "Epoch 486/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3796 - val_loss: 1.4450\n",
      "Epoch 487/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3715 - val_loss: 1.4134\n",
      "Epoch 488/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3708 - val_loss: 1.4600\n",
      "Epoch 489/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3777 - val_loss: 1.4688\n",
      "Epoch 490/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3733 - val_loss: 1.5742\n",
      "Epoch 491/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3701 - val_loss: 1.4014\n",
      "Epoch 492/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3699 - val_loss: 1.3944\n",
      "Epoch 493/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3744 - val_loss: 1.4169\n",
      "Epoch 494/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3786 - val_loss: 1.4208\n",
      "Epoch 495/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3741 - val_loss: 1.6841\n",
      "Epoch 496/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3690 - val_loss: 1.4060\n",
      "Epoch 497/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3658 - val_loss: 1.4453\n",
      "Epoch 498/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3720 - val_loss: 1.4163\n",
      "Epoch 499/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3731 - val_loss: 1.5722\n",
      "Epoch 500/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3716 - val_loss: 1.4070\n",
      "Epoch 501/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3725 - val_loss: 1.4686\n",
      "Epoch 502/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3704 - val_loss: 1.4987\n",
      "Epoch 503/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3715 - val_loss: 1.4858\n",
      "Epoch 504/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3624 - val_loss: 1.3712\n",
      "Epoch 505/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3619 - val_loss: 1.4191\n",
      "Epoch 506/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3701 - val_loss: 1.4089\n",
      "Epoch 507/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3725 - val_loss: 1.3983\n",
      "Epoch 508/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3619 - val_loss: 1.4368\n",
      "Epoch 509/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3700 - val_loss: 1.4254\n",
      "Epoch 510/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3664 - val_loss: 1.4544\n",
      "Epoch 511/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3746 - val_loss: 1.3678\n",
      "Epoch 512/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3689 - val_loss: 1.3666\n",
      "Epoch 513/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3680 - val_loss: 1.4707\n",
      "Epoch 514/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3598 - val_loss: 1.3762\n",
      "Epoch 515/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3721 - val_loss: 1.4617\n",
      "Epoch 516/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3692 - val_loss: 1.4197\n",
      "Epoch 517/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3619 - val_loss: 1.3892\n",
      "Epoch 518/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3734 - val_loss: 1.3884\n",
      "Epoch 519/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3662 - val_loss: 1.3788\n",
      "Epoch 520/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3580 - val_loss: 1.3877\n",
      "Epoch 521/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3569 - val_loss: 1.3831\n",
      "Epoch 522/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3673 - val_loss: 1.3985\n",
      "Epoch 523/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3633 - val_loss: 1.4474\n",
      "Epoch 524/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3615 - val_loss: 1.4386\n",
      "Epoch 525/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3635 - val_loss: 1.4346\n",
      "Epoch 526/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3643 - val_loss: 1.5015\n",
      "Epoch 527/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3733 - val_loss: 1.4029\n",
      "Epoch 528/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3645 - val_loss: 1.4169\n",
      "Epoch 529/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3712 - val_loss: 1.4118\n",
      "Epoch 530/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3640 - val_loss: 1.4252\n",
      "Epoch 531/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3515 - val_loss: 1.4973\n",
      "Epoch 532/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3559 - val_loss: 1.4038\n",
      "Epoch 533/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3638 - val_loss: 1.3846\n",
      "Epoch 534/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3656 - val_loss: 1.3920\n",
      "Epoch 535/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3646 - val_loss: 1.3806\n",
      "Epoch 536/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3578 - val_loss: 1.3973\n",
      "Epoch 537/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3590 - val_loss: 1.4029\n",
      "Epoch 538/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3595 - val_loss: 1.4346\n",
      "Epoch 539/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3543 - val_loss: 1.4388\n",
      "Epoch 540/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3548 - val_loss: 1.3925\n",
      "Epoch 541/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3623 - val_loss: 1.4204\n",
      "Epoch 542/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3588 - val_loss: 1.4114\n",
      "Epoch 543/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3532 - val_loss: 1.4425\n",
      "Epoch 544/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3511 - val_loss: 1.3829\n",
      "Epoch 545/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3586 - val_loss: 1.4280\n",
      "Epoch 546/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3550 - val_loss: 1.4159\n",
      "Epoch 547/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3676 - val_loss: 1.4356\n",
      "Epoch 548/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3607 - val_loss: 1.4066\n",
      "Epoch 549/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3547 - val_loss: 1.3886\n",
      "Epoch 550/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3521 - val_loss: 1.4279\n",
      "Epoch 551/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3514 - val_loss: 1.4124\n",
      "Epoch 552/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3523 - val_loss: 1.3964\n",
      "Epoch 553/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3588 - val_loss: 1.4224\n",
      "Epoch 554/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3638 - val_loss: 1.4311\n",
      "Epoch 555/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3522 - val_loss: 1.4103\n",
      "Epoch 556/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3529 - val_loss: 1.3764\n",
      "Epoch 557/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3549 - val_loss: 1.4026\n",
      "Epoch 558/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3545 - val_loss: 1.3901\n",
      "Epoch 559/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3575 - val_loss: 1.4249\n",
      "Epoch 560/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3518 - val_loss: 1.3769\n",
      "Epoch 561/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3562 - val_loss: 1.5383\n",
      "Epoch 562/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3505 - val_loss: 1.4381\n",
      "Epoch 563/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3511 - val_loss: 1.4050\n",
      "Epoch 564/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3403 - val_loss: 1.3994\n",
      "Epoch 565/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3457 - val_loss: 1.3770\n",
      "Epoch 566/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3588 - val_loss: 1.3660\n",
      "Epoch 567/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3537 - val_loss: 1.3876\n",
      "Epoch 568/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3441 - val_loss: 1.3818\n",
      "Epoch 569/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3489 - val_loss: 1.4103\n",
      "Epoch 570/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3399 - val_loss: 1.4160\n",
      "Epoch 571/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3555 - val_loss: 1.4086\n",
      "Epoch 572/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3518 - val_loss: 1.4131\n",
      "Epoch 573/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3456 - val_loss: 1.3898\n",
      "Epoch 574/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3482 - val_loss: 1.4463\n",
      "Epoch 575/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3506 - val_loss: 1.4565\n",
      "Epoch 576/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3559 - val_loss: 1.3550\n",
      "Epoch 577/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3431 - val_loss: 1.4048\n",
      "Epoch 578/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3576 - val_loss: 1.3908\n",
      "Epoch 579/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3453 - val_loss: 1.3906\n",
      "Epoch 580/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3491 - val_loss: 1.4446\n",
      "Epoch 581/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3442 - val_loss: 1.3907\n",
      "Epoch 582/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3499 - val_loss: 1.3877\n",
      "Epoch 583/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3418 - val_loss: 1.3683\n",
      "Epoch 584/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3479 - val_loss: 1.4032\n",
      "Epoch 585/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3438 - val_loss: 1.3986\n",
      "Epoch 586/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3480 - val_loss: 1.3808\n",
      "Epoch 587/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3406 - val_loss: 1.3942\n",
      "Epoch 588/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3471 - val_loss: 1.4242\n",
      "Epoch 589/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3461 - val_loss: 1.3947\n",
      "Epoch 590/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3536 - val_loss: 1.4937\n",
      "Epoch 591/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3463 - val_loss: 1.3819\n",
      "Epoch 592/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3418 - val_loss: 1.4107\n",
      "Epoch 593/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3568 - val_loss: 1.4171\n",
      "Epoch 594/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3489 - val_loss: 1.3755\n",
      "Epoch 595/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3416 - val_loss: 1.3766\n",
      "Epoch 596/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3370 - val_loss: 1.3764\n",
      "Epoch 597/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3464 - val_loss: 1.3601\n",
      "Epoch 598/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3344 - val_loss: 1.3742\n",
      "Epoch 599/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3477 - val_loss: 1.4070\n",
      "Epoch 600/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3526 - val_loss: 1.4361\n",
      "Epoch 601/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3364 - val_loss: 1.3939\n",
      "Epoch 602/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3408 - val_loss: 1.3624\n",
      "Epoch 603/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3417 - val_loss: 1.4202\n",
      "Epoch 604/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3324 - val_loss: 1.4011\n",
      "Epoch 605/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3390 - val_loss: 1.4147\n",
      "Epoch 606/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3424 - val_loss: 1.3909\n",
      "Epoch 607/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3379 - val_loss: 1.3546\n",
      "Epoch 608/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3489 - val_loss: 1.4272\n",
      "Epoch 609/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3369 - val_loss: 1.4260\n",
      "Epoch 610/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3492 - val_loss: 1.3954\n",
      "Epoch 611/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3522 - val_loss: 1.3518\n",
      "Epoch 612/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3402 - val_loss: 1.4307\n",
      "Epoch 613/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3397 - val_loss: 1.3589\n",
      "Epoch 614/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3618 - val_loss: 1.3988\n",
      "Epoch 615/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3381 - val_loss: 1.3226\n",
      "Epoch 616/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3393 - val_loss: 1.3818\n",
      "Epoch 617/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3391 - val_loss: 1.3816\n",
      "Epoch 618/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3530 - val_loss: 1.4932\n",
      "Epoch 619/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3413 - val_loss: 1.3999\n",
      "Epoch 620/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3339 - val_loss: 1.3770\n",
      "Epoch 621/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3380 - val_loss: 1.3489\n",
      "Epoch 622/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3357 - val_loss: 1.3927\n",
      "Epoch 623/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3310 - val_loss: 1.3593\n",
      "Epoch 624/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3360 - val_loss: 1.3961\n",
      "Epoch 625/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3363 - val_loss: 1.4059\n",
      "Epoch 626/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3306 - val_loss: 1.3635\n",
      "Epoch 627/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3354 - val_loss: 1.3668\n",
      "Epoch 628/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3355 - val_loss: 1.3841\n",
      "Epoch 629/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3366 - val_loss: 1.3873\n",
      "Epoch 630/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3322 - val_loss: 1.3934\n",
      "Epoch 631/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3447 - val_loss: 1.3597\n",
      "Epoch 632/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3371 - val_loss: 1.3807\n",
      "Epoch 633/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3376 - val_loss: 1.4465\n",
      "Epoch 634/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3337 - val_loss: 1.4378\n",
      "Epoch 635/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3269 - val_loss: 1.3744\n",
      "Epoch 636/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3434 - val_loss: 1.3981\n",
      "Epoch 637/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3344 - val_loss: 1.4180\n",
      "Epoch 638/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3454 - val_loss: 1.4177\n",
      "Epoch 639/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3289 - val_loss: 1.3828\n",
      "Epoch 640/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3376 - val_loss: 1.5076\n",
      "Epoch 641/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3318 - val_loss: 1.4166\n",
      "Epoch 642/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3366 - val_loss: 1.4238\n",
      "Epoch 643/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3332 - val_loss: 1.4326\n",
      "Epoch 644/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3403 - val_loss: 1.3723\n",
      "Epoch 645/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3344 - val_loss: 1.3530\n",
      "Epoch 646/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3405 - val_loss: 1.4065\n",
      "Epoch 647/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3345 - val_loss: 1.4547\n",
      "Epoch 648/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3409 - val_loss: 1.3544\n",
      "Epoch 649/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3435 - val_loss: 1.3828\n",
      "Epoch 650/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3397 - val_loss: 1.3750\n",
      "Epoch 651/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3297 - val_loss: 1.4163\n",
      "Epoch 652/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3323 - val_loss: 1.4177\n",
      "Epoch 653/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3381 - val_loss: 1.3685\n",
      "Epoch 654/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3311 - val_loss: 1.3710\n",
      "Epoch 655/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3255 - val_loss: 1.3543\n",
      "Epoch 656/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3308 - val_loss: 1.3809\n",
      "Epoch 657/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3321 - val_loss: 1.4246\n",
      "Epoch 658/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3380 - val_loss: 1.3913\n",
      "Epoch 659/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3265 - val_loss: 1.3484\n",
      "Epoch 660/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3217 - val_loss: 1.3939\n",
      "Epoch 661/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3352 - val_loss: 1.3772\n",
      "Epoch 662/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3292 - val_loss: 1.3845\n",
      "Epoch 663/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3203 - val_loss: 1.3519\n",
      "Epoch 664/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3315 - val_loss: 1.3831\n",
      "Epoch 665/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3258 - val_loss: 1.3948\n",
      "Epoch 666/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3295 - val_loss: 1.4151\n",
      "Epoch 667/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3273 - val_loss: 1.3952\n",
      "Epoch 668/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3339 - val_loss: 1.3927\n",
      "Epoch 669/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3125 - val_loss: 1.4009\n",
      "Epoch 670/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3268 - val_loss: 1.3809\n",
      "Epoch 671/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3324 - val_loss: 1.4686\n",
      "Epoch 672/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3270 - val_loss: 1.3705\n",
      "Epoch 673/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3253 - val_loss: 1.4062\n",
      "Epoch 674/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3241 - val_loss: 1.4091\n",
      "Epoch 675/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3274 - val_loss: 1.3827\n",
      "Epoch 676/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3286 - val_loss: 1.3441\n",
      "Epoch 677/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3331 - val_loss: 1.4522\n",
      "Epoch 678/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3362 - val_loss: 1.4230\n",
      "Epoch 679/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3233 - val_loss: 1.3513\n",
      "Epoch 680/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3259 - val_loss: 1.3764\n",
      "Epoch 681/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3247 - val_loss: 1.3654\n",
      "Epoch 682/700\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3317 - val_loss: 1.3456\n",
      "Epoch 683/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3265 - val_loss: 1.3328\n",
      "Epoch 684/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3284 - val_loss: 1.3953\n",
      "Epoch 685/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3302 - val_loss: 1.3870\n",
      "Epoch 686/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3212 - val_loss: 1.3965\n",
      "Epoch 687/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3093 - val_loss: 1.4300\n",
      "Epoch 688/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3311 - val_loss: 1.3877\n",
      "Epoch 689/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3264 - val_loss: 1.3482\n",
      "Epoch 690/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3313 - val_loss: 1.3532\n",
      "Epoch 691/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3245 - val_loss: 1.3361\n",
      "Epoch 692/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3231 - val_loss: 1.3524\n",
      "Epoch 693/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3207 - val_loss: 1.3754\n",
      "Epoch 694/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3247 - val_loss: 1.3984\n",
      "Epoch 695/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3346 - val_loss: 1.3615\n",
      "Epoch 696/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3256 - val_loss: 1.3719\n",
      "Epoch 697/700\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3331 - val_loss: 1.4217\n",
      "Epoch 698/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3285 - val_loss: 1.3747\n",
      "Epoch 699/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3202 - val_loss: 1.4236\n",
      "Epoch 700/700\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3225 - val_loss: 1.4027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4027082559908288\n",
      "0.9710260422058659\n",
      "Epoch 1/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 15.5962 - val_loss: 26.3928\n",
      "Epoch 2/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 6.7670 - val_loss: 4.2031\n",
      "Epoch 3/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 5.2923 - val_loss: 4.8093\n",
      "Epoch 4/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.8672 - val_loss: 5.1834\n",
      "Epoch 5/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.7289 - val_loss: 3.8615\n",
      "Epoch 6/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.5716 - val_loss: 4.6315\n",
      "Epoch 7/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.2792 - val_loss: 3.6589\n",
      "Epoch 8/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.2689 - val_loss: 3.3169\n",
      "Epoch 9/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 3.6916 - val_loss: 3.5520\n",
      "Epoch 10/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.4067 - val_loss: 2.9970\n",
      "Epoch 11/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.5652 - val_loss: 2.9567\n",
      "Epoch 12/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.1879 - val_loss: 3.2280\n",
      "Epoch 13/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.3264 - val_loss: 2.8996\n",
      "Epoch 14/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.2992 - val_loss: 3.2506\n",
      "Epoch 15/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.1159 - val_loss: 2.8596\n",
      "Epoch 16/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.1291 - val_loss: 2.8602\n",
      "Epoch 17/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.9982 - val_loss: 2.7848\n",
      "Epoch 18/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.9388 - val_loss: 2.8234\n",
      "Epoch 19/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.9547 - val_loss: 2.7502\n",
      "Epoch 20/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.8099 - val_loss: 3.0240\n",
      "Epoch 21/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.7406 - val_loss: 2.6102\n",
      "Epoch 22/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.6982 - val_loss: 2.9511\n",
      "Epoch 23/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.6647 - val_loss: 2.5503\n",
      "Epoch 24/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.6224 - val_loss: 2.5014\n",
      "Epoch 25/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.6300 - val_loss: 2.8047\n",
      "Epoch 26/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.5198 - val_loss: 2.6658\n",
      "Epoch 27/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.4923 - val_loss: 2.3599\n",
      "Epoch 28/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.4603 - val_loss: 2.5148\n",
      "Epoch 29/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.4262 - val_loss: 2.3872\n",
      "Epoch 30/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.4036 - val_loss: 2.3292\n",
      "Epoch 31/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3927 - val_loss: 2.2952\n",
      "Epoch 32/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 2.3696 - val_loss: 2.3258\n",
      "Epoch 33/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3746 - val_loss: 2.4996\n",
      "Epoch 34/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3541 - val_loss: 2.5712\n",
      "Epoch 35/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 2.3311 - val_loss: 2.2071\n",
      "Epoch 36/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3155 - val_loss: 2.2706\n",
      "Epoch 37/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3096 - val_loss: 2.2610\n",
      "Epoch 38/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.2937 - val_loss: 2.1935\n",
      "Epoch 39/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.2600 - val_loss: 2.2280\n",
      "Epoch 40/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.2316 - val_loss: 2.4680\n",
      "Epoch 41/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 2.2387 - val_loss: 2.2072\n",
      "Epoch 42/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.2092 - val_loss: 2.1246\n",
      "Epoch 43/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1617 - val_loss: 2.2128\n",
      "Epoch 44/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1698 - val_loss: 2.1468\n",
      "Epoch 45/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1506 - val_loss: 2.1939\n",
      "Epoch 46/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1233 - val_loss: 2.0276\n",
      "Epoch 47/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0969 - val_loss: 2.1002\n",
      "Epoch 48/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1019 - val_loss: 2.1613\n",
      "Epoch 49/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0893 - val_loss: 2.0113\n",
      "Epoch 50/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 2.0611 - val_loss: 2.0138\n",
      "Epoch 51/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0526 - val_loss: 2.0692\n",
      "Epoch 52/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0305 - val_loss: 2.1439\n",
      "Epoch 53/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 2.0380 - val_loss: 2.1780\n",
      "Epoch 54/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 2.0253 - val_loss: 2.0042\n",
      "Epoch 55/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0201 - val_loss: 2.1567\n",
      "Epoch 56/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0047 - val_loss: 2.0317\n",
      "Epoch 57/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9717 - val_loss: 1.9482\n",
      "Epoch 58/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9723 - val_loss: 1.9249\n",
      "Epoch 59/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9767 - val_loss: 2.0263\n",
      "Epoch 60/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9725 - val_loss: 1.9851\n",
      "Epoch 61/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9476 - val_loss: 1.9681\n",
      "Epoch 62/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9475 - val_loss: 1.9934\n",
      "Epoch 63/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9390 - val_loss: 1.8950\n",
      "Epoch 64/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9320 - val_loss: 1.9967\n",
      "Epoch 65/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9345 - val_loss: 1.9050\n",
      "Epoch 66/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9154 - val_loss: 1.9438\n",
      "Epoch 67/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9255 - val_loss: 2.1928\n",
      "Epoch 68/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8980 - val_loss: 1.9998\n",
      "Epoch 69/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8960 - val_loss: 1.8723\n",
      "Epoch 70/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8865 - val_loss: 1.9314\n",
      "Epoch 71/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8882 - val_loss: 1.9681\n",
      "Epoch 72/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8786 - val_loss: 1.9077\n",
      "Epoch 73/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8805 - val_loss: 1.7992\n",
      "Epoch 74/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8794 - val_loss: 1.9167\n",
      "Epoch 75/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8540 - val_loss: 1.9155\n",
      "Epoch 76/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8559 - val_loss: 1.8716\n",
      "Epoch 77/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8566 - val_loss: 1.8787\n",
      "Epoch 78/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8416 - val_loss: 1.7848\n",
      "Epoch 79/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8572 - val_loss: 1.9079\n",
      "Epoch 80/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8524 - val_loss: 1.8391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8274 - val_loss: 1.9322\n",
      "Epoch 82/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.8261 - val_loss: 1.7887\n",
      "Epoch 83/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8249 - val_loss: 1.7826\n",
      "Epoch 84/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8072 - val_loss: 1.8716\n",
      "Epoch 85/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8108 - val_loss: 1.8248\n",
      "Epoch 86/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7989 - val_loss: 1.8452\n",
      "Epoch 87/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8077 - val_loss: 1.9506\n",
      "Epoch 88/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7858 - val_loss: 1.7675\n",
      "Epoch 89/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7946 - val_loss: 1.7811\n",
      "Epoch 90/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7643 - val_loss: 1.8855\n",
      "Epoch 91/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7799 - val_loss: 1.7397\n",
      "Epoch 92/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7691 - val_loss: 1.7913\n",
      "Epoch 93/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7648 - val_loss: 1.7255\n",
      "Epoch 94/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7542 - val_loss: 1.7164\n",
      "Epoch 95/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7582 - val_loss: 1.7555\n",
      "Epoch 96/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7542 - val_loss: 1.7123\n",
      "Epoch 97/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7378 - val_loss: 1.7570\n",
      "Epoch 98/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7417 - val_loss: 1.8070\n",
      "Epoch 99/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7434 - val_loss: 1.7751\n",
      "Epoch 100/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7392 - val_loss: 1.8495\n",
      "Epoch 101/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7305 - val_loss: 1.7345\n",
      "Epoch 102/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7381 - val_loss: 1.7427\n",
      "Epoch 103/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7226 - val_loss: 1.7846\n",
      "Epoch 104/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7267 - val_loss: 1.6869\n",
      "Epoch 105/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6916 - val_loss: 1.7107\n",
      "Epoch 106/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7005 - val_loss: 1.6966\n",
      "Epoch 107/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7129 - val_loss: 1.6943\n",
      "Epoch 108/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7084 - val_loss: 1.7094\n",
      "Epoch 109/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6891 - val_loss: 1.7056\n",
      "Epoch 110/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6924 - val_loss: 1.7033\n",
      "Epoch 111/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6886 - val_loss: 1.7159\n",
      "Epoch 112/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6756 - val_loss: 1.7478\n",
      "Epoch 113/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6777 - val_loss: 1.7100\n",
      "Epoch 114/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6845 - val_loss: 1.7099\n",
      "Epoch 115/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6665 - val_loss: 1.8313\n",
      "Epoch 116/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6581 - val_loss: 1.7024\n",
      "Epoch 117/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6670 - val_loss: 1.7161\n",
      "Epoch 118/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6651 - val_loss: 1.7521\n",
      "Epoch 119/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6733 - val_loss: 1.6326\n",
      "Epoch 120/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6670 - val_loss: 1.7310\n",
      "Epoch 121/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6628 - val_loss: 1.7222\n",
      "Epoch 122/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6534 - val_loss: 1.7466\n",
      "Epoch 123/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6488 - val_loss: 1.6736\n",
      "Epoch 124/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6550 - val_loss: 1.6726\n",
      "Epoch 125/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6465 - val_loss: 1.6311\n",
      "Epoch 126/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6433 - val_loss: 1.6272\n",
      "Epoch 127/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6332 - val_loss: 1.5985\n",
      "Epoch 128/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6308 - val_loss: 1.6284\n",
      "Epoch 129/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6398 - val_loss: 1.6827\n",
      "Epoch 130/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6201 - val_loss: 1.6535\n",
      "Epoch 131/700\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.6282 - val_loss: 1.5805\n",
      "Epoch 132/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6146 - val_loss: 1.6190\n",
      "Epoch 133/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6239 - val_loss: 1.6927\n",
      "Epoch 134/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6280 - val_loss: 1.6337\n",
      "Epoch 135/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5991 - val_loss: 1.6386\n",
      "Epoch 136/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6091 - val_loss: 1.6232\n",
      "Epoch 137/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6046 - val_loss: 1.6262\n",
      "Epoch 138/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6059 - val_loss: 1.6316\n",
      "Epoch 139/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6129 - val_loss: 1.6019\n",
      "Epoch 140/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5954 - val_loss: 1.7712\n",
      "Epoch 141/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6032 - val_loss: 1.7945\n",
      "Epoch 142/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5901 - val_loss: 1.6269\n",
      "Epoch 143/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5965 - val_loss: 1.6062\n",
      "Epoch 144/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6042 - val_loss: 1.6475\n",
      "Epoch 145/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5899 - val_loss: 1.6534\n",
      "Epoch 146/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5854 - val_loss: 1.5919\n",
      "Epoch 147/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5828 - val_loss: 1.7563\n",
      "Epoch 148/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5932 - val_loss: 1.5960\n",
      "Epoch 149/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5746 - val_loss: 1.6216\n",
      "Epoch 150/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5679 - val_loss: 1.7224\n",
      "Epoch 151/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5964 - val_loss: 1.6399\n",
      "Epoch 152/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5675 - val_loss: 1.6329\n",
      "Epoch 153/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5777 - val_loss: 1.6062\n",
      "Epoch 154/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5606 - val_loss: 1.5912\n",
      "Epoch 155/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5542 - val_loss: 1.5413\n",
      "Epoch 156/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5651 - val_loss: 1.5580\n",
      "Epoch 157/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5556 - val_loss: 1.6062\n",
      "Epoch 158/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5561 - val_loss: 1.5834\n",
      "Epoch 159/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5704 - val_loss: 1.5825\n",
      "Epoch 160/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5536 - val_loss: 1.5776\n",
      "Epoch 161/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5536 - val_loss: 1.6545\n",
      "Epoch 162/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5513 - val_loss: 1.5909\n",
      "Epoch 163/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5553 - val_loss: 1.6236\n",
      "Epoch 164/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5507 - val_loss: 1.5278\n",
      "Epoch 165/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5512 - val_loss: 1.5575\n",
      "Epoch 166/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5545 - val_loss: 1.5417\n",
      "Epoch 167/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5375 - val_loss: 1.5883\n",
      "Epoch 168/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5481 - val_loss: 1.5251\n",
      "Epoch 169/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5406 - val_loss: 1.5631\n",
      "Epoch 170/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.5371 - val_loss: 1.6164\n",
      "Epoch 171/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5322 - val_loss: 1.6656\n",
      "Epoch 172/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5439 - val_loss: 1.5436\n",
      "Epoch 173/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5307 - val_loss: 1.6413\n",
      "Epoch 174/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5190 - val_loss: 1.5539\n",
      "Epoch 175/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5295 - val_loss: 1.5176\n",
      "Epoch 176/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5236 - val_loss: 1.5685\n",
      "Epoch 177/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5099 - val_loss: 1.5414\n",
      "Epoch 178/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5236 - val_loss: 1.5719\n",
      "Epoch 179/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5089 - val_loss: 1.6264\n",
      "Epoch 180/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5106 - val_loss: 1.5444\n",
      "Epoch 181/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5286 - val_loss: 1.5268\n",
      "Epoch 182/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5104 - val_loss: 1.5465\n",
      "Epoch 183/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5257 - val_loss: 1.5927\n",
      "Epoch 184/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5098 - val_loss: 1.5307\n",
      "Epoch 185/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5153 - val_loss: 1.5139\n",
      "Epoch 186/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5157 - val_loss: 1.5139\n",
      "Epoch 187/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5021 - val_loss: 1.5229\n",
      "Epoch 188/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4916 - val_loss: 1.5590\n",
      "Epoch 189/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4961 - val_loss: 1.5283\n",
      "Epoch 190/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5036 - val_loss: 1.5487\n",
      "Epoch 191/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5004 - val_loss: 1.5541\n",
      "Epoch 192/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5031 - val_loss: 1.5341\n",
      "Epoch 193/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5047 - val_loss: 1.5259\n",
      "Epoch 194/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4998 - val_loss: 1.5816\n",
      "Epoch 195/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4995 - val_loss: 1.5078\n",
      "Epoch 196/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4903 - val_loss: 1.5255\n",
      "Epoch 197/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4888 - val_loss: 1.5552\n",
      "Epoch 198/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4945 - val_loss: 1.5220\n",
      "Epoch 199/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4885 - val_loss: 1.4806\n",
      "Epoch 200/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5076 - val_loss: 1.5333\n",
      "Epoch 201/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4837 - val_loss: 1.5269\n",
      "Epoch 202/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4849 - val_loss: 1.4700\n",
      "Epoch 203/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4939 - val_loss: 1.4848\n",
      "Epoch 204/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4808 - val_loss: 1.5704\n",
      "Epoch 205/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4791 - val_loss: 1.5574\n",
      "Epoch 206/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4771 - val_loss: 1.4919\n",
      "Epoch 207/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4883 - val_loss: 1.4805\n",
      "Epoch 208/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4786 - val_loss: 1.5799\n",
      "Epoch 209/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4713 - val_loss: 1.5853\n",
      "Epoch 210/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4643 - val_loss: 1.5470\n",
      "Epoch 211/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4742 - val_loss: 1.5684\n",
      "Epoch 212/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4661 - val_loss: 1.5834\n",
      "Epoch 213/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4635 - val_loss: 1.5005\n",
      "Epoch 214/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4613 - val_loss: 1.5830\n",
      "Epoch 215/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4729 - val_loss: 1.5022\n",
      "Epoch 216/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4560 - val_loss: 1.4842\n",
      "Epoch 217/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4671 - val_loss: 1.4684\n",
      "Epoch 218/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4626 - val_loss: 1.4584\n",
      "Epoch 219/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4691 - val_loss: 1.5172\n",
      "Epoch 220/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4598 - val_loss: 1.4856\n",
      "Epoch 221/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4594 - val_loss: 1.4545\n",
      "Epoch 222/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4625 - val_loss: 1.4490\n",
      "Epoch 223/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4472 - val_loss: 1.5074\n",
      "Epoch 224/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4627 - val_loss: 1.4717\n",
      "Epoch 225/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4565 - val_loss: 1.5170\n",
      "Epoch 226/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4483 - val_loss: 1.5261\n",
      "Epoch 227/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4365 - val_loss: 1.4548\n",
      "Epoch 228/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4439 - val_loss: 1.4945\n",
      "Epoch 229/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4588 - val_loss: 1.5276\n",
      "Epoch 230/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4524 - val_loss: 1.4575\n",
      "Epoch 231/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4446 - val_loss: 1.4543\n",
      "Epoch 232/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4486 - val_loss: 1.4545\n",
      "Epoch 233/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4427 - val_loss: 1.5300\n",
      "Epoch 234/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4549 - val_loss: 1.4415\n",
      "Epoch 235/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4302 - val_loss: 1.4928\n",
      "Epoch 236/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4381 - val_loss: 1.5908\n",
      "Epoch 237/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4431 - val_loss: 1.4837\n",
      "Epoch 238/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4485 - val_loss: 1.7684\n",
      "Epoch 239/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4439 - val_loss: 1.5226\n",
      "Epoch 240/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4362 - val_loss: 1.4607\n",
      "Epoch 241/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4432 - val_loss: 1.4303\n",
      "Epoch 242/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4511 - val_loss: 1.4621\n",
      "Epoch 243/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4250 - val_loss: 1.5127\n",
      "Epoch 244/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4354 - val_loss: 1.4177\n",
      "Epoch 245/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4362 - val_loss: 1.4612\n",
      "Epoch 246/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4156 - val_loss: 1.4690\n",
      "Epoch 247/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4470 - val_loss: 1.4712\n",
      "Epoch 248/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4296 - val_loss: 1.4615\n",
      "Epoch 249/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4271 - val_loss: 1.4448\n",
      "Epoch 250/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4305 - val_loss: 1.5100\n",
      "Epoch 251/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4348 - val_loss: 1.4886\n",
      "Epoch 252/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4195 - val_loss: 1.4461\n",
      "Epoch 253/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4343 - val_loss: 1.4428\n",
      "Epoch 254/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4141 - val_loss: 1.4388\n",
      "Epoch 255/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4211 - val_loss: 1.5481\n",
      "Epoch 256/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4266 - val_loss: 1.4821\n",
      "Epoch 257/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4120 - val_loss: 1.4548\n",
      "Epoch 258/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4187 - val_loss: 1.4669\n",
      "Epoch 259/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4188 - val_loss: 1.4017\n",
      "Epoch 260/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4165 - val_loss: 1.4809\n",
      "Epoch 261/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4240 - val_loss: 1.4753\n",
      "Epoch 262/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4078 - val_loss: 1.4375\n",
      "Epoch 263/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4078 - val_loss: 1.4356\n",
      "Epoch 264/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4260 - val_loss: 1.4334\n",
      "Epoch 265/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4150 - val_loss: 1.4847\n",
      "Epoch 266/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4089 - val_loss: 1.4813\n",
      "Epoch 267/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4106 - val_loss: 1.4663\n",
      "Epoch 268/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4012 - val_loss: 1.5346\n",
      "Epoch 269/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4020 - val_loss: 1.4706\n",
      "Epoch 270/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4093 - val_loss: 1.4383\n",
      "Epoch 271/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4011 - val_loss: 1.4036\n",
      "Epoch 272/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4173 - val_loss: 1.4470\n",
      "Epoch 273/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4047 - val_loss: 1.5155\n",
      "Epoch 274/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4035 - val_loss: 1.4155\n",
      "Epoch 275/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4005 - val_loss: 1.4250\n",
      "Epoch 276/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4156 - val_loss: 1.4273\n",
      "Epoch 277/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4039 - val_loss: 1.4055\n",
      "Epoch 278/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3912 - val_loss: 1.4251\n",
      "Epoch 279/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4044 - val_loss: 1.4320\n",
      "Epoch 280/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3940 - val_loss: 1.3981\n",
      "Epoch 281/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4008 - val_loss: 1.4206\n",
      "Epoch 282/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3941 - val_loss: 1.4575\n",
      "Epoch 283/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3958 - val_loss: 1.4782\n",
      "Epoch 284/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3855 - val_loss: 1.4406\n",
      "Epoch 285/700\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.3939 - val_loss: 1.4105\n",
      "Epoch 286/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3942 - val_loss: 1.4345\n",
      "Epoch 287/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3901 - val_loss: 1.4346\n",
      "Epoch 288/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3891 - val_loss: 1.4869\n",
      "Epoch 289/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3927 - val_loss: 1.5308\n",
      "Epoch 290/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3899 - val_loss: 1.4110\n",
      "Epoch 291/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3957 - val_loss: 1.4142\n",
      "Epoch 292/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3865 - val_loss: 1.4032\n",
      "Epoch 293/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3968 - val_loss: 1.3917\n",
      "Epoch 294/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3903 - val_loss: 1.4024\n",
      "Epoch 295/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3808 - val_loss: 1.4102\n",
      "Epoch 296/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3915 - val_loss: 1.3772\n",
      "Epoch 297/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3860 - val_loss: 1.4352\n",
      "Epoch 298/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3753 - val_loss: 1.4266\n",
      "Epoch 299/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3640 - val_loss: 1.4388\n",
      "Epoch 300/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3820 - val_loss: 1.4473\n",
      "Epoch 301/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3830 - val_loss: 1.4170\n",
      "Epoch 302/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3773 - val_loss: 1.4430\n",
      "Epoch 303/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3872 - val_loss: 1.4865\n",
      "Epoch 304/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3820 - val_loss: 1.4875\n",
      "Epoch 305/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3755 - val_loss: 1.4135\n",
      "Epoch 306/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3712 - val_loss: 1.4338\n",
      "Epoch 307/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3796 - val_loss: 1.4130\n",
      "Epoch 308/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3798 - val_loss: 1.4118\n",
      "Epoch 309/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3750 - val_loss: 1.4180\n",
      "Epoch 310/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3744 - val_loss: 1.4074\n",
      "Epoch 311/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3607 - val_loss: 1.4015\n",
      "Epoch 312/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3819 - val_loss: 1.4481\n",
      "Epoch 313/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3710 - val_loss: 1.4870\n",
      "Epoch 314/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3791 - val_loss: 1.4325\n",
      "Epoch 315/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3705 - val_loss: 1.3873\n",
      "Epoch 316/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3603 - val_loss: 1.3990\n",
      "Epoch 317/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3707 - val_loss: 1.4055\n",
      "Epoch 318/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3843 - val_loss: 1.3901\n",
      "Epoch 319/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3572 - val_loss: 1.3911\n",
      "Epoch 320/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3738 - val_loss: 1.3723\n",
      "Epoch 321/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3661 - val_loss: 1.3921\n",
      "Epoch 322/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3564 - val_loss: 1.3659\n",
      "Epoch 323/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3667 - val_loss: 1.5186\n",
      "Epoch 324/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3708 - val_loss: 1.3765\n",
      "Epoch 325/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3649 - val_loss: 1.3864\n",
      "Epoch 326/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3584 - val_loss: 1.4039\n",
      "Epoch 327/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3741 - val_loss: 1.3559\n",
      "Epoch 328/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3513 - val_loss: 1.3889\n",
      "Epoch 329/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3682 - val_loss: 1.3851\n",
      "Epoch 330/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3547 - val_loss: 1.3776\n",
      "Epoch 331/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3586 - val_loss: 1.3582\n",
      "Epoch 332/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3604 - val_loss: 1.4665\n",
      "Epoch 333/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3554 - val_loss: 1.3862\n",
      "Epoch 334/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3576 - val_loss: 1.3689\n",
      "Epoch 335/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3514 - val_loss: 1.4232\n",
      "Epoch 336/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3664 - val_loss: 1.4468\n",
      "Epoch 337/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3546 - val_loss: 1.3777\n",
      "Epoch 338/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3560 - val_loss: 1.3970\n",
      "Epoch 339/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3608 - val_loss: 1.3788\n",
      "Epoch 340/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3469 - val_loss: 1.4684\n",
      "Epoch 341/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3550 - val_loss: 1.3458\n",
      "Epoch 342/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3527 - val_loss: 1.3946\n",
      "Epoch 343/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3515 - val_loss: 1.4165\n",
      "Epoch 344/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3631 - val_loss: 1.3774\n",
      "Epoch 345/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3464 - val_loss: 1.4619\n",
      "Epoch 346/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3461 - val_loss: 1.4081\n",
      "Epoch 347/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3503 - val_loss: 1.3693\n",
      "Epoch 348/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3491 - val_loss: 1.3859\n",
      "Epoch 349/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3488 - val_loss: 1.3819\n",
      "Epoch 350/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3417 - val_loss: 1.3890\n",
      "Epoch 351/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3379 - val_loss: 1.3619\n",
      "Epoch 352/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3465 - val_loss: 1.4097\n",
      "Epoch 353/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3425 - val_loss: 1.3612\n",
      "Epoch 354/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3457 - val_loss: 1.4089\n",
      "Epoch 355/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3386 - val_loss: 1.3935\n",
      "Epoch 356/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3338 - val_loss: 1.3511\n",
      "Epoch 357/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3397 - val_loss: 1.3949\n",
      "Epoch 358/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3392 - val_loss: 1.4111\n",
      "Epoch 359/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3359 - val_loss: 1.4019\n",
      "Epoch 360/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3339 - val_loss: 1.3574\n",
      "Epoch 361/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3441 - val_loss: 1.3685\n",
      "Epoch 362/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3443 - val_loss: 1.4178\n",
      "Epoch 363/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3431 - val_loss: 1.3967\n",
      "Epoch 364/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3337 - val_loss: 1.4255\n",
      "Epoch 365/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3289 - val_loss: 1.3447\n",
      "Epoch 366/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3333 - val_loss: 1.4028\n",
      "Epoch 367/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3296 - val_loss: 1.4052\n",
      "Epoch 368/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3237 - val_loss: 1.3588\n",
      "Epoch 369/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3377 - val_loss: 1.3254\n",
      "Epoch 370/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3482 - val_loss: 1.4357\n",
      "Epoch 371/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3295 - val_loss: 1.3415\n",
      "Epoch 372/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3331 - val_loss: 1.3626\n",
      "Epoch 373/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3326 - val_loss: 1.3971\n",
      "Epoch 374/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3247 - val_loss: 1.3879\n",
      "Epoch 375/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3257 - val_loss: 1.3485\n",
      "Epoch 376/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3253 - val_loss: 1.3798\n",
      "Epoch 377/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3246 - val_loss: 1.3821\n",
      "Epoch 378/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3387 - val_loss: 1.3811\n",
      "Epoch 379/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3386 - val_loss: 1.3440\n",
      "Epoch 380/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3424 - val_loss: 1.4350\n",
      "Epoch 381/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3244 - val_loss: 1.3483\n",
      "Epoch 382/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3347 - val_loss: 1.4157\n",
      "Epoch 383/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3232 - val_loss: 1.3821\n",
      "Epoch 384/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3275 - val_loss: 1.3762\n",
      "Epoch 385/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3239 - val_loss: 1.3159\n",
      "Epoch 386/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3168 - val_loss: 1.3568\n",
      "Epoch 387/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3172 - val_loss: 1.3940\n",
      "Epoch 388/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3255 - val_loss: 1.3334\n",
      "Epoch 389/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3257 - val_loss: 1.3579\n",
      "Epoch 390/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3346 - val_loss: 1.3227\n",
      "Epoch 391/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3172 - val_loss: 1.3810\n",
      "Epoch 392/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3117 - val_loss: 1.3529\n",
      "Epoch 393/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3148 - val_loss: 1.3855\n",
      "Epoch 394/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3220 - val_loss: 1.3821\n",
      "Epoch 395/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3257 - val_loss: 1.3911\n",
      "Epoch 396/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3121 - val_loss: 1.3466\n",
      "Epoch 397/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3146 - val_loss: 1.3620\n",
      "Epoch 398/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3314 - val_loss: 1.3617\n",
      "Epoch 399/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3188 - val_loss: 1.3944\n",
      "Epoch 400/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3170 - val_loss: 1.3598\n",
      "Epoch 401/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3114 - val_loss: 1.3829\n",
      "Epoch 402/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3287 - val_loss: 1.3924\n",
      "Epoch 403/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3122 - val_loss: 1.3933\n",
      "Epoch 404/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3088 - val_loss: 1.3566\n",
      "Epoch 405/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3079 - val_loss: 1.3723\n",
      "Epoch 406/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3083 - val_loss: 1.3833\n",
      "Epoch 407/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3104 - val_loss: 1.3334\n",
      "Epoch 408/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3150 - val_loss: 1.3813\n",
      "Epoch 409/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3143 - val_loss: 1.3971\n",
      "Epoch 410/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3067 - val_loss: 1.3867\n",
      "Epoch 411/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3121 - val_loss: 1.3747\n",
      "Epoch 412/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3185 - val_loss: 1.3777\n",
      "Epoch 413/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3155 - val_loss: 1.3933\n",
      "Epoch 414/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3245 - val_loss: 1.3293\n",
      "Epoch 415/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3120 - val_loss: 1.3797\n",
      "Epoch 416/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2994 - val_loss: 1.3632\n",
      "Epoch 417/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3099 - val_loss: 1.3956\n",
      "Epoch 418/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3055 - val_loss: 1.3955\n",
      "Epoch 419/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3096 - val_loss: 1.3550\n",
      "Epoch 420/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2988 - val_loss: 1.3709\n",
      "Epoch 421/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3286 - val_loss: 1.3658\n",
      "Epoch 422/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3165 - val_loss: 1.4031\n",
      "Epoch 423/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2966 - val_loss: 1.3422\n",
      "Epoch 424/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3038 - val_loss: 1.3526\n",
      "Epoch 425/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3084 - val_loss: 1.3427\n",
      "Epoch 426/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3028 - val_loss: 1.3756\n",
      "Epoch 427/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3048 - val_loss: 1.3701\n",
      "Epoch 428/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3054 - val_loss: 1.3642\n",
      "Epoch 429/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2984 - val_loss: 1.3746\n",
      "Epoch 430/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2961 - val_loss: 1.3710\n",
      "Epoch 431/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2954 - val_loss: 1.3391\n",
      "Epoch 432/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2996 - val_loss: 1.3837\n",
      "Epoch 433/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2986 - val_loss: 1.3272\n",
      "Epoch 434/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3083 - val_loss: 1.3570\n",
      "Epoch 435/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2926 - val_loss: 1.3451\n",
      "Epoch 436/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2917 - val_loss: 1.3610\n",
      "Epoch 437/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3028 - val_loss: 1.2965\n",
      "Epoch 438/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2963 - val_loss: 1.4233\n",
      "Epoch 439/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2971 - val_loss: 1.3653\n",
      "Epoch 440/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3049 - val_loss: 1.3556\n",
      "Epoch 441/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2950 - val_loss: 1.3349\n",
      "Epoch 442/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2984 - val_loss: 1.4235\n",
      "Epoch 443/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2860 - val_loss: 1.3624\n",
      "Epoch 444/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3108 - val_loss: 1.3013\n",
      "Epoch 445/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2950 - val_loss: 1.3217\n",
      "Epoch 446/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2912 - val_loss: 1.3511\n",
      "Epoch 447/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2925 - val_loss: 1.4242\n",
      "Epoch 448/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2911 - val_loss: 1.3611\n",
      "Epoch 449/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3117 - val_loss: 1.3737\n",
      "Epoch 450/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2879 - val_loss: 1.3493\n",
      "Epoch 451/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2972 - val_loss: 1.3019\n",
      "Epoch 452/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2841 - val_loss: 1.3265\n",
      "Epoch 453/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2934 - val_loss: 1.3558\n",
      "Epoch 454/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2913 - val_loss: 1.3478\n",
      "Epoch 455/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2863 - val_loss: 1.3557\n",
      "Epoch 456/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2953 - val_loss: 1.3644\n",
      "Epoch 457/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2856 - val_loss: 1.3603\n",
      "Epoch 458/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2867 - val_loss: 1.3540\n",
      "Epoch 459/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2934 - val_loss: 1.3007\n",
      "Epoch 460/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2950 - val_loss: 1.3036\n",
      "Epoch 461/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2827 - val_loss: 1.3927\n",
      "Epoch 462/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2839 - val_loss: 1.3369\n",
      "Epoch 463/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2911 - val_loss: 1.3296\n",
      "Epoch 464/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2903 - val_loss: 1.3783\n",
      "Epoch 465/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2855 - val_loss: 1.3530\n",
      "Epoch 466/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2926 - val_loss: 1.3541\n",
      "Epoch 467/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2867 - val_loss: 1.4300\n",
      "Epoch 468/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2864 - val_loss: 1.2989\n",
      "Epoch 469/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2922 - val_loss: 1.3362\n",
      "Epoch 470/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2907 - val_loss: 1.2777\n",
      "Epoch 471/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2807 - val_loss: 1.2932\n",
      "Epoch 472/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2755 - val_loss: 1.3264\n",
      "Epoch 473/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2900 - val_loss: 1.3303\n",
      "Epoch 474/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2773 - val_loss: 1.3548\n",
      "Epoch 475/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2822 - val_loss: 1.3031\n",
      "Epoch 476/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2944 - val_loss: 1.3233\n",
      "Epoch 477/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2893 - val_loss: 1.3384\n",
      "Epoch 478/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2819 - val_loss: 1.3338\n",
      "Epoch 479/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2815 - val_loss: 1.3500\n",
      "Epoch 480/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2838 - val_loss: 1.3339\n",
      "Epoch 481/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2857 - val_loss: 1.2937\n",
      "Epoch 482/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2850 - val_loss: 1.3411\n",
      "Epoch 483/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2837 - val_loss: 1.3299\n",
      "Epoch 484/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2696 - val_loss: 1.3335\n",
      "Epoch 485/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2771 - val_loss: 1.3282\n",
      "Epoch 486/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2817 - val_loss: 1.2836\n",
      "Epoch 487/700\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2810 - val_loss: 1.3032\n",
      "Epoch 488/700\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 1.2829 - val_loss: 1.2990\n",
      "Epoch 489/700\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.2793 - val_loss: 1.3425\n",
      "Epoch 490/700\n",
      "432/432 [==============================] - 6s 15ms/step - loss: 1.2735 - val_loss: 1.2768\n",
      "Epoch 491/700\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2772 - val_loss: 1.3708\n",
      "Epoch 492/700\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2776 - val_loss: 1.3200\n",
      "Epoch 493/700\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2764 - val_loss: 1.3415\n",
      "Epoch 494/700\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 1.2763 - val_loss: 1.4241\n",
      "Epoch 495/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2716 - val_loss: 1.3137\n",
      "Epoch 496/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2762 - val_loss: 1.2818\n",
      "Epoch 497/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2804 - val_loss: 1.4779\n",
      "Epoch 498/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2718 - val_loss: 1.3461\n",
      "Epoch 499/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2806 - val_loss: 1.3042\n",
      "Epoch 500/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2781 - val_loss: 1.3787\n",
      "Epoch 501/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2747 - val_loss: 1.3439\n",
      "Epoch 502/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2781 - val_loss: 1.3684\n",
      "Epoch 503/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2697 - val_loss: 1.3729\n",
      "Epoch 504/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2757 - val_loss: 1.3468\n",
      "Epoch 505/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2727 - val_loss: 1.3427\n",
      "Epoch 506/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2680 - val_loss: 1.3285\n",
      "Epoch 507/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2753 - val_loss: 1.3350\n",
      "Epoch 508/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2689 - val_loss: 1.3454\n",
      "Epoch 509/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2815 - val_loss: 1.3185\n",
      "Epoch 510/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2630 - val_loss: 1.3157\n",
      "Epoch 511/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2781 - val_loss: 1.3902\n",
      "Epoch 512/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2675 - val_loss: 1.2865\n",
      "Epoch 513/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2760 - val_loss: 1.3115\n",
      "Epoch 514/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2660 - val_loss: 1.3722\n",
      "Epoch 515/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2800 - val_loss: 1.3878\n",
      "Epoch 516/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2683 - val_loss: 1.3047\n",
      "Epoch 517/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2705 - val_loss: 1.3128\n",
      "Epoch 518/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2659 - val_loss: 1.3003\n",
      "Epoch 519/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2665 - val_loss: 1.2989\n",
      "Epoch 520/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2703 - val_loss: 1.3767\n",
      "Epoch 521/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2678 - val_loss: 1.3287\n",
      "Epoch 522/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2756 - val_loss: 1.3691\n",
      "Epoch 523/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2759 - val_loss: 1.3660\n",
      "Epoch 524/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2660 - val_loss: 1.3139\n",
      "Epoch 525/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2633 - val_loss: 1.3140\n",
      "Epoch 526/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2690 - val_loss: 1.3033\n",
      "Epoch 527/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2684 - val_loss: 1.3378\n",
      "Epoch 528/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2630 - val_loss: 1.3241\n",
      "Epoch 529/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2685 - val_loss: 1.3282\n",
      "Epoch 530/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2546 - val_loss: 1.2989\n",
      "Epoch 531/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2634 - val_loss: 1.2899\n",
      "Epoch 532/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2690 - val_loss: 1.3334\n",
      "Epoch 533/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2547 - val_loss: 1.3843\n",
      "Epoch 534/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2670 - val_loss: 1.3241\n",
      "Epoch 535/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2571 - val_loss: 1.3453\n",
      "Epoch 536/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2683 - val_loss: 1.3236\n",
      "Epoch 537/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2641 - val_loss: 1.3142\n",
      "Epoch 538/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2651 - val_loss: 1.3783\n",
      "Epoch 539/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2582 - val_loss: 1.3230\n",
      "Epoch 540/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2572 - val_loss: 1.2762\n",
      "Epoch 541/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2762 - val_loss: 1.3773\n",
      "Epoch 542/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2684 - val_loss: 1.3384\n",
      "Epoch 543/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2675 - val_loss: 1.3224\n",
      "Epoch 544/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2492 - val_loss: 1.3283\n",
      "Epoch 545/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2599 - val_loss: 1.3236\n",
      "Epoch 546/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2640 - val_loss: 1.3139\n",
      "Epoch 547/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2698 - val_loss: 1.3013\n",
      "Epoch 548/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2627 - val_loss: 1.2739\n",
      "Epoch 549/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2593 - val_loss: 1.3286\n",
      "Epoch 550/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2623 - val_loss: 1.3424\n",
      "Epoch 551/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2626 - val_loss: 1.2923\n",
      "Epoch 552/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2593 - val_loss: 1.3178\n",
      "Epoch 553/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2604 - val_loss: 1.3077\n",
      "Epoch 554/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2558 - val_loss: 1.2946\n",
      "Epoch 555/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2631 - val_loss: 1.2767\n",
      "Epoch 556/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2528 - val_loss: 1.3291\n",
      "Epoch 557/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2574 - val_loss: 1.2993\n",
      "Epoch 558/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2563 - val_loss: 1.2718\n",
      "Epoch 559/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2581 - val_loss: 1.2828\n",
      "Epoch 560/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2567 - val_loss: 1.3317\n",
      "Epoch 561/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2576 - val_loss: 1.3382\n",
      "Epoch 562/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2517 - val_loss: 1.4143\n",
      "Epoch 563/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2523 - val_loss: 1.3508\n",
      "Epoch 564/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2568 - val_loss: 1.2707\n",
      "Epoch 565/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2575 - val_loss: 1.2965\n",
      "Epoch 566/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2593 - val_loss: 1.3143\n",
      "Epoch 567/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2580 - val_loss: 1.2872\n",
      "Epoch 568/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2622 - val_loss: 1.2753\n",
      "Epoch 569/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2516 - val_loss: 1.2894\n",
      "Epoch 570/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2583 - val_loss: 1.2848\n",
      "Epoch 571/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2463 - val_loss: 1.3183\n",
      "Epoch 572/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2451 - val_loss: 1.3129\n",
      "Epoch 573/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2476 - val_loss: 1.2904\n",
      "Epoch 574/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2559 - val_loss: 1.3299\n",
      "Epoch 575/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2566 - val_loss: 1.2940\n",
      "Epoch 576/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2493 - val_loss: 1.3191\n",
      "Epoch 577/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2536 - val_loss: 1.2806\n",
      "Epoch 578/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2531 - val_loss: 1.2982\n",
      "Epoch 579/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2502 - val_loss: 1.3085\n",
      "Epoch 580/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2493 - val_loss: 1.3133\n",
      "Epoch 581/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2474 - val_loss: 1.3466\n",
      "Epoch 582/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2545 - val_loss: 1.3101\n",
      "Epoch 583/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2618 - val_loss: 1.2961\n",
      "Epoch 584/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2461 - val_loss: 1.3250\n",
      "Epoch 585/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2529 - val_loss: 1.3243\n",
      "Epoch 586/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2465 - val_loss: 1.2779\n",
      "Epoch 587/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2521 - val_loss: 1.3210\n",
      "Epoch 588/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2603 - val_loss: 1.3438\n",
      "Epoch 589/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2489 - val_loss: 1.3282\n",
      "Epoch 590/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2539 - val_loss: 1.3440\n",
      "Epoch 591/700\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2541 - val_loss: 1.3199\n",
      "Epoch 592/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2445 - val_loss: 1.2805\n",
      "Epoch 593/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2497 - val_loss: 1.2984\n",
      "Epoch 594/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2394 - val_loss: 1.3619\n",
      "Epoch 595/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2445 - val_loss: 1.2767\n",
      "Epoch 596/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2453 - val_loss: 1.3198\n",
      "Epoch 597/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2491 - val_loss: 1.2850\n",
      "Epoch 598/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2502 - val_loss: 1.2772\n",
      "Epoch 599/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2375 - val_loss: 1.2874\n",
      "Epoch 600/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2502 - val_loss: 1.2742\n",
      "Epoch 601/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2481 - val_loss: 1.3264\n",
      "Epoch 602/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2534 - val_loss: 1.2956\n",
      "Epoch 603/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2386 - val_loss: 1.2910\n",
      "Epoch 604/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2481 - val_loss: 1.3163\n",
      "Epoch 605/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2505 - val_loss: 1.3353\n",
      "Epoch 606/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2501 - val_loss: 1.2636\n",
      "Epoch 607/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2474 - val_loss: 1.3630\n",
      "Epoch 608/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2464 - val_loss: 1.2921\n",
      "Epoch 609/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2376 - val_loss: 1.2759\n",
      "Epoch 610/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2376 - val_loss: 1.2958\n",
      "Epoch 611/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2404 - val_loss: 1.3808\n",
      "Epoch 612/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2497 - val_loss: 1.3902\n",
      "Epoch 613/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2509 - val_loss: 1.2798\n",
      "Epoch 614/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2431 - val_loss: 1.3147\n",
      "Epoch 615/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2376 - val_loss: 1.3389\n",
      "Epoch 616/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2434 - val_loss: 1.3020\n",
      "Epoch 617/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2584 - val_loss: 1.3469\n",
      "Epoch 618/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2375 - val_loss: 1.2739\n",
      "Epoch 619/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2365 - val_loss: 1.2827\n",
      "Epoch 620/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2433 - val_loss: 1.3003\n",
      "Epoch 621/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2358 - val_loss: 1.2443\n",
      "Epoch 622/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2356 - val_loss: 1.2937\n",
      "Epoch 623/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2445 - val_loss: 1.2951\n",
      "Epoch 624/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2467 - val_loss: 1.3078\n",
      "Epoch 625/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2381 - val_loss: 1.3073\n",
      "Epoch 626/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2376 - val_loss: 1.2973\n",
      "Epoch 627/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2398 - val_loss: 1.2731\n",
      "Epoch 628/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2404 - val_loss: 1.3282\n",
      "Epoch 629/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2409 - val_loss: 1.2867\n",
      "Epoch 630/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2346 - val_loss: 1.2765\n",
      "Epoch 631/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2426 - val_loss: 1.3102\n",
      "Epoch 632/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2312 - val_loss: 1.3361\n",
      "Epoch 633/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2382 - val_loss: 1.2402\n",
      "Epoch 634/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2358 - val_loss: 1.2548\n",
      "Epoch 635/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2464 - val_loss: 1.3132\n",
      "Epoch 636/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2449 - val_loss: 1.3783\n",
      "Epoch 637/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2356 - val_loss: 1.2796\n",
      "Epoch 638/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2485 - val_loss: 1.3008\n",
      "Epoch 639/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2390 - val_loss: 1.2462\n",
      "Epoch 640/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2395 - val_loss: 1.3150\n",
      "Epoch 641/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2353 - val_loss: 1.3478\n",
      "Epoch 642/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2390 - val_loss: 1.3784\n",
      "Epoch 643/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2389 - val_loss: 1.2762\n",
      "Epoch 644/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2377 - val_loss: 1.2873\n",
      "Epoch 645/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2273 - val_loss: 1.2835\n",
      "Epoch 646/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2462 - val_loss: 1.2633\n",
      "Epoch 647/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2355 - val_loss: 1.2759\n",
      "Epoch 648/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2361 - val_loss: 1.3366\n",
      "Epoch 649/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2474 - val_loss: 1.2794\n",
      "Epoch 650/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2319 - val_loss: 1.2816\n",
      "Epoch 651/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2356 - val_loss: 1.2548\n",
      "Epoch 652/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2283 - val_loss: 1.2798\n",
      "Epoch 653/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2319 - val_loss: 1.2817\n",
      "Epoch 654/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2434 - val_loss: 1.2681\n",
      "Epoch 655/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2345 - val_loss: 1.2904\n",
      "Epoch 656/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2353 - val_loss: 1.2815\n",
      "Epoch 657/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2413 - val_loss: 1.2915\n",
      "Epoch 658/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2332 - val_loss: 1.2939\n",
      "Epoch 659/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2296 - val_loss: 1.3238\n",
      "Epoch 660/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2292 - val_loss: 1.3117\n",
      "Epoch 661/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2231 - val_loss: 1.3066\n",
      "Epoch 662/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2397 - val_loss: 1.2936\n",
      "Epoch 663/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2298 - val_loss: 1.2870\n",
      "Epoch 664/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2338 - val_loss: 1.3677\n",
      "Epoch 665/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2238 - val_loss: 1.3104\n",
      "Epoch 666/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2360 - val_loss: 1.2633\n",
      "Epoch 667/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2300 - val_loss: 1.2353\n",
      "Epoch 668/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2304 - val_loss: 1.2720\n",
      "Epoch 669/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2360 - val_loss: 1.2639\n",
      "Epoch 670/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2294 - val_loss: 1.3098\n",
      "Epoch 671/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2369 - val_loss: 1.2928\n",
      "Epoch 672/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2339 - val_loss: 1.2695\n",
      "Epoch 673/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2296 - val_loss: 1.3693\n",
      "Epoch 674/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2255 - val_loss: 1.2599\n",
      "Epoch 675/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2393 - val_loss: 1.2639\n",
      "Epoch 676/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2235 - val_loss: 1.2751\n",
      "Epoch 677/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2264 - val_loss: 1.2868\n",
      "Epoch 678/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2235 - val_loss: 1.2629\n",
      "Epoch 679/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2279 - val_loss: 1.2822\n",
      "Epoch 680/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2297 - val_loss: 1.2759\n",
      "Epoch 681/700\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2320 - val_loss: 1.2974\n",
      "Epoch 682/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2378 - val_loss: 1.3026\n",
      "Epoch 683/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2296 - val_loss: 1.3106\n",
      "Epoch 684/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2365 - val_loss: 1.3261\n",
      "Epoch 685/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2267 - val_loss: 1.2728\n",
      "Epoch 686/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2270 - val_loss: 1.2542\n",
      "Epoch 687/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2235 - val_loss: 1.2574\n",
      "Epoch 688/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2240 - val_loss: 1.2521\n",
      "Epoch 689/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2265 - val_loss: 1.2649\n",
      "Epoch 690/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2333 - val_loss: 1.2505\n",
      "Epoch 691/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2275 - val_loss: 1.3049\n",
      "Epoch 692/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2274 - val_loss: 1.2588\n",
      "Epoch 693/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2260 - val_loss: 1.2412\n",
      "Epoch 694/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2268 - val_loss: 1.2608\n",
      "Epoch 695/700\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2231 - val_loss: 1.3018\n",
      "Epoch 696/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2331 - val_loss: 1.2966\n",
      "Epoch 697/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2302 - val_loss: 1.2827\n",
      "Epoch 698/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2310 - val_loss: 1.2440\n",
      "Epoch 699/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2217 - val_loss: 1.3469\n",
      "Epoch 700/700\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2208 - val_loss: 1.2678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2678021115076423\n",
      "0.9769125935161681\n",
      "Epoch 1/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 9.3025 - val_loss: 4.1411\n",
      "Epoch 2/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 5.4440 - val_loss: 4.9067\n",
      "Epoch 3/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 4.7304 - val_loss: 4.0526\n",
      "Epoch 4/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 4.5598 - val_loss: 4.0305\n",
      "Epoch 5/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 4.3356 - val_loss: 5.0820\n",
      "Epoch 6/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 4.3541 - val_loss: 4.1450\n",
      "Epoch 7/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 4.2742 - val_loss: 4.3790\n",
      "Epoch 8/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 4.3711 - val_loss: 3.9020\n",
      "Epoch 9/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 4.1576 - val_loss: 3.9432\n",
      "Epoch 10/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 4.0522 - val_loss: 3.6831\n",
      "Epoch 11/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.6525 - val_loss: 3.6031\n",
      "Epoch 12/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 3.8863 - val_loss: 3.2151\n",
      "Epoch 13/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 3.5766 - val_loss: 3.3388\n",
      "Epoch 14/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.2707 - val_loss: 2.9835\n",
      "Epoch 15/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 3.1545 - val_loss: 3.4568\n",
      "Epoch 16/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.1412 - val_loss: 3.0971\n",
      "Epoch 17/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.1186 - val_loss: 3.4391\n",
      "Epoch 18/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.9468 - val_loss: 2.7772\n",
      "Epoch 19/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.9570 - val_loss: 2.6888\n",
      "Epoch 20/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.8428 - val_loss: 2.6928\n",
      "Epoch 21/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.7659 - val_loss: 3.4408\n",
      "Epoch 22/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.7562 - val_loss: 2.9801\n",
      "Epoch 23/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.7097 - val_loss: 2.5355\n",
      "Epoch 24/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.7069 - val_loss: 2.6591\n",
      "Epoch 25/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.6391 - val_loss: 2.6142\n",
      "Epoch 26/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.6030 - val_loss: 2.5954\n",
      "Epoch 27/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.6105 - val_loss: 2.4818\n",
      "Epoch 28/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.5650 - val_loss: 2.5462\n",
      "Epoch 29/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.5154 - val_loss: 2.4681\n",
      "Epoch 30/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.5252 - val_loss: 2.4385\n",
      "Epoch 31/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.4932 - val_loss: 2.4895\n",
      "Epoch 32/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.4712 - val_loss: 2.3929\n",
      "Epoch 33/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.4995 - val_loss: 2.3778\n",
      "Epoch 34/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.4212 - val_loss: 2.4474\n",
      "Epoch 35/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.4453 - val_loss: 2.5967\n",
      "Epoch 36/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.4231 - val_loss: 2.3430\n",
      "Epoch 37/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.4137 - val_loss: 2.5463\n",
      "Epoch 38/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.3958 - val_loss: 2.3445\n",
      "Epoch 39/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.3541 - val_loss: 2.2830\n",
      "Epoch 40/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.3372 - val_loss: 2.3556\n",
      "Epoch 41/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.3462 - val_loss: 2.4128\n",
      "Epoch 42/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.3550 - val_loss: 2.4742\n",
      "Epoch 43/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.2988 - val_loss: 2.3516\n",
      "Epoch 44/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.2793 - val_loss: 2.2910\n",
      "Epoch 45/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.2459 - val_loss: 2.4860\n",
      "Epoch 46/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2216 - val_loss: 2.5663\n",
      "Epoch 47/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.2236 - val_loss: 2.2797\n",
      "Epoch 48/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.2069 - val_loss: 2.1149\n",
      "Epoch 49/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.1560 - val_loss: 2.2882\n",
      "Epoch 50/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.1627 - val_loss: 2.1600\n",
      "Epoch 51/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.1578 - val_loss: 2.0861\n",
      "Epoch 52/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.1274 - val_loss: 2.1684\n",
      "Epoch 53/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.0984 - val_loss: 2.1883\n",
      "Epoch 54/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0814 - val_loss: 2.0366\n",
      "Epoch 55/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0850 - val_loss: 2.0606ETA: 0s - loss: 2.088\n",
      "Epoch 56/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0703 - val_loss: 2.1250\n",
      "Epoch 57/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0609 - val_loss: 1.9751\n",
      "Epoch 58/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 2.0346 - val_loss: 1.9644\n",
      "Epoch 59/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.0463 - val_loss: 2.0241\n",
      "Epoch 60/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.0235 - val_loss: 2.0209\n",
      "Epoch 61/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 2.0176 - val_loss: 2.0821\n",
      "Epoch 62/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9901 - val_loss: 1.9995\n",
      "Epoch 63/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 2.0004 - val_loss: 2.0052\n",
      "Epoch 64/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.9930 - val_loss: 2.0149\n",
      "Epoch 65/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.0027 - val_loss: 1.9475\n",
      "Epoch 66/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9777 - val_loss: 2.0921\n",
      "Epoch 67/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9778 - val_loss: 2.0281\n",
      "Epoch 68/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9564 - val_loss: 2.0215\n",
      "Epoch 69/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9619 - val_loss: 1.9107\n",
      "Epoch 70/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9501 - val_loss: 1.9133\n",
      "Epoch 71/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9298 - val_loss: 1.9177\n",
      "Epoch 72/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.9400 - val_loss: 2.0775\n",
      "Epoch 73/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9332 - val_loss: 1.9884\n",
      "Epoch 74/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9335 - val_loss: 2.2488\n",
      "Epoch 75/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.9218 - val_loss: 2.0572\n",
      "Epoch 76/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.9319 - val_loss: 1.9368\n",
      "Epoch 77/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9232 - val_loss: 1.9471\n",
      "Epoch 78/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9048 - val_loss: 1.9380\n",
      "Epoch 79/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9161 - val_loss: 1.8809\n",
      "Epoch 80/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 4s 10ms/step - loss: 1.9076 - val_loss: 1.8886\n",
      "Epoch 81/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8779 - val_loss: 1.8550\n",
      "Epoch 82/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8796 - val_loss: 1.9043\n",
      "Epoch 83/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8732 - val_loss: 1.8519\n",
      "Epoch 84/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8960 - val_loss: 1.9773\n",
      "Epoch 85/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8683 - val_loss: 1.9382\n",
      "Epoch 86/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.8609 - val_loss: 1.9045\n",
      "Epoch 87/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8482 - val_loss: 1.8340\n",
      "Epoch 88/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8496 - val_loss: 2.0184\n",
      "Epoch 89/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8722 - val_loss: 1.8511\n",
      "Epoch 90/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8232 - val_loss: 1.7839\n",
      "Epoch 91/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8232 - val_loss: 1.9902\n",
      "Epoch 92/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.8279 - val_loss: 1.8676\n",
      "Epoch 93/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8287 - val_loss: 1.8593\n",
      "Epoch 94/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.8153 - val_loss: 1.8682\n",
      "Epoch 95/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7991 - val_loss: 1.8261\n",
      "Epoch 96/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7901 - val_loss: 1.8687\n",
      "Epoch 97/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8032 - val_loss: 1.8457\n",
      "Epoch 98/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7916 - val_loss: 1.8425\n",
      "Epoch 99/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7990 - val_loss: 1.8407\n",
      "Epoch 100/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7827 - val_loss: 1.7567\n",
      "Epoch 101/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7944 - val_loss: 1.8563\n",
      "Epoch 102/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7760 - val_loss: 1.7611\n",
      "Epoch 103/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7825 - val_loss: 1.8015\n",
      "Epoch 104/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.7567 - val_loss: 1.7847\n",
      "Epoch 105/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7709 - val_loss: 1.7716\n",
      "Epoch 106/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7574 - val_loss: 1.7730\n",
      "Epoch 107/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7537 - val_loss: 1.7957\n",
      "Epoch 108/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7611 - val_loss: 1.7665\n",
      "Epoch 109/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7547 - val_loss: 1.9082\n",
      "Epoch 110/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7375 - val_loss: 1.7682\n",
      "Epoch 111/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.7349 - val_loss: 1.7841\n",
      "Epoch 112/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7392 - val_loss: 1.7528\n",
      "Epoch 113/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7402 - val_loss: 1.7323\n",
      "Epoch 114/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7241 - val_loss: 1.7002\n",
      "Epoch 115/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.7099 - val_loss: 1.6929\n",
      "Epoch 116/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.7061 - val_loss: 1.7025\n",
      "Epoch 117/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7080 - val_loss: 1.7468\n",
      "Epoch 118/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7143 - val_loss: 1.6783\n",
      "Epoch 119/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6956 - val_loss: 1.8141\n",
      "Epoch 120/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.7053 - val_loss: 1.6915\n",
      "Epoch 121/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7117 - val_loss: 1.7487\n",
      "Epoch 122/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6806 - val_loss: 1.7083\n",
      "Epoch 123/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6898 - val_loss: 1.6880\n",
      "Epoch 124/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6771 - val_loss: 1.7440\n",
      "Epoch 125/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.7034 - val_loss: 1.7157\n",
      "Epoch 126/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6834 - val_loss: 1.6847\n",
      "Epoch 127/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6975 - val_loss: 1.6576\n",
      "Epoch 128/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6931 - val_loss: 1.7347\n",
      "Epoch 129/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6822 - val_loss: 1.7292\n",
      "Epoch 130/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6792 - val_loss: 1.6765\n",
      "Epoch 131/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6662 - val_loss: 1.7197\n",
      "Epoch 132/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6590 - val_loss: 1.7287\n",
      "Epoch 133/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6587 - val_loss: 1.7222\n",
      "Epoch 134/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6628 - val_loss: 1.7093\n",
      "Epoch 135/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6728 - val_loss: 1.6780\n",
      "Epoch 136/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6464 - val_loss: 1.6561\n",
      "Epoch 137/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6455 - val_loss: 1.8523\n",
      "Epoch 138/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6477 - val_loss: 1.7098\n",
      "Epoch 139/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6497 - val_loss: 1.7374\n",
      "Epoch 140/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6503 - val_loss: 1.6893\n",
      "Epoch 141/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6350 - val_loss: 1.6757\n",
      "Epoch 142/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6349 - val_loss: 1.7977\n",
      "Epoch 143/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6375 - val_loss: 1.6837\n",
      "Epoch 144/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6280 - val_loss: 1.7093\n",
      "Epoch 145/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6345 - val_loss: 1.7087\n",
      "Epoch 146/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6234 - val_loss: 1.7071\n",
      "Epoch 147/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6341 - val_loss: 1.6489\n",
      "Epoch 148/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6319 - val_loss: 1.6292\n",
      "Epoch 149/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6215 - val_loss: 1.6436\n",
      "Epoch 150/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6241 - val_loss: 1.7102\n",
      "Epoch 151/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.6467 - val_loss: 1.6306\n",
      "Epoch 152/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6013 - val_loss: 1.6982\n",
      "Epoch 153/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6250 - val_loss: 1.6465\n",
      "Epoch 154/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6239 - val_loss: 1.7099\n",
      "Epoch 155/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6157 - val_loss: 1.6519\n",
      "Epoch 156/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6112 - val_loss: 1.6644\n",
      "Epoch 157/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6132 - val_loss: 1.6554\n",
      "Epoch 158/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6074 - val_loss: 1.6160\n",
      "Epoch 159/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 4s 10ms/step - loss: 1.6020 - val_loss: 1.5996\n",
      "Epoch 160/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6050 - val_loss: 1.6218\n",
      "Epoch 161/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5940 - val_loss: 1.5944\n",
      "Epoch 162/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5860 - val_loss: 1.6270\n",
      "Epoch 163/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6002 - val_loss: 1.6729\n",
      "Epoch 164/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5842 - val_loss: 1.7446\n",
      "Epoch 165/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5963 - val_loss: 1.6163\n",
      "Epoch 166/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5920 - val_loss: 1.5698\n",
      "Epoch 167/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5772 - val_loss: 1.6594\n",
      "Epoch 168/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5741 - val_loss: 1.5841\n",
      "Epoch 169/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5900 - val_loss: 1.6403\n",
      "Epoch 170/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5760 - val_loss: 1.8280\n",
      "Epoch 171/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5766 - val_loss: 1.6419\n",
      "Epoch 172/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5681 - val_loss: 1.6357\n",
      "Epoch 173/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5832 - val_loss: 1.6176\n",
      "Epoch 174/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5758 - val_loss: 1.6191\n",
      "Epoch 175/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5716 - val_loss: 1.5907\n",
      "Epoch 176/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5888 - val_loss: 1.6460\n",
      "Epoch 177/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5569 - val_loss: 1.5481\n",
      "Epoch 178/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5782 - val_loss: 1.5955\n",
      "Epoch 179/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5626 - val_loss: 1.5640\n",
      "Epoch 180/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5500 - val_loss: 1.6765\n",
      "Epoch 181/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5574 - val_loss: 1.5458\n",
      "Epoch 182/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5582 - val_loss: 1.6992\n",
      "Epoch 183/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5564 - val_loss: 1.5701\n",
      "Epoch 184/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5543 - val_loss: 1.5997\n",
      "Epoch 185/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5544 - val_loss: 1.6022\n",
      "Epoch 186/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.5498 - val_loss: 1.6232\n",
      "Epoch 187/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5632 - val_loss: 1.5468\n",
      "Epoch 188/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5519 - val_loss: 1.5652\n",
      "Epoch 189/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5555 - val_loss: 1.6030\n",
      "Epoch 190/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5451 - val_loss: 1.5869\n",
      "Epoch 191/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5488 - val_loss: 1.5698\n",
      "Epoch 192/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5305 - val_loss: 1.6214\n",
      "Epoch 193/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5400 - val_loss: 1.5504\n",
      "Epoch 194/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5396 - val_loss: 1.5513\n",
      "Epoch 195/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5418 - val_loss: 1.5633\n",
      "Epoch 196/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5387 - val_loss: 1.6506\n",
      "Epoch 197/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5259 - val_loss: 1.5756\n",
      "Epoch 198/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.5409 - val_loss: 1.5701\n",
      "Epoch 199/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5374 - val_loss: 1.6079\n",
      "Epoch 200/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5160 - val_loss: 1.5682\n",
      "Epoch 201/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5256 - val_loss: 1.5987\n",
      "Epoch 202/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.5485 - val_loss: 1.6271\n",
      "Epoch 203/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5140 - val_loss: 1.5567\n",
      "Epoch 204/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5214 - val_loss: 1.5193\n",
      "Epoch 205/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5116 - val_loss: 1.5340\n",
      "Epoch 206/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5288 - val_loss: 1.5467\n",
      "Epoch 207/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5177 - val_loss: 1.6085\n",
      "Epoch 208/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5159 - val_loss: 1.5217\n",
      "Epoch 209/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5216 - val_loss: 1.5627\n",
      "Epoch 210/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5069 - val_loss: 1.5338\n",
      "Epoch 211/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5220 - val_loss: 1.6825\n",
      "Epoch 212/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5172 - val_loss: 1.6652\n",
      "Epoch 213/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5352 - val_loss: 1.5738\n",
      "Epoch 214/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5059 - val_loss: 1.5192\n",
      "Epoch 215/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5020 - val_loss: 1.6242\n",
      "Epoch 216/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5087 - val_loss: 1.5392\n",
      "Epoch 217/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5000 - val_loss: 1.5549\n",
      "Epoch 218/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5043 - val_loss: 1.5777\n",
      "Epoch 219/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.4974 - val_loss: 1.5533\n",
      "Epoch 220/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5079 - val_loss: 1.5055\n",
      "Epoch 221/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4991 - val_loss: 1.5563\n",
      "Epoch 222/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5015 - val_loss: 1.5310\n",
      "Epoch 223/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5079 - val_loss: 1.5694\n",
      "Epoch 224/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.4938 - val_loss: 1.4995\n",
      "Epoch 225/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4897 - val_loss: 1.4810\n",
      "Epoch 226/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4908 - val_loss: 1.4974\n",
      "Epoch 227/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4831 - val_loss: 1.4997\n",
      "Epoch 228/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4924 - val_loss: 1.5927\n",
      "Epoch 229/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4962 - val_loss: 1.5250\n",
      "Epoch 230/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4878 - val_loss: 1.5260\n",
      "Epoch 231/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.5028 - val_loss: 1.5766\n",
      "Epoch 232/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4859 - val_loss: 1.6313\n",
      "Epoch 233/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4890 - val_loss: 1.5260\n",
      "Epoch 234/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4828 - val_loss: 1.5473\n",
      "Epoch 235/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4845 - val_loss: 1.4941\n",
      "Epoch 236/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4781 - val_loss: 1.5580\n",
      "Epoch 237/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.4861 - val_loss: 1.4559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4798 - val_loss: 1.5290\n",
      "Epoch 239/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4934 - val_loss: 1.5416\n",
      "Epoch 240/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4794 - val_loss: 1.5823\n",
      "Epoch 241/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4883 - val_loss: 1.6483\n",
      "Epoch 242/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4877 - val_loss: 1.5836\n",
      "Epoch 243/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4769 - val_loss: 1.6445\n",
      "Epoch 244/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4689 - val_loss: 1.5048\n",
      "Epoch 245/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4617 - val_loss: 1.4965\n",
      "Epoch 246/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4628 - val_loss: 1.5003\n",
      "Epoch 247/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4699 - val_loss: 1.6082\n",
      "Epoch 248/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4597 - val_loss: 1.4977\n",
      "Epoch 249/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4635 - val_loss: 1.5035\n",
      "Epoch 250/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.4656 - val_loss: 1.5197\n",
      "Epoch 251/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4672 - val_loss: 1.5132\n",
      "Epoch 252/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4614 - val_loss: 1.4585\n",
      "Epoch 253/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4559 - val_loss: 1.5150\n",
      "Epoch 254/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4537 - val_loss: 1.4610\n",
      "Epoch 255/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4542 - val_loss: 1.5288\n",
      "Epoch 256/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4651 - val_loss: 1.5169\n",
      "Epoch 257/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4682 - val_loss: 1.5220\n",
      "Epoch 258/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4690 - val_loss: 1.4960\n",
      "Epoch 259/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4484 - val_loss: 1.5243\n",
      "Epoch 260/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4628 - val_loss: 1.4826\n",
      "Epoch 261/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4516 - val_loss: 1.4954\n",
      "Epoch 262/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4610 - val_loss: 1.4702\n",
      "Epoch 263/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4491 - val_loss: 1.5370\n",
      "Epoch 264/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4576 - val_loss: 1.5185\n",
      "Epoch 265/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4615 - val_loss: 1.5899\n",
      "Epoch 266/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4517 - val_loss: 1.5356\n",
      "Epoch 267/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4465 - val_loss: 1.4567\n",
      "Epoch 268/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4469 - val_loss: 1.5244\n",
      "Epoch 269/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4391 - val_loss: 1.4683\n",
      "Epoch 270/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4385 - val_loss: 1.4609\n",
      "Epoch 271/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4397 - val_loss: 1.5008\n",
      "Epoch 272/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4506 - val_loss: 1.5531\n",
      "Epoch 273/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4495 - val_loss: 1.5809\n",
      "Epoch 274/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4381 - val_loss: 1.5350\n",
      "Epoch 275/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4440 - val_loss: 1.5286\n",
      "Epoch 276/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4305 - val_loss: 1.5115\n",
      "Epoch 277/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4396 - val_loss: 1.4732\n",
      "Epoch 278/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4280 - val_loss: 1.4476\n",
      "Epoch 279/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4417 - val_loss: 1.4561\n",
      "Epoch 280/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4418 - val_loss: 1.4783\n",
      "Epoch 281/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4324 - val_loss: 1.4665\n",
      "Epoch 282/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4266 - val_loss: 1.4747\n",
      "Epoch 283/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4260 - val_loss: 1.4858\n",
      "Epoch 284/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4274 - val_loss: 1.4927\n",
      "Epoch 285/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4341 - val_loss: 1.4773\n",
      "Epoch 286/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4330 - val_loss: 1.4510\n",
      "Epoch 287/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4332 - val_loss: 1.4660\n",
      "Epoch 288/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4293 - val_loss: 1.4632\n",
      "Epoch 289/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4224 - val_loss: 1.5081\n",
      "Epoch 290/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4319 - val_loss: 1.4836\n",
      "Epoch 291/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.4332 - val_loss: 1.5059\n",
      "Epoch 292/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4289 - val_loss: 1.4369\n",
      "Epoch 293/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4292 - val_loss: 1.5562\n",
      "Epoch 294/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4269 - val_loss: 1.4687\n",
      "Epoch 295/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4193 - val_loss: 1.4849\n",
      "Epoch 296/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4264 - val_loss: 1.4512\n",
      "Epoch 297/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4200 - val_loss: 1.4450\n",
      "Epoch 298/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4249 - val_loss: 1.4464\n",
      "Epoch 299/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4197 - val_loss: 1.4340\n",
      "Epoch 300/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4023 - val_loss: 1.4433\n",
      "Epoch 301/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4360 - val_loss: 1.4796\n",
      "Epoch 302/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4255 - val_loss: 1.4260\n",
      "Epoch 303/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4188 - val_loss: 1.5215\n",
      "Epoch 304/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4144 - val_loss: 1.4100\n",
      "Epoch 305/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4083 - val_loss: 1.5027\n",
      "Epoch 306/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4124 - val_loss: 1.4788\n",
      "Epoch 307/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.4118 - val_loss: 1.4406\n",
      "Epoch 308/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4219 - val_loss: 1.4599\n",
      "Epoch 309/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4090 - val_loss: 1.4144\n",
      "Epoch 310/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4124 - val_loss: 1.4158\n",
      "Epoch 311/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4018 - val_loss: 1.4178\n",
      "Epoch 312/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4159 - val_loss: 1.5135\n",
      "Epoch 313/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3978 - val_loss: 1.4942\n",
      "Epoch 314/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4093 - val_loss: 1.5041\n",
      "Epoch 315/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4031 - val_loss: 1.4756\n",
      "Epoch 316/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3969 - val_loss: 1.4556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4054 - val_loss: 1.4652\n",
      "Epoch 318/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4082 - val_loss: 1.5317\n",
      "Epoch 319/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4027 - val_loss: 1.4440\n",
      "Epoch 320/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4050 - val_loss: 1.4751\n",
      "Epoch 321/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4050 - val_loss: 1.4455\n",
      "Epoch 322/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3941 - val_loss: 1.4278\n",
      "Epoch 323/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4054 - val_loss: 1.4559\n",
      "Epoch 324/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3902 - val_loss: 1.4292\n",
      "Epoch 325/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3978 - val_loss: 1.5778\n",
      "Epoch 326/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4111 - val_loss: 1.4309\n",
      "Epoch 327/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4082 - val_loss: 1.4621\n",
      "Epoch 328/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3977 - val_loss: 1.4649\n",
      "Epoch 329/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3915 - val_loss: 1.4485\n",
      "Epoch 330/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4016 - val_loss: 1.4259\n",
      "Epoch 331/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3935 - val_loss: 1.4400\n",
      "Epoch 332/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3806 - val_loss: 1.5833\n",
      "Epoch 333/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3897 - val_loss: 1.4286\n",
      "Epoch 334/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3833 - val_loss: 1.4611\n",
      "Epoch 335/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3852 - val_loss: 1.3922\n",
      "Epoch 336/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3848 - val_loss: 1.4259\n",
      "Epoch 337/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3833 - val_loss: 1.4423\n",
      "Epoch 338/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3900 - val_loss: 1.5014\n",
      "Epoch 339/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3978 - val_loss: 1.3859\n",
      "Epoch 340/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3768 - val_loss: 1.5773\n",
      "Epoch 341/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3767 - val_loss: 1.4630\n",
      "Epoch 342/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4028 - val_loss: 1.4999\n",
      "Epoch 343/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3748 - val_loss: 1.4720\n",
      "Epoch 344/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3760 - val_loss: 1.4042\n",
      "Epoch 345/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3846 - val_loss: 1.4002\n",
      "Epoch 346/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3781 - val_loss: 1.5146\n",
      "Epoch 347/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3740 - val_loss: 1.3978\n",
      "Epoch 348/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3877 - val_loss: 1.4144\n",
      "Epoch 349/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3643 - val_loss: 1.5854\n",
      "Epoch 350/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3660 - val_loss: 1.4192\n",
      "Epoch 351/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3851 - val_loss: 1.4174\n",
      "Epoch 352/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3755 - val_loss: 1.5195\n",
      "Epoch 353/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3785 - val_loss: 1.4113\n",
      "Epoch 354/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3765 - val_loss: 1.4084\n",
      "Epoch 355/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3693 - val_loss: 1.4078\n",
      "Epoch 356/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3769 - val_loss: 1.4644\n",
      "Epoch 357/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3904 - val_loss: 1.4783\n",
      "Epoch 358/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3750 - val_loss: 1.4341\n",
      "Epoch 359/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3661 - val_loss: 1.5519\n",
      "Epoch 360/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3765 - val_loss: 1.4573\n",
      "Epoch 361/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3796 - val_loss: 1.4511\n",
      "Epoch 362/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3681 - val_loss: 1.4340\n",
      "Epoch 363/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3764 - val_loss: 1.4076\n",
      "Epoch 364/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3639 - val_loss: 1.4118\n",
      "Epoch 365/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3675 - val_loss: 1.4796\n",
      "Epoch 366/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3628 - val_loss: 1.4568\n",
      "Epoch 367/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3743 - val_loss: 1.3812\n",
      "Epoch 368/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3707 - val_loss: 1.4815\n",
      "Epoch 369/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3625 - val_loss: 1.4265\n",
      "Epoch 370/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3564 - val_loss: 1.4382\n",
      "Epoch 371/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3586 - val_loss: 1.3822\n",
      "Epoch 372/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3668 - val_loss: 1.4758\n",
      "Epoch 373/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3646 - val_loss: 1.3829\n",
      "Epoch 374/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3562 - val_loss: 1.4539\n",
      "Epoch 375/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3501 - val_loss: 1.4266\n",
      "Epoch 376/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3630 - val_loss: 1.4157\n",
      "Epoch 377/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3608 - val_loss: 1.3980\n",
      "Epoch 378/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3497 - val_loss: 1.4126\n",
      "Epoch 379/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3618 - val_loss: 1.4674\n",
      "Epoch 380/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3495 - val_loss: 1.3989\n",
      "Epoch 381/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3700 - val_loss: 1.4064\n",
      "Epoch 382/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3573 - val_loss: 1.4308\n",
      "Epoch 383/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3617 - val_loss: 1.4148\n",
      "Epoch 384/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3540 - val_loss: 1.3898\n",
      "Epoch 385/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3692 - val_loss: 1.3739\n",
      "Epoch 386/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3617 - val_loss: 1.4927\n",
      "Epoch 387/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3580 - val_loss: 1.3677\n",
      "Epoch 388/700\n",
      "346/346 [==============================] - 1630s 5s/step - loss: 1.3549 - val_loss: 1.3606\n",
      "Epoch 389/700\n",
      "346/346 [==============================] - 9420s 27s/step - loss: 1.3611 - val_loss: 1.4130\n",
      "Epoch 390/700\n",
      "346/346 [==============================] - 15s 42ms/step - loss: 1.3567 - val_loss: 1.4068\n",
      "Epoch 391/700\n",
      "346/346 [==============================] - 9s 26ms/step - loss: 1.3522 - val_loss: 1.4274\n",
      "Epoch 392/700\n",
      "346/346 [==============================] - 10s 29ms/step - loss: 1.3558 - val_loss: 1.4172\n",
      "Epoch 393/700\n",
      "346/346 [==============================] - 8s 24ms/step - loss: 1.3561 - val_loss: 1.3925\n",
      "Epoch 394/700\n",
      "346/346 [==============================] - 4550s 13s/step - loss: 1.3451 - val_loss: 1.4094\n",
      "Epoch 395/700\n",
      "346/346 [==============================] - 6s 17ms/step - loss: 1.3582 - val_loss: 1.4236\n",
      "Epoch 396/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3466 - val_loss: 1.4169\n",
      "Epoch 397/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3544 - val_loss: 1.4420\n",
      "Epoch 398/700\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3560 - val_loss: 1.4285\n",
      "Epoch 399/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3483 - val_loss: 1.4935\n",
      "Epoch 400/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3579 - val_loss: 1.3867\n",
      "Epoch 401/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3412 - val_loss: 1.4033\n",
      "Epoch 402/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3422 - val_loss: 1.4184\n",
      "Epoch 403/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3503 - val_loss: 1.3567\n",
      "Epoch 404/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3502 - val_loss: 1.4247\n",
      "Epoch 405/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3380 - val_loss: 1.3991\n",
      "Epoch 406/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3404 - val_loss: 1.4576\n",
      "Epoch 407/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3501 - val_loss: 1.3753\n",
      "Epoch 408/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3394 - val_loss: 1.3804\n",
      "Epoch 409/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3603 - val_loss: 1.3844\n",
      "Epoch 410/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3424 - val_loss: 1.3860\n",
      "Epoch 411/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3385 - val_loss: 1.3618\n",
      "Epoch 412/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3399 - val_loss: 1.3859\n",
      "Epoch 413/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3343 - val_loss: 1.3579\n",
      "Epoch 414/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3364 - val_loss: 1.3932\n",
      "Epoch 415/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3421 - val_loss: 1.3960\n",
      "Epoch 416/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3386 - val_loss: 1.3601\n",
      "Epoch 417/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3390 - val_loss: 1.4168\n",
      "Epoch 418/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3385 - val_loss: 1.4024\n",
      "Epoch 419/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3294 - val_loss: 1.3845\n",
      "Epoch 420/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3372 - val_loss: 1.4470\n",
      "Epoch 421/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3412 - val_loss: 1.3751\n",
      "Epoch 422/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3277 - val_loss: 1.4036\n",
      "Epoch 423/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3284 - val_loss: 1.3767\n",
      "Epoch 424/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3382 - val_loss: 1.3412\n",
      "Epoch 425/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3337 - val_loss: 1.3863\n",
      "Epoch 426/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3342 - val_loss: 1.3745\n",
      "Epoch 427/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3369 - val_loss: 1.3676\n",
      "Epoch 428/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3271 - val_loss: 1.3670\n",
      "Epoch 429/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3400 - val_loss: 1.3617\n",
      "Epoch 430/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3309 - val_loss: 1.3801\n",
      "Epoch 431/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3340 - val_loss: 1.4080\n",
      "Epoch 432/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3234 - val_loss: 1.3665\n",
      "Epoch 433/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3213 - val_loss: 1.3539\n",
      "Epoch 434/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3371 - val_loss: 1.3931\n",
      "Epoch 435/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3239 - val_loss: 1.4385\n",
      "Epoch 436/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3238 - val_loss: 1.3896\n",
      "Epoch 437/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3216 - val_loss: 1.3822\n",
      "Epoch 438/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3239 - val_loss: 1.3668\n",
      "Epoch 439/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3266 - val_loss: 1.3612\n",
      "Epoch 440/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3178 - val_loss: 1.3568\n",
      "Epoch 441/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3266 - val_loss: 1.3918\n",
      "Epoch 442/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3305 - val_loss: 1.4042\n",
      "Epoch 443/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3213 - val_loss: 1.4162\n",
      "Epoch 444/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3211 - val_loss: 1.3683\n",
      "Epoch 445/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3344 - val_loss: 1.4161\n",
      "Epoch 446/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3156 - val_loss: 1.3556\n",
      "Epoch 447/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3288 - val_loss: 1.3303\n",
      "Epoch 448/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3199 - val_loss: 1.3681\n",
      "Epoch 449/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3178 - val_loss: 1.4120\n",
      "Epoch 450/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3214 - val_loss: 1.3467\n",
      "Epoch 451/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3088 - val_loss: 1.3365\n",
      "Epoch 452/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3119 - val_loss: 1.3671\n",
      "Epoch 453/700\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3205 - val_loss: 1.3994\n",
      "Epoch 454/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3161 - val_loss: 1.3876\n",
      "Epoch 455/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3067 - val_loss: 1.3520\n",
      "Epoch 456/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3139 - val_loss: 1.4057\n",
      "Epoch 457/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3369 - val_loss: 1.3480\n",
      "Epoch 458/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3139 - val_loss: 1.3981\n",
      "Epoch 459/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3196 - val_loss: 1.3317\n",
      "Epoch 460/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3163 - val_loss: 1.3592\n",
      "Epoch 461/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3203 - val_loss: 1.3578\n",
      "Epoch 462/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3139 - val_loss: 1.4218\n",
      "Epoch 463/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3165 - val_loss: 1.3489\n",
      "Epoch 464/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3271 - val_loss: 1.4027\n",
      "Epoch 465/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3209 - val_loss: 1.3727\n",
      "Epoch 466/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3132 - val_loss: 1.4793\n",
      "Epoch 467/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3164 - val_loss: 1.3252\n",
      "Epoch 468/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3154 - val_loss: 1.3964\n",
      "Epoch 469/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3154 - val_loss: 1.3174\n",
      "Epoch 470/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3095 - val_loss: 1.4285\n",
      "Epoch 471/700\n",
      "346/346 [==============================] - 6s 16ms/step - loss: 1.3196 - val_loss: 1.3393\n",
      "Epoch 472/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3237 - val_loss: 1.3260\n",
      "Epoch 473/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3127 - val_loss: 1.3609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3034 - val_loss: 1.3512\n",
      "Epoch 475/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3097 - val_loss: 1.3553\n",
      "Epoch 476/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3049 - val_loss: 1.3432\n",
      "Epoch 477/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3100 - val_loss: 1.3375\n",
      "Epoch 478/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3096 - val_loss: 1.3563\n",
      "Epoch 479/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3135 - val_loss: 1.3381\n",
      "Epoch 480/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3139 - val_loss: 1.3735\n",
      "Epoch 481/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2995 - val_loss: 1.3472\n",
      "Epoch 482/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3107 - val_loss: 1.3341\n",
      "Epoch 483/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3063 - val_loss: 1.4116\n",
      "Epoch 484/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3076 - val_loss: 1.3423\n",
      "Epoch 485/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3142 - val_loss: 1.3442\n",
      "Epoch 486/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3042 - val_loss: 1.3751\n",
      "Epoch 487/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2985 - val_loss: 1.3712\n",
      "Epoch 488/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3159 - val_loss: 1.3837\n",
      "Epoch 489/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3132 - val_loss: 1.4051\n",
      "Epoch 490/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3059 - val_loss: 1.3691\n",
      "Epoch 491/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3040 - val_loss: 1.3990\n",
      "Epoch 492/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3029 - val_loss: 1.3564\n",
      "Epoch 493/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2954 - val_loss: 1.3279\n",
      "Epoch 494/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2935 - val_loss: 1.3721\n",
      "Epoch 495/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3026 - val_loss: 1.3530\n",
      "Epoch 496/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2949 - val_loss: 1.3652\n",
      "Epoch 497/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2986 - val_loss: 1.3319\n",
      "Epoch 498/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3115 - val_loss: 1.3334\n",
      "Epoch 499/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3055 - val_loss: 1.3365\n",
      "Epoch 500/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2892 - val_loss: 1.3340\n",
      "Epoch 501/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2829 - val_loss: 1.3261\n",
      "Epoch 502/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3093 - val_loss: 1.3678\n",
      "Epoch 503/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2789 - val_loss: 1.3860\n",
      "Epoch 504/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2886 - val_loss: 1.3495\n",
      "Epoch 505/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2979 - val_loss: 1.3338\n",
      "Epoch 506/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2888 - val_loss: 1.3781\n",
      "Epoch 507/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2857 - val_loss: 1.3186\n",
      "Epoch 508/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2878 - val_loss: 1.4147\n",
      "Epoch 509/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2926 - val_loss: 1.3025\n",
      "Epoch 510/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2977 - val_loss: 1.2959\n",
      "Epoch 511/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2983 - val_loss: 1.3554\n",
      "Epoch 512/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2964 - val_loss: 1.3768\n",
      "Epoch 513/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2857 - val_loss: 1.3171\n",
      "Epoch 514/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.3009 - val_loss: 1.3597\n",
      "Epoch 515/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2942 - val_loss: 1.4054\n",
      "Epoch 516/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2854 - val_loss: 1.3212\n",
      "Epoch 517/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2957 - val_loss: 1.3622\n",
      "Epoch 518/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2993 - val_loss: 1.3316\n",
      "Epoch 519/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2932 - val_loss: 1.3256\n",
      "Epoch 520/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2871 - val_loss: 1.3518\n",
      "Epoch 521/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2846 - val_loss: 1.3349\n",
      "Epoch 522/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2827 - val_loss: 1.3426\n",
      "Epoch 523/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2897 - val_loss: 1.4007\n",
      "Epoch 524/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3048 - val_loss: 1.3295\n",
      "Epoch 525/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2885 - val_loss: 1.2907\n",
      "Epoch 526/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2832 - val_loss: 1.3086\n",
      "Epoch 527/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2890 - val_loss: 1.4671\n",
      "Epoch 528/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2846 - val_loss: 1.3355\n",
      "Epoch 529/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2861 - val_loss: 1.3197\n",
      "Epoch 530/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2868 - val_loss: 1.3277\n",
      "Epoch 531/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2840 - val_loss: 1.3324\n",
      "Epoch 532/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2853 - val_loss: 1.4022\n",
      "Epoch 533/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2889 - val_loss: 1.3354\n",
      "Epoch 534/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2724 - val_loss: 1.3309\n",
      "Epoch 535/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2841 - val_loss: 1.5370\n",
      "Epoch 536/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2916 - val_loss: 1.2915\n",
      "Epoch 537/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2792 - val_loss: 1.3361\n",
      "Epoch 538/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2824 - val_loss: 1.3385\n",
      "Epoch 539/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2817 - val_loss: 1.3652\n",
      "Epoch 540/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2880 - val_loss: 1.3688\n",
      "Epoch 541/700\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.2771 - val_loss: 1.3483\n",
      "Epoch 542/700\n",
      "346/346 [==============================] - 3s 10ms/step - loss: 1.2903 - val_loss: 1.4332\n",
      "Epoch 543/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2854 - val_loss: 1.3641\n",
      "Epoch 544/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2859 - val_loss: 1.3491\n",
      "Epoch 545/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2737 - val_loss: 1.3396\n",
      "Epoch 546/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2833 - val_loss: 1.2848\n",
      "Epoch 547/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2743 - val_loss: 1.3279\n",
      "Epoch 548/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2740 - val_loss: 1.4011\n",
      "Epoch 549/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2810 - val_loss: 1.2999\n",
      "Epoch 550/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2941 - val_loss: 1.2835\n",
      "Epoch 551/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2736 - val_loss: 1.3755\n",
      "Epoch 552/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2725 - val_loss: 1.4027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2884 - val_loss: 1.3096\n",
      "Epoch 554/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2672 - val_loss: 1.3174\n",
      "Epoch 555/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2767 - val_loss: 1.2913\n",
      "Epoch 556/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2796 - val_loss: 1.2813\n",
      "Epoch 557/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2737 - val_loss: 1.3612\n",
      "Epoch 558/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2848 - val_loss: 1.3372\n",
      "Epoch 559/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2806 - val_loss: 1.4236\n",
      "Epoch 560/700\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2788 - val_loss: 1.3493\n",
      "Epoch 561/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2661 - val_loss: 1.3783\n",
      "Epoch 562/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2729 - val_loss: 1.3492\n",
      "Epoch 563/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2722 - val_loss: 1.3337\n",
      "Epoch 564/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2636 - val_loss: 1.2943\n",
      "Epoch 565/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2729 - val_loss: 1.3249\n",
      "Epoch 566/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2766 - val_loss: 1.3212\n",
      "Epoch 567/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2866 - val_loss: 1.3426\n",
      "Epoch 568/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2750 - val_loss: 1.3775\n",
      "Epoch 569/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2752 - val_loss: 1.3164\n",
      "Epoch 570/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2797 - val_loss: 1.3378\n",
      "Epoch 571/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2623 - val_loss: 1.2766\n",
      "Epoch 572/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2669 - val_loss: 1.3555\n",
      "Epoch 573/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2733 - val_loss: 1.2990\n",
      "Epoch 574/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2636 - val_loss: 1.3158\n",
      "Epoch 575/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2765 - val_loss: 1.3388\n",
      "Epoch 576/700\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2608 - val_loss: 1.3275\n",
      "Epoch 577/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2638 - val_loss: 1.4635\n",
      "Epoch 578/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2650 - val_loss: 1.3996\n",
      "Epoch 579/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2761 - val_loss: 1.3402\n",
      "Epoch 580/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2785 - val_loss: 1.3409\n",
      "Epoch 581/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2709 - val_loss: 1.3197\n",
      "Epoch 582/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2718 - val_loss: 1.3295\n",
      "Epoch 583/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2704 - val_loss: 1.3135\n",
      "Epoch 584/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2591 - val_loss: 1.3479\n",
      "Epoch 585/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2588 - val_loss: 1.3113\n",
      "Epoch 586/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2686 - val_loss: 1.3424\n",
      "Epoch 587/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2694 - val_loss: 1.3609\n",
      "Epoch 588/700\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.2771 - val_loss: 1.4010\n",
      "Epoch 589/700\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.2679 - val_loss: 1.2812\n",
      "Epoch 590/700\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2704 - val_loss: 1.3080\n",
      "Epoch 591/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2713 - val_loss: 1.4060\n",
      "Epoch 592/700\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2728 - val_loss: 1.2932\n",
      "Epoch 593/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2818 - val_loss: 1.3542\n",
      "Epoch 594/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2538 - val_loss: 1.3500\n",
      "Epoch 595/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2583 - val_loss: 1.3576\n",
      "Epoch 596/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2611 - val_loss: 1.3016\n",
      "Epoch 597/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2665 - val_loss: 1.3637\n",
      "Epoch 598/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2750 - val_loss: 1.2826\n",
      "Epoch 599/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2653 - val_loss: 1.3409\n",
      "Epoch 600/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2574 - val_loss: 1.2855\n",
      "Epoch 601/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2673 - val_loss: 1.2901\n",
      "Epoch 602/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2533 - val_loss: 1.3312\n",
      "Epoch 603/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2583 - val_loss: 1.2871\n",
      "Epoch 604/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2601 - val_loss: 1.3421\n",
      "Epoch 605/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2597 - val_loss: 1.3634\n",
      "Epoch 606/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2466 - val_loss: 1.2721\n",
      "Epoch 607/700\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2629 - val_loss: 1.3472\n",
      "Epoch 608/700\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2522 - val_loss: 1.3343\n",
      "Epoch 609/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2596 - val_loss: 1.3697\n",
      "Epoch 610/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2687 - val_loss: 1.3267\n",
      "Epoch 611/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2679 - val_loss: 1.3613\n",
      "Epoch 612/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2589 - val_loss: 1.2923\n",
      "Epoch 613/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2608 - val_loss: 1.4065\n",
      "Epoch 614/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2570 - val_loss: 1.2954\n",
      "Epoch 615/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2557 - val_loss: 1.2910\n",
      "Epoch 616/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2561 - val_loss: 1.3167\n",
      "Epoch 617/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2624 - val_loss: 1.3073\n",
      "Epoch 618/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2505 - val_loss: 1.2898\n",
      "Epoch 619/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2622 - val_loss: 1.3074\n",
      "Epoch 620/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2527 - val_loss: 1.3467\n",
      "Epoch 621/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2614 - val_loss: 1.3042\n",
      "Epoch 622/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2435 - val_loss: 1.2968\n",
      "Epoch 623/700\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.2526 - val_loss: 1.3036\n",
      "Epoch 624/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2501 - val_loss: 1.4819\n",
      "Epoch 625/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2632 - val_loss: 1.3166\n",
      "Epoch 626/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2425 - val_loss: 1.2964\n",
      "Epoch 627/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2404 - val_loss: 1.2934\n",
      "Epoch 628/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2628 - val_loss: 1.3199\n",
      "Epoch 629/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2491 - val_loss: 1.3034\n",
      "Epoch 630/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2499 - val_loss: 1.3298\n",
      "Epoch 631/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2498 - val_loss: 1.3698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 632/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2469 - val_loss: 1.2467\n",
      "Epoch 633/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2418 - val_loss: 1.2740\n",
      "Epoch 634/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2499 - val_loss: 1.3373\n",
      "Epoch 635/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2514 - val_loss: 1.3276\n",
      "Epoch 636/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2593 - val_loss: 1.3229\n",
      "Epoch 637/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2442 - val_loss: 1.3092\n",
      "Epoch 638/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2540 - val_loss: 1.2687\n",
      "Epoch 639/700\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2715 - val_loss: 1.3011\n",
      "Epoch 640/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2507 - val_loss: 1.3326\n",
      "Epoch 641/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2514 - val_loss: 1.3479\n",
      "Epoch 642/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2434 - val_loss: 1.3006\n",
      "Epoch 643/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2566 - val_loss: 1.3206\n",
      "Epoch 644/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2468 - val_loss: 1.2723\n",
      "Epoch 645/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2444 - val_loss: 1.3140\n",
      "Epoch 646/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2498 - val_loss: 1.2863\n",
      "Epoch 647/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2456 - val_loss: 1.3305\n",
      "Epoch 648/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2515 - val_loss: 1.2885\n",
      "Epoch 649/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2429 - val_loss: 1.3007\n",
      "Epoch 650/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2491 - val_loss: 1.3220\n",
      "Epoch 651/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2503 - val_loss: 1.3049\n",
      "Epoch 652/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2503 - val_loss: 1.3104\n",
      "Epoch 653/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2465 - val_loss: 1.3110\n",
      "Epoch 654/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2318 - val_loss: 1.2775\n",
      "Epoch 655/700\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2551 - val_loss: 1.3833\n",
      "Epoch 656/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2482 - val_loss: 1.2629\n",
      "Epoch 657/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2489 - val_loss: 1.3132\n",
      "Epoch 658/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2331 - val_loss: 1.3443\n",
      "Epoch 659/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2413 - val_loss: 1.2662\n",
      "Epoch 660/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2393 - val_loss: 1.2871\n",
      "Epoch 661/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2430 - val_loss: 1.2789\n",
      "Epoch 662/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2465 - val_loss: 1.2661\n",
      "Epoch 663/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2439 - val_loss: 1.3319\n",
      "Epoch 664/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2491 - val_loss: 1.2853\n",
      "Epoch 665/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2424 - val_loss: 1.2637\n",
      "Epoch 666/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2423 - val_loss: 1.3920\n",
      "Epoch 667/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2471 - val_loss: 1.3331\n",
      "Epoch 668/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2468 - val_loss: 1.2691\n",
      "Epoch 669/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2445 - val_loss: 1.2930\n",
      "Epoch 670/700\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2381 - val_loss: 1.2936\n",
      "Epoch 671/700\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2403 - val_loss: 1.3016\n",
      "Epoch 672/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2510 - val_loss: 1.3072\n",
      "Epoch 673/700\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2473 - val_loss: 1.2685\n",
      "Epoch 674/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2417 - val_loss: 1.2574\n",
      "Epoch 675/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2464 - val_loss: 1.3306\n",
      "Epoch 676/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2377 - val_loss: 1.2872\n",
      "Epoch 677/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2382 - val_loss: 1.3529\n",
      "Epoch 678/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2391 - val_loss: 1.3094\n",
      "Epoch 679/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2399 - val_loss: 1.2975\n",
      "Epoch 680/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2323 - val_loss: 1.3359\n",
      "Epoch 681/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2491 - val_loss: 1.3148\n",
      "Epoch 682/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2413 - val_loss: 1.2349\n",
      "Epoch 683/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2373 - val_loss: 1.2658\n",
      "Epoch 684/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2380 - val_loss: 1.3555\n",
      "Epoch 685/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2344 - val_loss: 1.2991\n",
      "Epoch 686/700\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2398 - val_loss: 1.3014\n",
      "Epoch 687/700\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2326 - val_loss: 1.2928\n",
      "Epoch 688/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2405 - val_loss: 1.3545\n",
      "Epoch 689/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2292 - val_loss: 1.3011\n",
      "Epoch 690/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2343 - val_loss: 1.3111\n",
      "Epoch 691/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2478 - val_loss: 1.3321\n",
      "Epoch 692/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2328 - val_loss: 1.2733\n",
      "Epoch 693/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2244 - val_loss: 1.3065\n",
      "Epoch 694/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2412 - val_loss: 1.2864\n",
      "Epoch 695/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2405 - val_loss: 1.2785\n",
      "Epoch 696/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2339 - val_loss: 1.2729\n",
      "Epoch 697/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2473 - val_loss: 1.2787\n",
      "Epoch 698/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2329 - val_loss: 1.3098\n",
      "Epoch 699/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2313 - val_loss: 1.2532\n",
      "Epoch 700/700\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2272 - val_loss: 1.3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.302521669606683\n",
      "0.9758319525355773\n",
      "Epoch 1/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 11.2104 - val_loss: 6.8906\n",
      "Epoch 2/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 8.9424 - val_loss: 8.5822\n",
      "Epoch 3/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 5.6202 - val_loss: 3.9684\n",
      "Epoch 4/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 4.3877 - val_loss: 5.3162\n",
      "Epoch 5/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.5549 - val_loss: 3.9616\n",
      "Epoch 6/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 5.3778 - val_loss: 4.1002\n",
      "Epoch 7/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.2300 - val_loss: 4.1818\n",
      "Epoch 8/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 4.5544 - val_loss: 6.5666\n",
      "Epoch 9/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 5.7678 - val_loss: 3.8070\n",
      "Epoch 10/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 4.1340 - val_loss: 5.4556\n",
      "Epoch 11/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.0511 - val_loss: 3.0845\n",
      "Epoch 12/700\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 3.3062 - val_loss: 3.0329\n",
      "Epoch 13/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 3.8638 - val_loss: 2.9800\n",
      "Epoch 14/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.4834 - val_loss: 3.0403\n",
      "Epoch 15/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.1772 - val_loss: 3.6345\n",
      "Epoch 16/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 3.3266 - val_loss: 3.1361\n",
      "Epoch 17/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.1723 - val_loss: 6.3603\n",
      "Epoch 18/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.2241 - val_loss: 2.8272\n",
      "Epoch 19/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 3.2353 - val_loss: 2.8656\n",
      "Epoch 20/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 3.1582 - val_loss: 2.8575\n",
      "Epoch 21/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.0510 - val_loss: 2.7951\n",
      "Epoch 22/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.0122 - val_loss: 2.8099\n",
      "Epoch 23/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.9742 - val_loss: 2.8606\n",
      "Epoch 24/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.9023 - val_loss: 2.7259\n",
      "Epoch 25/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.8313 - val_loss: 2.9301\n",
      "Epoch 26/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.9008 - val_loss: 2.5722\n",
      "Epoch 27/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.8688 - val_loss: 2.7158\n",
      "Epoch 28/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7109 - val_loss: 2.5691\n",
      "Epoch 29/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7001 - val_loss: 2.7659\n",
      "Epoch 30/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5809 - val_loss: 2.4995\n",
      "Epoch 31/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5839 - val_loss: 2.7265\n",
      "Epoch 32/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 2.6259 - val_loss: 3.2786\n",
      "Epoch 33/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5835 - val_loss: 2.3849\n",
      "Epoch 34/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5224 - val_loss: 2.4481\n",
      "Epoch 35/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4807 - val_loss: 2.7518\n",
      "Epoch 36/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.4654 - val_loss: 2.3845\n",
      "Epoch 37/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4577 - val_loss: 2.6237\n",
      "Epoch 38/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3986 - val_loss: 2.3128\n",
      "Epoch 39/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4552 - val_loss: 2.3160\n",
      "Epoch 40/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3862 - val_loss: 2.2647\n",
      "Epoch 41/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3525 - val_loss: 2.2812\n",
      "Epoch 42/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3690 - val_loss: 2.6792\n",
      "Epoch 43/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3225 - val_loss: 2.5003\n",
      "Epoch 44/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3293 - val_loss: 2.2423\n",
      "Epoch 45/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3014 - val_loss: 2.3167\n",
      "Epoch 46/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2994 - val_loss: 2.3909\n",
      "Epoch 47/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2675 - val_loss: 2.2925\n",
      "Epoch 48/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2614 - val_loss: 2.4105\n",
      "Epoch 49/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.2629 - val_loss: 2.1975\n",
      "Epoch 50/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2269 - val_loss: 2.3813\n",
      "Epoch 51/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2434 - val_loss: 2.1909\n",
      "Epoch 52/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2239 - val_loss: 2.3936\n",
      "Epoch 53/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.1902 - val_loss: 2.1208\n",
      "Epoch 54/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1727 - val_loss: 2.0910\n",
      "Epoch 55/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2032 - val_loss: 2.2226\n",
      "Epoch 56/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 2.1613 - val_loss: 2.1723\n",
      "Epoch 57/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.1282 - val_loss: 2.1929\n",
      "Epoch 58/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1342 - val_loss: 2.0983\n",
      "Epoch 59/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1102 - val_loss: 2.0762\n",
      "Epoch 60/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1182 - val_loss: 2.2497\n",
      "Epoch 61/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1235 - val_loss: 2.1163\n",
      "Epoch 62/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0953 - val_loss: 2.0998\n",
      "Epoch 63/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0926 - val_loss: 2.2123\n",
      "Epoch 64/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.0936 - val_loss: 2.0861\n",
      "Epoch 65/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 2.0798 - val_loss: 2.0112\n",
      "Epoch 66/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.0661 - val_loss: 2.0541\n",
      "Epoch 67/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0470 - val_loss: 1.9843\n",
      "Epoch 68/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0490 - val_loss: 2.0403\n",
      "Epoch 69/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0525 - val_loss: 2.1041\n",
      "Epoch 70/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0298 - val_loss: 2.0047\n",
      "Epoch 71/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.0503 - val_loss: 1.9789\n",
      "Epoch 72/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.0250 - val_loss: 2.0608\n",
      "Epoch 73/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.0423 - val_loss: 1.9177\n",
      "Epoch 74/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.0100 - val_loss: 2.0637\n",
      "Epoch 75/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9889 - val_loss: 1.9218\n",
      "Epoch 76/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.0034 - val_loss: 2.0622\n",
      "Epoch 77/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 2.0025 - val_loss: 2.1009\n",
      "Epoch 78/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9914 - val_loss: 2.0045\n",
      "Epoch 79/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9701 - val_loss: 1.9676\n",
      "Epoch 80/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9642 - val_loss: 1.9139\n",
      "Epoch 81/700\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.9933 - val_loss: 1.9655\n",
      "Epoch 82/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.9596 - val_loss: 2.0144\n",
      "Epoch 83/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9597 - val_loss: 1.9271\n",
      "Epoch 84/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9273 - val_loss: 1.9045\n",
      "Epoch 85/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9413 - val_loss: 1.9041\n",
      "Epoch 86/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9351 - val_loss: 2.1746\n",
      "Epoch 87/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9197 - val_loss: 1.8728\n",
      "Epoch 88/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9119 - val_loss: 2.0198\n",
      "Epoch 89/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9318 - val_loss: 1.9017\n",
      "Epoch 90/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9129 - val_loss: 1.9144\n",
      "Epoch 91/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8993 - val_loss: 1.8981\n",
      "Epoch 92/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8843 - val_loss: 1.9412\n",
      "Epoch 93/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8916 - val_loss: 1.8774\n",
      "Epoch 94/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8815 - val_loss: 1.9886\n",
      "Epoch 95/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9082 - val_loss: 1.9361\n",
      "Epoch 96/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8826 - val_loss: 1.8986\n",
      "Epoch 97/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.8849 - val_loss: 1.8498\n",
      "Epoch 98/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.8590 - val_loss: 1.8984\n",
      "Epoch 99/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8483 - val_loss: 1.8080\n",
      "Epoch 100/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8643 - val_loss: 1.9079\n",
      "Epoch 101/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8467 - val_loss: 1.9499\n",
      "Epoch 102/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8517 - val_loss: 1.8629\n",
      "Epoch 103/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8485 - val_loss: 1.8407\n",
      "Epoch 104/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8407 - val_loss: 1.8509\n",
      "Epoch 105/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8366 - val_loss: 1.8821\n",
      "Epoch 106/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8275 - val_loss: 1.8529\n",
      "Epoch 107/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8099 - val_loss: 1.9208\n",
      "Epoch 108/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8274 - val_loss: 1.9668\n",
      "Epoch 109/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8284 - val_loss: 1.7454\n",
      "Epoch 110/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8227 - val_loss: 1.8087\n",
      "Epoch 111/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8068 - val_loss: 1.8086\n",
      "Epoch 112/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8010 - val_loss: 1.8948\n",
      "Epoch 113/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8030 - val_loss: 1.9070\n",
      "Epoch 114/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.7916 - val_loss: 1.8496\n",
      "Epoch 115/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.8063 - val_loss: 1.7656\n",
      "Epoch 116/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7758 - val_loss: 1.8808\n",
      "Epoch 117/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7716 - val_loss: 1.7801\n",
      "Epoch 118/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7785 - val_loss: 1.8103\n",
      "Epoch 119/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7903 - val_loss: 1.8131\n",
      "Epoch 120/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7724 - val_loss: 1.8260\n",
      "Epoch 121/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7731 - val_loss: 1.8633\n",
      "Epoch 122/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7686 - val_loss: 1.7291\n",
      "Epoch 123/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7594 - val_loss: 1.8952\n",
      "Epoch 124/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7461 - val_loss: 1.7156\n",
      "Epoch 125/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7623 - val_loss: 1.7227\n",
      "Epoch 126/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7388 - val_loss: 1.6980\n",
      "Epoch 127/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7414 - val_loss: 1.7146\n",
      "Epoch 128/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7371 - val_loss: 1.7398\n",
      "Epoch 129/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7334 - val_loss: 1.7761\n",
      "Epoch 130/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.7364 - val_loss: 1.7297\n",
      "Epoch 131/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7190 - val_loss: 1.8310\n",
      "Epoch 132/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7181 - val_loss: 1.7328\n",
      "Epoch 133/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7366 - val_loss: 1.7138\n",
      "Epoch 134/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7020 - val_loss: 1.7148\n",
      "Epoch 135/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7053 - val_loss: 1.7043\n",
      "Epoch 136/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7261 - val_loss: 1.7879\n",
      "Epoch 137/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.7079 - val_loss: 1.6670\n",
      "Epoch 138/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7122 - val_loss: 1.7274\n",
      "Epoch 139/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6968 - val_loss: 1.7404\n",
      "Epoch 140/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6867 - val_loss: 1.6756\n",
      "Epoch 141/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6987 - val_loss: 1.8262\n",
      "Epoch 142/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6931 - val_loss: 1.8500\n",
      "Epoch 143/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6824 - val_loss: 1.6933\n",
      "Epoch 144/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6745 - val_loss: 1.6941\n",
      "Epoch 145/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6698 - val_loss: 1.6816\n",
      "Epoch 146/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6701 - val_loss: 1.7161\n",
      "Epoch 147/700\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.6767 - val_loss: 1.6943\n",
      "Epoch 148/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6790 - val_loss: 1.6648\n",
      "Epoch 149/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6553 - val_loss: 1.6583\n",
      "Epoch 150/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6726 - val_loss: 1.6853\n",
      "Epoch 151/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6589 - val_loss: 1.6841\n",
      "Epoch 152/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6704 - val_loss: 1.6675\n",
      "Epoch 153/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6520 - val_loss: 1.7348\n",
      "Epoch 154/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6635 - val_loss: 1.7748\n",
      "Epoch 155/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6477 - val_loss: 1.6498\n",
      "Epoch 156/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6523 - val_loss: 1.8677\n",
      "Epoch 157/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6502 - val_loss: 1.7080\n",
      "Epoch 158/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6358 - val_loss: 1.6513\n",
      "Epoch 159/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6268 - val_loss: 1.6953\n",
      "Epoch 160/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6552 - val_loss: 1.6839\n",
      "Epoch 161/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6397 - val_loss: 1.7382\n",
      "Epoch 162/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6367 - val_loss: 1.5992\n",
      "Epoch 163/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.6262 - val_loss: 1.6841\n",
      "Epoch 164/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6359 - val_loss: 1.7004\n",
      "Epoch 165/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6216 - val_loss: 1.6311\n",
      "Epoch 166/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6276 - val_loss: 1.6370\n",
      "Epoch 167/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6153 - val_loss: 1.6251\n",
      "Epoch 168/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6056 - val_loss: 1.6288\n",
      "Epoch 169/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6135 - val_loss: 1.6415\n",
      "Epoch 170/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6161 - val_loss: 1.6526\n",
      "Epoch 171/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5987 - val_loss: 1.6880\n",
      "Epoch 172/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6004 - val_loss: 1.6072\n",
      "Epoch 173/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6024 - val_loss: 1.6755\n",
      "Epoch 174/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5941 - val_loss: 1.5966\n",
      "Epoch 175/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5987 - val_loss: 1.5742\n",
      "Epoch 176/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5932 - val_loss: 1.7681\n",
      "Epoch 177/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6065 - val_loss: 1.5996\n",
      "Epoch 178/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5935 - val_loss: 1.6960\n",
      "Epoch 179/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5914 - val_loss: 1.5613\n",
      "Epoch 180/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5733 - val_loss: 1.6234\n",
      "Epoch 181/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6047 - val_loss: 1.5843\n",
      "Epoch 182/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6208 - val_loss: 1.6871\n",
      "Epoch 183/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5807 - val_loss: 1.5931\n",
      "Epoch 184/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5884 - val_loss: 1.6205\n",
      "Epoch 185/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5857 - val_loss: 1.5830\n",
      "Epoch 186/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5611 - val_loss: 1.5715\n",
      "Epoch 187/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5885 - val_loss: 1.5751\n",
      "Epoch 188/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5635 - val_loss: 1.6354\n",
      "Epoch 189/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5742 - val_loss: 1.6623\n",
      "Epoch 190/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5604 - val_loss: 1.5849\n",
      "Epoch 191/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5668 - val_loss: 1.6082\n",
      "Epoch 192/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5833 - val_loss: 1.7613\n",
      "Epoch 193/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5666 - val_loss: 1.5893\n",
      "Epoch 194/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5584 - val_loss: 1.5880\n",
      "Epoch 195/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5446 - val_loss: 1.6519\n",
      "Epoch 196/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5522 - val_loss: 1.5621\n",
      "Epoch 197/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5529 - val_loss: 1.6555\n",
      "Epoch 198/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5537 - val_loss: 1.5779\n",
      "Epoch 199/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5507 - val_loss: 1.5900\n",
      "Epoch 200/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5537 - val_loss: 1.5466\n",
      "Epoch 201/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5479 - val_loss: 1.5546\n",
      "Epoch 202/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5428 - val_loss: 1.5873\n",
      "Epoch 203/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5382 - val_loss: 1.6095\n",
      "Epoch 204/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5457 - val_loss: 1.6089\n",
      "Epoch 205/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5503 - val_loss: 1.5897\n",
      "Epoch 206/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5461 - val_loss: 1.5569\n",
      "Epoch 207/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5497 - val_loss: 1.5901\n",
      "Epoch 208/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5163 - val_loss: 1.5462\n",
      "Epoch 209/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5280 - val_loss: 1.7288\n",
      "Epoch 210/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5249 - val_loss: 1.5250\n",
      "Epoch 211/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5450 - val_loss: 1.5606\n",
      "Epoch 212/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5263 - val_loss: 1.5442\n",
      "Epoch 213/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5228 - val_loss: 1.5192\n",
      "Epoch 214/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5259 - val_loss: 1.5348\n",
      "Epoch 215/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5179 - val_loss: 1.5230\n",
      "Epoch 216/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5121 - val_loss: 1.7595\n",
      "Epoch 217/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5127 - val_loss: 1.5377\n",
      "Epoch 218/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5102 - val_loss: 1.5639\n",
      "Epoch 219/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5120 - val_loss: 1.5236\n",
      "Epoch 220/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5176 - val_loss: 1.5353\n",
      "Epoch 221/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5294 - val_loss: 1.5702\n",
      "Epoch 222/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5149 - val_loss: 1.5412\n",
      "Epoch 223/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5237 - val_loss: 1.5603\n",
      "Epoch 224/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5092 - val_loss: 1.5625\n",
      "Epoch 225/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5237 - val_loss: 1.5232\n",
      "Epoch 226/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5045 - val_loss: 1.5575\n",
      "Epoch 227/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5047 - val_loss: 1.5546\n",
      "Epoch 228/700\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4984 - val_loss: 1.5445\n",
      "Epoch 229/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4935 - val_loss: 1.5500\n",
      "Epoch 230/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4889 - val_loss: 1.5499\n",
      "Epoch 231/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4972 - val_loss: 1.5080\n",
      "Epoch 232/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5056 - val_loss: 1.5475\n",
      "Epoch 233/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4861 - val_loss: 1.5252\n",
      "Epoch 234/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4975 - val_loss: 1.5537\n",
      "Epoch 235/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4922 - val_loss: 1.5319\n",
      "Epoch 236/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4986 - val_loss: 1.5705\n",
      "Epoch 237/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5016 - val_loss: 1.5930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4807 - val_loss: 1.5059\n",
      "Epoch 239/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4846 - val_loss: 1.5554\n",
      "Epoch 240/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4848 - val_loss: 1.5284\n",
      "Epoch 241/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4919 - val_loss: 1.5050\n",
      "Epoch 242/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4830 - val_loss: 1.5892\n",
      "Epoch 243/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4804 - val_loss: 1.5050\n",
      "Epoch 244/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4770 - val_loss: 1.4894\n",
      "Epoch 245/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4793 - val_loss: 1.5222\n",
      "Epoch 246/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4803 - val_loss: 1.5236\n",
      "Epoch 247/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4927 - val_loss: 1.5112\n",
      "Epoch 248/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4893 - val_loss: 1.5859\n",
      "Epoch 249/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4695 - val_loss: 1.5064\n",
      "Epoch 250/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4720 - val_loss: 1.5502\n",
      "Epoch 251/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4613 - val_loss: 1.5426\n",
      "Epoch 252/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4652 - val_loss: 1.4822\n",
      "Epoch 253/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4817 - val_loss: 1.5408\n",
      "Epoch 254/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4675 - val_loss: 1.4659\n",
      "Epoch 255/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4756 - val_loss: 1.5275\n",
      "Epoch 256/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4668 - val_loss: 1.4756\n",
      "Epoch 257/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4704 - val_loss: 1.4718\n",
      "Epoch 258/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4605 - val_loss: 1.4928\n",
      "Epoch 259/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4546 - val_loss: 1.5007\n",
      "Epoch 260/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4528 - val_loss: 1.4825\n",
      "Epoch 261/700\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.4605 - val_loss: 1.4753\n",
      "Epoch 262/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4452 - val_loss: 1.4828\n",
      "Epoch 263/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4576 - val_loss: 1.4714\n",
      "Epoch 264/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4505 - val_loss: 1.4717\n",
      "Epoch 265/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4468 - val_loss: 1.5244\n",
      "Epoch 266/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4527 - val_loss: 1.4801\n",
      "Epoch 267/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4558 - val_loss: 1.5088\n",
      "Epoch 268/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4551 - val_loss: 1.5169\n",
      "Epoch 269/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4476 - val_loss: 1.5008\n",
      "Epoch 270/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4435 - val_loss: 1.6283\n",
      "Epoch 271/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4617 - val_loss: 1.4574\n",
      "Epoch 272/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4490 - val_loss: 1.5083\n",
      "Epoch 273/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4451 - val_loss: 1.4841\n",
      "Epoch 274/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4259 - val_loss: 1.4499\n",
      "Epoch 275/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4273 - val_loss: 1.4549\n",
      "Epoch 276/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4449 - val_loss: 1.4809\n",
      "Epoch 277/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4426 - val_loss: 1.5349\n",
      "Epoch 278/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4481 - val_loss: 1.4981\n",
      "Epoch 279/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4458 - val_loss: 1.4670\n",
      "Epoch 280/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4396 - val_loss: 1.4507\n",
      "Epoch 281/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4395 - val_loss: 1.4700\n",
      "Epoch 282/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4341 - val_loss: 1.4770\n",
      "Epoch 283/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4290 - val_loss: 1.4474\n",
      "Epoch 284/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4281 - val_loss: 1.5762\n",
      "Epoch 285/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4274 - val_loss: 1.4966\n",
      "Epoch 286/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4267 - val_loss: 1.4692\n",
      "Epoch 287/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4490 - val_loss: 1.5226\n",
      "Epoch 288/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4507 - val_loss: 1.5042\n",
      "Epoch 289/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4217 - val_loss: 1.4710\n",
      "Epoch 290/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4195 - val_loss: 1.5014\n",
      "Epoch 291/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4217 - val_loss: 1.5110\n",
      "Epoch 292/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4144 - val_loss: 1.5032\n",
      "Epoch 293/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4376 - val_loss: 1.4530\n",
      "Epoch 294/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4116 - val_loss: 1.4351\n",
      "Epoch 295/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4225 - val_loss: 1.5256\n",
      "Epoch 296/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4332 - val_loss: 1.4911\n",
      "Epoch 297/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4166 - val_loss: 1.4641\n",
      "Epoch 298/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4250 - val_loss: 1.5417\n",
      "Epoch 299/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4313 - val_loss: 1.4576\n",
      "Epoch 300/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4185 - val_loss: 1.4531\n",
      "Epoch 301/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4198 - val_loss: 1.4136\n",
      "Epoch 302/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4159 - val_loss: 1.4362\n",
      "Epoch 303/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4215 - val_loss: 1.5052\n",
      "Epoch 304/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4084 - val_loss: 1.4790\n",
      "Epoch 305/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4323 - val_loss: 1.5230\n",
      "Epoch 306/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4068 - val_loss: 1.4961\n",
      "Epoch 307/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4222 - val_loss: 1.4644\n",
      "Epoch 308/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4154 - val_loss: 1.4456\n",
      "Epoch 309/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4163 - val_loss: 1.4795\n",
      "Epoch 310/700\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4073 - val_loss: 1.4704\n",
      "Epoch 311/700\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4085 - val_loss: 1.3914\n",
      "Epoch 312/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4037 - val_loss: 1.5249\n",
      "Epoch 313/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4073 - val_loss: 1.4480\n",
      "Epoch 314/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3988 - val_loss: 1.4573\n",
      "Epoch 315/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4054 - val_loss: 1.5306\n",
      "Epoch 316/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4112 - val_loss: 1.5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4158 - val_loss: 1.3898\n",
      "Epoch 318/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4054 - val_loss: 1.4055\n",
      "Epoch 319/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4110 - val_loss: 1.4354\n",
      "Epoch 320/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4073 - val_loss: 1.4445\n",
      "Epoch 321/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3925 - val_loss: 1.4450\n",
      "Epoch 322/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3912 - val_loss: 1.4575\n",
      "Epoch 323/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3941 - val_loss: 1.4449\n",
      "Epoch 324/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3894 - val_loss: 1.4125\n",
      "Epoch 325/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3887 - val_loss: 1.3705\n",
      "Epoch 326/700\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4028 - val_loss: 1.4116\n",
      "Epoch 327/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3830 - val_loss: 1.4337\n",
      "Epoch 328/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3961 - val_loss: 1.4299\n",
      "Epoch 329/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3913 - val_loss: 1.4376\n",
      "Epoch 330/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3917 - val_loss: 1.4238\n",
      "Epoch 331/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3960 - val_loss: 1.4533\n",
      "Epoch 332/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3911 - val_loss: 1.4135\n",
      "Epoch 333/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3827 - val_loss: 1.4211\n",
      "Epoch 334/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3981 - val_loss: 1.4006\n",
      "Epoch 335/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4003 - val_loss: 1.4979\n",
      "Epoch 336/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3937 - val_loss: 1.4463\n",
      "Epoch 337/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3662 - val_loss: 1.4315\n",
      "Epoch 338/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3867 - val_loss: 1.5123\n",
      "Epoch 339/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3869 - val_loss: 1.4409\n",
      "Epoch 340/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3918 - val_loss: 1.4555\n",
      "Epoch 341/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3893 - val_loss: 1.4510\n",
      "Epoch 342/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3753 - val_loss: 1.4480\n",
      "Epoch 343/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3974 - val_loss: 1.4780\n",
      "Epoch 344/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3778 - val_loss: 1.3909\n",
      "Epoch 345/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3767 - val_loss: 1.4015\n",
      "Epoch 346/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3768 - val_loss: 1.4228\n",
      "Epoch 347/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3795 - val_loss: 1.3899\n",
      "Epoch 348/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3743 - val_loss: 1.3808\n",
      "Epoch 349/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3788 - val_loss: 1.4331\n",
      "Epoch 350/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3926 - val_loss: 1.3924\n",
      "Epoch 351/700\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.3703 - val_loss: 1.4411\n",
      "Epoch 352/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3829 - val_loss: 1.3943\n",
      "Epoch 353/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3748 - val_loss: 1.4700\n",
      "Epoch 354/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3829 - val_loss: 1.4022\n",
      "Epoch 355/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3740 - val_loss: 1.3999\n",
      "Epoch 356/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3821 - val_loss: 1.4449\n",
      "Epoch 357/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3824 - val_loss: 1.3696\n",
      "Epoch 358/700\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.3676 - val_loss: 1.4598\n",
      "Epoch 359/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3743 - val_loss: 1.4087\n",
      "Epoch 360/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3686 - val_loss: 1.4028\n",
      "Epoch 361/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3615 - val_loss: 1.4131\n",
      "Epoch 362/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3667 - val_loss: 1.3808\n",
      "Epoch 363/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3619 - val_loss: 1.4019\n",
      "Epoch 364/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3675 - val_loss: 1.3741\n",
      "Epoch 365/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3803 - val_loss: 1.4461\n",
      "Epoch 366/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3579 - val_loss: 1.3821\n",
      "Epoch 367/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3508 - val_loss: 1.4355\n",
      "Epoch 368/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3729 - val_loss: 1.4849\n",
      "Epoch 369/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3605 - val_loss: 1.3795\n",
      "Epoch 370/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3598 - val_loss: 1.3985\n",
      "Epoch 371/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3621 - val_loss: 1.5093\n",
      "Epoch 372/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3689 - val_loss: 1.4638\n",
      "Epoch 373/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3727 - val_loss: 1.4418\n",
      "Epoch 374/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3624 - val_loss: 1.4034\n",
      "Epoch 375/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3620 - val_loss: 1.3970\n",
      "Epoch 376/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3455 - val_loss: 1.3716\n",
      "Epoch 377/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3535 - val_loss: 1.3806\n",
      "Epoch 378/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3611 - val_loss: 1.3965\n",
      "Epoch 379/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3471 - val_loss: 1.4338\n",
      "Epoch 380/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3462 - val_loss: 1.4151\n",
      "Epoch 381/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3509 - val_loss: 1.3435\n",
      "Epoch 382/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3547 - val_loss: 1.3930\n",
      "Epoch 383/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3456 - val_loss: 1.3845\n",
      "Epoch 384/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3572 - val_loss: 1.4133\n",
      "Epoch 385/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3580 - val_loss: 1.4781\n",
      "Epoch 386/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3612 - val_loss: 1.4020\n",
      "Epoch 387/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3622 - val_loss: 1.4700\n",
      "Epoch 388/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3493 - val_loss: 1.3674\n",
      "Epoch 389/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3650 - val_loss: 1.3990\n",
      "Epoch 390/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3399 - val_loss: 1.4109\n",
      "Epoch 391/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3411 - val_loss: 1.4073\n",
      "Epoch 392/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3453 - val_loss: 1.4230\n",
      "Epoch 393/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3402 - val_loss: 1.3894\n",
      "Epoch 394/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3498 - val_loss: 1.3864\n",
      "Epoch 395/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3482 - val_loss: 1.3696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3587 - val_loss: 1.3530\n",
      "Epoch 397/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3451 - val_loss: 1.3655\n",
      "Epoch 398/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3473 - val_loss: 1.3500\n",
      "Epoch 399/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3411 - val_loss: 1.3726\n",
      "Epoch 400/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3459 - val_loss: 1.4568\n",
      "Epoch 401/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3457 - val_loss: 1.3764\n",
      "Epoch 402/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3446 - val_loss: 1.3596\n",
      "Epoch 403/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3402 - val_loss: 1.3954\n",
      "Epoch 404/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3333 - val_loss: 1.3985\n",
      "Epoch 405/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3400 - val_loss: 1.4017\n",
      "Epoch 406/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3481 - val_loss: 1.4010\n",
      "Epoch 407/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3435 - val_loss: 1.3964\n",
      "Epoch 408/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3328 - val_loss: 1.3747\n",
      "Epoch 409/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3339 - val_loss: 1.3415\n",
      "Epoch 410/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3352 - val_loss: 1.3652\n",
      "Epoch 411/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3441 - val_loss: 1.4099\n",
      "Epoch 412/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3305 - val_loss: 1.4179\n",
      "Epoch 413/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3364 - val_loss: 1.4088\n",
      "Epoch 414/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3276 - val_loss: 1.3743\n",
      "Epoch 415/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3242 - val_loss: 1.3511\n",
      "Epoch 416/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3323 - val_loss: 1.3609\n",
      "Epoch 417/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3289 - val_loss: 1.3443\n",
      "Epoch 418/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3384 - val_loss: 1.3729\n",
      "Epoch 419/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3533 - val_loss: 1.3538\n",
      "Epoch 420/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3138 - val_loss: 1.3833\n",
      "Epoch 421/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3339 - val_loss: 1.3634\n",
      "Epoch 422/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3267 - val_loss: 1.4103\n",
      "Epoch 423/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3296 - val_loss: 1.3543\n",
      "Epoch 424/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3347 - val_loss: 1.4022\n",
      "Epoch 425/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3232 - val_loss: 1.5038\n",
      "Epoch 426/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3355 - val_loss: 1.4020\n",
      "Epoch 427/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3098 - val_loss: 1.3978\n",
      "Epoch 428/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3376 - val_loss: 1.3198\n",
      "Epoch 429/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3178 - val_loss: 1.3414\n",
      "Epoch 430/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3272 - val_loss: 1.3416\n",
      "Epoch 431/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3175 - val_loss: 1.3925\n",
      "Epoch 432/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3211 - val_loss: 1.3965\n",
      "Epoch 433/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3356 - val_loss: 1.3780\n",
      "Epoch 434/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3265 - val_loss: 1.3585\n",
      "Epoch 435/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3278 - val_loss: 1.4057\n",
      "Epoch 436/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3247 - val_loss: 1.3797\n",
      "Epoch 437/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3303 - val_loss: 1.3685\n",
      "Epoch 438/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3127 - val_loss: 1.3701\n",
      "Epoch 439/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3206 - val_loss: 1.3729\n",
      "Epoch 440/700\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.3249 - val_loss: 1.3547\n",
      "Epoch 441/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3281 - val_loss: 1.4033\n",
      "Epoch 442/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3274 - val_loss: 1.4077\n",
      "Epoch 443/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3226 - val_loss: 1.3874\n",
      "Epoch 444/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3148 - val_loss: 1.3820\n",
      "Epoch 445/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3176 - val_loss: 1.3547\n",
      "Epoch 446/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3217 - val_loss: 1.3677\n",
      "Epoch 447/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3289 - val_loss: 1.3823\n",
      "Epoch 448/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3261 - val_loss: 1.3642\n",
      "Epoch 449/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3156 - val_loss: 1.3649\n",
      "Epoch 450/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3101 - val_loss: 1.3567\n",
      "Epoch 451/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3199 - val_loss: 1.3585\n",
      "Epoch 452/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3176 - val_loss: 1.3383\n",
      "Epoch 453/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3266 - val_loss: 1.3984\n",
      "Epoch 454/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3382 - val_loss: 1.4144\n",
      "Epoch 455/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3149 - val_loss: 1.3932\n",
      "Epoch 456/700\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.2939 - val_loss: 1.3817\n",
      "Epoch 457/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3202 - val_loss: 1.3473\n",
      "Epoch 458/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3225 - val_loss: 1.3709\n",
      "Epoch 459/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3109 - val_loss: 1.3698\n",
      "Epoch 460/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3016 - val_loss: 1.4089\n",
      "Epoch 461/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3150 - val_loss: 1.3530\n",
      "Epoch 462/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3002 - val_loss: 1.3458\n",
      "Epoch 463/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3128 - val_loss: 1.3614\n",
      "Epoch 464/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3086 - val_loss: 1.3785\n",
      "Epoch 465/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3234 - val_loss: 1.3805\n",
      "Epoch 466/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3228 - val_loss: 1.3729\n",
      "Epoch 467/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3000 - val_loss: 1.3403\n",
      "Epoch 468/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3132 - val_loss: 1.4039\n",
      "Epoch 469/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3108 - val_loss: 1.4257\n",
      "Epoch 470/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3078 - val_loss: 1.3570\n",
      "Epoch 471/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3088 - val_loss: 1.3763\n",
      "Epoch 472/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3136 - val_loss: 1.5594\n",
      "Epoch 473/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3056 - val_loss: 1.3415\n",
      "Epoch 474/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3114 - val_loss: 1.3366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3021 - val_loss: 1.3297\n",
      "Epoch 476/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3047 - val_loss: 1.3417\n",
      "Epoch 477/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2859 - val_loss: 1.3891\n",
      "Epoch 478/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3204 - val_loss: 1.3558\n",
      "Epoch 479/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3060 - val_loss: 1.3560\n",
      "Epoch 480/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2980 - val_loss: 1.3993\n",
      "Epoch 481/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3087 - val_loss: 1.4052\n",
      "Epoch 482/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2897 - val_loss: 1.3343\n",
      "Epoch 483/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3137 - val_loss: 1.3323\n",
      "Epoch 484/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3091 - val_loss: 1.4163\n",
      "Epoch 485/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3046 - val_loss: 1.3163\n",
      "Epoch 486/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2971 - val_loss: 1.3919\n",
      "Epoch 487/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3026 - val_loss: 1.3459\n",
      "Epoch 488/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2993 - val_loss: 1.3557\n",
      "Epoch 489/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3003 - val_loss: 1.3770\n",
      "Epoch 490/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3005 - val_loss: 1.3396\n",
      "Epoch 491/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2996 - val_loss: 1.3645\n",
      "Epoch 492/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3051 - val_loss: 1.3538\n",
      "Epoch 493/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3144 - val_loss: 1.3830\n",
      "Epoch 494/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2873 - val_loss: 1.3363\n",
      "Epoch 495/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2998 - val_loss: 1.3352\n",
      "Epoch 496/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2811 - val_loss: 1.3150\n",
      "Epoch 497/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2987 - val_loss: 1.3093\n",
      "Epoch 498/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2833 - val_loss: 1.3691\n",
      "Epoch 499/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3060 - val_loss: 1.4054\n",
      "Epoch 500/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3017 - val_loss: 1.3598\n",
      "Epoch 501/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2909 - val_loss: 1.3297\n",
      "Epoch 502/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2915 - val_loss: 1.3882\n",
      "Epoch 503/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3033 - val_loss: 1.3311\n",
      "Epoch 504/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2965 - val_loss: 1.4244\n",
      "Epoch 505/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2950 - val_loss: 1.3771\n",
      "Epoch 506/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2919 - val_loss: 1.3846\n",
      "Epoch 507/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3032 - val_loss: 1.3156\n",
      "Epoch 508/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2909 - val_loss: 1.3181\n",
      "Epoch 509/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2863 - val_loss: 1.3446\n",
      "Epoch 510/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2860 - val_loss: 1.3336\n",
      "Epoch 511/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2826 - val_loss: 1.3127\n",
      "Epoch 512/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2838 - val_loss: 1.3317\n",
      "Epoch 513/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2987 - val_loss: 1.3117\n",
      "Epoch 514/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2965 - val_loss: 1.3587\n",
      "Epoch 515/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2954 - val_loss: 1.3213\n",
      "Epoch 516/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2908 - val_loss: 1.3571\n",
      "Epoch 517/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2880 - val_loss: 1.3368\n",
      "Epoch 518/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2901 - val_loss: 1.3412\n",
      "Epoch 519/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2904 - val_loss: 1.3067\n",
      "Epoch 520/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2804 - val_loss: 1.3039\n",
      "Epoch 521/700\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.2846 - val_loss: 1.3741\n",
      "Epoch 522/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2916 - val_loss: 1.3597\n",
      "Epoch 523/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2816 - val_loss: 1.3183\n",
      "Epoch 524/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2887 - val_loss: 1.4004\n",
      "Epoch 525/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2773 - val_loss: 1.3112\n",
      "Epoch 526/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2840 - val_loss: 1.3085\n",
      "Epoch 527/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2843 - val_loss: 1.3350\n",
      "Epoch 528/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2863 - val_loss: 1.3149\n",
      "Epoch 529/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2763 - val_loss: 1.3731\n",
      "Epoch 530/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2998 - val_loss: 1.3434\n",
      "Epoch 531/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2934 - val_loss: 1.3305\n",
      "Epoch 532/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2907 - val_loss: 1.3375\n",
      "Epoch 533/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2810 - val_loss: 1.4045\n",
      "Epoch 534/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2784 - val_loss: 1.3329\n",
      "Epoch 535/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3041 - val_loss: 1.2955\n",
      "Epoch 536/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2836 - val_loss: 1.3160\n",
      "Epoch 537/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2741 - val_loss: 1.3636\n",
      "Epoch 538/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2836 - val_loss: 1.3715\n",
      "Epoch 539/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2730 - val_loss: 1.3506\n",
      "Epoch 540/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2925 - val_loss: 1.3183\n",
      "Epoch 541/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2916 - val_loss: 1.3288\n",
      "Epoch 542/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2758 - val_loss: 1.3416\n",
      "Epoch 543/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2810 - val_loss: 1.3383\n",
      "Epoch 544/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2774 - val_loss: 1.3147\n",
      "Epoch 545/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2790 - val_loss: 1.3545\n",
      "Epoch 546/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2839 - val_loss: 1.3767\n",
      "Epoch 547/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2862 - val_loss: 1.3552\n",
      "Epoch 548/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2883 - val_loss: 1.4225\n",
      "Epoch 549/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2721 - val_loss: 1.3039\n",
      "Epoch 550/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2712 - val_loss: 1.3263\n",
      "Epoch 551/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2856 - val_loss: 1.2951\n",
      "Epoch 552/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2858 - val_loss: 1.3695\n",
      "Epoch 553/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2748 - val_loss: 1.3205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2690 - val_loss: 1.3118\n",
      "Epoch 555/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2750 - val_loss: 1.3390\n",
      "Epoch 556/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2764 - val_loss: 1.3721\n",
      "Epoch 557/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2775 - val_loss: 1.2878\n",
      "Epoch 558/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2784 - val_loss: 1.3533\n",
      "Epoch 559/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2920 - val_loss: 1.3366\n",
      "Epoch 560/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2737 - val_loss: 1.3156\n",
      "Epoch 561/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2845 - val_loss: 1.2921\n",
      "Epoch 562/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2658 - val_loss: 1.3529\n",
      "Epoch 563/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2781 - val_loss: 1.3527\n",
      "Epoch 564/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2734 - val_loss: 1.3059\n",
      "Epoch 565/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2772 - val_loss: 1.3197\n",
      "Epoch 566/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2796 - val_loss: 1.3441\n",
      "Epoch 567/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2757 - val_loss: 1.3441\n",
      "Epoch 568/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2631 - val_loss: 1.3015\n",
      "Epoch 569/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2754 - val_loss: 1.3542\n",
      "Epoch 570/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2782 - val_loss: 1.3493\n",
      "Epoch 571/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2719 - val_loss: 1.3799\n",
      "Epoch 572/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2607 - val_loss: 1.2948\n",
      "Epoch 573/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2709 - val_loss: 1.3162\n",
      "Epoch 574/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2667 - val_loss: 1.3281\n",
      "Epoch 575/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2733 - val_loss: 1.3659\n",
      "Epoch 576/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2667 - val_loss: 1.3165\n",
      "Epoch 577/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2677 - val_loss: 1.3478\n",
      "Epoch 578/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2778 - val_loss: 1.3578\n",
      "Epoch 579/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2693 - val_loss: 1.3041\n",
      "Epoch 580/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2598 - val_loss: 1.3290\n",
      "Epoch 581/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2694 - val_loss: 1.3988\n",
      "Epoch 582/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2673 - val_loss: 1.2953\n",
      "Epoch 583/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2627 - val_loss: 1.3306\n",
      "Epoch 584/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2543 - val_loss: 1.2895\n",
      "Epoch 585/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2734 - val_loss: 1.3272\n",
      "Epoch 586/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2766 - val_loss: 1.3413\n",
      "Epoch 587/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2693 - val_loss: 1.3280\n",
      "Epoch 588/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2729 - val_loss: 1.3298\n",
      "Epoch 589/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2686 - val_loss: 1.3268\n",
      "Epoch 590/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2672 - val_loss: 1.4055\n",
      "Epoch 591/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2583 - val_loss: 1.2932\n",
      "Epoch 592/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2557 - val_loss: 1.3125\n",
      "Epoch 593/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2529 - val_loss: 1.3313\n",
      "Epoch 594/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2562 - val_loss: 1.2803\n",
      "Epoch 595/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2539 - val_loss: 1.3549\n",
      "Epoch 596/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2563 - val_loss: 1.3261\n",
      "Epoch 597/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2661 - val_loss: 1.3933\n",
      "Epoch 598/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2642 - val_loss: 1.3039\n",
      "Epoch 599/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2582 - val_loss: 1.3471\n",
      "Epoch 600/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2713 - val_loss: 1.3210\n",
      "Epoch 601/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2600 - val_loss: 1.3121\n",
      "Epoch 602/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2685 - val_loss: 1.3098\n",
      "Epoch 603/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2610 - val_loss: 1.3394\n",
      "Epoch 604/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2599 - val_loss: 1.3207\n",
      "Epoch 605/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2640 - val_loss: 1.2929\n",
      "Epoch 606/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2683 - val_loss: 1.2915\n",
      "Epoch 607/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2518 - val_loss: 1.3383\n",
      "Epoch 608/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2563 - val_loss: 1.3494\n",
      "Epoch 609/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2608 - val_loss: 1.3115\n",
      "Epoch 610/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2556 - val_loss: 1.3190\n",
      "Epoch 611/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2663 - val_loss: 1.3099\n",
      "Epoch 612/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2483 - val_loss: 1.3530\n",
      "Epoch 613/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2533 - val_loss: 1.3120\n",
      "Epoch 614/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2657 - val_loss: 1.3931\n",
      "Epoch 615/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2597 - val_loss: 1.2746\n",
      "Epoch 616/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2539 - val_loss: 1.3071\n",
      "Epoch 617/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2525 - val_loss: 1.3011\n",
      "Epoch 618/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2596 - val_loss: 1.3522\n",
      "Epoch 619/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2615 - val_loss: 1.3131\n",
      "Epoch 620/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2728 - val_loss: 1.3038\n",
      "Epoch 621/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2435 - val_loss: 1.3859\n",
      "Epoch 622/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2635 - val_loss: 1.3292\n",
      "Epoch 623/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2551 - val_loss: 1.3092\n",
      "Epoch 624/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2562 - val_loss: 1.2603\n",
      "Epoch 625/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2508 - val_loss: 1.2888\n",
      "Epoch 626/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2596 - val_loss: 1.3640\n",
      "Epoch 627/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2592 - val_loss: 1.2863\n",
      "Epoch 628/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2592 - val_loss: 1.3568\n",
      "Epoch 629/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2528 - val_loss: 1.3412\n",
      "Epoch 630/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2785 - val_loss: 1.3206\n",
      "Epoch 631/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2580 - val_loss: 1.2953\n",
      "Epoch 632/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2505 - val_loss: 1.3726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2614 - val_loss: 1.3536\n",
      "Epoch 634/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2489 - val_loss: 1.2946\n",
      "Epoch 635/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2528 - val_loss: 1.3073\n",
      "Epoch 636/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2494 - val_loss: 1.2960\n",
      "Epoch 637/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2454 - val_loss: 1.2648\n",
      "Epoch 638/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2574 - val_loss: 1.3805\n",
      "Epoch 639/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2406 - val_loss: 1.3080\n",
      "Epoch 640/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2549 - val_loss: 1.3101\n",
      "Epoch 641/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2553 - val_loss: 1.3011\n",
      "Epoch 642/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2567 - val_loss: 1.2742\n",
      "Epoch 643/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2456 - val_loss: 1.2938\n",
      "Epoch 644/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2481 - val_loss: 1.3188\n",
      "Epoch 645/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2524 - val_loss: 1.3924\n",
      "Epoch 646/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2483 - val_loss: 1.3123\n",
      "Epoch 647/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2451 - val_loss: 1.3082\n",
      "Epoch 648/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2502 - val_loss: 1.2969\n",
      "Epoch 649/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2444 - val_loss: 1.2854\n",
      "Epoch 650/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2602 - val_loss: 1.3265\n",
      "Epoch 651/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2463 - val_loss: 1.3122\n",
      "Epoch 652/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2409 - val_loss: 1.3445\n",
      "Epoch 653/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2409 - val_loss: 1.2725\n",
      "Epoch 654/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2362 - val_loss: 1.2780\n",
      "Epoch 655/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2491 - val_loss: 1.3109\n",
      "Epoch 656/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2462 - val_loss: 1.3015\n",
      "Epoch 657/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2497 - val_loss: 1.2846\n",
      "Epoch 658/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2472 - val_loss: 1.3333\n",
      "Epoch 659/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2426 - val_loss: 1.2969\n",
      "Epoch 660/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2443 - val_loss: 1.2823\n",
      "Epoch 661/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2538 - val_loss: 1.3420\n",
      "Epoch 662/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2468 - val_loss: 1.3702\n",
      "Epoch 663/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2315 - val_loss: 1.3482\n",
      "Epoch 664/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2400 - val_loss: 1.3039\n",
      "Epoch 665/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2390 - val_loss: 1.2794\n",
      "Epoch 666/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2418 - val_loss: 1.3086\n",
      "Epoch 667/700\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.2372 - val_loss: 1.3541\n",
      "Epoch 668/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2486 - val_loss: 1.2969\n",
      "Epoch 669/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2450 - val_loss: 1.3393\n",
      "Epoch 670/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2432 - val_loss: 1.2958\n",
      "Epoch 671/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2490 - val_loss: 1.3169\n",
      "Epoch 672/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2411 - val_loss: 1.3132\n",
      "Epoch 673/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2342 - val_loss: 1.3249\n",
      "Epoch 674/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2492 - val_loss: 1.3049\n",
      "Epoch 675/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2354 - val_loss: 1.3306\n",
      "Epoch 676/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2354 - val_loss: 1.3034\n",
      "Epoch 677/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2388 - val_loss: 1.2647\n",
      "Epoch 678/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2331 - val_loss: 1.3269\n",
      "Epoch 679/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2323 - val_loss: 1.3316\n",
      "Epoch 680/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2519 - val_loss: 1.3174\n",
      "Epoch 681/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2408 - val_loss: 1.3040\n",
      "Epoch 682/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2377 - val_loss: 1.3512\n",
      "Epoch 683/700\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.2372 - val_loss: 1.2829\n",
      "Epoch 684/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2372 - val_loss: 1.2909\n",
      "Epoch 685/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2414 - val_loss: 1.3338\n",
      "Epoch 686/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2279 - val_loss: 1.3065\n",
      "Epoch 687/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2300 - val_loss: 1.2885\n",
      "Epoch 688/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2256 - val_loss: 1.3026\n",
      "Epoch 689/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2393 - val_loss: 1.3204\n",
      "Epoch 690/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2291 - val_loss: 1.3099\n",
      "Epoch 691/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2359 - val_loss: 1.4208\n",
      "Epoch 692/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2382 - val_loss: 1.3233\n",
      "Epoch 693/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2260 - val_loss: 1.3179\n",
      "Epoch 694/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2446 - val_loss: 1.3147\n",
      "Epoch 695/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2522 - val_loss: 1.3255\n",
      "Epoch 696/700\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2389 - val_loss: 1.2874\n",
      "Epoch 697/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2393 - val_loss: 1.3804\n",
      "Epoch 698/700\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2343 - val_loss: 1.2922\n",
      "Epoch 699/700\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2402 - val_loss: 1.3382\n",
      "Epoch 700/700\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2311 - val_loss: 1.3208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3207925168482997\n",
      "0.9748507126162422\n",
      "Epoch 1/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 6.8026 - val_loss: 4.1201\n",
      "Epoch 2/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 4.5721 - val_loss: 4.3288\n",
      "Epoch 3/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 4.3730 - val_loss: 3.9897\n",
      "Epoch 4/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 3.9256 - val_loss: 3.3224\n",
      "Epoch 5/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 3.2974 - val_loss: 3.0041\n",
      "Epoch 6/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 3.0032 - val_loss: 2.9008\n",
      "Epoch 7/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.8036 - val_loss: 2.9395\n",
      "Epoch 8/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.7092 - val_loss: 2.5990\n",
      "Epoch 9/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.6324 - val_loss: 2.8369\n",
      "Epoch 10/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.5771 - val_loss: 2.4335\n",
      "Epoch 11/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.5302 - val_loss: 2.3690\n",
      "Epoch 12/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.4831 - val_loss: 2.5418\n",
      "Epoch 13/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.4729 - val_loss: 2.3340\n",
      "Epoch 14/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.4211 - val_loss: 2.4632\n",
      "Epoch 15/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.4176 - val_loss: 2.6780\n",
      "Epoch 16/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.3672 - val_loss: 2.3437\n",
      "Epoch 17/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.3486 - val_loss: 2.5028\n",
      "Epoch 18/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.3472 - val_loss: 2.4011\n",
      "Epoch 19/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.3001 - val_loss: 2.2319\n",
      "Epoch 20/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.2799 - val_loss: 2.5713\n",
      "Epoch 21/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.2671 - val_loss: 2.1327\n",
      "Epoch 22/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.2228 - val_loss: 2.1442\n",
      "Epoch 23/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.2311 - val_loss: 2.1755\n",
      "Epoch 24/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.2107 - val_loss: 2.2349\n",
      "Epoch 25/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.2086 - val_loss: 2.2304\n",
      "Epoch 26/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1796 - val_loss: 2.0951\n",
      "Epoch 27/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1600 - val_loss: 2.2076\n",
      "Epoch 28/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1583 - val_loss: 2.0669\n",
      "Epoch 29/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1416 - val_loss: 2.1709\n",
      "Epoch 30/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.1271 - val_loss: 2.0948\n",
      "Epoch 31/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1353 - val_loss: 1.9700\n",
      "Epoch 32/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.1137 - val_loss: 2.0605\n",
      "Epoch 33/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1059 - val_loss: 2.1827\n",
      "Epoch 34/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0955 - val_loss: 2.2967\n",
      "Epoch 35/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.1007 - val_loss: 2.1003\n",
      "Epoch 36/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0839 - val_loss: 1.9811\n",
      "Epoch 37/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0801 - val_loss: 2.0482\n",
      "Epoch 38/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0751 - val_loss: 2.0492\n",
      "Epoch 39/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0729 - val_loss: 1.9847\n",
      "Epoch 40/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0511 - val_loss: 2.2052\n",
      "Epoch 41/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0700 - val_loss: 2.0626\n",
      "Epoch 42/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0544 - val_loss: 2.0073\n",
      "Epoch 43/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0473 - val_loss: 1.9709\n",
      "Epoch 44/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0382 - val_loss: 2.1357\n",
      "Epoch 45/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0273 - val_loss: 2.0939\n",
      "Epoch 46/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 2.0324 - val_loss: 2.0849\n",
      "Epoch 47/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0233 - val_loss: 2.0248\n",
      "Epoch 48/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0227 - val_loss: 2.1159\n",
      "Epoch 49/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0162 - val_loss: 1.9566\n",
      "Epoch 50/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0115 - val_loss: 2.0515\n",
      "Epoch 51/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 2.0166 - val_loss: 1.9355\n",
      "Epoch 52/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 2.0055 - val_loss: 1.9701\n",
      "Epoch 53/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9995 - val_loss: 2.0251\n",
      "Epoch 54/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9999 - val_loss: 1.9357\n",
      "Epoch 55/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9908 - val_loss: 2.0623\n",
      "Epoch 56/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9866 - val_loss: 1.9556\n",
      "Epoch 57/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9947 - val_loss: 1.9625\n",
      "Epoch 58/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9741 - val_loss: 1.9765\n",
      "Epoch 59/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9774 - val_loss: 1.9426\n",
      "Epoch 60/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9804 - val_loss: 1.9068\n",
      "Epoch 61/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9562 - val_loss: 1.9648\n",
      "Epoch 62/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9653 - val_loss: 1.9794\n",
      "Epoch 63/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9548 - val_loss: 1.9755\n",
      "Epoch 64/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9552 - val_loss: 1.9666\n",
      "Epoch 65/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9526 - val_loss: 1.9313\n",
      "Epoch 66/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9531 - val_loss: 2.0017\n",
      "Epoch 67/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9521 - val_loss: 1.9246\n",
      "Epoch 68/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9394 - val_loss: 2.0491\n",
      "Epoch 69/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9366 - val_loss: 1.8818\n",
      "Epoch 70/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9304 - val_loss: 1.8830\n",
      "Epoch 71/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9384 - val_loss: 1.9608\n",
      "Epoch 72/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9233 - val_loss: 1.8777\n",
      "Epoch 73/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9268 - val_loss: 1.9026\n",
      "Epoch 74/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9253 - val_loss: 1.9588\n",
      "Epoch 75/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9207 - val_loss: 1.8651\n",
      "Epoch 76/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9184 - val_loss: 1.8753\n",
      "Epoch 77/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9089 - val_loss: 1.9930\n",
      "Epoch 78/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9011 - val_loss: 1.9286\n",
      "Epoch 79/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.9035 - val_loss: 1.9431\n",
      "Epoch 80/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.9034 - val_loss: 1.8643\n",
      "Epoch 81/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.9063 - val_loss: 1.9685\n",
      "Epoch 82/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8983 - val_loss: 1.8605\n",
      "Epoch 83/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8966 - val_loss: 1.9031\n",
      "Epoch 84/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8939 - val_loss: 1.9499\n",
      "Epoch 85/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8932 - val_loss: 1.8293\n",
      "Epoch 86/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8930 - val_loss: 1.8699\n",
      "Epoch 87/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8856 - val_loss: 2.0556\n",
      "Epoch 88/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8888 - val_loss: 1.8323\n",
      "Epoch 89/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8835 - val_loss: 1.8535\n",
      "Epoch 90/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8822 - val_loss: 1.7908\n",
      "Epoch 91/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8761 - val_loss: 1.8957\n",
      "Epoch 92/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8732 - val_loss: 1.7955\n",
      "Epoch 93/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8591 - val_loss: 1.8982\n",
      "Epoch 94/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8707 - val_loss: 1.8981\n",
      "Epoch 95/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8672 - val_loss: 1.8419\n",
      "Epoch 96/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8540 - val_loss: 1.9318\n",
      "Epoch 97/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8582 - val_loss: 1.8364\n",
      "Epoch 98/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8628 - val_loss: 1.8594\n",
      "Epoch 99/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8499 - val_loss: 1.8702\n",
      "Epoch 100/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8568 - val_loss: 2.0470\n",
      "Epoch 101/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8555 - val_loss: 1.8398\n",
      "Epoch 102/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8529 - val_loss: 1.8649\n",
      "Epoch 103/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8414 - val_loss: 1.8592\n",
      "Epoch 104/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8591 - val_loss: 1.7979\n",
      "Epoch 105/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8462 - val_loss: 1.8331\n",
      "Epoch 106/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8368 - val_loss: 1.8243\n",
      "Epoch 107/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8386 - val_loss: 1.8315\n",
      "Epoch 108/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8309 - val_loss: 1.8695\n",
      "Epoch 109/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8347 - val_loss: 1.8234\n",
      "Epoch 110/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8258 - val_loss: 1.8643\n",
      "Epoch 111/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8277 - val_loss: 1.7992\n",
      "Epoch 112/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8321 - val_loss: 1.8062\n",
      "Epoch 113/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8189 - val_loss: 1.7770\n",
      "Epoch 114/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8197 - val_loss: 1.8279\n",
      "Epoch 115/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8191 - val_loss: 1.8324\n",
      "Epoch 116/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8251 - val_loss: 1.8542\n",
      "Epoch 117/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8308 - val_loss: 1.8615\n",
      "Epoch 118/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8180 - val_loss: 1.8830\n",
      "Epoch 119/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8221 - val_loss: 1.8180\n",
      "Epoch 120/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8185 - val_loss: 1.8381\n",
      "Epoch 121/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8115 - val_loss: 1.8296\n",
      "Epoch 122/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8174 - val_loss: 1.7698\n",
      "Epoch 123/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.8206 - val_loss: 1.7604\n",
      "Epoch 124/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8120 - val_loss: 1.8018\n",
      "Epoch 125/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8077 - val_loss: 1.8527\n",
      "Epoch 126/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8140 - val_loss: 1.8339\n",
      "Epoch 127/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.8046 - val_loss: 1.7897\n",
      "Epoch 128/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8013 - val_loss: 1.9477\n",
      "Epoch 129/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8018 - val_loss: 1.7894\n",
      "Epoch 130/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8076 - val_loss: 1.7925\n",
      "Epoch 131/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7952 - val_loss: 1.7730\n",
      "Epoch 132/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8010 - val_loss: 1.8471\n",
      "Epoch 133/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7984 - val_loss: 1.9395\n",
      "Epoch 134/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7900 - val_loss: 1.7960\n",
      "Epoch 135/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.8061 - val_loss: 1.7977\n",
      "Epoch 136/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7935 - val_loss: 1.8915\n",
      "Epoch 137/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7851 - val_loss: 1.7780\n",
      "Epoch 138/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7837 - val_loss: 1.9350\n",
      "Epoch 139/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7958 - val_loss: 1.8086\n",
      "Epoch 140/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7822 - val_loss: 1.7927\n",
      "Epoch 141/900\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.7772 - val_loss: 1.7650\n",
      "Epoch 142/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7836 - val_loss: 1.7619\n",
      "Epoch 143/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7809 - val_loss: 1.8329\n",
      "Epoch 144/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7863 - val_loss: 1.8289\n",
      "Epoch 145/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7819 - val_loss: 1.8013\n",
      "Epoch 146/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7864 - val_loss: 1.8934\n",
      "Epoch 147/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7713 - val_loss: 1.7589\n",
      "Epoch 148/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7753 - val_loss: 1.8174\n",
      "Epoch 149/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7849 - val_loss: 1.7490\n",
      "Epoch 150/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7774 - val_loss: 1.7349\n",
      "Epoch 151/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7747 - val_loss: 1.7699\n",
      "Epoch 152/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7758 - val_loss: 1.8023\n",
      "Epoch 153/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7611 - val_loss: 1.7080\n",
      "Epoch 154/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7708 - val_loss: 1.7658\n",
      "Epoch 155/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7696 - val_loss: 1.8280\n",
      "Epoch 156/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7513 - val_loss: 1.7284\n",
      "Epoch 157/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7655 - val_loss: 1.7599\n",
      "Epoch 158/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7649 - val_loss: 1.7758\n",
      "Epoch 159/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7606 - val_loss: 1.7705\n",
      "Epoch 160/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7682 - val_loss: 1.8255\n",
      "Epoch 161/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7520 - val_loss: 1.7299\n",
      "Epoch 162/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7571 - val_loss: 1.7692\n",
      "Epoch 163/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7558 - val_loss: 1.7533\n",
      "Epoch 164/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7662 - val_loss: 1.7880\n",
      "Epoch 165/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7598 - val_loss: 1.7639\n",
      "Epoch 166/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7472 - val_loss: 1.7778\n",
      "Epoch 167/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7611 - val_loss: 1.7353\n",
      "Epoch 168/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7572 - val_loss: 1.8143\n",
      "Epoch 169/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7652 - val_loss: 1.7971\n",
      "Epoch 170/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7566 - val_loss: 1.7742\n",
      "Epoch 171/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7554 - val_loss: 1.7552\n",
      "Epoch 172/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7493 - val_loss: 1.8689\n",
      "Epoch 173/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7374 - val_loss: 1.7399\n",
      "Epoch 174/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7456 - val_loss: 1.7732\n",
      "Epoch 175/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7421 - val_loss: 1.7777\n",
      "Epoch 176/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7467 - val_loss: 1.6949\n",
      "Epoch 177/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7444 - val_loss: 1.7381\n",
      "Epoch 178/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7394 - val_loss: 1.8969\n",
      "Epoch 179/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7449 - val_loss: 1.8112\n",
      "Epoch 180/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7367 - val_loss: 1.7435\n",
      "Epoch 181/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7348 - val_loss: 1.7790\n",
      "Epoch 182/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7351 - val_loss: 1.7158\n",
      "Epoch 183/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7379 - val_loss: 1.9443\n",
      "Epoch 184/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7286 - val_loss: 1.7644\n",
      "Epoch 185/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7348 - val_loss: 1.6951\n",
      "Epoch 186/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7320 - val_loss: 1.7697\n",
      "Epoch 187/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7295 - val_loss: 1.7785\n",
      "Epoch 188/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7347 - val_loss: 1.6907\n",
      "Epoch 189/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7290 - val_loss: 1.7431\n",
      "Epoch 190/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7278 - val_loss: 1.7860\n",
      "Epoch 191/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7313 - val_loss: 1.7736\n",
      "Epoch 192/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7304 - val_loss: 1.7958\n",
      "Epoch 193/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7248 - val_loss: 1.7907\n",
      "Epoch 194/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7275 - val_loss: 1.7034\n",
      "Epoch 195/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7220 - val_loss: 1.7438\n",
      "Epoch 196/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7289 - val_loss: 1.6758\n",
      "Epoch 197/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7197 - val_loss: 1.7523\n",
      "Epoch 198/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7245 - val_loss: 1.7566\n",
      "Epoch 199/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7194 - val_loss: 1.8214\n",
      "Epoch 200/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7156 - val_loss: 1.7956\n",
      "Epoch 201/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.7251 - val_loss: 1.8625\n",
      "Epoch 202/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7290 - val_loss: 1.7445\n",
      "Epoch 203/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7163 - val_loss: 1.7158\n",
      "Epoch 204/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7185 - val_loss: 1.7130\n",
      "Epoch 205/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7157 - val_loss: 1.7316\n",
      "Epoch 206/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7116 - val_loss: 1.6962\n",
      "Epoch 207/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7209 - val_loss: 1.7256\n",
      "Epoch 208/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7195 - val_loss: 1.7355\n",
      "Epoch 209/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7165 - val_loss: 1.7563\n",
      "Epoch 210/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7197 - val_loss: 1.7586\n",
      "Epoch 211/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7164 - val_loss: 1.7279\n",
      "Epoch 212/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7037 - val_loss: 1.7074\n",
      "Epoch 213/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7132 - val_loss: 1.6876\n",
      "Epoch 214/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7041 - val_loss: 1.8162\n",
      "Epoch 215/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7060 - val_loss: 1.7585\n",
      "Epoch 216/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.7122 - val_loss: 1.6962\n",
      "Epoch 217/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7109 - val_loss: 1.7837\n",
      "Epoch 218/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7150 - val_loss: 1.7973\n",
      "Epoch 219/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7055 - val_loss: 1.7297\n",
      "Epoch 220/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7103 - val_loss: 1.6792\n",
      "Epoch 221/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6950 - val_loss: 1.7253\n",
      "Epoch 222/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6990 - val_loss: 1.6756\n",
      "Epoch 223/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6994 - val_loss: 1.7707\n",
      "Epoch 224/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7013 - val_loss: 1.7086\n",
      "Epoch 225/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6958 - val_loss: 1.7562\n",
      "Epoch 226/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6949 - val_loss: 1.7903\n",
      "Epoch 227/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6963 - val_loss: 1.7312\n",
      "Epoch 228/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7017 - val_loss: 1.7152\n",
      "Epoch 229/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6957 - val_loss: 1.6503\n",
      "Epoch 230/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6975 - val_loss: 1.6761\n",
      "Epoch 231/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7081 - val_loss: 1.7546\n",
      "Epoch 232/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6960 - val_loss: 1.7048\n",
      "Epoch 233/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6990 - val_loss: 1.7170\n",
      "Epoch 234/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6925 - val_loss: 1.8354\n",
      "Epoch 235/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7010 - val_loss: 1.6664\n",
      "Epoch 236/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6939 - val_loss: 1.7856\n",
      "Epoch 237/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6943 - val_loss: 1.7382\n",
      "Epoch 238/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7000 - val_loss: 1.7167\n",
      "Epoch 239/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.7023 - val_loss: 1.7465\n",
      "Epoch 240/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6917 - val_loss: 1.7459\n",
      "Epoch 241/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6972 - val_loss: 1.7310\n",
      "Epoch 242/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6909 - val_loss: 1.7647\n",
      "Epoch 243/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6892 - val_loss: 1.7385\n",
      "Epoch 244/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6881 - val_loss: 1.7402\n",
      "Epoch 245/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6884 - val_loss: 1.7122\n",
      "Epoch 246/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6992 - val_loss: 1.7594\n",
      "Epoch 247/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6840 - val_loss: 1.6718\n",
      "Epoch 248/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6911 - val_loss: 1.6296\n",
      "Epoch 249/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6963 - val_loss: 1.7060\n",
      "Epoch 250/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6944 - val_loss: 1.7391\n",
      "Epoch 251/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6851 - val_loss: 1.6922\n",
      "Epoch 252/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6858 - val_loss: 1.6766\n",
      "Epoch 253/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6914 - val_loss: 1.7469\n",
      "Epoch 254/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6892 - val_loss: 1.7532\n",
      "Epoch 255/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6793 - val_loss: 1.7984\n",
      "Epoch 256/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6918 - val_loss: 1.8066\n",
      "Epoch 257/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6763 - val_loss: 1.6568\n",
      "Epoch 258/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6831 - val_loss: 1.6903\n",
      "Epoch 259/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6844 - val_loss: 1.7395\n",
      "Epoch 260/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6775 - val_loss: 1.6697\n",
      "Epoch 261/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6786 - val_loss: 1.7420\n",
      "Epoch 262/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6776 - val_loss: 1.6650\n",
      "Epoch 263/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6843 - val_loss: 1.6659\n",
      "Epoch 264/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6801 - val_loss: 1.6919\n",
      "Epoch 265/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6781 - val_loss: 1.6850\n",
      "Epoch 266/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6730 - val_loss: 1.7358\n",
      "Epoch 267/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6747 - val_loss: 1.6954\n",
      "Epoch 268/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6817 - val_loss: 1.6587\n",
      "Epoch 269/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6739 - val_loss: 1.7648\n",
      "Epoch 270/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6725 - val_loss: 1.6280\n",
      "Epoch 271/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6721 - val_loss: 1.6472\n",
      "Epoch 272/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6727 - val_loss: 1.6268\n",
      "Epoch 273/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6752 - val_loss: 1.7085\n",
      "Epoch 274/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6733 - val_loss: 1.6879\n",
      "Epoch 275/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6871 - val_loss: 1.6778\n",
      "Epoch 276/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6748 - val_loss: 1.6460\n",
      "Epoch 277/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6749 - val_loss: 1.7668\n",
      "Epoch 278/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6750 - val_loss: 1.7322\n",
      "Epoch 279/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6676 - val_loss: 1.6937\n",
      "Epoch 280/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6701 - val_loss: 1.6814\n",
      "Epoch 281/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6685 - val_loss: 1.7512\n",
      "Epoch 282/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6760 - val_loss: 1.6513\n",
      "Epoch 283/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6658 - val_loss: 1.6700\n",
      "Epoch 284/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6677 - val_loss: 1.6784\n",
      "Epoch 285/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6725 - val_loss: 1.6662\n",
      "Epoch 286/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6705 - val_loss: 1.7043\n",
      "Epoch 287/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6677 - val_loss: 1.6310\n",
      "Epoch 288/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6686 - val_loss: 1.6568\n",
      "Epoch 289/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6665 - val_loss: 1.7236\n",
      "Epoch 290/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6631 - val_loss: 1.6337\n",
      "Epoch 291/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6669 - val_loss: 1.7269\n",
      "Epoch 292/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6669 - val_loss: 1.6988\n",
      "Epoch 293/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6675 - val_loss: 1.7531\n",
      "Epoch 294/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6651 - val_loss: 1.7393\n",
      "Epoch 295/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6681 - val_loss: 1.6632\n",
      "Epoch 296/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6599 - val_loss: 1.6989\n",
      "Epoch 297/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6668 - val_loss: 1.6890\n",
      "Epoch 298/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6668 - val_loss: 1.7830\n",
      "Epoch 299/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6729 - val_loss: 1.6354\n",
      "Epoch 300/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6635 - val_loss: 1.6730\n",
      "Epoch 301/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6621 - val_loss: 1.7103\n",
      "Epoch 302/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6593 - val_loss: 1.6177\n",
      "Epoch 303/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6526 - val_loss: 1.6847\n",
      "Epoch 304/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6619 - val_loss: 1.6692\n",
      "Epoch 305/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6650 - val_loss: 1.6823\n",
      "Epoch 306/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6646 - val_loss: 1.6356\n",
      "Epoch 307/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6668 - val_loss: 1.6419\n",
      "Epoch 308/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6552 - val_loss: 1.6569\n",
      "Epoch 309/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6621 - val_loss: 1.7385\n",
      "Epoch 310/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6584 - val_loss: 1.7349\n",
      "Epoch 311/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6647 - val_loss: 1.7617\n",
      "Epoch 312/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6511 - val_loss: 1.6569\n",
      "Epoch 313/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6577 - val_loss: 1.6589\n",
      "Epoch 314/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6591 - val_loss: 1.6253\n",
      "Epoch 315/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6557 - val_loss: 1.6790\n",
      "Epoch 316/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6591 - val_loss: 1.7057\n",
      "Epoch 317/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6538 - val_loss: 1.6899\n",
      "Epoch 318/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6533 - val_loss: 1.6869\n",
      "Epoch 319/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6516 - val_loss: 1.6922\n",
      "Epoch 320/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6527 - val_loss: 1.7280\n",
      "Epoch 321/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6632 - val_loss: 1.8409\n",
      "Epoch 322/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6511 - val_loss: 1.6280\n",
      "Epoch 323/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6555 - val_loss: 1.6959\n",
      "Epoch 324/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6540 - val_loss: 1.6416\n",
      "Epoch 325/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6521 - val_loss: 1.6660\n",
      "Epoch 326/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6482 - val_loss: 1.6646\n",
      "Epoch 327/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6517 - val_loss: 1.6774\n",
      "Epoch 328/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6558 - val_loss: 1.6599\n",
      "Epoch 329/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6493 - val_loss: 1.6536\n",
      "Epoch 330/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6478 - val_loss: 1.6630\n",
      "Epoch 331/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6495 - val_loss: 1.6474\n",
      "Epoch 332/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6473 - val_loss: 1.6814\n",
      "Epoch 333/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6403 - val_loss: 1.6597\n",
      "Epoch 334/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6525 - val_loss: 1.6776\n",
      "Epoch 335/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6470 - val_loss: 1.6589\n",
      "Epoch 336/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6500 - val_loss: 1.6345\n",
      "Epoch 337/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6369 - val_loss: 1.6549\n",
      "Epoch 338/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6424 - val_loss: 1.6422\n",
      "Epoch 339/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6498 - val_loss: 1.6721\n",
      "Epoch 340/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6468 - val_loss: 1.6805\n",
      "Epoch 341/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6488 - val_loss: 1.6468\n",
      "Epoch 342/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6461 - val_loss: 1.6902\n",
      "Epoch 343/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6360 - val_loss: 1.6544\n",
      "Epoch 344/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6415 - val_loss: 1.6710\n",
      "Epoch 345/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6466 - val_loss: 1.7006\n",
      "Epoch 346/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6412 - val_loss: 1.7280\n",
      "Epoch 347/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6431 - val_loss: 1.6299\n",
      "Epoch 348/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6455 - val_loss: 1.6592\n",
      "Epoch 349/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6475 - val_loss: 1.6246\n",
      "Epoch 350/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6451 - val_loss: 1.6963\n",
      "Epoch 351/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6338 - val_loss: 1.6373\n",
      "Epoch 352/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6484 - val_loss: 1.6660\n",
      "Epoch 353/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6464 - val_loss: 1.7151\n",
      "Epoch 354/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6403 - val_loss: 1.6209\n",
      "Epoch 355/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6409 - val_loss: 1.7786\n",
      "Epoch 356/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6462 - val_loss: 1.6376\n",
      "Epoch 357/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6391 - val_loss: 1.6954\n",
      "Epoch 358/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6351 - val_loss: 1.7408\n",
      "Epoch 359/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6430 - val_loss: 1.6540\n",
      "Epoch 360/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6334 - val_loss: 1.6057\n",
      "Epoch 361/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6345 - val_loss: 1.6581\n",
      "Epoch 362/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6274 - val_loss: 1.6930\n",
      "Epoch 363/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6337 - val_loss: 1.6609\n",
      "Epoch 364/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6392 - val_loss: 1.6540\n",
      "Epoch 365/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6383 - val_loss: 1.5980\n",
      "Epoch 366/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6384 - val_loss: 1.6755\n",
      "Epoch 367/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6381 - val_loss: 1.6511\n",
      "Epoch 368/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6353 - val_loss: 1.6866\n",
      "Epoch 369/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6339 - val_loss: 1.6231\n",
      "Epoch 370/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6423 - val_loss: 1.6159\n",
      "Epoch 371/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6310 - val_loss: 1.6502\n",
      "Epoch 372/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6314 - val_loss: 1.6404\n",
      "Epoch 373/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6395 - val_loss: 1.6831\n",
      "Epoch 374/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6336 - val_loss: 1.6346\n",
      "Epoch 375/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6360 - val_loss: 1.6674\n",
      "Epoch 376/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6330 - val_loss: 1.6206\n",
      "Epoch 377/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6383 - val_loss: 1.6454\n",
      "Epoch 378/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6305 - val_loss: 1.6522\n",
      "Epoch 379/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6277 - val_loss: 1.6338\n",
      "Epoch 380/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6293 - val_loss: 1.6093\n",
      "Epoch 381/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6250 - val_loss: 1.6440\n",
      "Epoch 382/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6328 - val_loss: 1.6032\n",
      "Epoch 383/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6315 - val_loss: 1.6498\n",
      "Epoch 384/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6352 - val_loss: 1.7852\n",
      "Epoch 385/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6268 - val_loss: 1.6229\n",
      "Epoch 386/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6302 - val_loss: 1.6201\n",
      "Epoch 387/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6354 - val_loss: 1.6858\n",
      "Epoch 388/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6249 - val_loss: 1.6742\n",
      "Epoch 389/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6302 - val_loss: 1.6039\n",
      "Epoch 390/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6268 - val_loss: 1.6062\n",
      "Epoch 391/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6191 - val_loss: 1.6933\n",
      "Epoch 392/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6248 - val_loss: 1.6850\n",
      "Epoch 393/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6213 - val_loss: 1.6437\n",
      "Epoch 394/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6295 - val_loss: 1.6321\n",
      "Epoch 395/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6298 - val_loss: 1.6020\n",
      "Epoch 396/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6273 - val_loss: 1.5924\n",
      "Epoch 397/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6255 - val_loss: 1.6215\n",
      "Epoch 398/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6305 - val_loss: 1.6351\n",
      "Epoch 399/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6333 - val_loss: 1.6699\n",
      "Epoch 400/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6266 - val_loss: 1.6794\n",
      "Epoch 401/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6385 - val_loss: 1.6351\n",
      "Epoch 402/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6279 - val_loss: 1.6365\n",
      "Epoch 403/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6250 - val_loss: 1.6280\n",
      "Epoch 404/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6203 - val_loss: 1.6473\n",
      "Epoch 405/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6183 - val_loss: 1.6307\n",
      "Epoch 406/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6243 - val_loss: 1.6287\n",
      "Epoch 407/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6250 - val_loss: 1.6127\n",
      "Epoch 408/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6147 - val_loss: 1.6655\n",
      "Epoch 409/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6197 - val_loss: 1.6600\n",
      "Epoch 410/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6160 - val_loss: 1.6939\n",
      "Epoch 411/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6198 - val_loss: 1.6158\n",
      "Epoch 412/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6201 - val_loss: 1.6384\n",
      "Epoch 413/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6193 - val_loss: 1.7465\n",
      "Epoch 414/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6170 - val_loss: 1.6700\n",
      "Epoch 415/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6217 - val_loss: 1.5799\n",
      "Epoch 416/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6317 - val_loss: 1.6505\n",
      "Epoch 417/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6245 - val_loss: 1.6694\n",
      "Epoch 418/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6257 - val_loss: 1.6843\n",
      "Epoch 419/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6170 - val_loss: 1.6506\n",
      "Epoch 420/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6138 - val_loss: 1.5878\n",
      "Epoch 421/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6188 - val_loss: 1.7230\n",
      "Epoch 422/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6164 - val_loss: 1.6031\n",
      "Epoch 423/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6179 - val_loss: 1.6068\n",
      "Epoch 424/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6160 - val_loss: 1.5912\n",
      "Epoch 425/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6210 - val_loss: 1.6661\n",
      "Epoch 426/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6179 - val_loss: 1.6757\n",
      "Epoch 427/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6131 - val_loss: 1.6423\n",
      "Epoch 428/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6161 - val_loss: 1.5874\n",
      "Epoch 429/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6104 - val_loss: 1.6863\n",
      "Epoch 430/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6114 - val_loss: 1.6617\n",
      "Epoch 431/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6136 - val_loss: 1.6084\n",
      "Epoch 432/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6178 - val_loss: 1.6333\n",
      "Epoch 433/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6227 - val_loss: 1.6596\n",
      "Epoch 434/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6157 - val_loss: 1.6530\n",
      "Epoch 435/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6190 - val_loss: 1.6031\n",
      "Epoch 436/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6114 - val_loss: 1.6487\n",
      "Epoch 437/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6156 - val_loss: 1.6418\n",
      "Epoch 438/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6069 - val_loss: 1.6925\n",
      "Epoch 439/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6163 - val_loss: 1.6184\n",
      "Epoch 440/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6151 - val_loss: 1.6665\n",
      "Epoch 441/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6124 - val_loss: 1.6163\n",
      "Epoch 442/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6104 - val_loss: 1.6905\n",
      "Epoch 443/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6080 - val_loss: 1.5972\n",
      "Epoch 444/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6091 - val_loss: 1.6334\n",
      "Epoch 445/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6152 - val_loss: 1.6004\n",
      "Epoch 446/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6167 - val_loss: 1.7095\n",
      "Epoch 447/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6115 - val_loss: 1.6843\n",
      "Epoch 448/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6088 - val_loss: 1.6192\n",
      "Epoch 449/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6127 - val_loss: 1.6177\n",
      "Epoch 450/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6125 - val_loss: 1.6668\n",
      "Epoch 451/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6081 - val_loss: 1.6612\n",
      "Epoch 452/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6064 - val_loss: 1.6016\n",
      "Epoch 453/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6076 - val_loss: 1.6266\n",
      "Epoch 454/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6078 - val_loss: 1.6430\n",
      "Epoch 455/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6048 - val_loss: 1.6728\n",
      "Epoch 456/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6165 - val_loss: 1.6425\n",
      "Epoch 457/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6109 - val_loss: 1.6113\n",
      "Epoch 458/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6117 - val_loss: 1.6479\n",
      "Epoch 459/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6102 - val_loss: 1.6913\n",
      "Epoch 460/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5992 - val_loss: 1.6224\n",
      "Epoch 461/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6084 - val_loss: 1.6371\n",
      "Epoch 462/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6046 - val_loss: 1.7134\n",
      "Epoch 463/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6036 - val_loss: 1.6321\n",
      "Epoch 464/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6122 - val_loss: 1.7131\n",
      "Epoch 465/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6014 - val_loss: 1.5857\n",
      "Epoch 466/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6067 - val_loss: 1.7446\n",
      "Epoch 467/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6045 - val_loss: 1.6270\n",
      "Epoch 468/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6054 - val_loss: 1.6287\n",
      "Epoch 469/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6041 - val_loss: 1.6656\n",
      "Epoch 470/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6020 - val_loss: 1.7913\n",
      "Epoch 471/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6046 - val_loss: 1.7047\n",
      "Epoch 472/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6032 - val_loss: 1.6114\n",
      "Epoch 473/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6074 - val_loss: 1.6350\n",
      "Epoch 474/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5979 - val_loss: 1.6733\n",
      "Epoch 475/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5965 - val_loss: 1.6898\n",
      "Epoch 476/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6047 - val_loss: 1.6039\n",
      "Epoch 477/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5962 - val_loss: 1.6736\n",
      "Epoch 478/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.6106 - val_loss: 1.6330\n",
      "Epoch 479/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5989 - val_loss: 1.6153\n",
      "Epoch 480/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5966 - val_loss: 1.6474\n",
      "Epoch 481/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6029 - val_loss: 1.6028\n",
      "Epoch 482/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5983 - val_loss: 1.5976\n",
      "Epoch 483/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6015 - val_loss: 1.5789\n",
      "Epoch 484/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6030 - val_loss: 1.6280\n",
      "Epoch 485/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6011 - val_loss: 1.6650\n",
      "Epoch 486/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5980 - val_loss: 1.7471\n",
      "Epoch 487/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5983 - val_loss: 1.6075\n",
      "Epoch 488/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5925 - val_loss: 1.6592\n",
      "Epoch 489/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5921 - val_loss: 1.6604\n",
      "Epoch 490/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6083 - val_loss: 1.6051\n",
      "Epoch 491/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5997 - val_loss: 1.6728\n",
      "Epoch 492/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5978 - val_loss: 1.5782\n",
      "Epoch 493/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6066 - val_loss: 1.6223\n",
      "Epoch 494/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5922 - val_loss: 1.5957\n",
      "Epoch 495/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5975 - val_loss: 1.6048\n",
      "Epoch 496/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5934 - val_loss: 1.6064\n",
      "Epoch 497/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6003 - val_loss: 1.6775\n",
      "Epoch 498/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6023 - val_loss: 1.6038\n",
      "Epoch 499/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5969 - val_loss: 1.6161\n",
      "Epoch 500/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5889 - val_loss: 1.5929\n",
      "Epoch 501/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6003 - val_loss: 1.7577\n",
      "Epoch 502/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5888 - val_loss: 1.6903\n",
      "Epoch 503/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5854 - val_loss: 1.6689\n",
      "Epoch 504/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5954 - val_loss: 1.5805\n",
      "Epoch 505/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5876 - val_loss: 1.6048\n",
      "Epoch 506/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5996 - val_loss: 1.6076\n",
      "Epoch 507/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5913 - val_loss: 1.6954\n",
      "Epoch 508/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.6052 - val_loss: 1.6320\n",
      "Epoch 509/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5876 - val_loss: 1.6168\n",
      "Epoch 510/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5898 - val_loss: 1.5986\n",
      "Epoch 511/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5890 - val_loss: 1.6120\n",
      "Epoch 512/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5880 - val_loss: 1.6965\n",
      "Epoch 513/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5974 - val_loss: 1.5878\n",
      "Epoch 514/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5915 - val_loss: 1.6807\n",
      "Epoch 515/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5913 - val_loss: 1.7440\n",
      "Epoch 516/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5895 - val_loss: 1.6391\n",
      "Epoch 517/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.6013 - val_loss: 1.7547\n",
      "Epoch 518/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5906 - val_loss: 1.5696\n",
      "Epoch 519/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5844 - val_loss: 1.6028\n",
      "Epoch 520/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5923 - val_loss: 1.6062\n",
      "Epoch 521/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5874 - val_loss: 1.5996\n",
      "Epoch 522/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5912 - val_loss: 1.6423\n",
      "Epoch 523/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5880 - val_loss: 1.5886\n",
      "Epoch 524/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5954 - val_loss: 1.5795\n",
      "Epoch 525/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5909 - val_loss: 1.6788\n",
      "Epoch 526/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5854 - val_loss: 1.6387\n",
      "Epoch 527/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5889 - val_loss: 1.5807\n",
      "Epoch 528/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5891 - val_loss: 1.6498\n",
      "Epoch 529/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5873 - val_loss: 1.6814\n",
      "Epoch 530/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5814 - val_loss: 1.6521\n",
      "Epoch 531/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5811 - val_loss: 1.6490\n",
      "Epoch 532/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5861 - val_loss: 1.6056\n",
      "Epoch 533/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5846 - val_loss: 1.6291\n",
      "Epoch 534/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5810 - val_loss: 1.6153\n",
      "Epoch 535/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5847 - val_loss: 1.6344\n",
      "Epoch 536/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5843 - val_loss: 1.5935\n",
      "Epoch 537/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5797 - val_loss: 1.5818\n",
      "Epoch 538/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5762 - val_loss: 1.7680\n",
      "Epoch 539/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5887 - val_loss: 1.6051\n",
      "Epoch 540/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5855 - val_loss: 1.6054\n",
      "Epoch 541/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5889 - val_loss: 1.5840\n",
      "Epoch 542/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5811 - val_loss: 1.5940\n",
      "Epoch 543/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5800 - val_loss: 1.6941\n",
      "Epoch 544/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5860 - val_loss: 1.5979\n",
      "Epoch 545/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5893 - val_loss: 1.6505\n",
      "Epoch 546/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5757 - val_loss: 1.5683\n",
      "Epoch 547/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5807 - val_loss: 1.5852\n",
      "Epoch 548/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5879 - val_loss: 1.5938\n",
      "Epoch 549/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5694 - val_loss: 1.6036\n",
      "Epoch 550/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5820 - val_loss: 1.6274\n",
      "Epoch 551/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5774 - val_loss: 1.7196\n",
      "Epoch 552/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5781 - val_loss: 1.5907\n",
      "Epoch 553/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5750 - val_loss: 1.5534\n",
      "Epoch 554/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5769 - val_loss: 1.8524\n",
      "Epoch 555/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5819 - val_loss: 1.5796\n",
      "Epoch 556/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5777 - val_loss: 1.6468\n",
      "Epoch 557/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5820 - val_loss: 1.6057\n",
      "Epoch 558/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5753 - val_loss: 1.5707\n",
      "Epoch 559/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5785 - val_loss: 1.6591\n",
      "Epoch 560/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5783 - val_loss: 1.6957\n",
      "Epoch 561/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5829 - val_loss: 1.5676\n",
      "Epoch 562/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5789 - val_loss: 1.6412\n",
      "Epoch 563/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5754 - val_loss: 1.5726\n",
      "Epoch 564/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5686 - val_loss: 1.6293\n",
      "Epoch 565/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5747 - val_loss: 1.6951\n",
      "Epoch 566/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5750 - val_loss: 1.6535\n",
      "Epoch 567/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5717 - val_loss: 1.5392\n",
      "Epoch 568/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5791 - val_loss: 1.5717\n",
      "Epoch 569/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5742 - val_loss: 1.5558\n",
      "Epoch 570/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5722 - val_loss: 1.6084\n",
      "Epoch 571/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5684 - val_loss: 1.5871\n",
      "Epoch 572/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5668 - val_loss: 1.5855\n",
      "Epoch 573/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5781 - val_loss: 1.5700\n",
      "Epoch 574/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5740 - val_loss: 1.5741\n",
      "Epoch 575/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5722 - val_loss: 1.6605\n",
      "Epoch 576/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5661 - val_loss: 1.7121\n",
      "Epoch 577/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5681 - val_loss: 1.5914\n",
      "Epoch 578/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5776 - val_loss: 1.5511\n",
      "Epoch 579/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5720 - val_loss: 1.6308\n",
      "Epoch 580/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5704 - val_loss: 1.5982\n",
      "Epoch 581/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5742 - val_loss: 1.6201\n",
      "Epoch 582/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5729 - val_loss: 1.6951\n",
      "Epoch 583/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5715 - val_loss: 1.5567\n",
      "Epoch 584/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5710 - val_loss: 1.7326\n",
      "Epoch 585/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5701 - val_loss: 1.5676\n",
      "Epoch 586/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5664 - val_loss: 1.5645\n",
      "Epoch 587/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5708 - val_loss: 1.5917\n",
      "Epoch 588/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5718 - val_loss: 1.6040\n",
      "Epoch 589/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5678 - val_loss: 1.6968\n",
      "Epoch 590/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5667 - val_loss: 1.6132\n",
      "Epoch 591/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5729 - val_loss: 1.7966\n",
      "Epoch 592/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5632 - val_loss: 1.6001\n",
      "Epoch 593/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5714 - val_loss: 1.6016\n",
      "Epoch 594/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5803 - val_loss: 1.6337\n",
      "Epoch 595/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5704 - val_loss: 1.6311\n",
      "Epoch 596/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5820 - val_loss: 1.5718\n",
      "Epoch 597/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5765 - val_loss: 1.5992\n",
      "Epoch 598/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5765 - val_loss: 1.6001\n",
      "Epoch 599/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5734 - val_loss: 1.5677\n",
      "Epoch 600/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5654 - val_loss: 1.6350\n",
      "Epoch 601/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5693 - val_loss: 1.5954\n",
      "Epoch 602/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5725 - val_loss: 1.5693\n",
      "Epoch 603/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5715 - val_loss: 1.5711\n",
      "Epoch 604/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5617 - val_loss: 1.5387\n",
      "Epoch 605/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5658 - val_loss: 1.5634\n",
      "Epoch 606/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5664 - val_loss: 1.5857\n",
      "Epoch 607/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5693 - val_loss: 1.6099\n",
      "Epoch 608/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5705 - val_loss: 1.6167\n",
      "Epoch 609/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5679 - val_loss: 1.6634\n",
      "Epoch 610/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5720 - val_loss: 1.6273\n",
      "Epoch 611/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5659 - val_loss: 1.6231\n",
      "Epoch 612/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5677 - val_loss: 1.6076\n",
      "Epoch 613/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5601 - val_loss: 1.6078\n",
      "Epoch 614/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5617 - val_loss: 1.6353\n",
      "Epoch 615/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5620 - val_loss: 1.5698\n",
      "Epoch 616/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5667 - val_loss: 1.5359\n",
      "Epoch 617/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5728 - val_loss: 1.6256\n",
      "Epoch 618/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5674 - val_loss: 1.7075\n",
      "Epoch 619/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5616 - val_loss: 1.5941\n",
      "Epoch 620/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5609 - val_loss: 1.5735\n",
      "Epoch 621/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5699 - val_loss: 1.5899\n",
      "Epoch 622/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5664 - val_loss: 1.6030\n",
      "Epoch 623/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5637 - val_loss: 1.6496\n",
      "Epoch 624/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5708 - val_loss: 1.6295\n",
      "Epoch 625/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5621 - val_loss: 1.5562\n",
      "Epoch 626/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5596 - val_loss: 1.6011\n",
      "Epoch 627/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5563 - val_loss: 1.5655\n",
      "Epoch 628/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5672 - val_loss: 1.5664\n",
      "Epoch 629/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5551 - val_loss: 1.6547\n",
      "Epoch 630/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5746 - val_loss: 1.5597\n",
      "Epoch 631/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5610 - val_loss: 1.5780\n",
      "Epoch 632/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5613 - val_loss: 1.6449\n",
      "Epoch 633/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5658 - val_loss: 1.5816\n",
      "Epoch 634/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5649 - val_loss: 1.6104\n",
      "Epoch 635/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5589 - val_loss: 1.5616\n",
      "Epoch 636/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5645 - val_loss: 1.5602\n",
      "Epoch 637/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5728 - val_loss: 1.6032\n",
      "Epoch 638/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5682 - val_loss: 1.6582\n",
      "Epoch 639/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5602 - val_loss: 1.6119\n",
      "Epoch 640/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5594 - val_loss: 1.5486\n",
      "Epoch 641/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5652 - val_loss: 1.5693\n",
      "Epoch 642/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5601 - val_loss: 1.5410\n",
      "Epoch 643/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5643 - val_loss: 1.6562\n",
      "Epoch 644/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5590 - val_loss: 1.5353\n",
      "Epoch 645/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5676 - val_loss: 1.6151\n",
      "Epoch 646/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5589 - val_loss: 1.6392\n",
      "Epoch 647/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5630 - val_loss: 1.6490\n",
      "Epoch 648/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5570 - val_loss: 1.6369\n",
      "Epoch 649/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5532 - val_loss: 1.5297\n",
      "Epoch 650/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5698 - val_loss: 1.6241\n",
      "Epoch 651/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5564 - val_loss: 1.5691\n",
      "Epoch 652/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5617 - val_loss: 1.6826\n",
      "Epoch 653/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5583 - val_loss: 1.6242\n",
      "Epoch 654/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5575 - val_loss: 1.6384\n",
      "Epoch 655/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5669 - val_loss: 1.5765\n",
      "Epoch 656/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5620 - val_loss: 1.5701\n",
      "Epoch 657/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5631 - val_loss: 1.5513\n",
      "Epoch 658/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5565 - val_loss: 1.5730\n",
      "Epoch 659/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5619 - val_loss: 1.5854\n",
      "Epoch 660/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5582 - val_loss: 1.6525\n",
      "Epoch 661/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5660 - val_loss: 1.5755\n",
      "Epoch 662/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5497 - val_loss: 1.5243\n",
      "Epoch 663/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5616 - val_loss: 1.5324\n",
      "Epoch 664/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5520 - val_loss: 1.6259\n",
      "Epoch 665/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5598 - val_loss: 1.6316\n",
      "Epoch 666/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5575 - val_loss: 1.5614\n",
      "Epoch 667/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5603 - val_loss: 1.5858\n",
      "Epoch 668/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5544 - val_loss: 1.6115\n",
      "Epoch 669/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5491 - val_loss: 1.6308\n",
      "Epoch 670/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5642 - val_loss: 1.5872\n",
      "Epoch 671/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5514 - val_loss: 1.6354\n",
      "Epoch 672/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5571 - val_loss: 1.6024\n",
      "Epoch 673/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5593 - val_loss: 1.5344\n",
      "Epoch 674/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5568 - val_loss: 1.5647\n",
      "Epoch 675/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5558 - val_loss: 1.6101\n",
      "Epoch 676/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5550 - val_loss: 1.5612\n",
      "Epoch 677/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5529 - val_loss: 1.5773\n",
      "Epoch 678/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5523 - val_loss: 1.6322\n",
      "Epoch 679/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5537 - val_loss: 1.5617\n",
      "Epoch 680/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5617 - val_loss: 1.6378\n",
      "Epoch 681/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5521 - val_loss: 1.5654\n",
      "Epoch 682/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5592 - val_loss: 1.6418\n",
      "Epoch 683/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5682 - val_loss: 1.6930\n",
      "Epoch 684/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5593 - val_loss: 1.5984\n",
      "Epoch 685/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5546 - val_loss: 1.5514\n",
      "Epoch 686/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5597 - val_loss: 1.5460\n",
      "Epoch 687/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5559 - val_loss: 1.5777\n",
      "Epoch 688/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5555 - val_loss: 1.6275\n",
      "Epoch 689/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5566 - val_loss: 1.6105\n",
      "Epoch 690/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5517 - val_loss: 1.6023\n",
      "Epoch 691/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5531 - val_loss: 1.6053\n",
      "Epoch 692/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5588 - val_loss: 1.5892\n",
      "Epoch 693/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5458 - val_loss: 1.6115\n",
      "Epoch 694/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5513 - val_loss: 1.5490\n",
      "Epoch 695/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5521 - val_loss: 1.6361\n",
      "Epoch 696/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5556 - val_loss: 1.6762\n",
      "Epoch 697/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5513 - val_loss: 1.5739\n",
      "Epoch 698/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5579 - val_loss: 1.5712\n",
      "Epoch 699/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5501 - val_loss: 1.6000\n",
      "Epoch 700/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5555 - val_loss: 1.5466\n",
      "Epoch 701/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5588 - val_loss: 1.6108\n",
      "Epoch 702/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5536 - val_loss: 1.5427\n",
      "Epoch 703/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5507 - val_loss: 1.6541\n",
      "Epoch 704/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5577 - val_loss: 1.7617\n",
      "Epoch 705/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5590 - val_loss: 1.5872\n",
      "Epoch 706/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5474 - val_loss: 1.5296\n",
      "Epoch 707/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5488 - val_loss: 1.5235\n",
      "Epoch 708/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5530 - val_loss: 1.6074\n",
      "Epoch 709/900\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.5523 - val_loss: 1.5644\n",
      "Epoch 710/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5468 - val_loss: 1.6464\n",
      "Epoch 711/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5450 - val_loss: 1.5549\n",
      "Epoch 712/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5545 - val_loss: 1.6390\n",
      "Epoch 713/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5533 - val_loss: 1.5518\n",
      "Epoch 714/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5514 - val_loss: 1.6322\n",
      "Epoch 715/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5542 - val_loss: 1.6085\n",
      "Epoch 716/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5498 - val_loss: 1.5500\n",
      "Epoch 717/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5544 - val_loss: 1.5722\n",
      "Epoch 718/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5464 - val_loss: 1.5181\n",
      "Epoch 719/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5539 - val_loss: 1.6152\n",
      "Epoch 720/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5450 - val_loss: 1.5692\n",
      "Epoch 721/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5504 - val_loss: 1.5744\n",
      "Epoch 722/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5528 - val_loss: 1.5672\n",
      "Epoch 723/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5505 - val_loss: 1.6034\n",
      "Epoch 724/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5468 - val_loss: 1.5582\n",
      "Epoch 725/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5512 - val_loss: 1.6266\n",
      "Epoch 726/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5528 - val_loss: 1.5505\n",
      "Epoch 727/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5555 - val_loss: 1.6664\n",
      "Epoch 728/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5500 - val_loss: 1.5430\n",
      "Epoch 729/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5551 - val_loss: 1.5715\n",
      "Epoch 730/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5489 - val_loss: 1.5870\n",
      "Epoch 731/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5513 - val_loss: 1.5657\n",
      "Epoch 732/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5460 - val_loss: 1.6107\n",
      "Epoch 733/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5457 - val_loss: 1.5461\n",
      "Epoch 734/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5535 - val_loss: 1.5904\n",
      "Epoch 735/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5411 - val_loss: 1.5259\n",
      "Epoch 736/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5523 - val_loss: 1.5243\n",
      "Epoch 737/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5427 - val_loss: 1.6254\n",
      "Epoch 738/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5497 - val_loss: 1.5682\n",
      "Epoch 739/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5472 - val_loss: 1.5797\n",
      "Epoch 740/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5508 - val_loss: 1.6454\n",
      "Epoch 741/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5523 - val_loss: 1.5711\n",
      "Epoch 742/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5493 - val_loss: 1.5398\n",
      "Epoch 743/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5414 - val_loss: 1.5489\n",
      "Epoch 744/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5402 - val_loss: 1.5914\n",
      "Epoch 745/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5463 - val_loss: 1.5514\n",
      "Epoch 746/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5486 - val_loss: 1.5644\n",
      "Epoch 747/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5389 - val_loss: 1.5876\n",
      "Epoch 748/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5434 - val_loss: 1.7160\n",
      "Epoch 749/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5422 - val_loss: 1.5649\n",
      "Epoch 750/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5441 - val_loss: 1.6236\n",
      "Epoch 751/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5573 - val_loss: 1.5934\n",
      "Epoch 752/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5458 - val_loss: 1.5740\n",
      "Epoch 753/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5456 - val_loss: 1.6359\n",
      "Epoch 754/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5461 - val_loss: 1.5496\n",
      "Epoch 755/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5340 - val_loss: 1.6083\n",
      "Epoch 756/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5499 - val_loss: 1.5406\n",
      "Epoch 757/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5396 - val_loss: 1.5362\n",
      "Epoch 758/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5476 - val_loss: 1.5410\n",
      "Epoch 759/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5503 - val_loss: 1.5592\n",
      "Epoch 760/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5453 - val_loss: 1.5673\n",
      "Epoch 761/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5425 - val_loss: 1.5840\n",
      "Epoch 762/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5473 - val_loss: 1.5246\n",
      "Epoch 763/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5426 - val_loss: 1.6468\n",
      "Epoch 764/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5419 - val_loss: 1.6118\n",
      "Epoch 765/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5490 - val_loss: 1.5847\n",
      "Epoch 766/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5396 - val_loss: 1.5835\n",
      "Epoch 767/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5465 - val_loss: 1.5640\n",
      "Epoch 768/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5378 - val_loss: 1.5933\n",
      "Epoch 769/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5478 - val_loss: 1.5623\n",
      "Epoch 770/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5446 - val_loss: 1.5472\n",
      "Epoch 771/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5432 - val_loss: 1.7019\n",
      "Epoch 772/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5381 - val_loss: 1.5732\n",
      "Epoch 773/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5416 - val_loss: 1.5539\n",
      "Epoch 774/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5437 - val_loss: 1.5911\n",
      "Epoch 775/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5403 - val_loss: 1.5757\n",
      "Epoch 776/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5489 - val_loss: 1.5400\n",
      "Epoch 777/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5424 - val_loss: 1.5762\n",
      "Epoch 778/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5408 - val_loss: 1.5433\n",
      "Epoch 779/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5387 - val_loss: 1.5315\n",
      "Epoch 780/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5448 - val_loss: 1.5613\n",
      "Epoch 781/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5417 - val_loss: 1.5438\n",
      "Epoch 782/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5409 - val_loss: 1.5606\n",
      "Epoch 783/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5459 - val_loss: 1.5278\n",
      "Epoch 784/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5380 - val_loss: 1.5144\n",
      "Epoch 785/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5424 - val_loss: 1.5522\n",
      "Epoch 786/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5377 - val_loss: 1.5544\n",
      "Epoch 787/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5428 - val_loss: 1.5805\n",
      "Epoch 788/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5436 - val_loss: 1.5716\n",
      "Epoch 789/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5401 - val_loss: 1.5469\n",
      "Epoch 790/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5446 - val_loss: 1.5600\n",
      "Epoch 791/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5384 - val_loss: 1.5785\n",
      "Epoch 792/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5440 - val_loss: 1.5732\n",
      "Epoch 793/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5485 - val_loss: 1.5927\n",
      "Epoch 794/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5435 - val_loss: 1.5822\n",
      "Epoch 795/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5476 - val_loss: 1.5928\n",
      "Epoch 796/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5409 - val_loss: 1.5760\n",
      "Epoch 797/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5396 - val_loss: 1.5767\n",
      "Epoch 798/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5386 - val_loss: 1.5893\n",
      "Epoch 799/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5418 - val_loss: 1.5402\n",
      "Epoch 800/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5350 - val_loss: 1.6044\n",
      "Epoch 801/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5416 - val_loss: 1.5760\n",
      "Epoch 802/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5372 - val_loss: 1.5748\n",
      "Epoch 803/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5394 - val_loss: 1.5871\n",
      "Epoch 804/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5334 - val_loss: 1.6122\n",
      "Epoch 805/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5323 - val_loss: 1.5435\n",
      "Epoch 806/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5395 - val_loss: 1.6590\n",
      "Epoch 807/900\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.5423 - val_loss: 1.6080\n",
      "Epoch 808/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5367 - val_loss: 1.5693\n",
      "Epoch 809/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5406 - val_loss: 1.6063\n",
      "Epoch 810/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5374 - val_loss: 1.5647\n",
      "Epoch 811/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5311 - val_loss: 1.5463\n",
      "Epoch 812/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5373 - val_loss: 1.6085\n",
      "Epoch 813/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5428 - val_loss: 1.6261\n",
      "Epoch 814/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5295 - val_loss: 1.5788\n",
      "Epoch 815/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5363 - val_loss: 1.7195\n",
      "Epoch 816/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5370 - val_loss: 1.6836\n",
      "Epoch 817/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5532 - val_loss: 1.6979\n",
      "Epoch 818/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5356 - val_loss: 1.6035\n",
      "Epoch 819/900\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.5354 - val_loss: 1.5302\n",
      "Epoch 820/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5331 - val_loss: 1.5604\n",
      "Epoch 821/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5437 - val_loss: 1.5897\n",
      "Epoch 822/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5380 - val_loss: 1.5945\n",
      "Epoch 823/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5461 - val_loss: 1.5248\n",
      "Epoch 824/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5326 - val_loss: 1.5789\n",
      "Epoch 825/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5402 - val_loss: 1.5555\n",
      "Epoch 826/900\n",
      "1728/1728 [==============================] - 8s 5ms/step - loss: 1.5301 - val_loss: 1.5437\n",
      "Epoch 827/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5385 - val_loss: 1.5435\n",
      "Epoch 828/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5403 - val_loss: 1.6116\n",
      "Epoch 829/900\n",
      "1728/1728 [==============================] - 8s 4ms/step - loss: 1.5381 - val_loss: 1.5846\n",
      "Epoch 830/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5329 - val_loss: 1.5314\n",
      "Epoch 831/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5367 - val_loss: 1.5977\n",
      "Epoch 832/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5338 - val_loss: 1.5810\n",
      "Epoch 833/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5297 - val_loss: 1.6972\n",
      "Epoch 834/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5327 - val_loss: 1.5883\n",
      "Epoch 835/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5376 - val_loss: 1.5731\n",
      "Epoch 836/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5351 - val_loss: 1.5739\n",
      "Epoch 837/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5341 - val_loss: 1.5309\n",
      "Epoch 838/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5358 - val_loss: 1.5586\n",
      "Epoch 839/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5338 - val_loss: 1.5929\n",
      "Epoch 840/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5329 - val_loss: 1.5587\n",
      "Epoch 841/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5315 - val_loss: 1.5761\n",
      "Epoch 842/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5312 - val_loss: 1.5707\n",
      "Epoch 843/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5320 - val_loss: 1.5352\n",
      "Epoch 844/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5368 - val_loss: 1.5679\n",
      "Epoch 845/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5387 - val_loss: 1.5483\n",
      "Epoch 846/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5302 - val_loss: 1.5888\n",
      "Epoch 847/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5403 - val_loss: 1.5203\n",
      "Epoch 848/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5343 - val_loss: 1.5384\n",
      "Epoch 849/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5288 - val_loss: 1.5411\n",
      "Epoch 850/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5335 - val_loss: 1.6182\n",
      "Epoch 851/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5376 - val_loss: 1.5746\n",
      "Epoch 852/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5307 - val_loss: 1.6003\n",
      "Epoch 853/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5274 - val_loss: 1.5682\n",
      "Epoch 854/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5325 - val_loss: 1.5971\n",
      "Epoch 855/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5329 - val_loss: 1.7356\n",
      "Epoch 856/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5368 - val_loss: 1.5779\n",
      "Epoch 857/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5354 - val_loss: 1.5815\n",
      "Epoch 858/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5397 - val_loss: 1.5570\n",
      "Epoch 859/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5350 - val_loss: 1.5175\n",
      "Epoch 860/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5284 - val_loss: 1.5778\n",
      "Epoch 861/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5323 - val_loss: 1.6239\n",
      "Epoch 862/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5332 - val_loss: 1.5863\n",
      "Epoch 863/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5311 - val_loss: 1.5694\n",
      "Epoch 864/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5236 - val_loss: 1.5834\n",
      "Epoch 865/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5312 - val_loss: 1.5883\n",
      "Epoch 866/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5275 - val_loss: 1.5572\n",
      "Epoch 867/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5318 - val_loss: 1.5459\n",
      "Epoch 868/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5247 - val_loss: 1.5749\n",
      "Epoch 869/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5327 - val_loss: 1.5696\n",
      "Epoch 870/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5297 - val_loss: 1.5420\n",
      "Epoch 871/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5292 - val_loss: 1.5451\n",
      "Epoch 872/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5306 - val_loss: 1.5168\n",
      "Epoch 873/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5358 - val_loss: 1.5995\n",
      "Epoch 874/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5273 - val_loss: 1.6120\n",
      "Epoch 875/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5317 - val_loss: 1.5924\n",
      "Epoch 876/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5271 - val_loss: 1.5933\n",
      "Epoch 877/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5290 - val_loss: 1.5502\n",
      "Epoch 878/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5296 - val_loss: 1.5266\n",
      "Epoch 879/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5346 - val_loss: 1.5570\n",
      "Epoch 880/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5242 - val_loss: 1.5395\n",
      "Epoch 881/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5304 - val_loss: 1.5661\n",
      "Epoch 882/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5327 - val_loss: 1.6695\n",
      "Epoch 883/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5225 - val_loss: 1.6071\n",
      "Epoch 884/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5382 - val_loss: 1.5659\n",
      "Epoch 885/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5358 - val_loss: 1.5438\n",
      "Epoch 886/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5339 - val_loss: 1.6295\n",
      "Epoch 887/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5292 - val_loss: 1.5366\n",
      "Epoch 888/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5359 - val_loss: 1.5131\n",
      "Epoch 889/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5281 - val_loss: 1.6285\n",
      "Epoch 890/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5211 - val_loss: 1.5716\n",
      "Epoch 891/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5254 - val_loss: 1.5571\n",
      "Epoch 892/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5340 - val_loss: 1.5559\n",
      "Epoch 893/900\n",
      "1728/1728 [==============================] - 7s 4ms/step - loss: 1.5342 - val_loss: 1.5316\n",
      "Epoch 894/900\n",
      "1728/1728 [==============================] - 6s 4ms/step - loss: 1.5249 - val_loss: 1.5913\n",
      "Epoch 895/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5251 - val_loss: 1.5522\n",
      "Epoch 896/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5318 - val_loss: 1.5102\n",
      "Epoch 897/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5286 - val_loss: 1.5664\n",
      "Epoch 898/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5261 - val_loss: 1.5840\n",
      "Epoch 899/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5312 - val_loss: 1.6460\n",
      "Epoch 900/900\n",
      "1728/1728 [==============================] - 6s 3ms/step - loss: 1.5316 - val_loss: 1.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6725517662216887\n",
      "0.9592552111750746\n",
      "Epoch 1/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 8.3188 - val_loss: 5.6651\n",
      "Epoch 2/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 4.8764 - val_loss: 6.0445\n",
      "Epoch 3/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 5.0390 - val_loss: 4.8543\n",
      "Epoch 4/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 3.9874 - val_loss: 5.1834\n",
      "Epoch 5/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 3.6954 - val_loss: 3.1777\n",
      "Epoch 6/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 3.4480 - val_loss: 3.0853\n",
      "Epoch 7/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 3.2584 - val_loss: 3.5631\n",
      "Epoch 8/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 3.1323 - val_loss: 2.8745\n",
      "Epoch 9/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 3.0714 - val_loss: 2.9226\n",
      "Epoch 10/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.9535 - val_loss: 2.9714\n",
      "Epoch 11/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.8920 - val_loss: 2.7267\n",
      "Epoch 12/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.8260 - val_loss: 2.8228\n",
      "Epoch 13/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.7299 - val_loss: 2.9788\n",
      "Epoch 14/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.6553 - val_loss: 2.4789\n",
      "Epoch 15/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.6067 - val_loss: 2.4665\n",
      "Epoch 16/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.5375 - val_loss: 2.6140\n",
      "Epoch 17/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.5254 - val_loss: 2.5124\n",
      "Epoch 18/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.5033 - val_loss: 2.5008\n",
      "Epoch 19/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.4703 - val_loss: 2.4364\n",
      "Epoch 20/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.4247 - val_loss: 2.3747\n",
      "Epoch 21/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.4248 - val_loss: 2.5674\n",
      "Epoch 22/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.4233 - val_loss: 2.3583\n",
      "Epoch 23/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3778 - val_loss: 2.6950\n",
      "Epoch 24/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3653 - val_loss: 2.3534\n",
      "Epoch 25/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3393 - val_loss: 2.2954\n",
      "Epoch 26/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3206 - val_loss: 2.3439\n",
      "Epoch 27/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3090 - val_loss: 2.2475\n",
      "Epoch 28/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.2560 - val_loss: 2.2248\n",
      "Epoch 29/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2671 - val_loss: 2.3742\n",
      "Epoch 30/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.2350 - val_loss: 2.1654\n",
      "Epoch 31/900\n",
      "864/864 [==============================] - 9s 10ms/step - loss: 2.2096 - val_loss: 2.2693\n",
      "Epoch 32/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 2.2072 - val_loss: 2.2630\n",
      "Epoch 33/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.1842 - val_loss: 2.2256\n",
      "Epoch 34/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1802 - val_loss: 2.2972\n",
      "Epoch 35/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1624 - val_loss: 2.2130\n",
      "Epoch 36/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1354 - val_loss: 2.0696\n",
      "Epoch 37/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1327 - val_loss: 2.0743\n",
      "Epoch 38/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1008 - val_loss: 2.0647\n",
      "Epoch 39/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.1136 - val_loss: 2.1326\n",
      "Epoch 40/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0823 - val_loss: 2.1225\n",
      "Epoch 41/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0687 - val_loss: 2.1672\n",
      "Epoch 42/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0641 - val_loss: 1.9982\n",
      "Epoch 43/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.0514 - val_loss: 2.0088\n",
      "Epoch 44/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0355 - val_loss: 2.1152\n",
      "Epoch 45/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0334 - val_loss: 1.9678\n",
      "Epoch 46/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0223 - val_loss: 1.9958\n",
      "Epoch 47/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0103 - val_loss: 2.1325\n",
      "Epoch 48/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0078 - val_loss: 1.9350\n",
      "Epoch 49/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0003 - val_loss: 2.0299\n",
      "Epoch 50/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 2.0022 - val_loss: 1.9752\n",
      "Epoch 51/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9988 - val_loss: 1.9779\n",
      "Epoch 52/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9879 - val_loss: 2.0679\n",
      "Epoch 53/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9699 - val_loss: 1.9287\n",
      "Epoch 54/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9753 - val_loss: 1.9259\n",
      "Epoch 55/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9871 - val_loss: 1.9242\n",
      "Epoch 56/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.9567 - val_loss: 1.9119\n",
      "Epoch 57/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9630 - val_loss: 2.0670\n",
      "Epoch 58/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9486 - val_loss: 1.9237\n",
      "Epoch 59/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9648 - val_loss: 1.8981\n",
      "Epoch 60/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9481 - val_loss: 1.9521\n",
      "Epoch 61/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9262 - val_loss: 1.9233\n",
      "Epoch 62/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9358 - val_loss: 1.8747\n",
      "Epoch 63/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9302 - val_loss: 1.9905\n",
      "Epoch 64/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9316 - val_loss: 1.8786\n",
      "Epoch 65/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9193 - val_loss: 1.9135\n",
      "Epoch 66/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9191 - val_loss: 1.9035\n",
      "Epoch 67/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9102 - val_loss: 1.9508\n",
      "Epoch 68/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9150 - val_loss: 1.9001\n",
      "Epoch 69/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8985 - val_loss: 1.9253\n",
      "Epoch 70/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9081 - val_loss: 1.8731\n",
      "Epoch 71/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8940 - val_loss: 2.0266\n",
      "Epoch 72/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8808 - val_loss: 1.9664\n",
      "Epoch 73/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8905 - val_loss: 1.8649\n",
      "Epoch 74/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8995 - val_loss: 1.8699\n",
      "Epoch 75/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8782 - val_loss: 1.8552\n",
      "Epoch 76/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8960 - val_loss: 1.9381\n",
      "Epoch 77/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8599 - val_loss: 1.8049\n",
      "Epoch 78/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8793 - val_loss: 1.8188\n",
      "Epoch 79/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8804 - val_loss: 1.9237\n",
      "Epoch 80/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8578 - val_loss: 2.0068\n",
      "Epoch 81/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8619 - val_loss: 1.8677\n",
      "Epoch 82/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8801 - val_loss: 1.8626\n",
      "Epoch 83/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8663 - val_loss: 1.8483\n",
      "Epoch 84/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8549 - val_loss: 1.9046\n",
      "Epoch 85/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8532 - val_loss: 1.7852\n",
      "Epoch 86/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8349 - val_loss: 1.8473\n",
      "Epoch 87/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8382 - val_loss: 1.8224\n",
      "Epoch 88/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8514 - val_loss: 1.7758\n",
      "Epoch 89/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8467 - val_loss: 1.7647\n",
      "Epoch 90/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8328 - val_loss: 1.7897\n",
      "Epoch 91/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8302 - val_loss: 1.9301\n",
      "Epoch 92/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8251 - val_loss: 1.8143\n",
      "Epoch 93/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8229 - val_loss: 1.8543\n",
      "Epoch 94/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8214 - val_loss: 1.8869\n",
      "Epoch 95/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8242 - val_loss: 1.8743\n",
      "Epoch 96/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8145 - val_loss: 1.9079\n",
      "Epoch 97/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8192 - val_loss: 1.8639\n",
      "Epoch 98/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8091 - val_loss: 1.7845\n",
      "Epoch 99/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8074 - val_loss: 1.8050\n",
      "Epoch 100/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8129 - val_loss: 1.8391\n",
      "Epoch 101/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8013 - val_loss: 1.8169\n",
      "Epoch 102/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8106 - val_loss: 1.8146\n",
      "Epoch 103/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8178 - val_loss: 1.8231\n",
      "Epoch 104/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7934 - val_loss: 1.7609\n",
      "Epoch 105/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7982 - val_loss: 1.7550\n",
      "Epoch 106/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7871 - val_loss: 1.8365\n",
      "Epoch 107/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7936 - val_loss: 1.8007\n",
      "Epoch 108/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7916 - val_loss: 1.8341\n",
      "Epoch 109/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7780 - val_loss: 1.7793\n",
      "Epoch 110/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7935 - val_loss: 1.8054\n",
      "Epoch 111/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7835 - val_loss: 1.8234\n",
      "Epoch 112/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7836 - val_loss: 1.7796\n",
      "Epoch 113/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7849 - val_loss: 1.8232\n",
      "Epoch 114/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7734 - val_loss: 1.7900\n",
      "Epoch 115/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7777 - val_loss: 1.7587\n",
      "Epoch 116/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7794 - val_loss: 1.7992\n",
      "Epoch 117/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7765 - val_loss: 1.8132\n",
      "Epoch 118/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7687 - val_loss: 1.7367\n",
      "Epoch 119/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7641 - val_loss: 1.7972\n",
      "Epoch 120/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7630 - val_loss: 1.8114\n",
      "Epoch 121/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7737 - val_loss: 1.8393\n",
      "Epoch 122/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7592 - val_loss: 1.8521\n",
      "Epoch 123/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7544 - val_loss: 1.8365\n",
      "Epoch 124/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7480 - val_loss: 1.7800\n",
      "Epoch 125/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7567 - val_loss: 1.8301\n",
      "Epoch 126/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7455 - val_loss: 1.7876\n",
      "Epoch 127/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7585 - val_loss: 1.7981\n",
      "Epoch 128/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7522 - val_loss: 1.8258\n",
      "Epoch 129/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7467 - val_loss: 1.7348\n",
      "Epoch 130/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7391 - val_loss: 1.8287\n",
      "Epoch 131/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7436 - val_loss: 1.7512\n",
      "Epoch 132/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7472 - val_loss: 1.7440\n",
      "Epoch 133/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7387 - val_loss: 1.7828\n",
      "Epoch 134/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7421 - val_loss: 1.7682\n",
      "Epoch 135/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7437 - val_loss: 1.7770\n",
      "Epoch 136/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7348 - val_loss: 1.7332\n",
      "Epoch 137/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7247 - val_loss: 1.7297\n",
      "Epoch 138/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7308 - val_loss: 1.7777\n",
      "Epoch 139/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7306 - val_loss: 1.7224\n",
      "Epoch 140/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7243 - val_loss: 1.7391\n",
      "Epoch 141/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7320 - val_loss: 1.7033\n",
      "Epoch 142/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7321 - val_loss: 1.8479\n",
      "Epoch 143/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7206 - val_loss: 1.7097\n",
      "Epoch 144/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7126 - val_loss: 1.6948\n",
      "Epoch 145/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7189 - val_loss: 1.7108\n",
      "Epoch 146/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7161 - val_loss: 1.7059\n",
      "Epoch 147/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7147 - val_loss: 1.6881\n",
      "Epoch 148/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7158 - val_loss: 1.8817\n",
      "Epoch 149/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7177 - val_loss: 1.7892\n",
      "Epoch 150/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7160 - val_loss: 1.7144\n",
      "Epoch 151/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7145 - val_loss: 1.7244\n",
      "Epoch 152/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7105 - val_loss: 1.8297\n",
      "Epoch 153/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7118 - val_loss: 1.6733\n",
      "Epoch 154/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6983 - val_loss: 1.6770\n",
      "Epoch 155/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7018 - val_loss: 1.7359\n",
      "Epoch 156/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7116 - val_loss: 1.7896\n",
      "Epoch 157/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7063 - val_loss: 1.7268\n",
      "Epoch 158/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.7010 - val_loss: 1.7255\n",
      "Epoch 159/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7004 - val_loss: 1.7197\n",
      "Epoch 160/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6947 - val_loss: 1.6904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7007 - val_loss: 1.6802\n",
      "Epoch 162/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6892 - val_loss: 1.7436\n",
      "Epoch 163/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6955 - val_loss: 1.7351\n",
      "Epoch 164/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6882 - val_loss: 1.7637\n",
      "Epoch 165/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6878 - val_loss: 1.7298\n",
      "Epoch 166/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6887 - val_loss: 1.6958\n",
      "Epoch 167/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6892 - val_loss: 1.8285\n",
      "Epoch 168/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6869 - val_loss: 1.6982\n",
      "Epoch 169/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6886 - val_loss: 1.6979\n",
      "Epoch 170/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6801 - val_loss: 1.7186\n",
      "Epoch 171/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6827 - val_loss: 1.6736\n",
      "Epoch 172/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6734 - val_loss: 1.7070\n",
      "Epoch 173/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6868 - val_loss: 1.6460\n",
      "Epoch 174/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6776 - val_loss: 1.7104\n",
      "Epoch 175/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6677 - val_loss: 1.6538\n",
      "Epoch 176/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6707 - val_loss: 1.6778\n",
      "Epoch 177/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6790 - val_loss: 1.6594\n",
      "Epoch 178/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6748 - val_loss: 1.6791\n",
      "Epoch 179/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6709 - val_loss: 1.7032\n",
      "Epoch 180/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6675 - val_loss: 1.6592\n",
      "Epoch 181/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6716 - val_loss: 1.7881\n",
      "Epoch 182/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6761 - val_loss: 1.7330\n",
      "Epoch 183/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6711 - val_loss: 1.6650\n",
      "Epoch 184/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6674 - val_loss: 1.6432\n",
      "Epoch 185/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6654 - val_loss: 1.7132\n",
      "Epoch 186/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6685 - val_loss: 1.6500\n",
      "Epoch 187/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6604 - val_loss: 1.6806\n",
      "Epoch 188/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6610 - val_loss: 1.7109\n",
      "Epoch 189/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6541 - val_loss: 1.7603\n",
      "Epoch 190/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6538 - val_loss: 1.6403\n",
      "Epoch 191/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6505 - val_loss: 1.6628\n",
      "Epoch 192/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6556 - val_loss: 1.6518\n",
      "Epoch 193/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6573 - val_loss: 1.7134\n",
      "Epoch 194/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6479 - val_loss: 1.6775\n",
      "Epoch 195/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6616 - val_loss: 1.7082\n",
      "Epoch 196/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6513 - val_loss: 1.8295\n",
      "Epoch 197/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6480 - val_loss: 1.6357\n",
      "Epoch 198/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6567 - val_loss: 1.6898\n",
      "Epoch 199/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6576 - val_loss: 1.6784\n",
      "Epoch 200/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6457 - val_loss: 1.6442\n",
      "Epoch 201/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6460 - val_loss: 1.7025\n",
      "Epoch 202/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6437 - val_loss: 1.6770\n",
      "Epoch 203/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6491 - val_loss: 1.6428\n",
      "Epoch 204/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6529 - val_loss: 1.7040\n",
      "Epoch 205/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6353 - val_loss: 1.6800\n",
      "Epoch 206/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6363 - val_loss: 1.6445\n",
      "Epoch 207/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6398 - val_loss: 1.6524\n",
      "Epoch 208/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6414 - val_loss: 1.6566\n",
      "Epoch 209/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6415 - val_loss: 1.6559\n",
      "Epoch 210/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6442 - val_loss: 1.6266\n",
      "Epoch 211/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6430 - val_loss: 1.7506\n",
      "Epoch 212/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6325 - val_loss: 1.6452\n",
      "Epoch 213/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6330 - val_loss: 1.7677\n",
      "Epoch 214/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6424 - val_loss: 1.6705\n",
      "Epoch 215/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6293 - val_loss: 1.7030\n",
      "Epoch 216/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6240 - val_loss: 1.7081\n",
      "Epoch 217/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6354 - val_loss: 1.6701\n",
      "Epoch 218/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6396 - val_loss: 1.6214\n",
      "Epoch 219/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6277 - val_loss: 1.6257\n",
      "Epoch 220/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6287 - val_loss: 1.6476\n",
      "Epoch 221/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6319 - val_loss: 1.6394\n",
      "Epoch 222/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6283 - val_loss: 1.6980\n",
      "Epoch 223/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6271 - val_loss: 1.6687\n",
      "Epoch 224/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6274 - val_loss: 1.5895\n",
      "Epoch 225/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6148 - val_loss: 1.6420\n",
      "Epoch 226/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6248 - val_loss: 1.6291\n",
      "Epoch 227/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6207 - val_loss: 1.6027\n",
      "Epoch 228/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6219 - val_loss: 1.6552\n",
      "Epoch 229/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6222 - val_loss: 1.6739\n",
      "Epoch 230/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6155 - val_loss: 1.6546\n",
      "Epoch 231/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6216 - val_loss: 1.6657\n",
      "Epoch 232/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6210 - val_loss: 1.6714\n",
      "Epoch 233/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6176 - val_loss: 1.6410\n",
      "Epoch 234/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6098 - val_loss: 1.6212\n",
      "Epoch 235/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6175 - val_loss: 1.6208\n",
      "Epoch 236/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6204 - val_loss: 1.6380\n",
      "Epoch 237/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6098 - val_loss: 1.6955\n",
      "Epoch 238/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6094 - val_loss: 1.6043\n",
      "Epoch 239/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6114 - val_loss: 1.6011\n",
      "Epoch 240/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6034 - val_loss: 1.6404\n",
      "Epoch 241/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6159 - val_loss: 1.6698\n",
      "Epoch 242/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6020 - val_loss: 1.6422\n",
      "Epoch 243/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6128 - val_loss: 1.6629\n",
      "Epoch 244/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6185 - val_loss: 1.5922\n",
      "Epoch 245/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6082 - val_loss: 1.6189\n",
      "Epoch 246/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6085 - val_loss: 1.6770\n",
      "Epoch 247/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6063 - val_loss: 1.6457\n",
      "Epoch 248/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6014 - val_loss: 1.5865\n",
      "Epoch 249/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6029 - val_loss: 1.6104\n",
      "Epoch 250/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5987 - val_loss: 1.6685\n",
      "Epoch 251/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5940 - val_loss: 1.6203\n",
      "Epoch 252/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5927 - val_loss: 1.6344\n",
      "Epoch 253/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6031 - val_loss: 1.6140\n",
      "Epoch 254/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6015 - val_loss: 1.6556\n",
      "Epoch 255/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5932 - val_loss: 1.6515\n",
      "Epoch 256/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6009 - val_loss: 1.7014\n",
      "Epoch 257/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5987 - val_loss: 1.6295\n",
      "Epoch 258/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5906 - val_loss: 1.6563\n",
      "Epoch 259/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5997 - val_loss: 1.6384\n",
      "Epoch 260/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5949 - val_loss: 1.6113\n",
      "Epoch 261/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5901 - val_loss: 1.7077\n",
      "Epoch 262/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5903 - val_loss: 1.6034\n",
      "Epoch 263/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5946 - val_loss: 1.5856\n",
      "Epoch 264/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5912 - val_loss: 1.7483\n",
      "Epoch 265/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5996 - val_loss: 1.6561\n",
      "Epoch 266/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5810 - val_loss: 1.6751\n",
      "Epoch 267/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5922 - val_loss: 1.6689\n",
      "Epoch 268/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5914 - val_loss: 1.6307\n",
      "Epoch 269/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5810 - val_loss: 1.5743\n",
      "Epoch 270/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5791 - val_loss: 1.5962\n",
      "Epoch 271/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5776 - val_loss: 1.6211\n",
      "Epoch 272/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5890 - val_loss: 1.6077\n",
      "Epoch 273/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5910 - val_loss: 1.6226\n",
      "Epoch 274/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5850 - val_loss: 1.6615\n",
      "Epoch 275/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5743 - val_loss: 1.6382\n",
      "Epoch 276/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5872 - val_loss: 1.6521\n",
      "Epoch 277/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5819 - val_loss: 1.6761\n",
      "Epoch 278/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5734 - val_loss: 1.5594\n",
      "Epoch 279/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5839 - val_loss: 1.6047\n",
      "Epoch 280/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5810 - val_loss: 1.5860\n",
      "Epoch 281/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5790 - val_loss: 1.6303\n",
      "Epoch 282/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5868 - val_loss: 1.6339\n",
      "Epoch 283/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5767 - val_loss: 1.6102\n",
      "Epoch 284/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5822 - val_loss: 1.5676\n",
      "Epoch 285/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5736 - val_loss: 1.5960\n",
      "Epoch 286/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5662 - val_loss: 1.5926\n",
      "Epoch 287/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5769 - val_loss: 1.5775\n",
      "Epoch 288/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5702 - val_loss: 1.5923\n",
      "Epoch 289/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5787 - val_loss: 1.6057\n",
      "Epoch 290/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5768 - val_loss: 1.5636\n",
      "Epoch 291/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5683 - val_loss: 1.6162\n",
      "Epoch 292/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5668 - val_loss: 1.5830\n",
      "Epoch 293/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5705 - val_loss: 1.6177\n",
      "Epoch 294/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5792 - val_loss: 1.6287\n",
      "Epoch 295/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5750 - val_loss: 1.8055\n",
      "Epoch 296/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5737 - val_loss: 1.5557\n",
      "Epoch 297/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5692 - val_loss: 1.5920\n",
      "Epoch 298/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5718 - val_loss: 1.6217\n",
      "Epoch 299/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5678 - val_loss: 1.5730\n",
      "Epoch 300/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5600 - val_loss: 1.6308\n",
      "Epoch 301/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5686 - val_loss: 1.6143\n",
      "Epoch 302/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5719 - val_loss: 1.5709\n",
      "Epoch 303/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5656 - val_loss: 1.6148\n",
      "Epoch 304/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5628 - val_loss: 1.6415\n",
      "Epoch 305/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5649 - val_loss: 1.5944\n",
      "Epoch 306/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5629 - val_loss: 1.5726\n",
      "Epoch 307/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5672 - val_loss: 1.5824\n",
      "Epoch 308/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5630 - val_loss: 1.6708\n",
      "Epoch 309/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5662 - val_loss: 1.5615\n",
      "Epoch 310/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5578 - val_loss: 1.6114\n",
      "Epoch 311/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5589 - val_loss: 1.5740\n",
      "Epoch 312/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5617 - val_loss: 1.5907\n",
      "Epoch 313/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5518 - val_loss: 1.5881\n",
      "Epoch 314/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5548 - val_loss: 1.7219\n",
      "Epoch 315/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5605 - val_loss: 1.5606\n",
      "Epoch 316/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5620 - val_loss: 1.6219\n",
      "Epoch 317/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5549 - val_loss: 1.6325\n",
      "Epoch 318/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5641 - val_loss: 1.5184\n",
      "Epoch 319/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5437 - val_loss: 1.6488\n",
      "Epoch 320/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5623 - val_loss: 1.6582\n",
      "Epoch 321/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5404 - val_loss: 1.5401\n",
      "Epoch 322/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5577 - val_loss: 1.6567\n",
      "Epoch 323/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5464 - val_loss: 1.5700\n",
      "Epoch 324/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5511 - val_loss: 1.5487\n",
      "Epoch 325/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5444 - val_loss: 1.6801\n",
      "Epoch 326/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5610 - val_loss: 1.5900\n",
      "Epoch 327/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5535 - val_loss: 1.5338\n",
      "Epoch 328/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5479 - val_loss: 1.5963\n",
      "Epoch 329/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5581 - val_loss: 1.6105\n",
      "Epoch 330/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5415 - val_loss: 1.6362\n",
      "Epoch 331/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5451 - val_loss: 1.5705\n",
      "Epoch 332/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5464 - val_loss: 1.5348\n",
      "Epoch 333/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5523 - val_loss: 1.5965\n",
      "Epoch 334/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5484 - val_loss: 1.5778\n",
      "Epoch 335/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5452 - val_loss: 1.6349\n",
      "Epoch 336/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5384 - val_loss: 1.5186\n",
      "Epoch 337/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5469 - val_loss: 1.5970\n",
      "Epoch 338/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5439 - val_loss: 1.5983\n",
      "Epoch 339/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5424 - val_loss: 1.5839\n",
      "Epoch 340/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5424 - val_loss: 1.6262\n",
      "Epoch 341/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5431 - val_loss: 1.5557\n",
      "Epoch 342/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5425 - val_loss: 1.5694\n",
      "Epoch 343/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5345 - val_loss: 1.5857\n",
      "Epoch 344/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5328 - val_loss: 1.5514\n",
      "Epoch 345/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5334 - val_loss: 1.5247\n",
      "Epoch 346/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5359 - val_loss: 1.5212\n",
      "Epoch 347/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5367 - val_loss: 1.6063\n",
      "Epoch 348/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5352 - val_loss: 1.6468\n",
      "Epoch 349/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5367 - val_loss: 1.6730\n",
      "Epoch 350/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5309 - val_loss: 1.5629\n",
      "Epoch 351/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5313 - val_loss: 1.5748\n",
      "Epoch 352/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5300 - val_loss: 1.5396\n",
      "Epoch 353/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5260 - val_loss: 1.5776\n",
      "Epoch 354/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5324 - val_loss: 1.5714\n",
      "Epoch 355/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5262 - val_loss: 1.5464\n",
      "Epoch 356/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5329 - val_loss: 1.5702\n",
      "Epoch 357/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5313 - val_loss: 1.5076\n",
      "Epoch 358/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5327 - val_loss: 1.5902\n",
      "Epoch 359/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5244 - val_loss: 1.5594\n",
      "Epoch 360/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5275 - val_loss: 1.5241\n",
      "Epoch 361/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5228 - val_loss: 1.5745\n",
      "Epoch 362/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5299 - val_loss: 1.5975\n",
      "Epoch 363/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5250 - val_loss: 1.4883\n",
      "Epoch 364/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5255 - val_loss: 1.5609\n",
      "Epoch 365/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5269 - val_loss: 1.5850\n",
      "Epoch 366/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5339 - val_loss: 1.5975\n",
      "Epoch 367/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5224 - val_loss: 1.5208\n",
      "Epoch 368/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5152 - val_loss: 1.5983\n",
      "Epoch 369/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5266 - val_loss: 1.5598\n",
      "Epoch 370/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5141 - val_loss: 1.6517\n",
      "Epoch 371/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5259 - val_loss: 1.5519\n",
      "Epoch 372/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5189 - val_loss: 1.5558\n",
      "Epoch 373/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5252 - val_loss: 1.5398\n",
      "Epoch 374/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5185 - val_loss: 1.5654\n",
      "Epoch 375/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5174 - val_loss: 1.5301\n",
      "Epoch 376/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5192 - val_loss: 1.5097\n",
      "Epoch 377/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5195 - val_loss: 1.6160\n",
      "Epoch 378/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5196 - val_loss: 1.5423\n",
      "Epoch 379/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5103 - val_loss: 1.6013\n",
      "Epoch 380/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5215 - val_loss: 1.5932\n",
      "Epoch 381/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5124 - val_loss: 1.5575\n",
      "Epoch 382/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5155 - val_loss: 1.5875\n",
      "Epoch 383/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5229 - val_loss: 1.6129\n",
      "Epoch 384/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5183 - val_loss: 1.5952\n",
      "Epoch 385/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5138 - val_loss: 1.5015\n",
      "Epoch 386/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5058 - val_loss: 1.5800\n",
      "Epoch 387/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5113 - val_loss: 1.5115\n",
      "Epoch 388/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5111 - val_loss: 1.5228\n",
      "Epoch 389/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5119 - val_loss: 1.5314\n",
      "Epoch 390/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5093 - val_loss: 1.5466\n",
      "Epoch 391/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5083 - val_loss: 1.5694\n",
      "Epoch 392/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5015 - val_loss: 1.5350\n",
      "Epoch 393/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4995 - val_loss: 1.4930\n",
      "Epoch 394/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5010 - val_loss: 1.5166\n",
      "Epoch 395/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5024 - val_loss: 1.5561\n",
      "Epoch 396/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5021 - val_loss: 1.5427\n",
      "Epoch 397/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4994 - val_loss: 1.5409\n",
      "Epoch 398/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5047 - val_loss: 1.5407\n",
      "Epoch 399/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5176 - val_loss: 1.5464\n",
      "Epoch 400/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5082 - val_loss: 1.5302\n",
      "Epoch 401/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5120 - val_loss: 1.5090\n",
      "Epoch 402/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5054 - val_loss: 1.5226\n",
      "Epoch 403/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5132 - val_loss: 1.5304\n",
      "Epoch 404/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5055 - val_loss: 1.5731\n",
      "Epoch 405/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4965 - val_loss: 1.5932\n",
      "Epoch 406/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5026 - val_loss: 1.5240\n",
      "Epoch 407/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5078 - val_loss: 1.5291\n",
      "Epoch 408/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5038 - val_loss: 1.5286\n",
      "Epoch 409/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5069 - val_loss: 1.6168\n",
      "Epoch 410/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4955 - val_loss: 1.5286\n",
      "Epoch 411/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4912 - val_loss: 1.5655\n",
      "Epoch 412/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4972 - val_loss: 1.5346\n",
      "Epoch 413/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5075 - val_loss: 1.5570\n",
      "Epoch 414/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5074 - val_loss: 1.5380\n",
      "Epoch 415/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4898 - val_loss: 1.6940\n",
      "Epoch 416/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5052 - val_loss: 1.5763\n",
      "Epoch 417/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4987 - val_loss: 1.5144\n",
      "Epoch 418/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4922 - val_loss: 1.5300\n",
      "Epoch 419/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4880 - val_loss: 1.5313\n",
      "Epoch 420/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5032 - val_loss: 1.5078\n",
      "Epoch 421/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4935 - val_loss: 1.5622\n",
      "Epoch 422/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4997 - val_loss: 1.4885\n",
      "Epoch 423/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4943 - val_loss: 1.4875\n",
      "Epoch 424/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4970 - val_loss: 1.5310\n",
      "Epoch 425/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4858 - val_loss: 1.5031\n",
      "Epoch 426/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4962 - val_loss: 1.5197\n",
      "Epoch 427/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4889 - val_loss: 1.5271\n",
      "Epoch 428/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4992 - val_loss: 1.5264\n",
      "Epoch 429/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4840 - val_loss: 1.5242\n",
      "Epoch 430/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4899 - val_loss: 1.5346\n",
      "Epoch 431/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5006 - val_loss: 1.6199\n",
      "Epoch 432/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4904 - val_loss: 1.4947\n",
      "Epoch 433/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4928 - val_loss: 1.5149\n",
      "Epoch 434/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4908 - val_loss: 1.5032\n",
      "Epoch 435/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4847 - val_loss: 1.4943\n",
      "Epoch 436/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4903 - val_loss: 1.5183\n",
      "Epoch 437/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4919 - val_loss: 1.5131\n",
      "Epoch 438/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4959 - val_loss: 1.4728\n",
      "Epoch 439/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5016 - val_loss: 1.5040\n",
      "Epoch 440/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4873 - val_loss: 1.5115\n",
      "Epoch 441/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4807 - val_loss: 1.5141\n",
      "Epoch 442/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4860 - val_loss: 1.5119\n",
      "Epoch 443/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4832 - val_loss: 1.5294\n",
      "Epoch 444/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4816 - val_loss: 1.5547\n",
      "Epoch 445/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4888 - val_loss: 1.5212\n",
      "Epoch 446/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4884 - val_loss: 1.4969\n",
      "Epoch 447/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4821 - val_loss: 1.5686\n",
      "Epoch 448/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4919 - val_loss: 1.5223\n",
      "Epoch 449/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4746 - val_loss: 1.5118\n",
      "Epoch 450/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4826 - val_loss: 1.4909\n",
      "Epoch 451/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4779 - val_loss: 1.4919\n",
      "Epoch 452/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4793 - val_loss: 1.4830\n",
      "Epoch 453/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4763 - val_loss: 1.5330\n",
      "Epoch 454/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4834 - val_loss: 1.5795\n",
      "Epoch 455/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4766 - val_loss: 1.4797\n",
      "Epoch 456/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4779 - val_loss: 1.4671\n",
      "Epoch 457/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4808 - val_loss: 1.5514\n",
      "Epoch 458/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4694 - val_loss: 1.5299\n",
      "Epoch 459/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4814 - val_loss: 1.6001\n",
      "Epoch 460/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4711 - val_loss: 1.5165\n",
      "Epoch 461/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4785 - val_loss: 1.4759\n",
      "Epoch 462/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4765 - val_loss: 1.4804\n",
      "Epoch 463/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4643 - val_loss: 1.5480\n",
      "Epoch 464/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4749 - val_loss: 1.5824\n",
      "Epoch 465/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4746 - val_loss: 1.5311\n",
      "Epoch 466/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4716 - val_loss: 1.5515\n",
      "Epoch 467/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4665 - val_loss: 1.5030\n",
      "Epoch 468/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4725 - val_loss: 1.5277\n",
      "Epoch 469/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4719 - val_loss: 1.4825\n",
      "Epoch 470/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4655 - val_loss: 1.5387\n",
      "Epoch 471/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4726 - val_loss: 1.5227\n",
      "Epoch 472/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4703 - val_loss: 1.4998\n",
      "Epoch 473/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4664 - val_loss: 1.4746\n",
      "Epoch 474/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4713 - val_loss: 1.5001\n",
      "Epoch 475/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4648 - val_loss: 1.4489\n",
      "Epoch 476/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4615 - val_loss: 1.5213\n",
      "Epoch 477/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4649 - val_loss: 1.5162\n",
      "Epoch 478/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4710 - val_loss: 1.4934\n",
      "Epoch 479/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4739 - val_loss: 1.5232\n",
      "Epoch 480/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4596 - val_loss: 1.5621\n",
      "Epoch 481/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4685 - val_loss: 1.4535\n",
      "Epoch 482/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4713 - val_loss: 1.4608\n",
      "Epoch 483/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4689 - val_loss: 1.5506\n",
      "Epoch 484/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4740 - val_loss: 1.5136\n",
      "Epoch 485/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4572 - val_loss: 1.5173\n",
      "Epoch 486/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4684 - val_loss: 1.4795\n",
      "Epoch 487/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4612 - val_loss: 1.4820\n",
      "Epoch 488/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4699 - val_loss: 1.4701\n",
      "Epoch 489/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4645 - val_loss: 1.5442\n",
      "Epoch 490/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4685 - val_loss: 1.5179\n",
      "Epoch 491/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4616 - val_loss: 1.5512\n",
      "Epoch 492/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4649 - val_loss: 1.4934\n",
      "Epoch 493/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4615 - val_loss: 1.5158\n",
      "Epoch 494/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4646 - val_loss: 1.5303\n",
      "Epoch 495/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4573 - val_loss: 1.4901\n",
      "Epoch 496/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4618 - val_loss: 1.5032\n",
      "Epoch 497/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4581 - val_loss: 1.5235\n",
      "Epoch 498/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4549 - val_loss: 1.4967\n",
      "Epoch 499/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4606 - val_loss: 1.5147\n",
      "Epoch 500/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4609 - val_loss: 1.5125\n",
      "Epoch 501/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4618 - val_loss: 1.4688\n",
      "Epoch 502/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4594 - val_loss: 1.4629\n",
      "Epoch 503/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4471 - val_loss: 1.4997\n",
      "Epoch 504/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4605 - val_loss: 1.4946\n",
      "Epoch 505/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4509 - val_loss: 1.4508\n",
      "Epoch 506/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4531 - val_loss: 1.5433\n",
      "Epoch 507/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4546 - val_loss: 1.5761\n",
      "Epoch 508/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4435 - val_loss: 1.4402\n",
      "Epoch 509/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4595 - val_loss: 1.4162\n",
      "Epoch 510/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4610 - val_loss: 1.5083\n",
      "Epoch 511/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4549 - val_loss: 1.4293\n",
      "Epoch 512/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4501 - val_loss: 1.5667\n",
      "Epoch 513/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4485 - val_loss: 1.4526\n",
      "Epoch 514/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4457 - val_loss: 1.4669\n",
      "Epoch 515/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4538 - val_loss: 1.4818\n",
      "Epoch 516/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4550 - val_loss: 1.4670\n",
      "Epoch 517/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4574 - val_loss: 1.4714\n",
      "Epoch 518/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4577 - val_loss: 1.4584\n",
      "Epoch 519/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4540 - val_loss: 1.5100\n",
      "Epoch 520/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4568 - val_loss: 1.4525\n",
      "Epoch 521/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4586 - val_loss: 1.4793\n",
      "Epoch 522/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4495 - val_loss: 1.4940\n",
      "Epoch 523/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4533 - val_loss: 1.4620\n",
      "Epoch 524/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4462 - val_loss: 1.4907\n",
      "Epoch 525/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4448 - val_loss: 1.4990\n",
      "Epoch 526/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4518 - val_loss: 1.4636\n",
      "Epoch 527/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4477 - val_loss: 1.4867\n",
      "Epoch 528/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4473 - val_loss: 1.4842\n",
      "Epoch 529/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4476 - val_loss: 1.4590\n",
      "Epoch 530/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4418 - val_loss: 1.4738\n",
      "Epoch 531/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4485 - val_loss: 1.4458\n",
      "Epoch 532/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4397 - val_loss: 1.4747\n",
      "Epoch 533/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4523 - val_loss: 1.4722\n",
      "Epoch 534/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4532 - val_loss: 1.4767\n",
      "Epoch 535/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4380 - val_loss: 1.4728\n",
      "Epoch 536/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4485 - val_loss: 1.5316\n",
      "Epoch 537/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4482 - val_loss: 1.6200\n",
      "Epoch 538/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4446 - val_loss: 1.4981\n",
      "Epoch 539/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4422 - val_loss: 1.5528\n",
      "Epoch 540/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4484 - val_loss: 1.4790\n",
      "Epoch 541/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4517 - val_loss: 1.4541\n",
      "Epoch 542/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4462 - val_loss: 1.5239\n",
      "Epoch 543/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4464 - val_loss: 1.5447\n",
      "Epoch 544/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4413 - val_loss: 1.5524\n",
      "Epoch 545/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4372 - val_loss: 1.4548\n",
      "Epoch 546/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4428 - val_loss: 1.4277\n",
      "Epoch 547/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4423 - val_loss: 1.4366\n",
      "Epoch 548/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4427 - val_loss: 1.4370\n",
      "Epoch 549/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4404 - val_loss: 1.4836\n",
      "Epoch 550/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4411 - val_loss: 1.5139\n",
      "Epoch 551/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4455 - val_loss: 1.4259\n",
      "Epoch 552/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4475 - val_loss: 1.5214\n",
      "Epoch 553/900\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 1.4448 - val_loss: 1.4632\n",
      "Epoch 554/900\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 1.4391 - val_loss: 1.5471\n",
      "Epoch 555/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4355 - val_loss: 1.5144\n",
      "Epoch 556/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4406 - val_loss: 1.4782\n",
      "Epoch 557/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4323 - val_loss: 1.4952\n",
      "Epoch 558/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4405 - val_loss: 1.4691\n",
      "Epoch 559/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4324 - val_loss: 1.5102\n",
      "Epoch 560/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4426 - val_loss: 1.5492\n",
      "Epoch 561/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4441 - val_loss: 1.5230\n",
      "Epoch 562/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4359 - val_loss: 1.4324\n",
      "Epoch 563/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4371 - val_loss: 1.4504\n",
      "Epoch 564/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4393 - val_loss: 1.4825\n",
      "Epoch 565/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4408 - val_loss: 1.4785\n",
      "Epoch 566/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4313 - val_loss: 1.4577\n",
      "Epoch 567/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4364 - val_loss: 1.4647\n",
      "Epoch 568/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4297 - val_loss: 1.4372\n",
      "Epoch 569/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4289 - val_loss: 1.4291\n",
      "Epoch 570/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4401 - val_loss: 1.4587\n",
      "Epoch 571/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4334 - val_loss: 1.5555\n",
      "Epoch 572/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4304 - val_loss: 1.4027\n",
      "Epoch 573/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4424 - val_loss: 1.4518\n",
      "Epoch 574/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4362 - val_loss: 1.5231\n",
      "Epoch 575/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4261 - val_loss: 1.5276\n",
      "Epoch 576/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4404 - val_loss: 1.4927\n",
      "Epoch 577/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4292 - val_loss: 1.4719\n",
      "Epoch 578/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4422 - val_loss: 1.4668\n",
      "Epoch 579/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4317 - val_loss: 1.4406\n",
      "Epoch 580/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4301 - val_loss: 1.6323\n",
      "Epoch 581/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4293 - val_loss: 1.4905\n",
      "Epoch 582/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4359 - val_loss: 1.5020\n",
      "Epoch 583/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4336 - val_loss: 1.4358\n",
      "Epoch 584/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4179 - val_loss: 1.4404\n",
      "Epoch 585/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4411 - val_loss: 1.4421\n",
      "Epoch 586/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4207 - val_loss: 1.4240\n",
      "Epoch 587/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4368 - val_loss: 1.4700\n",
      "Epoch 588/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4247 - val_loss: 1.4387\n",
      "Epoch 589/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4282 - val_loss: 1.5714\n",
      "Epoch 590/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4341 - val_loss: 1.4611\n",
      "Epoch 591/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4265 - val_loss: 1.4688\n",
      "Epoch 592/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4264 - val_loss: 1.4311\n",
      "Epoch 593/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4343 - val_loss: 1.6113\n",
      "Epoch 594/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4244 - val_loss: 1.4709\n",
      "Epoch 595/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4297 - val_loss: 1.4475\n",
      "Epoch 596/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4287 - val_loss: 1.4121\n",
      "Epoch 597/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4314 - val_loss: 1.4560\n",
      "Epoch 598/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4235 - val_loss: 1.4816\n",
      "Epoch 599/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4334 - val_loss: 1.4459\n",
      "Epoch 600/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4210 - val_loss: 1.4763\n",
      "Epoch 601/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4250 - val_loss: 1.3828\n",
      "Epoch 602/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4256 - val_loss: 1.4526\n",
      "Epoch 603/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4256 - val_loss: 1.4241\n",
      "Epoch 604/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4302 - val_loss: 1.4486\n",
      "Epoch 605/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4227 - val_loss: 1.4943\n",
      "Epoch 606/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4246 - val_loss: 1.4184\n",
      "Epoch 607/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4196 - val_loss: 1.4290\n",
      "Epoch 608/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4333 - val_loss: 1.5171\n",
      "Epoch 609/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4153 - val_loss: 1.4493\n",
      "Epoch 610/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4238 - val_loss: 1.5019\n",
      "Epoch 611/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4249 - val_loss: 1.5041\n",
      "Epoch 612/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4213 - val_loss: 1.4698\n",
      "Epoch 613/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4164 - val_loss: 1.4222\n",
      "Epoch 614/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4293 - val_loss: 1.4666\n",
      "Epoch 615/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4156 - val_loss: 1.4941\n",
      "Epoch 616/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4218 - val_loss: 1.4803\n",
      "Epoch 617/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4211 - val_loss: 1.4633\n",
      "Epoch 618/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4204 - val_loss: 1.4705\n",
      "Epoch 619/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4317 - val_loss: 1.5622\n",
      "Epoch 620/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4172 - val_loss: 1.5220\n",
      "Epoch 621/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4193 - val_loss: 1.4627\n",
      "Epoch 622/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4259 - val_loss: 1.5344\n",
      "Epoch 623/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4330 - val_loss: 1.4869\n",
      "Epoch 624/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4197 - val_loss: 1.5048\n",
      "Epoch 625/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4279 - val_loss: 1.4224\n",
      "Epoch 626/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4283 - val_loss: 1.4315\n",
      "Epoch 627/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4114 - val_loss: 1.6153\n",
      "Epoch 628/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4203 - val_loss: 1.4403\n",
      "Epoch 629/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4295 - val_loss: 1.5500\n",
      "Epoch 630/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4215 - val_loss: 1.4515\n",
      "Epoch 631/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4206 - val_loss: 1.4696\n",
      "Epoch 632/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4204 - val_loss: 1.4052\n",
      "Epoch 633/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4280 - val_loss: 1.5536\n",
      "Epoch 634/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4181 - val_loss: 1.4457\n",
      "Epoch 635/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4154 - val_loss: 1.4170\n",
      "Epoch 636/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4216 - val_loss: 1.4804\n",
      "Epoch 637/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4240 - val_loss: 1.4928\n",
      "Epoch 638/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4141 - val_loss: 1.4566\n",
      "Epoch 639/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4279 - val_loss: 1.4082\n",
      "Epoch 640/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4207 - val_loss: 1.4241\n",
      "Epoch 641/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4191 - val_loss: 1.4521\n",
      "Epoch 642/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4165 - val_loss: 1.4206\n",
      "Epoch 643/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4237 - val_loss: 1.4769\n",
      "Epoch 644/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4136 - val_loss: 1.3960\n",
      "Epoch 645/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4188 - val_loss: 1.4144\n",
      "Epoch 646/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4119 - val_loss: 1.4494\n",
      "Epoch 647/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4200 - val_loss: 1.5143\n",
      "Epoch 648/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4157 - val_loss: 1.4674\n",
      "Epoch 649/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4286 - val_loss: 1.4166\n",
      "Epoch 650/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4152 - val_loss: 1.4598\n",
      "Epoch 651/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4084 - val_loss: 1.4194\n",
      "Epoch 652/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3988 - val_loss: 1.4782\n",
      "Epoch 653/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4111 - val_loss: 1.4180\n",
      "Epoch 654/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4049 - val_loss: 1.4641\n",
      "Epoch 655/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4169 - val_loss: 1.4114\n",
      "Epoch 656/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4146 - val_loss: 1.4093\n",
      "Epoch 657/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4189 - val_loss: 1.4556\n",
      "Epoch 658/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4092 - val_loss: 1.5071\n",
      "Epoch 659/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4150 - val_loss: 1.4687\n",
      "Epoch 660/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4181 - val_loss: 1.4893\n",
      "Epoch 661/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4155 - val_loss: 1.4380\n",
      "Epoch 662/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4178 - val_loss: 1.4807\n",
      "Epoch 663/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4057 - val_loss: 1.4487\n",
      "Epoch 664/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4082 - val_loss: 1.4966\n",
      "Epoch 665/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4097 - val_loss: 1.4104\n",
      "Epoch 666/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4176 - val_loss: 1.4259\n",
      "Epoch 667/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4093 - val_loss: 1.4186\n",
      "Epoch 668/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4081 - val_loss: 1.4915\n",
      "Epoch 669/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4162 - val_loss: 1.4014\n",
      "Epoch 670/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4122 - val_loss: 1.4573\n",
      "Epoch 671/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3999 - val_loss: 1.4271\n",
      "Epoch 672/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4126 - val_loss: 1.4576\n",
      "Epoch 673/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4110 - val_loss: 1.4505\n",
      "Epoch 674/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4152 - val_loss: 1.4283\n",
      "Epoch 675/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4187 - val_loss: 1.4231\n",
      "Epoch 676/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4153 - val_loss: 1.4253\n",
      "Epoch 677/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4146 - val_loss: 1.4788\n",
      "Epoch 678/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4093 - val_loss: 1.4389\n",
      "Epoch 679/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4028 - val_loss: 1.4135\n",
      "Epoch 680/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3997 - val_loss: 1.4545\n",
      "Epoch 681/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4051 - val_loss: 1.4534\n",
      "Epoch 682/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4121 - val_loss: 1.4123\n",
      "Epoch 683/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4078 - val_loss: 1.5485\n",
      "Epoch 684/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4079 - val_loss: 1.3955\n",
      "Epoch 685/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4067 - val_loss: 1.4720\n",
      "Epoch 686/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4058 - val_loss: 1.4266\n",
      "Epoch 687/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4070 - val_loss: 1.4154\n",
      "Epoch 688/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4069 - val_loss: 1.4127\n",
      "Epoch 689/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4008 - val_loss: 1.3888\n",
      "Epoch 690/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4048 - val_loss: 1.4813\n",
      "Epoch 691/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4032 - val_loss: 1.4600\n",
      "Epoch 692/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4096 - val_loss: 1.4007\n",
      "Epoch 693/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4035 - val_loss: 1.4245\n",
      "Epoch 694/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4120 - val_loss: 1.4990\n",
      "Epoch 695/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3951 - val_loss: 1.4142\n",
      "Epoch 696/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4079 - val_loss: 1.4540\n",
      "Epoch 697/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4008 - val_loss: 1.4013\n",
      "Epoch 698/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4025 - val_loss: 1.4720\n",
      "Epoch 699/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4079 - val_loss: 1.4223\n",
      "Epoch 700/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4027 - val_loss: 1.4975\n",
      "Epoch 701/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4041 - val_loss: 1.4200\n",
      "Epoch 702/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4007 - val_loss: 1.5235\n",
      "Epoch 703/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4053 - val_loss: 1.4375\n",
      "Epoch 704/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4034 - val_loss: 1.4067\n",
      "Epoch 705/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4015 - val_loss: 1.4168\n",
      "Epoch 706/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3972 - val_loss: 1.4449\n",
      "Epoch 707/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4133 - val_loss: 1.4535\n",
      "Epoch 708/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4074 - val_loss: 1.4434\n",
      "Epoch 709/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3982 - val_loss: 1.3811\n",
      "Epoch 710/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3987 - val_loss: 1.4342\n",
      "Epoch 711/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4012 - val_loss: 1.4564\n",
      "Epoch 712/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4006 - val_loss: 1.4390\n",
      "Epoch 713/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4013 - val_loss: 1.4468\n",
      "Epoch 714/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4050 - val_loss: 1.4571\n",
      "Epoch 715/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3995 - val_loss: 1.4005\n",
      "Epoch 716/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3983 - val_loss: 1.4658\n",
      "Epoch 717/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3966 - val_loss: 1.4370\n",
      "Epoch 718/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4014 - val_loss: 1.4211\n",
      "Epoch 719/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4001 - val_loss: 1.4411\n",
      "Epoch 720/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4020 - val_loss: 1.5088\n",
      "Epoch 721/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3949 - val_loss: 1.4682\n",
      "Epoch 722/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3991 - val_loss: 1.4552\n",
      "Epoch 723/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4056 - val_loss: 1.4027\n",
      "Epoch 724/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3940 - val_loss: 1.4211\n",
      "Epoch 725/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.3929 - val_loss: 1.4132\n",
      "Epoch 726/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3978 - val_loss: 1.4285\n",
      "Epoch 727/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3998 - val_loss: 1.4180\n",
      "Epoch 728/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3998 - val_loss: 1.4400\n",
      "Epoch 729/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3986 - val_loss: 1.5372\n",
      "Epoch 730/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3955 - val_loss: 1.4093\n",
      "Epoch 731/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3998 - val_loss: 1.4343\n",
      "Epoch 732/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3927 - val_loss: 1.3951\n",
      "Epoch 733/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3994 - val_loss: 1.4732\n",
      "Epoch 734/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4008 - val_loss: 1.4377\n",
      "Epoch 735/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3940 - val_loss: 1.4250\n",
      "Epoch 736/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3939 - val_loss: 1.3840\n",
      "Epoch 737/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4020 - val_loss: 1.4510\n",
      "Epoch 738/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.3961 - val_loss: 1.4140\n",
      "Epoch 739/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4017 - val_loss: 1.4050\n",
      "Epoch 740/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3968 - val_loss: 1.4340\n",
      "Epoch 741/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3928 - val_loss: 1.4184\n",
      "Epoch 742/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4011 - val_loss: 1.4173\n",
      "Epoch 743/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3987 - val_loss: 1.4335\n",
      "Epoch 744/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3975 - val_loss: 1.5012\n",
      "Epoch 745/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3963 - val_loss: 1.4187\n",
      "Epoch 746/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3875 - val_loss: 1.5097\n",
      "Epoch 747/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3937 - val_loss: 1.3774\n",
      "Epoch 748/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3977 - val_loss: 1.4019\n",
      "Epoch 749/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3836 - val_loss: 1.3834\n",
      "Epoch 750/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3874 - val_loss: 1.4942\n",
      "Epoch 751/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3893 - val_loss: 1.4615\n",
      "Epoch 752/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3936 - val_loss: 1.3870\n",
      "Epoch 753/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3933 - val_loss: 1.4308\n",
      "Epoch 754/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3920 - val_loss: 1.4537\n",
      "Epoch 755/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3954 - val_loss: 1.4617\n",
      "Epoch 756/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3913 - val_loss: 1.4431\n",
      "Epoch 757/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3935 - val_loss: 1.4335\n",
      "Epoch 758/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3876 - val_loss: 1.3669\n",
      "Epoch 759/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4012 - val_loss: 1.4443\n",
      "Epoch 760/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3860 - val_loss: 1.3996\n",
      "Epoch 761/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3807 - val_loss: 1.5067\n",
      "Epoch 762/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3895 - val_loss: 1.4002\n",
      "Epoch 763/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3927 - val_loss: 1.3962\n",
      "Epoch 764/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3837 - val_loss: 1.3798\n",
      "Epoch 765/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3996 - val_loss: 1.4201\n",
      "Epoch 766/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3920 - val_loss: 1.3947\n",
      "Epoch 767/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3956 - val_loss: 1.4070\n",
      "Epoch 768/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3919 - val_loss: 1.4522\n",
      "Epoch 769/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3962 - val_loss: 1.4507\n",
      "Epoch 770/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3837 - val_loss: 1.4482\n",
      "Epoch 771/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3809 - val_loss: 1.3926\n",
      "Epoch 772/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3879 - val_loss: 1.4598\n",
      "Epoch 773/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3928 - val_loss: 1.3939\n",
      "Epoch 774/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3876 - val_loss: 1.3985\n",
      "Epoch 775/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3893 - val_loss: 1.4000\n",
      "Epoch 776/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3901 - val_loss: 1.4148\n",
      "Epoch 777/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3853 - val_loss: 1.4044\n",
      "Epoch 778/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3874 - val_loss: 1.4019\n",
      "Epoch 779/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3834 - val_loss: 1.4000\n",
      "Epoch 780/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3808 - val_loss: 1.4197\n",
      "Epoch 781/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3826 - val_loss: 1.3891\n",
      "Epoch 782/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3794 - val_loss: 1.4211\n",
      "Epoch 783/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3846 - val_loss: 1.4509\n",
      "Epoch 784/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3788 - val_loss: 1.3818\n",
      "Epoch 785/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3896 - val_loss: 1.4245\n",
      "Epoch 786/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3825 - val_loss: 1.4120\n",
      "Epoch 787/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3886 - val_loss: 1.4365\n",
      "Epoch 788/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3791 - val_loss: 1.4075\n",
      "Epoch 789/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3876 - val_loss: 1.3758\n",
      "Epoch 790/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3846 - val_loss: 1.4598\n",
      "Epoch 791/900\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.3909 - val_loss: 1.4233\n",
      "Epoch 792/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3890 - val_loss: 1.3494\n",
      "Epoch 793/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3735 - val_loss: 1.4038\n",
      "Epoch 794/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3863 - val_loss: 1.4087\n",
      "Epoch 795/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3863 - val_loss: 1.3845\n",
      "Epoch 796/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3825 - val_loss: 1.5098\n",
      "Epoch 797/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3751 - val_loss: 1.4007\n",
      "Epoch 798/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3831 - val_loss: 1.4404\n",
      "Epoch 799/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3781 - val_loss: 1.4230\n",
      "Epoch 800/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3740 - val_loss: 1.4200\n",
      "Epoch 801/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3858 - val_loss: 1.4096\n",
      "Epoch 802/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3785 - val_loss: 1.4373\n",
      "Epoch 803/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3684 - val_loss: 1.4254\n",
      "Epoch 804/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.3808 - val_loss: 1.4258\n",
      "Epoch 805/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3847 - val_loss: 1.3807\n",
      "Epoch 806/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3852 - val_loss: 1.4171\n",
      "Epoch 807/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3839 - val_loss: 1.4128\n",
      "Epoch 808/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3834 - val_loss: 1.3858\n",
      "Epoch 809/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3824 - val_loss: 1.4228\n",
      "Epoch 810/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3790 - val_loss: 1.4097\n",
      "Epoch 811/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3857 - val_loss: 1.4018\n",
      "Epoch 812/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3736 - val_loss: 1.4685\n",
      "Epoch 813/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3785 - val_loss: 1.3776\n",
      "Epoch 814/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3752 - val_loss: 1.4097\n",
      "Epoch 815/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3763 - val_loss: 1.4154\n",
      "Epoch 816/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3863 - val_loss: 1.4724\n",
      "Epoch 817/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.3852 - val_loss: 1.3696\n",
      "Epoch 818/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3797 - val_loss: 1.4003\n",
      "Epoch 819/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3742 - val_loss: 1.3985\n",
      "Epoch 820/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3758 - val_loss: 1.3965\n",
      "Epoch 821/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3852 - val_loss: 1.4034\n",
      "Epoch 822/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3830 - val_loss: 1.4081\n",
      "Epoch 823/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3762 - val_loss: 1.4051\n",
      "Epoch 824/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3734 - val_loss: 1.4250\n",
      "Epoch 825/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3826 - val_loss: 1.4280\n",
      "Epoch 826/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3838 - val_loss: 1.3970\n",
      "Epoch 827/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3782 - val_loss: 1.3957\n",
      "Epoch 828/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3765 - val_loss: 1.3782\n",
      "Epoch 829/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3743 - val_loss: 1.3910\n",
      "Epoch 830/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3722 - val_loss: 1.3699\n",
      "Epoch 831/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3761 - val_loss: 1.5489\n",
      "Epoch 832/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3734 - val_loss: 1.4394\n",
      "Epoch 833/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3774 - val_loss: 1.3905\n",
      "Epoch 834/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3754 - val_loss: 1.4384\n",
      "Epoch 835/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3841 - val_loss: 1.4021\n",
      "Epoch 836/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3743 - val_loss: 1.4627\n",
      "Epoch 837/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3792 - val_loss: 1.3887\n",
      "Epoch 838/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3879 - val_loss: 1.3965\n",
      "Epoch 839/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3664 - val_loss: 1.3748\n",
      "Epoch 840/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3797 - val_loss: 1.3942\n",
      "Epoch 841/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3814 - val_loss: 1.4371\n",
      "Epoch 842/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3807 - val_loss: 1.4458\n",
      "Epoch 843/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3777 - val_loss: 1.3942\n",
      "Epoch 844/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3768 - val_loss: 1.4612\n",
      "Epoch 845/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3818 - val_loss: 1.4065\n",
      "Epoch 846/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3788 - val_loss: 1.3669\n",
      "Epoch 847/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3786 - val_loss: 1.4263\n",
      "Epoch 848/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3834 - val_loss: 1.3951\n",
      "Epoch 849/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3730 - val_loss: 1.3836\n",
      "Epoch 850/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3773 - val_loss: 1.3675\n",
      "Epoch 851/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3748 - val_loss: 1.3618\n",
      "Epoch 852/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3671 - val_loss: 1.3677\n",
      "Epoch 853/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3821 - val_loss: 1.3897\n",
      "Epoch 854/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3686 - val_loss: 1.4234\n",
      "Epoch 855/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3806 - val_loss: 1.4130\n",
      "Epoch 856/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.3601 - val_loss: 1.4424\n",
      "Epoch 857/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.3735 - val_loss: 1.4680\n",
      "Epoch 858/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3759 - val_loss: 1.3796\n",
      "Epoch 859/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3737 - val_loss: 1.4940\n",
      "Epoch 860/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3721 - val_loss: 1.4217\n",
      "Epoch 861/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3717 - val_loss: 1.3864\n",
      "Epoch 862/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3746 - val_loss: 1.4324\n",
      "Epoch 863/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3702 - val_loss: 1.4339\n",
      "Epoch 864/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3690 - val_loss: 1.3617\n",
      "Epoch 865/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3642 - val_loss: 1.4183\n",
      "Epoch 866/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3638 - val_loss: 1.4382\n",
      "Epoch 867/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3698 - val_loss: 1.3644\n",
      "Epoch 868/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3694 - val_loss: 1.4423\n",
      "Epoch 869/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3643 - val_loss: 1.4101\n",
      "Epoch 870/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.3713 - val_loss: 1.4740\n",
      "Epoch 871/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3706 - val_loss: 1.4797\n",
      "Epoch 872/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3706 - val_loss: 1.4452\n",
      "Epoch 873/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3692 - val_loss: 1.4052\n",
      "Epoch 874/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3694 - val_loss: 1.4182\n",
      "Epoch 875/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3630 - val_loss: 1.4195\n",
      "Epoch 876/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3711 - val_loss: 1.3870\n",
      "Epoch 877/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3671 - val_loss: 1.4167\n",
      "Epoch 878/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3691 - val_loss: 1.4055\n",
      "Epoch 879/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3627 - val_loss: 1.3999\n",
      "Epoch 880/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3751 - val_loss: 1.3782\n",
      "Epoch 881/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3663 - val_loss: 1.5221\n",
      "Epoch 882/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3710 - val_loss: 1.4281\n",
      "Epoch 883/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3738 - val_loss: 1.3516\n",
      "Epoch 884/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3727 - val_loss: 1.3916\n",
      "Epoch 885/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3671 - val_loss: 1.3842\n",
      "Epoch 886/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3599 - val_loss: 1.3742\n",
      "Epoch 887/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3730 - val_loss: 1.4682\n",
      "Epoch 888/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3621 - val_loss: 1.3619\n",
      "Epoch 889/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3718 - val_loss: 1.3982\n",
      "Epoch 890/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3693 - val_loss: 1.4035\n",
      "Epoch 891/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3689 - val_loss: 1.3821\n",
      "Epoch 892/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3650 - val_loss: 1.4360\n",
      "Epoch 893/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3673 - val_loss: 1.3888\n",
      "Epoch 894/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3688 - val_loss: 1.4053\n",
      "Epoch 895/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3638 - val_loss: 1.3680\n",
      "Epoch 896/900\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.3647 - val_loss: 1.3716\n",
      "Epoch 897/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3659 - val_loss: 1.3870\n",
      "Epoch 898/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3643 - val_loss: 1.4732\n",
      "Epoch 899/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3658 - val_loss: 1.4196\n",
      "Epoch 900/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3656 - val_loss: 1.4751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4751341580773174\n",
      "0.9691166584423421\n",
      "Epoch 1/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 10.4195 - val_loss: 5.5270\n",
      "Epoch 2/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 5.2542 - val_loss: 4.8959\n",
      "Epoch 3/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.6501 - val_loss: 4.5158\n",
      "Epoch 4/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.5090 - val_loss: 6.1353\n",
      "Epoch 5/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.3504 - val_loss: 3.6596\n",
      "Epoch 6/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 4.3406 - val_loss: 3.6868\n",
      "Epoch 7/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.7221 - val_loss: 3.3408\n",
      "Epoch 8/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 3.5696 - val_loss: 4.0098\n",
      "Epoch 9/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.3813 - val_loss: 3.2526\n",
      "Epoch 10/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.2008 - val_loss: 4.0843\n",
      "Epoch 11/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.2173 - val_loss: 2.8695\n",
      "Epoch 12/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.0951 - val_loss: 2.8207\n",
      "Epoch 13/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 3.0022 - val_loss: 2.8780\n",
      "Epoch 14/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.8815 - val_loss: 2.9472\n",
      "Epoch 15/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.8591 - val_loss: 2.5831\n",
      "Epoch 16/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.7698 - val_loss: 2.8248\n",
      "Epoch 17/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.7574 - val_loss: 2.6641\n",
      "Epoch 18/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.6610 - val_loss: 2.7608\n",
      "Epoch 19/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.6112 - val_loss: 2.7963\n",
      "Epoch 20/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.5374 - val_loss: 2.5986\n",
      "Epoch 21/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.5247 - val_loss: 2.6047\n",
      "Epoch 22/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.4888 - val_loss: 2.5820\n",
      "Epoch 23/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.4421 - val_loss: 2.5053\n",
      "Epoch 24/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.4312 - val_loss: 2.2996\n",
      "Epoch 25/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.3968 - val_loss: 2.3437\n",
      "Epoch 26/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.3566 - val_loss: 2.2655\n",
      "Epoch 27/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.3438 - val_loss: 2.2814\n",
      "Epoch 28/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.3336 - val_loss: 2.2268\n",
      "Epoch 29/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2921 - val_loss: 2.2140\n",
      "Epoch 30/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2692 - val_loss: 2.1669\n",
      "Epoch 31/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.2616 - val_loss: 2.2313\n",
      "Epoch 32/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2398 - val_loss: 2.1220\n",
      "Epoch 33/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2184 - val_loss: 2.1935\n",
      "Epoch 34/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2120 - val_loss: 2.2703\n",
      "Epoch 35/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.1808 - val_loss: 2.1018\n",
      "Epoch 36/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1467 - val_loss: 2.1314\n",
      "Epoch 37/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.1564 - val_loss: 2.4313\n",
      "Epoch 38/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1557 - val_loss: 2.0542\n",
      "Epoch 39/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.1051 - val_loss: 2.1308\n",
      "Epoch 40/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0951 - val_loss: 2.1284\n",
      "Epoch 41/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0922 - val_loss: 2.2071\n",
      "Epoch 42/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0722 - val_loss: 2.1016\n",
      "Epoch 43/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0544 - val_loss: 2.0832\n",
      "Epoch 44/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0491 - val_loss: 2.0238\n",
      "Epoch 45/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0617 - val_loss: 2.0730\n",
      "Epoch 46/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0352 - val_loss: 1.9882\n",
      "Epoch 47/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0258 - val_loss: 1.9936\n",
      "Epoch 48/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0274 - val_loss: 2.0805\n",
      "Epoch 49/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0164 - val_loss: 1.9551\n",
      "Epoch 50/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0057 - val_loss: 1.9514\n",
      "Epoch 51/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.0017 - val_loss: 2.0582\n",
      "Epoch 52/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9884 - val_loss: 2.0051\n",
      "Epoch 53/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0017 - val_loss: 2.0165\n",
      "Epoch 54/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9778 - val_loss: 2.1112\n",
      "Epoch 55/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9651 - val_loss: 1.9330\n",
      "Epoch 56/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9702 - val_loss: 2.0167\n",
      "Epoch 57/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9484 - val_loss: 1.9876\n",
      "Epoch 58/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9562 - val_loss: 1.9009\n",
      "Epoch 59/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9211 - val_loss: 2.0157\n",
      "Epoch 60/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9212 - val_loss: 1.8918\n",
      "Epoch 61/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9212 - val_loss: 1.9450\n",
      "Epoch 62/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9172 - val_loss: 1.8868\n",
      "Epoch 63/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9173 - val_loss: 1.9043\n",
      "Epoch 64/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9100 - val_loss: 1.9068\n",
      "Epoch 65/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8972 - val_loss: 1.9128\n",
      "Epoch 66/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8995 - val_loss: 1.8415\n",
      "Epoch 67/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8928 - val_loss: 1.9801\n",
      "Epoch 68/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8853 - val_loss: 1.8971\n",
      "Epoch 69/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8708 - val_loss: 1.8437\n",
      "Epoch 70/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8785 - val_loss: 1.8865\n",
      "Epoch 71/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8781 - val_loss: 1.9919\n",
      "Epoch 72/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8732 - val_loss: 1.8163\n",
      "Epoch 73/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8505 - val_loss: 1.7891\n",
      "Epoch 74/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8534 - val_loss: 1.8626\n",
      "Epoch 75/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8523 - val_loss: 1.8632\n",
      "Epoch 76/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8404 - val_loss: 1.8202\n",
      "Epoch 77/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8474 - val_loss: 2.0323\n",
      "Epoch 78/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8313 - val_loss: 1.8942\n",
      "Epoch 79/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8405 - val_loss: 1.7987\n",
      "Epoch 80/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8282 - val_loss: 1.9182\n",
      "Epoch 81/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8250 - val_loss: 1.8227\n",
      "Epoch 82/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8272 - val_loss: 1.8682\n",
      "Epoch 83/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8097 - val_loss: 1.9573\n",
      "Epoch 84/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8311 - val_loss: 1.7786\n",
      "Epoch 85/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8254 - val_loss: 1.8645\n",
      "Epoch 86/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8076 - val_loss: 1.8349\n",
      "Epoch 87/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8024 - val_loss: 1.8682\n",
      "Epoch 88/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.8082 - val_loss: 1.7776\n",
      "Epoch 89/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7922 - val_loss: 1.8451\n",
      "Epoch 90/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7967 - val_loss: 1.8048\n",
      "Epoch 91/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7906 - val_loss: 1.7902\n",
      "Epoch 92/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7968 - val_loss: 1.8732\n",
      "Epoch 93/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7785 - val_loss: 1.7529\n",
      "Epoch 94/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7701 - val_loss: 1.7530\n",
      "Epoch 95/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7722 - val_loss: 1.7773\n",
      "Epoch 96/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7704 - val_loss: 1.8989\n",
      "Epoch 97/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7646 - val_loss: 1.7176\n",
      "Epoch 98/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7702 - val_loss: 1.8456\n",
      "Epoch 99/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7554 - val_loss: 1.8200\n",
      "Epoch 100/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7725 - val_loss: 1.7600\n",
      "Epoch 101/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7513 - val_loss: 1.6994\n",
      "Epoch 102/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7522 - val_loss: 1.7175\n",
      "Epoch 103/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7622 - val_loss: 1.7308\n",
      "Epoch 104/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7387 - val_loss: 1.7834\n",
      "Epoch 105/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7326 - val_loss: 1.8449\n",
      "Epoch 106/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7407 - val_loss: 1.6929\n",
      "Epoch 107/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7313 - val_loss: 1.7691\n",
      "Epoch 108/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7291 - val_loss: 1.7934\n",
      "Epoch 109/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7295 - val_loss: 1.7102\n",
      "Epoch 110/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7200 - val_loss: 1.7127\n",
      "Epoch 111/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7181 - val_loss: 1.6942\n",
      "Epoch 112/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7202 - val_loss: 1.7598\n",
      "Epoch 113/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7192 - val_loss: 1.7326\n",
      "Epoch 114/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7214 - val_loss: 1.7041\n",
      "Epoch 115/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6997 - val_loss: 1.7920\n",
      "Epoch 116/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6981 - val_loss: 1.6907\n",
      "Epoch 117/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7036 - val_loss: 1.7664\n",
      "Epoch 118/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.7025 - val_loss: 1.7660\n",
      "Epoch 119/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.7052 - val_loss: 1.7217\n",
      "Epoch 120/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7119 - val_loss: 1.7040\n",
      "Epoch 121/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6849 - val_loss: 1.6810\n",
      "Epoch 122/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6913 - val_loss: 1.7238\n",
      "Epoch 123/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6750 - val_loss: 1.7199\n",
      "Epoch 124/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6903 - val_loss: 1.7202\n",
      "Epoch 125/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6862 - val_loss: 1.7156\n",
      "Epoch 126/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6843 - val_loss: 1.6565\n",
      "Epoch 127/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6875 - val_loss: 1.7807\n",
      "Epoch 128/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6758 - val_loss: 1.6924\n",
      "Epoch 129/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6729 - val_loss: 1.6809\n",
      "Epoch 130/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6693 - val_loss: 1.6616\n",
      "Epoch 131/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6808 - val_loss: 1.7119\n",
      "Epoch 132/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6587 - val_loss: 1.6765\n",
      "Epoch 133/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6964 - val_loss: 1.7574\n",
      "Epoch 134/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6610 - val_loss: 1.6620\n",
      "Epoch 135/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6579 - val_loss: 1.7651\n",
      "Epoch 136/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6735 - val_loss: 1.6855\n",
      "Epoch 137/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6491 - val_loss: 1.7144\n",
      "Epoch 138/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6661 - val_loss: 1.6883\n",
      "Epoch 139/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6452 - val_loss: 1.7190\n",
      "Epoch 140/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6521 - val_loss: 1.7304\n",
      "Epoch 141/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6581 - val_loss: 1.6282\n",
      "Epoch 142/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6507 - val_loss: 1.6846\n",
      "Epoch 143/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6539 - val_loss: 1.6376\n",
      "Epoch 144/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6451 - val_loss: 1.6634\n",
      "Epoch 145/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6411 - val_loss: 1.7208\n",
      "Epoch 146/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6452 - val_loss: 1.6645\n",
      "Epoch 147/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6466 - val_loss: 1.6675\n",
      "Epoch 148/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6432 - val_loss: 1.6768\n",
      "Epoch 149/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6391 - val_loss: 1.7324\n",
      "Epoch 150/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6363 - val_loss: 1.6407\n",
      "Epoch 151/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6363 - val_loss: 1.6193\n",
      "Epoch 152/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6271 - val_loss: 1.6842\n",
      "Epoch 153/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6379 - val_loss: 1.6429\n",
      "Epoch 154/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6289 - val_loss: 1.6552\n",
      "Epoch 155/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6203 - val_loss: 1.7038\n",
      "Epoch 156/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6297 - val_loss: 1.6363\n",
      "Epoch 157/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6192 - val_loss: 1.6418\n",
      "Epoch 158/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6232 - val_loss: 1.6825\n",
      "Epoch 159/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6426 - val_loss: 1.6376\n",
      "Epoch 160/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6141 - val_loss: 1.6013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6227 - val_loss: 1.6446\n",
      "Epoch 162/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6151 - val_loss: 1.6920\n",
      "Epoch 163/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6111 - val_loss: 1.6172\n",
      "Epoch 164/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6112 - val_loss: 1.5947\n",
      "Epoch 165/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6101 - val_loss: 1.6046\n",
      "Epoch 166/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6044 - val_loss: 1.5890\n",
      "Epoch 167/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6126 - val_loss: 1.6502\n",
      "Epoch 168/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5959 - val_loss: 1.6385\n",
      "Epoch 169/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6154 - val_loss: 1.6269\n",
      "Epoch 170/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6186 - val_loss: 1.6436\n",
      "Epoch 171/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6009 - val_loss: 1.6215\n",
      "Epoch 172/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6031 - val_loss: 1.6497\n",
      "Epoch 173/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5970 - val_loss: 1.6011\n",
      "Epoch 174/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5984 - val_loss: 1.6490\n",
      "Epoch 175/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.6015 - val_loss: 1.6196\n",
      "Epoch 176/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5838 - val_loss: 1.6323\n",
      "Epoch 177/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5968 - val_loss: 1.5694\n",
      "Epoch 178/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5871 - val_loss: 1.6003\n",
      "Epoch 179/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5852 - val_loss: 1.6043\n",
      "Epoch 180/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5947 - val_loss: 1.6703\n",
      "Epoch 181/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5856 - val_loss: 1.6486\n",
      "Epoch 182/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5813 - val_loss: 1.5982\n",
      "Epoch 183/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5935 - val_loss: 1.6025\n",
      "Epoch 184/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5788 - val_loss: 1.5991\n",
      "Epoch 185/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5793 - val_loss: 1.5698\n",
      "Epoch 186/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5767 - val_loss: 1.6171\n",
      "Epoch 187/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5713 - val_loss: 1.6340\n",
      "Epoch 188/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5857 - val_loss: 1.6362\n",
      "Epoch 189/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5671 - val_loss: 1.7095\n",
      "Epoch 190/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5807 - val_loss: 1.6388\n",
      "Epoch 191/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5786 - val_loss: 1.6187\n",
      "Epoch 192/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5670 - val_loss: 1.6497\n",
      "Epoch 193/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5660 - val_loss: 1.5727\n",
      "Epoch 194/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5664 - val_loss: 1.5425\n",
      "Epoch 195/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5643 - val_loss: 1.6521\n",
      "Epoch 196/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5583 - val_loss: 1.6918\n",
      "Epoch 197/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5700 - val_loss: 1.5847\n",
      "Epoch 198/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5696 - val_loss: 1.5713\n",
      "Epoch 199/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5607 - val_loss: 1.5469\n",
      "Epoch 200/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5538 - val_loss: 1.6314\n",
      "Epoch 201/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5663 - val_loss: 1.5825\n",
      "Epoch 202/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5525 - val_loss: 1.5989\n",
      "Epoch 203/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5485 - val_loss: 1.6140\n",
      "Epoch 204/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5506 - val_loss: 1.6784\n",
      "Epoch 205/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5561 - val_loss: 1.5968\n",
      "Epoch 206/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5519 - val_loss: 1.5714\n",
      "Epoch 207/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5530 - val_loss: 1.7027\n",
      "Epoch 208/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5426 - val_loss: 1.6296\n",
      "Epoch 209/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5507 - val_loss: 1.6347\n",
      "Epoch 210/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5499 - val_loss: 1.6044\n",
      "Epoch 211/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5527 - val_loss: 1.6058\n",
      "Epoch 212/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5418 - val_loss: 1.6340\n",
      "Epoch 213/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5275 - val_loss: 1.5372\n",
      "Epoch 214/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5359 - val_loss: 1.6095\n",
      "Epoch 215/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5431 - val_loss: 1.5753\n",
      "Epoch 216/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5509 - val_loss: 1.5220\n",
      "Epoch 217/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5390 - val_loss: 1.6170\n",
      "Epoch 218/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5297 - val_loss: 1.6341\n",
      "Epoch 219/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5309 - val_loss: 1.6284\n",
      "Epoch 220/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5394 - val_loss: 1.5033\n",
      "Epoch 221/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5394 - val_loss: 1.5324\n",
      "Epoch 222/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5195 - val_loss: 1.5563\n",
      "Epoch 223/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5413 - val_loss: 1.5998\n",
      "Epoch 224/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5183 - val_loss: 1.5726\n",
      "Epoch 225/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5362 - val_loss: 1.5897\n",
      "Epoch 226/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5254 - val_loss: 1.5647\n",
      "Epoch 227/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5218 - val_loss: 1.6013\n",
      "Epoch 228/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5344 - val_loss: 1.5738\n",
      "Epoch 229/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5139 - val_loss: 1.5456\n",
      "Epoch 230/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5129 - val_loss: 1.5847\n",
      "Epoch 231/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5061 - val_loss: 1.5634\n",
      "Epoch 232/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5172 - val_loss: 1.5451\n",
      "Epoch 233/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5146 - val_loss: 1.5375\n",
      "Epoch 234/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5220 - val_loss: 1.5245\n",
      "Epoch 235/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5139 - val_loss: 1.5975\n",
      "Epoch 236/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5109 - val_loss: 1.5055\n",
      "Epoch 237/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5062 - val_loss: 1.5214\n",
      "Epoch 238/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5141 - val_loss: 1.5566\n",
      "Epoch 239/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5202 - val_loss: 1.5197\n",
      "Epoch 240/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5150 - val_loss: 1.5780\n",
      "Epoch 241/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5163 - val_loss: 1.5695\n",
      "Epoch 242/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4983 - val_loss: 1.5341\n",
      "Epoch 243/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5034 - val_loss: 1.5425\n",
      "Epoch 244/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5050 - val_loss: 1.6681\n",
      "Epoch 245/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5177 - val_loss: 1.5514\n",
      "Epoch 246/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5052 - val_loss: 1.4984\n",
      "Epoch 247/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5079 - val_loss: 1.5695\n",
      "Epoch 248/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5113 - val_loss: 1.5983\n",
      "Epoch 249/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4941 - val_loss: 1.5558\n",
      "Epoch 250/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5026 - val_loss: 1.5105\n",
      "Epoch 251/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5067 - val_loss: 1.5538\n",
      "Epoch 252/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4937 - val_loss: 1.4892\n",
      "Epoch 253/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5039 - val_loss: 1.5344\n",
      "Epoch 254/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5024 - val_loss: 1.5493\n",
      "Epoch 255/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5030 - val_loss: 1.6145\n",
      "Epoch 256/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4991 - val_loss: 1.5427\n",
      "Epoch 257/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5014 - val_loss: 1.5250\n",
      "Epoch 258/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5046 - val_loss: 1.5157\n",
      "Epoch 259/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4807 - val_loss: 1.5734\n",
      "Epoch 260/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4893 - val_loss: 1.6277\n",
      "Epoch 261/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4940 - val_loss: 1.5547\n",
      "Epoch 262/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4936 - val_loss: 1.5053\n",
      "Epoch 263/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4924 - val_loss: 1.5249\n",
      "Epoch 264/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4929 - val_loss: 1.4787\n",
      "Epoch 265/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4886 - val_loss: 1.5935\n",
      "Epoch 266/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4959 - val_loss: 1.5279\n",
      "Epoch 267/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4929 - val_loss: 1.5214\n",
      "Epoch 268/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4887 - val_loss: 1.5011\n",
      "Epoch 269/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4964 - val_loss: 1.4958\n",
      "Epoch 270/900\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.4796 - val_loss: 1.4960\n",
      "Epoch 271/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4826 - val_loss: 1.4703\n",
      "Epoch 272/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4787 - val_loss: 1.6044\n",
      "Epoch 273/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4736 - val_loss: 1.4915\n",
      "Epoch 274/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4953 - val_loss: 1.5498\n",
      "Epoch 275/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4874 - val_loss: 1.5727\n",
      "Epoch 276/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4830 - val_loss: 1.5376\n",
      "Epoch 277/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4774 - val_loss: 1.4953\n",
      "Epoch 278/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4853 - val_loss: 1.6854\n",
      "Epoch 279/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4761 - val_loss: 1.5977\n",
      "Epoch 280/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4842 - val_loss: 1.4849\n",
      "Epoch 281/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4702 - val_loss: 1.5380\n",
      "Epoch 282/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4781 - val_loss: 1.4811\n",
      "Epoch 283/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4821 - val_loss: 1.4661\n",
      "Epoch 284/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4732 - val_loss: 1.5165\n",
      "Epoch 285/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4694 - val_loss: 1.4716\n",
      "Epoch 286/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4764 - val_loss: 1.5039\n",
      "Epoch 287/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4751 - val_loss: 1.5093\n",
      "Epoch 288/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4650 - val_loss: 1.4821\n",
      "Epoch 289/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4752 - val_loss: 1.5237\n",
      "Epoch 290/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4729 - val_loss: 1.4939\n",
      "Epoch 291/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4655 - val_loss: 1.4907\n",
      "Epoch 292/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4731 - val_loss: 1.6219\n",
      "Epoch 293/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4727 - val_loss: 1.4962\n",
      "Epoch 294/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4722 - val_loss: 1.4701\n",
      "Epoch 295/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4520 - val_loss: 1.5260\n",
      "Epoch 296/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4714 - val_loss: 1.4680\n",
      "Epoch 297/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4566 - val_loss: 1.4476\n",
      "Epoch 298/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4626 - val_loss: 1.4637\n",
      "Epoch 299/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4740 - val_loss: 1.4525\n",
      "Epoch 300/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4646 - val_loss: 1.5543\n",
      "Epoch 301/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4588 - val_loss: 1.5651\n",
      "Epoch 302/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4591 - val_loss: 1.5597\n",
      "Epoch 303/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4581 - val_loss: 1.4833\n",
      "Epoch 304/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4727 - val_loss: 1.5029\n",
      "Epoch 305/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4576 - val_loss: 1.4790\n",
      "Epoch 306/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4626 - val_loss: 1.4781\n",
      "Epoch 307/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4817 - val_loss: 1.5294\n",
      "Epoch 308/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4508 - val_loss: 1.4358\n",
      "Epoch 309/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4609 - val_loss: 1.5585\n",
      "Epoch 310/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4569 - val_loss: 1.5441\n",
      "Epoch 311/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4594 - val_loss: 1.4786\n",
      "Epoch 312/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4546 - val_loss: 1.4961\n",
      "Epoch 313/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4490 - val_loss: 1.4859\n",
      "Epoch 314/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4549 - val_loss: 1.5025\n",
      "Epoch 315/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4654 - val_loss: 1.6468\n",
      "Epoch 316/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4509 - val_loss: 1.4676\n",
      "Epoch 317/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4688 - val_loss: 1.4871\n",
      "Epoch 318/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4471 - val_loss: 1.5369\n",
      "Epoch 319/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4628 - val_loss: 1.4730\n",
      "Epoch 320/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4539 - val_loss: 1.4613\n",
      "Epoch 321/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4543 - val_loss: 1.5368\n",
      "Epoch 322/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4507 - val_loss: 1.5041\n",
      "Epoch 323/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4336 - val_loss: 1.4962\n",
      "Epoch 324/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4435 - val_loss: 1.4255\n",
      "Epoch 325/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4434 - val_loss: 1.4987\n",
      "Epoch 326/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4520 - val_loss: 1.4649\n",
      "Epoch 327/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4420 - val_loss: 1.5236\n",
      "Epoch 328/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4472 - val_loss: 1.5313\n",
      "Epoch 329/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4466 - val_loss: 1.4853\n",
      "Epoch 330/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4373 - val_loss: 1.5217\n",
      "Epoch 331/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4419 - val_loss: 1.4649\n",
      "Epoch 332/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4404 - val_loss: 1.4867\n",
      "Epoch 333/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4343 - val_loss: 1.4556\n",
      "Epoch 334/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4515 - val_loss: 1.4899\n",
      "Epoch 335/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4378 - val_loss: 1.4889\n",
      "Epoch 336/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4521 - val_loss: 1.4551\n",
      "Epoch 337/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4506 - val_loss: 1.5033\n",
      "Epoch 338/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4436 - val_loss: 1.4583\n",
      "Epoch 339/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4398 - val_loss: 1.4604\n",
      "Epoch 340/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4335 - val_loss: 1.5131\n",
      "Epoch 341/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4470 - val_loss: 1.4512\n",
      "Epoch 342/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4361 - val_loss: 1.4859\n",
      "Epoch 343/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4388 - val_loss: 1.4479\n",
      "Epoch 344/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4358 - val_loss: 1.4676\n",
      "Epoch 345/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4366 - val_loss: 1.5215\n",
      "Epoch 346/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4370 - val_loss: 1.4746\n",
      "Epoch 347/900\n",
      "576/576 [==============================] - 5s 10ms/step - loss: 1.4335 - val_loss: 1.4520\n",
      "Epoch 348/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4375 - val_loss: 1.4796\n",
      "Epoch 349/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4393 - val_loss: 1.4890\n",
      "Epoch 350/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4384 - val_loss: 1.4195\n",
      "Epoch 351/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4352 - val_loss: 1.4312\n",
      "Epoch 352/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4314 - val_loss: 1.4788\n",
      "Epoch 353/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4346 - val_loss: 1.4546\n",
      "Epoch 354/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4434 - val_loss: 1.4655\n",
      "Epoch 355/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4237 - val_loss: 1.4782\n",
      "Epoch 356/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4333 - val_loss: 1.4842\n",
      "Epoch 357/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4343 - val_loss: 1.4757\n",
      "Epoch 358/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4329 - val_loss: 1.4944\n",
      "Epoch 359/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4400 - val_loss: 1.4234\n",
      "Epoch 360/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4292 - val_loss: 1.4669\n",
      "Epoch 361/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4370 - val_loss: 1.4876\n",
      "Epoch 362/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4276 - val_loss: 1.4311\n",
      "Epoch 363/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4445 - val_loss: 1.4730\n",
      "Epoch 364/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4329 - val_loss: 1.4312\n",
      "Epoch 365/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.4395 - val_loss: 1.4699\n",
      "Epoch 366/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4244 - val_loss: 1.4212\n",
      "Epoch 367/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4203 - val_loss: 1.4713\n",
      "Epoch 368/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4299 - val_loss: 1.4502\n",
      "Epoch 369/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4208 - val_loss: 1.4755\n",
      "Epoch 370/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4286 - val_loss: 1.4046\n",
      "Epoch 371/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4203 - val_loss: 1.4162\n",
      "Epoch 372/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4232 - val_loss: 1.5057\n",
      "Epoch 373/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4263 - val_loss: 1.4144\n",
      "Epoch 374/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4218 - val_loss: 1.5774\n",
      "Epoch 375/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4274 - val_loss: 1.4824\n",
      "Epoch 376/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4226 - val_loss: 1.4688\n",
      "Epoch 377/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4336 - val_loss: 1.4440\n",
      "Epoch 378/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4240 - val_loss: 1.4552\n",
      "Epoch 379/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4270 - val_loss: 1.4449\n",
      "Epoch 380/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4275 - val_loss: 1.4655\n",
      "Epoch 381/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4210 - val_loss: 1.4315\n",
      "Epoch 382/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4178 - val_loss: 1.4458\n",
      "Epoch 383/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4129 - val_loss: 1.4767\n",
      "Epoch 384/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4264 - val_loss: 1.4815\n",
      "Epoch 385/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4199 - val_loss: 1.4754\n",
      "Epoch 386/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4253 - val_loss: 1.4456\n",
      "Epoch 387/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4176 - val_loss: 1.4534\n",
      "Epoch 388/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4151 - val_loss: 1.4275\n",
      "Epoch 389/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4204 - val_loss: 1.5168\n",
      "Epoch 390/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4130 - val_loss: 1.5305\n",
      "Epoch 391/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4242 - val_loss: 1.4383\n",
      "Epoch 392/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4196 - val_loss: 1.5027\n",
      "Epoch 393/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4235 - val_loss: 1.4570\n",
      "Epoch 394/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4124 - val_loss: 1.4840\n",
      "Epoch 395/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4159 - val_loss: 1.4667\n",
      "Epoch 396/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4138 - val_loss: 1.5455\n",
      "Epoch 397/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4223 - val_loss: 1.4629\n",
      "Epoch 398/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4178 - val_loss: 1.5042\n",
      "Epoch 399/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4204 - val_loss: 1.4402\n",
      "Epoch 400/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4134 - val_loss: 1.4728\n",
      "Epoch 401/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4105 - val_loss: 1.4171\n",
      "Epoch 402/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.4120 - val_loss: 1.4965\n",
      "Epoch 403/900\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.4196 - val_loss: 1.4216\n",
      "Epoch 404/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4170 - val_loss: 1.5151\n",
      "Epoch 405/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4186 - val_loss: 1.4399\n",
      "Epoch 406/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4096 - val_loss: 1.5129\n",
      "Epoch 407/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4186 - val_loss: 1.5112\n",
      "Epoch 408/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4140 - val_loss: 1.4620\n",
      "Epoch 409/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4141 - val_loss: 1.4322\n",
      "Epoch 410/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4047 - val_loss: 1.4814\n",
      "Epoch 411/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4046 - val_loss: 1.4264\n",
      "Epoch 412/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4187 - val_loss: 1.5410\n",
      "Epoch 413/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4071 - val_loss: 1.4378\n",
      "Epoch 414/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4119 - val_loss: 1.4727\n",
      "Epoch 415/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4144 - val_loss: 1.4746\n",
      "Epoch 416/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4132 - val_loss: 1.4789\n",
      "Epoch 417/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4120 - val_loss: 1.4432\n",
      "Epoch 418/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4078 - val_loss: 1.4383\n",
      "Epoch 419/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4040 - val_loss: 1.4639\n",
      "Epoch 420/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4058 - val_loss: 1.4456\n",
      "Epoch 421/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4021 - val_loss: 1.5191\n",
      "Epoch 422/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4093 - val_loss: 1.4516\n",
      "Epoch 423/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4031 - val_loss: 1.4102\n",
      "Epoch 424/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4051 - val_loss: 1.4667\n",
      "Epoch 425/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4089 - val_loss: 1.4551\n",
      "Epoch 426/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4059 - val_loss: 1.4339\n",
      "Epoch 427/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4052 - val_loss: 1.4755\n",
      "Epoch 428/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4031 - val_loss: 1.4286\n",
      "Epoch 429/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4078 - val_loss: 1.4535\n",
      "Epoch 430/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4094 - val_loss: 1.4220\n",
      "Epoch 431/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4076 - val_loss: 1.5360\n",
      "Epoch 432/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4046 - val_loss: 1.4150\n",
      "Epoch 433/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4066 - val_loss: 1.4508\n",
      "Epoch 434/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4052 - val_loss: 1.3874\n",
      "Epoch 435/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3970 - val_loss: 1.4378\n",
      "Epoch 436/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3998 - val_loss: 1.4018\n",
      "Epoch 437/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3899 - val_loss: 1.4026\n",
      "Epoch 438/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3959 - val_loss: 1.4076\n",
      "Epoch 439/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3943 - val_loss: 1.4224\n",
      "Epoch 440/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3953 - val_loss: 1.4302\n",
      "Epoch 441/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4016 - val_loss: 1.4413\n",
      "Epoch 442/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3859 - val_loss: 1.4328\n",
      "Epoch 443/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4078 - val_loss: 1.4180\n",
      "Epoch 444/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3952 - val_loss: 1.4225\n",
      "Epoch 445/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3956 - val_loss: 1.4611\n",
      "Epoch 446/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3919 - val_loss: 1.4185\n",
      "Epoch 447/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3950 - val_loss: 1.5285\n",
      "Epoch 448/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3917 - val_loss: 1.4080\n",
      "Epoch 449/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3993 - val_loss: 1.4501\n",
      "Epoch 450/900\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.4075 - val_loss: 1.4149\n",
      "Epoch 451/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.4004 - val_loss: 1.4326\n",
      "Epoch 452/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3916 - val_loss: 1.4357\n",
      "Epoch 453/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3911 - val_loss: 1.4053\n",
      "Epoch 454/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3945 - val_loss: 1.3900\n",
      "Epoch 455/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3900 - val_loss: 1.3945\n",
      "Epoch 456/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3869 - val_loss: 1.4774\n",
      "Epoch 457/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3917 - val_loss: 1.4659\n",
      "Epoch 458/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3908 - val_loss: 1.4377\n",
      "Epoch 459/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3857 - val_loss: 1.4342\n",
      "Epoch 460/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3896 - val_loss: 1.4581\n",
      "Epoch 461/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3963 - val_loss: 1.4265\n",
      "Epoch 462/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3874 - val_loss: 1.4885\n",
      "Epoch 463/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3893 - val_loss: 1.4324\n",
      "Epoch 464/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3949 - val_loss: 1.4657\n",
      "Epoch 465/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3936 - val_loss: 1.4430\n",
      "Epoch 466/900\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.3867 - val_loss: 1.5016\n",
      "Epoch 467/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3931 - val_loss: 1.4052\n",
      "Epoch 468/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3838 - val_loss: 1.4157\n",
      "Epoch 469/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3794 - val_loss: 1.4135\n",
      "Epoch 470/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3846 - val_loss: 1.4245\n",
      "Epoch 471/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3977 - val_loss: 1.4213\n",
      "Epoch 472/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3910 - val_loss: 1.3811\n",
      "Epoch 473/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3744 - val_loss: 1.3885\n",
      "Epoch 474/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3781 - val_loss: 1.3987\n",
      "Epoch 475/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3727 - val_loss: 1.4285\n",
      "Epoch 476/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3854 - val_loss: 1.4029\n",
      "Epoch 477/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3829 - val_loss: 1.4250\n",
      "Epoch 478/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3847 - val_loss: 1.4130\n",
      "Epoch 479/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3778 - val_loss: 1.4277\n",
      "Epoch 480/900\n",
      "576/576 [==============================] - 5s 10ms/step - loss: 1.3740 - val_loss: 1.3980\n",
      "Epoch 481/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3857 - val_loss: 1.3870\n",
      "Epoch 482/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3804 - val_loss: 1.4092\n",
      "Epoch 483/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3827 - val_loss: 1.4436\n",
      "Epoch 484/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3829 - val_loss: 1.4042\n",
      "Epoch 485/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3824 - val_loss: 1.4219\n",
      "Epoch 486/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3845 - val_loss: 1.4854\n",
      "Epoch 487/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3813 - val_loss: 1.4165\n",
      "Epoch 488/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3725 - val_loss: 1.3776\n",
      "Epoch 489/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3841 - val_loss: 1.4802\n",
      "Epoch 490/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3873 - val_loss: 1.4157\n",
      "Epoch 491/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3814 - val_loss: 1.4558\n",
      "Epoch 492/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3846 - val_loss: 1.4286\n",
      "Epoch 493/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3746 - val_loss: 1.4076\n",
      "Epoch 494/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3735 - val_loss: 1.4824\n",
      "Epoch 495/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3879 - val_loss: 1.4534\n",
      "Epoch 496/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3796 - val_loss: 1.4561\n",
      "Epoch 497/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3796 - val_loss: 1.4595\n",
      "Epoch 498/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3766 - val_loss: 1.3847\n",
      "Epoch 499/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3752 - val_loss: 1.4134\n",
      "Epoch 500/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3709 - val_loss: 1.4799\n",
      "Epoch 501/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3802 - val_loss: 1.4272\n",
      "Epoch 502/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3661 - val_loss: 1.3816\n",
      "Epoch 503/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3802 - val_loss: 1.3727\n",
      "Epoch 504/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3769 - val_loss: 1.4175\n",
      "Epoch 505/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3756 - val_loss: 1.4119\n",
      "Epoch 506/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3740 - val_loss: 1.4194\n",
      "Epoch 507/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3713 - val_loss: 1.4230\n",
      "Epoch 508/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3720 - val_loss: 1.4088\n",
      "Epoch 509/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3766 - val_loss: 1.4311\n",
      "Epoch 510/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3811 - val_loss: 1.3856\n",
      "Epoch 511/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3705 - val_loss: 1.3963\n",
      "Epoch 512/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3735 - val_loss: 1.3838\n",
      "Epoch 513/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3714 - val_loss: 1.3957\n",
      "Epoch 514/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3732 - val_loss: 1.4009\n",
      "Epoch 515/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3724 - val_loss: 1.4358\n",
      "Epoch 516/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3734 - val_loss: 1.3927\n",
      "Epoch 517/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3730 - val_loss: 1.4124\n",
      "Epoch 518/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3706 - val_loss: 1.4327\n",
      "Epoch 519/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3712 - val_loss: 1.3691\n",
      "Epoch 520/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3670 - val_loss: 1.4273\n",
      "Epoch 521/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3649 - val_loss: 1.4379\n",
      "Epoch 522/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3738 - val_loss: 1.4270\n",
      "Epoch 523/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3582 - val_loss: 1.3751\n",
      "Epoch 524/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3586 - val_loss: 1.3781\n",
      "Epoch 525/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3612 - val_loss: 1.3940\n",
      "Epoch 526/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3827 - val_loss: 1.3836\n",
      "Epoch 527/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3684 - val_loss: 1.3903\n",
      "Epoch 528/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3674 - val_loss: 1.3642\n",
      "Epoch 529/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3628 - val_loss: 1.4054\n",
      "Epoch 530/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3690 - val_loss: 1.4314\n",
      "Epoch 531/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3598 - val_loss: 1.3899\n",
      "Epoch 532/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3584 - val_loss: 1.3799\n",
      "Epoch 533/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3725 - val_loss: 1.4340\n",
      "Epoch 534/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3662 - val_loss: 1.4368\n",
      "Epoch 535/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3697 - val_loss: 1.4044\n",
      "Epoch 536/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3835 - val_loss: 1.3860\n",
      "Epoch 537/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3724 - val_loss: 1.4677\n",
      "Epoch 538/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3664 - val_loss: 1.3845\n",
      "Epoch 539/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3642 - val_loss: 1.3964\n",
      "Epoch 540/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3630 - val_loss: 1.3926\n",
      "Epoch 541/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3645 - val_loss: 1.4225\n",
      "Epoch 542/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3620 - val_loss: 1.4597\n",
      "Epoch 543/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3701 - val_loss: 1.3587\n",
      "Epoch 544/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3672 - val_loss: 1.4155\n",
      "Epoch 545/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3653 - val_loss: 1.3939\n",
      "Epoch 546/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3644 - val_loss: 1.4491\n",
      "Epoch 547/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3573 - val_loss: 1.4170\n",
      "Epoch 548/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3697 - val_loss: 1.3633\n",
      "Epoch 549/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3593 - val_loss: 1.4269\n",
      "Epoch 550/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3685 - val_loss: 1.4462\n",
      "Epoch 551/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3693 - val_loss: 1.3975\n",
      "Epoch 552/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3544 - val_loss: 1.3717\n",
      "Epoch 553/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3651 - val_loss: 1.4379\n",
      "Epoch 554/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3732 - val_loss: 1.3947\n",
      "Epoch 555/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3566 - val_loss: 1.3830\n",
      "Epoch 556/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3563 - val_loss: 1.4324\n",
      "Epoch 557/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3579 - val_loss: 1.4279\n",
      "Epoch 558/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3617 - val_loss: 1.4001\n",
      "Epoch 559/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3603 - val_loss: 1.3939\n",
      "Epoch 560/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3639 - val_loss: 1.3906\n",
      "Epoch 561/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3685 - val_loss: 1.4800\n",
      "Epoch 562/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3625 - val_loss: 1.3773\n",
      "Epoch 563/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3560 - val_loss: 1.4184\n",
      "Epoch 564/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3611 - val_loss: 1.3973\n",
      "Epoch 565/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3639 - val_loss: 1.3968\n",
      "Epoch 566/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3513 - val_loss: 1.4067\n",
      "Epoch 567/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3599 - val_loss: 1.4402\n",
      "Epoch 568/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3585 - val_loss: 1.4017\n",
      "Epoch 569/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3554 - val_loss: 1.4156\n",
      "Epoch 570/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3606 - val_loss: 1.4055\n",
      "Epoch 571/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3619 - val_loss: 1.3949\n",
      "Epoch 572/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3512 - val_loss: 1.4648\n",
      "Epoch 573/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3583 - val_loss: 1.3849\n",
      "Epoch 574/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3620 - val_loss: 1.3684\n",
      "Epoch 575/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3637 - val_loss: 1.4549\n",
      "Epoch 576/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3555 - val_loss: 1.3495\n",
      "Epoch 577/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3552 - val_loss: 1.3648\n",
      "Epoch 578/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3449 - val_loss: 1.3668\n",
      "Epoch 579/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3563 - val_loss: 1.3655\n",
      "Epoch 580/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3587 - val_loss: 1.4461\n",
      "Epoch 581/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3553 - val_loss: 1.3699\n",
      "Epoch 582/900\n",
      "576/576 [==============================] - 5s 10ms/step - loss: 1.3556 - val_loss: 1.3670\n",
      "Epoch 583/900\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.3523 - val_loss: 1.4107\n",
      "Epoch 584/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3566 - val_loss: 1.3758\n",
      "Epoch 585/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3522 - val_loss: 1.4308\n",
      "Epoch 586/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3631 - val_loss: 1.4468\n",
      "Epoch 587/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3448 - val_loss: 1.3868\n",
      "Epoch 588/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3516 - val_loss: 1.3747\n",
      "Epoch 589/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3486 - val_loss: 1.3585\n",
      "Epoch 590/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3466 - val_loss: 1.4300\n",
      "Epoch 591/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3491 - val_loss: 1.3981\n",
      "Epoch 592/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3516 - val_loss: 1.3835\n",
      "Epoch 593/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3528 - val_loss: 1.4227\n",
      "Epoch 594/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3514 - val_loss: 1.4019\n",
      "Epoch 595/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3443 - val_loss: 1.3935\n",
      "Epoch 596/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3549 - val_loss: 1.4155\n",
      "Epoch 597/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3479 - val_loss: 1.3845\n",
      "Epoch 598/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3493 - val_loss: 1.4377\n",
      "Epoch 599/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3489 - val_loss: 1.3663\n",
      "Epoch 600/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3534 - val_loss: 1.4656\n",
      "Epoch 601/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3508 - val_loss: 1.3551\n",
      "Epoch 602/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3495 - val_loss: 1.3704\n",
      "Epoch 603/900\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.3467 - val_loss: 1.3830\n",
      "Epoch 604/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3566 - val_loss: 1.4715\n",
      "Epoch 605/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3480 - val_loss: 1.3814\n",
      "Epoch 606/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3422 - val_loss: 1.3820\n",
      "Epoch 607/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3517 - val_loss: 1.4114\n",
      "Epoch 608/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3522 - val_loss: 1.3817\n",
      "Epoch 609/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3349 - val_loss: 1.3867\n",
      "Epoch 610/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3387 - val_loss: 1.3755\n",
      "Epoch 611/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3473 - val_loss: 1.3577\n",
      "Epoch 612/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3427 - val_loss: 1.3512\n",
      "Epoch 613/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3527 - val_loss: 1.4092\n",
      "Epoch 614/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3490 - val_loss: 1.3883\n",
      "Epoch 615/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3445 - val_loss: 1.3791\n",
      "Epoch 616/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3391 - val_loss: 1.3427\n",
      "Epoch 617/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3465 - val_loss: 1.4049\n",
      "Epoch 618/900\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.3462 - val_loss: 1.3790\n",
      "Epoch 619/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3468 - val_loss: 1.4750\n",
      "Epoch 620/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3449 - val_loss: 1.3701\n",
      "Epoch 621/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3465 - val_loss: 1.3781\n",
      "Epoch 622/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3483 - val_loss: 1.4047\n",
      "Epoch 623/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3416 - val_loss: 1.4343\n",
      "Epoch 624/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3504 - val_loss: 1.4379\n",
      "Epoch 625/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3372 - val_loss: 1.4015\n",
      "Epoch 626/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3421 - val_loss: 1.4176\n",
      "Epoch 627/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3407 - val_loss: 1.4131\n",
      "Epoch 628/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3491 - val_loss: 1.3819\n",
      "Epoch 629/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3418 - val_loss: 1.4174\n",
      "Epoch 630/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3372 - val_loss: 1.3662\n",
      "Epoch 631/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3414 - val_loss: 1.3916\n",
      "Epoch 632/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3348 - val_loss: 1.3699\n",
      "Epoch 633/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3395 - val_loss: 1.3845\n",
      "Epoch 634/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3380 - val_loss: 1.3499\n",
      "Epoch 635/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3395 - val_loss: 1.4488\n",
      "Epoch 636/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3468 - val_loss: 1.3476\n",
      "Epoch 637/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3347 - val_loss: 1.4208\n",
      "Epoch 638/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3394 - val_loss: 1.3543\n",
      "Epoch 639/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3311 - val_loss: 1.4108\n",
      "Epoch 640/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3436 - val_loss: 1.3775\n",
      "Epoch 641/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3389 - val_loss: 1.3584\n",
      "Epoch 642/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3480 - val_loss: 1.3780\n",
      "Epoch 643/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3419 - val_loss: 1.3895\n",
      "Epoch 644/900\n",
      "576/576 [==============================] - 7s 12ms/step - loss: 1.3312 - val_loss: 1.4112\n",
      "Epoch 645/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3374 - val_loss: 1.3561\n",
      "Epoch 646/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3496 - val_loss: 1.3498\n",
      "Epoch 647/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3316 - val_loss: 1.3398\n",
      "Epoch 648/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3334 - val_loss: 1.3401\n",
      "Epoch 649/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3321 - val_loss: 1.3709\n",
      "Epoch 650/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3475 - val_loss: 1.3648\n",
      "Epoch 651/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3308 - val_loss: 1.3875\n",
      "Epoch 652/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3316 - val_loss: 1.3342\n",
      "Epoch 653/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3374 - val_loss: 1.4109\n",
      "Epoch 654/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3382 - val_loss: 1.3695\n",
      "Epoch 655/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3351 - val_loss: 1.3836\n",
      "Epoch 656/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3353 - val_loss: 1.3740\n",
      "Epoch 657/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3471 - val_loss: 1.3766\n",
      "Epoch 658/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3246 - val_loss: 1.3682\n",
      "Epoch 659/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3339 - val_loss: 1.4199\n",
      "Epoch 660/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3388 - val_loss: 1.3720\n",
      "Epoch 661/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3362 - val_loss: 1.3870\n",
      "Epoch 662/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3342 - val_loss: 1.3891\n",
      "Epoch 663/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3389 - val_loss: 1.3732\n",
      "Epoch 664/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3360 - val_loss: 1.3557\n",
      "Epoch 665/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3329 - val_loss: 1.3409\n",
      "Epoch 666/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3216 - val_loss: 1.3768\n",
      "Epoch 667/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3362 - val_loss: 1.4258\n",
      "Epoch 668/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3310 - val_loss: 1.3744\n",
      "Epoch 669/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3285 - val_loss: 1.3829\n",
      "Epoch 670/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3379 - val_loss: 1.3333\n",
      "Epoch 671/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3235 - val_loss: 1.3443\n",
      "Epoch 672/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3356 - val_loss: 1.3954\n",
      "Epoch 673/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3362 - val_loss: 1.3865\n",
      "Epoch 674/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3242 - val_loss: 1.3538\n",
      "Epoch 675/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3280 - val_loss: 1.3915\n",
      "Epoch 676/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3209 - val_loss: 1.3532\n",
      "Epoch 677/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3314 - val_loss: 1.3426\n",
      "Epoch 678/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3388 - val_loss: 1.4921\n",
      "Epoch 679/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3347 - val_loss: 1.3687\n",
      "Epoch 680/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3216 - val_loss: 1.3992\n",
      "Epoch 681/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3253 - val_loss: 1.3792\n",
      "Epoch 682/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3207 - val_loss: 1.3724\n",
      "Epoch 683/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3301 - val_loss: 1.3923\n",
      "Epoch 684/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3310 - val_loss: 1.3502\n",
      "Epoch 685/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3304 - val_loss: 1.3632\n",
      "Epoch 686/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3272 - val_loss: 1.3871\n",
      "Epoch 687/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3264 - val_loss: 1.3851\n",
      "Epoch 688/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3319 - val_loss: 1.3670\n",
      "Epoch 689/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3352 - val_loss: 1.3472\n",
      "Epoch 690/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3250 - val_loss: 1.3812\n",
      "Epoch 691/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3281 - val_loss: 1.3847\n",
      "Epoch 692/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3266 - val_loss: 1.3647\n",
      "Epoch 693/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3238 - val_loss: 1.3461\n",
      "Epoch 694/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3210 - val_loss: 1.3730\n",
      "Epoch 695/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3146 - val_loss: 1.3950\n",
      "Epoch 696/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3313 - val_loss: 1.3998\n",
      "Epoch 697/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3284 - val_loss: 1.3882\n",
      "Epoch 698/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3233 - val_loss: 1.3396\n",
      "Epoch 699/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3240 - val_loss: 1.3596\n",
      "Epoch 700/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3257 - val_loss: 1.3808\n",
      "Epoch 701/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3263 - val_loss: 1.3470\n",
      "Epoch 702/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3143 - val_loss: 1.3731\n",
      "Epoch 703/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3291 - val_loss: 1.3287\n",
      "Epoch 704/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3152 - val_loss: 1.3639\n",
      "Epoch 705/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3207 - val_loss: 1.3606\n",
      "Epoch 706/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3289 - val_loss: 1.3844\n",
      "Epoch 707/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3193 - val_loss: 1.3864\n",
      "Epoch 708/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3376 - val_loss: 1.4079\n",
      "Epoch 709/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3228 - val_loss: 1.3428\n",
      "Epoch 710/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3166 - val_loss: 1.3418\n",
      "Epoch 711/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3218 - val_loss: 1.3782\n",
      "Epoch 712/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3291 - val_loss: 1.3880\n",
      "Epoch 713/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3200 - val_loss: 1.3744\n",
      "Epoch 714/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3154 - val_loss: 1.3763\n",
      "Epoch 715/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3180 - val_loss: 1.3536\n",
      "Epoch 716/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3313 - val_loss: 1.3808\n",
      "Epoch 717/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3199 - val_loss: 1.3702\n",
      "Epoch 718/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3228 - val_loss: 1.3822\n",
      "Epoch 719/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3236 - val_loss: 1.3514\n",
      "Epoch 720/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3137 - val_loss: 1.3753\n",
      "Epoch 721/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3229 - val_loss: 1.3746\n",
      "Epoch 722/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3129 - val_loss: 1.3605\n",
      "Epoch 723/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3158 - val_loss: 1.3850\n",
      "Epoch 724/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3200 - val_loss: 1.3718\n",
      "Epoch 725/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3177 - val_loss: 1.3547\n",
      "Epoch 726/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3184 - val_loss: 1.4051\n",
      "Epoch 727/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3206 - val_loss: 1.3146\n",
      "Epoch 728/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3075 - val_loss: 1.3555\n",
      "Epoch 729/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3190 - val_loss: 1.4368\n",
      "Epoch 730/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3188 - val_loss: 1.3662\n",
      "Epoch 731/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3139 - val_loss: 1.3744\n",
      "Epoch 732/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3181 - val_loss: 1.3515\n",
      "Epoch 733/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3132 - val_loss: 1.4119\n",
      "Epoch 734/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3185 - val_loss: 1.4276\n",
      "Epoch 735/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3291 - val_loss: 1.3597\n",
      "Epoch 736/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3110 - val_loss: 1.3866\n",
      "Epoch 737/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3106 - val_loss: 1.3685\n",
      "Epoch 738/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3173 - val_loss: 1.3438\n",
      "Epoch 739/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3162 - val_loss: 1.3413\n",
      "Epoch 740/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3177 - val_loss: 1.3428\n",
      "Epoch 741/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3243 - val_loss: 1.3293\n",
      "Epoch 742/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3231 - val_loss: 1.4467\n",
      "Epoch 743/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3157 - val_loss: 1.4020\n",
      "Epoch 744/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3288 - val_loss: 1.3869\n",
      "Epoch 745/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3111 - val_loss: 1.4201\n",
      "Epoch 746/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3154 - val_loss: 1.3491\n",
      "Epoch 747/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3100 - val_loss: 1.3392\n",
      "Epoch 748/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3151 - val_loss: 1.4491\n",
      "Epoch 749/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3160 - val_loss: 1.4247\n",
      "Epoch 750/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3176 - val_loss: 1.3531\n",
      "Epoch 751/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3195 - val_loss: 1.3792\n",
      "Epoch 752/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3163 - val_loss: 1.3483\n",
      "Epoch 753/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3172 - val_loss: 1.4094\n",
      "Epoch 754/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3121 - val_loss: 1.3544\n",
      "Epoch 755/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3223 - val_loss: 1.2950\n",
      "Epoch 756/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3199 - val_loss: 1.3354\n",
      "Epoch 757/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3193 - val_loss: 1.3564\n",
      "Epoch 758/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3149 - val_loss: 1.4447\n",
      "Epoch 759/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3179 - val_loss: 1.3597\n",
      "Epoch 760/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3110 - val_loss: 1.3669\n",
      "Epoch 761/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3162 - val_loss: 1.3271\n",
      "Epoch 762/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3045 - val_loss: 1.3237\n",
      "Epoch 763/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3048 - val_loss: 1.3524\n",
      "Epoch 764/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3049 - val_loss: 1.3261\n",
      "Epoch 765/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3057 - val_loss: 1.3404\n",
      "Epoch 766/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3181 - val_loss: 1.3363\n",
      "Epoch 767/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3207 - val_loss: 1.4165\n",
      "Epoch 768/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3021 - val_loss: 1.3764\n",
      "Epoch 769/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3153 - val_loss: 1.3649\n",
      "Epoch 770/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3105 - val_loss: 1.3519\n",
      "Epoch 771/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3203 - val_loss: 1.3250\n",
      "Epoch 772/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3131 - val_loss: 1.3274\n",
      "Epoch 773/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3090 - val_loss: 1.3275\n",
      "Epoch 774/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3115 - val_loss: 1.3662\n",
      "Epoch 775/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3150 - val_loss: 1.3583\n",
      "Epoch 776/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3033 - val_loss: 1.3293\n",
      "Epoch 777/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3103 - val_loss: 1.3376\n",
      "Epoch 778/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3062 - val_loss: 1.3806\n",
      "Epoch 779/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3142 - val_loss: 1.4250\n",
      "Epoch 780/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3140 - val_loss: 1.3451\n",
      "Epoch 781/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3088 - val_loss: 1.3124\n",
      "Epoch 782/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3059 - val_loss: 1.3505\n",
      "Epoch 783/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3128 - val_loss: 1.3501\n",
      "Epoch 784/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3060 - val_loss: 1.4074\n",
      "Epoch 785/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3096 - val_loss: 1.3306\n",
      "Epoch 786/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3060 - val_loss: 1.3304\n",
      "Epoch 787/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3033 - val_loss: 1.3905\n",
      "Epoch 788/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3127 - val_loss: 1.3954\n",
      "Epoch 789/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3129 - val_loss: 1.3801\n",
      "Epoch 790/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3037 - val_loss: 1.3798\n",
      "Epoch 791/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3070 - val_loss: 1.2863\n",
      "Epoch 792/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3071 - val_loss: 1.3825\n",
      "Epoch 793/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2986 - val_loss: 1.3775\n",
      "Epoch 794/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3094 - val_loss: 1.3713\n",
      "Epoch 795/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3084 - val_loss: 1.3280\n",
      "Epoch 796/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3069 - val_loss: 1.3811\n",
      "Epoch 797/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3088 - val_loss: 1.3659\n",
      "Epoch 798/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3083 - val_loss: 1.3711\n",
      "Epoch 799/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3043 - val_loss: 1.4742\n",
      "Epoch 800/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3137 - val_loss: 1.4128\n",
      "Epoch 801/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2997 - val_loss: 1.3674\n",
      "Epoch 802/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2992 - val_loss: 1.3123\n",
      "Epoch 803/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3060 - val_loss: 1.3820\n",
      "Epoch 804/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3039 - val_loss: 1.3314\n",
      "Epoch 805/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3041 - val_loss: 1.3595\n",
      "Epoch 806/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3101 - val_loss: 1.3412\n",
      "Epoch 807/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2998 - val_loss: 1.3541\n",
      "Epoch 808/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2986 - val_loss: 1.3558\n",
      "Epoch 809/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3051 - val_loss: 1.3796\n",
      "Epoch 810/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3037 - val_loss: 1.3567\n",
      "Epoch 811/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3023 - val_loss: 1.3633\n",
      "Epoch 812/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3131 - val_loss: 1.3776\n",
      "Epoch 813/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3110 - val_loss: 1.3441\n",
      "Epoch 814/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3097 - val_loss: 1.4096\n",
      "Epoch 815/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3075 - val_loss: 1.3307\n",
      "Epoch 816/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.2912 - val_loss: 1.3437\n",
      "Epoch 817/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3022 - val_loss: 1.4532\n",
      "Epoch 818/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.2963 - val_loss: 1.3309\n",
      "Epoch 819/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.2950 - val_loss: 1.3139\n",
      "Epoch 820/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2992 - val_loss: 1.3219\n",
      "Epoch 821/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2971 - val_loss: 1.3257\n",
      "Epoch 822/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3077 - val_loss: 1.4185\n",
      "Epoch 823/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2988 - val_loss: 1.3635\n",
      "Epoch 824/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2985 - val_loss: 1.4490\n",
      "Epoch 825/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3048 - val_loss: 1.3394\n",
      "Epoch 826/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3032 - val_loss: 1.3127\n",
      "Epoch 827/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3000 - val_loss: 1.3373\n",
      "Epoch 828/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2988 - val_loss: 1.3512\n",
      "Epoch 829/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2960 - val_loss: 1.2985\n",
      "Epoch 830/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2955 - val_loss: 1.3238\n",
      "Epoch 831/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2939 - val_loss: 1.3568\n",
      "Epoch 832/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2976 - val_loss: 1.4075\n",
      "Epoch 833/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3048 - val_loss: 1.3531\n",
      "Epoch 834/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3003 - val_loss: 1.3001\n",
      "Epoch 835/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3147 - val_loss: 1.4007\n",
      "Epoch 836/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3066 - val_loss: 1.3395\n",
      "Epoch 837/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.2978 - val_loss: 1.3719\n",
      "Epoch 838/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.2995 - val_loss: 1.3218\n",
      "Epoch 839/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2995 - val_loss: 1.3565\n",
      "Epoch 840/900\n",
      "576/576 [==============================] - 5s 10ms/step - loss: 1.2985 - val_loss: 1.3565\n",
      "Epoch 841/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2977 - val_loss: 1.3098\n",
      "Epoch 842/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2982 - val_loss: 1.2977\n",
      "Epoch 843/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3055 - val_loss: 1.3816\n",
      "Epoch 844/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2987 - val_loss: 1.3116\n",
      "Epoch 845/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3024 - val_loss: 1.3312\n",
      "Epoch 846/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2964 - val_loss: 1.3214\n",
      "Epoch 847/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3005 - val_loss: 1.3604\n",
      "Epoch 848/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3047 - val_loss: 1.3843\n",
      "Epoch 849/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3009 - val_loss: 1.3132\n",
      "Epoch 850/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2961 - val_loss: 1.3393\n",
      "Epoch 851/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3041 - val_loss: 1.3142\n",
      "Epoch 852/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2974 - val_loss: 1.3397\n",
      "Epoch 853/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2949 - val_loss: 1.3326\n",
      "Epoch 854/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.2953 - val_loss: 1.3651\n",
      "Epoch 855/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3023 - val_loss: 1.4054\n",
      "Epoch 856/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3026 - val_loss: 1.4029\n",
      "Epoch 857/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2938 - val_loss: 1.3896\n",
      "Epoch 858/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2972 - val_loss: 1.3456\n",
      "Epoch 859/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2904 - val_loss: 1.3496\n",
      "Epoch 860/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3007 - val_loss: 1.6019\n",
      "Epoch 861/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2941 - val_loss: 1.3302\n",
      "Epoch 862/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3006 - val_loss: 1.3205\n",
      "Epoch 863/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2986 - val_loss: 1.3381\n",
      "Epoch 864/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2985 - val_loss: 1.2920\n",
      "Epoch 865/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2943 - val_loss: 1.3177\n",
      "Epoch 866/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2958 - val_loss: 1.3772\n",
      "Epoch 867/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2991 - val_loss: 1.4695\n",
      "Epoch 868/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.2986 - val_loss: 1.3318\n",
      "Epoch 869/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3004 - val_loss: 1.3214\n",
      "Epoch 870/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2940 - val_loss: 1.3818\n",
      "Epoch 871/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2846 - val_loss: 1.3205\n",
      "Epoch 872/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2904 - val_loss: 1.3850\n",
      "Epoch 873/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2918 - val_loss: 1.3847\n",
      "Epoch 874/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3061 - val_loss: 1.3912\n",
      "Epoch 875/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3000 - val_loss: 1.3659\n",
      "Epoch 876/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3000 - val_loss: 1.3923\n",
      "Epoch 877/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2890 - val_loss: 1.3185\n",
      "Epoch 878/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2903 - val_loss: 1.3202\n",
      "Epoch 879/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2907 - val_loss: 1.3752\n",
      "Epoch 880/900\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3020 - val_loss: 1.3290\n",
      "Epoch 881/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2965 - val_loss: 1.3794\n",
      "Epoch 882/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.2939 - val_loss: 1.4111\n",
      "Epoch 883/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3070 - val_loss: 1.3214\n",
      "Epoch 884/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2971 - val_loss: 1.3208\n",
      "Epoch 885/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2979 - val_loss: 1.3331\n",
      "Epoch 886/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2918 - val_loss: 1.3354\n",
      "Epoch 887/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2926 - val_loss: 1.3676\n",
      "Epoch 888/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2905 - val_loss: 1.3707\n",
      "Epoch 889/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2996 - val_loss: 1.3510\n",
      "Epoch 890/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2959 - val_loss: 1.3090\n",
      "Epoch 891/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2929 - val_loss: 1.3990\n",
      "Epoch 892/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2992 - val_loss: 1.4059\n",
      "Epoch 893/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2851 - val_loss: 1.3253\n",
      "Epoch 894/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2954 - val_loss: 1.3836\n",
      "Epoch 895/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3069 - val_loss: 1.4071\n",
      "Epoch 896/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2901 - val_loss: 1.3298\n",
      "Epoch 897/900\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.2882 - val_loss: 1.3118\n",
      "Epoch 898/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.2916 - val_loss: 1.3352\n",
      "Epoch 899/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2897 - val_loss: 1.3334\n",
      "Epoch 900/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2854 - val_loss: 1.3895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3894839045230336\n",
      "0.9722834139443178\n",
      "Epoch 1/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 10.9575 - val_loss: 4.5142\n",
      "Epoch 2/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 5.1179 - val_loss: 4.3676\n",
      "Epoch 3/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 5.3240 - val_loss: 4.0071\n",
      "Epoch 4/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 4.5170 - val_loss: 5.2405\n",
      "Epoch 5/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 4.7989 - val_loss: 4.0830\n",
      "Epoch 6/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 4.2713 - val_loss: 3.9040\n",
      "Epoch 7/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 4.3526 - val_loss: 3.9191\n",
      "Epoch 8/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 4.3610 - val_loss: 3.5985\n",
      "Epoch 9/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.8460 - val_loss: 4.0678\n",
      "Epoch 10/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 3.7182 - val_loss: 3.6389\n",
      "Epoch 11/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.5214 - val_loss: 3.1233\n",
      "Epoch 12/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.4146 - val_loss: 3.0326\n",
      "Epoch 13/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.2697 - val_loss: 2.9436\n",
      "Epoch 14/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 3.2085 - val_loss: 3.5681\n",
      "Epoch 15/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 3.1089 - val_loss: 2.9937\n",
      "Epoch 16/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.9528 - val_loss: 2.7951\n",
      "Epoch 17/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.9386 - val_loss: 2.7915\n",
      "Epoch 18/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.8751 - val_loss: 2.9748\n",
      "Epoch 19/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.7750 - val_loss: 3.1193\n",
      "Epoch 20/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.7146 - val_loss: 2.5430\n",
      "Epoch 21/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.7110 - val_loss: 2.6288\n",
      "Epoch 22/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.6580 - val_loss: 2.5651\n",
      "Epoch 23/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.6040 - val_loss: 2.8371\n",
      "Epoch 24/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5297 - val_loss: 2.4963\n",
      "Epoch 25/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.5451 - val_loss: 2.6066\n",
      "Epoch 26/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.5126 - val_loss: 2.6966\n",
      "Epoch 27/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 2.5065 - val_loss: 2.3704\n",
      "Epoch 28/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4783 - val_loss: 2.3613\n",
      "Epoch 29/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4614 - val_loss: 2.5150\n",
      "Epoch 30/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.4549 - val_loss: 2.3319\n",
      "Epoch 31/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3748 - val_loss: 2.5431\n",
      "Epoch 32/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3676 - val_loss: 2.3371\n",
      "Epoch 33/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3539 - val_loss: 2.3002\n",
      "Epoch 34/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3461 - val_loss: 2.3045\n",
      "Epoch 35/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.3185 - val_loss: 2.2883\n",
      "Epoch 36/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3101 - val_loss: 2.2399\n",
      "Epoch 37/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2595 - val_loss: 2.2175\n",
      "Epoch 38/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2436 - val_loss: 2.4894\n",
      "Epoch 39/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2904 - val_loss: 2.1766\n",
      "Epoch 40/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.2252 - val_loss: 2.3015\n",
      "Epoch 41/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2140 - val_loss: 2.1317\n",
      "Epoch 42/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1891 - val_loss: 2.3077\n",
      "Epoch 43/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.2124 - val_loss: 2.1858\n",
      "Epoch 44/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1792 - val_loss: 2.1756\n",
      "Epoch 45/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1635 - val_loss: 2.3161\n",
      "Epoch 46/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1638 - val_loss: 2.1533\n",
      "Epoch 47/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1623 - val_loss: 2.2009\n",
      "Epoch 48/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1128 - val_loss: 2.2117\n",
      "Epoch 49/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1154 - val_loss: 2.1368\n",
      "Epoch 50/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1188 - val_loss: 2.2389\n",
      "Epoch 51/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0844 - val_loss: 2.0776\n",
      "Epoch 52/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0734 - val_loss: 2.0333\n",
      "Epoch 53/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0898 - val_loss: 2.0555\n",
      "Epoch 54/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0593 - val_loss: 2.0682\n",
      "Epoch 55/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.0620 - val_loss: 2.0755\n",
      "Epoch 56/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0376 - val_loss: 2.0077\n",
      "Epoch 57/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0343 - val_loss: 1.9919\n",
      "Epoch 58/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0224 - val_loss: 2.1225\n",
      "Epoch 59/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0184 - val_loss: 1.9617\n",
      "Epoch 60/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0183 - val_loss: 2.0674\n",
      "Epoch 61/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.0089 - val_loss: 2.0145\n",
      "Epoch 62/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9969 - val_loss: 1.9943\n",
      "Epoch 63/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9827 - val_loss: 2.0175\n",
      "Epoch 64/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9900 - val_loss: 2.0502\n",
      "Epoch 65/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9595 - val_loss: 1.9276\n",
      "Epoch 66/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9792 - val_loss: 1.9534\n",
      "Epoch 67/900\n",
      "432/432 [==============================] - 8s 18ms/step - loss: 1.9555 - val_loss: 1.9345\n",
      "Epoch 68/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9820 - val_loss: 2.0806\n",
      "Epoch 69/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.9477 - val_loss: 1.9422\n",
      "Epoch 70/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.9408 - val_loss: 1.9137\n",
      "Epoch 71/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.9296 - val_loss: 1.9585\n",
      "Epoch 72/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9400 - val_loss: 1.9834\n",
      "Epoch 73/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9269 - val_loss: 1.8984\n",
      "Epoch 74/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9263 - val_loss: 1.9812\n",
      "Epoch 75/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.9312 - val_loss: 1.9502\n",
      "Epoch 76/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8981 - val_loss: 1.9064\n",
      "Epoch 77/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9099 - val_loss: 1.9702\n",
      "Epoch 78/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8960 - val_loss: 1.8998\n",
      "Epoch 79/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9054 - val_loss: 1.8744\n",
      "Epoch 80/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8795 - val_loss: 1.8649\n",
      "Epoch 81/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8720 - val_loss: 1.8887\n",
      "Epoch 82/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8756 - val_loss: 1.8612\n",
      "Epoch 83/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8614 - val_loss: 1.8481\n",
      "Epoch 84/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.8718 - val_loss: 1.8467\n",
      "Epoch 85/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.8644 - val_loss: 1.9243\n",
      "Epoch 86/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8579 - val_loss: 1.8593\n",
      "Epoch 87/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8477 - val_loss: 1.8089\n",
      "Epoch 88/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8340 - val_loss: 1.8473\n",
      "Epoch 89/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8393 - val_loss: 1.9569\n",
      "Epoch 90/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8286 - val_loss: 1.8711\n",
      "Epoch 91/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8141 - val_loss: 1.8429\n",
      "Epoch 92/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8324 - val_loss: 1.8193\n",
      "Epoch 93/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8235 - val_loss: 1.8326\n",
      "Epoch 94/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8279 - val_loss: 1.8343\n",
      "Epoch 95/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8071 - val_loss: 1.8291\n",
      "Epoch 96/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.8121 - val_loss: 1.8665\n",
      "Epoch 97/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.7975 - val_loss: 1.7724\n",
      "Epoch 98/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7958 - val_loss: 1.9076\n",
      "Epoch 99/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.7970 - val_loss: 1.7920\n",
      "Epoch 100/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.7818 - val_loss: 1.8693\n",
      "Epoch 101/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7938 - val_loss: 1.7854\n",
      "Epoch 102/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7795 - val_loss: 1.7340\n",
      "Epoch 103/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7755 - val_loss: 1.7524\n",
      "Epoch 104/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7701 - val_loss: 1.8185\n",
      "Epoch 105/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7806 - val_loss: 1.8120\n",
      "Epoch 106/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7682 - val_loss: 1.7408\n",
      "Epoch 107/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7637 - val_loss: 1.7758\n",
      "Epoch 108/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7706 - val_loss: 1.7523\n",
      "Epoch 109/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7578 - val_loss: 1.7466\n",
      "Epoch 110/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7515 - val_loss: 1.7381\n",
      "Epoch 111/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7534 - val_loss: 1.8084\n",
      "Epoch 112/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7447 - val_loss: 1.7774\n",
      "Epoch 113/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7407 - val_loss: 1.7200\n",
      "Epoch 114/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.7469 - val_loss: 1.8477\n",
      "Epoch 115/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7534 - val_loss: 1.7422\n",
      "Epoch 116/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7363 - val_loss: 1.7447\n",
      "Epoch 117/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7311 - val_loss: 1.7115\n",
      "Epoch 118/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7305 - val_loss: 1.7207\n",
      "Epoch 119/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7395 - val_loss: 1.7754\n",
      "Epoch 120/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7296 - val_loss: 1.8137\n",
      "Epoch 121/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7280 - val_loss: 1.7120\n",
      "Epoch 122/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7176 - val_loss: 1.7100\n",
      "Epoch 123/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7261 - val_loss: 1.7627\n",
      "Epoch 124/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7059 - val_loss: 1.7174\n",
      "Epoch 125/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7076 - val_loss: 1.7348\n",
      "Epoch 126/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7147 - val_loss: 1.7622\n",
      "Epoch 127/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6922 - val_loss: 1.6853\n",
      "Epoch 128/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7060 - val_loss: 1.7723\n",
      "Epoch 129/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.7048 - val_loss: 1.7214\n",
      "Epoch 130/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.7155 - val_loss: 1.7307\n",
      "Epoch 131/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6875 - val_loss: 1.7865\n",
      "Epoch 132/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6929 - val_loss: 1.6643\n",
      "Epoch 133/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6989 - val_loss: 1.6880\n",
      "Epoch 134/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7008 - val_loss: 1.7664\n",
      "Epoch 135/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6843 - val_loss: 1.7397\n",
      "Epoch 136/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6884 - val_loss: 1.7019\n",
      "Epoch 137/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6801 - val_loss: 1.7252\n",
      "Epoch 138/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6869 - val_loss: 1.6787\n",
      "Epoch 139/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6741 - val_loss: 1.7084\n",
      "Epoch 140/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6728 - val_loss: 1.7450\n",
      "Epoch 141/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6620 - val_loss: 1.7547\n",
      "Epoch 142/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6685 - val_loss: 1.6938\n",
      "Epoch 143/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6796 - val_loss: 1.6745\n",
      "Epoch 144/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.6533 - val_loss: 1.7029\n",
      "Epoch 145/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6602 - val_loss: 1.6536\n",
      "Epoch 146/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6754 - val_loss: 1.6366\n",
      "Epoch 147/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6496 - val_loss: 1.7553\n",
      "Epoch 148/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6536 - val_loss: 1.6495\n",
      "Epoch 149/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6439 - val_loss: 1.6528\n",
      "Epoch 150/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6397 - val_loss: 1.6756\n",
      "Epoch 151/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6483 - val_loss: 1.7390\n",
      "Epoch 152/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6445 - val_loss: 1.6957\n",
      "Epoch 153/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6419 - val_loss: 1.7073\n",
      "Epoch 154/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6422 - val_loss: 1.6682\n",
      "Epoch 155/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6359 - val_loss: 1.7264\n",
      "Epoch 156/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6317 - val_loss: 1.6740\n",
      "Epoch 157/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6229 - val_loss: 1.7135\n",
      "Epoch 158/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6410 - val_loss: 1.6943\n",
      "Epoch 159/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 5s 11ms/step - loss: 1.6255 - val_loss: 1.6219\n",
      "Epoch 160/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.6093 - val_loss: 1.6962\n",
      "Epoch 161/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6153 - val_loss: 1.7144\n",
      "Epoch 162/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6256 - val_loss: 1.7006\n",
      "Epoch 163/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6149 - val_loss: 1.6498\n",
      "Epoch 164/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6202 - val_loss: 1.6066\n",
      "Epoch 165/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6085 - val_loss: 1.5758\n",
      "Epoch 166/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6044 - val_loss: 1.6146\n",
      "Epoch 167/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6083 - val_loss: 1.6398\n",
      "Epoch 168/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6001 - val_loss: 1.5867\n",
      "Epoch 169/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5966 - val_loss: 1.6543\n",
      "Epoch 170/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6015 - val_loss: 1.6752\n",
      "Epoch 171/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5934 - val_loss: 1.6084\n",
      "Epoch 172/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6087 - val_loss: 1.6511\n",
      "Epoch 173/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5970 - val_loss: 1.6342\n",
      "Epoch 174/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5927 - val_loss: 1.7392\n",
      "Epoch 175/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5812 - val_loss: 1.6418\n",
      "Epoch 176/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6055 - val_loss: 1.6024\n",
      "Epoch 177/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6013 - val_loss: 1.6002\n",
      "Epoch 178/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5842 - val_loss: 1.6596\n",
      "Epoch 179/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5698 - val_loss: 1.5838\n",
      "Epoch 180/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5719 - val_loss: 1.6179\n",
      "Epoch 181/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5834 - val_loss: 1.6025\n",
      "Epoch 182/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5752 - val_loss: 1.6913\n",
      "Epoch 183/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5781 - val_loss: 1.7354\n",
      "Epoch 184/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5697 - val_loss: 1.9619\n",
      "Epoch 185/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5849 - val_loss: 1.6462\n",
      "Epoch 186/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5779 - val_loss: 1.5664\n",
      "Epoch 187/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5583 - val_loss: 1.5781\n",
      "Epoch 188/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5913 - val_loss: 1.6524\n",
      "Epoch 189/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5731 - val_loss: 1.5581\n",
      "Epoch 190/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5781 - val_loss: 1.6445\n",
      "Epoch 191/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5624 - val_loss: 1.5668\n",
      "Epoch 192/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5651 - val_loss: 1.7200\n",
      "Epoch 193/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5500 - val_loss: 1.6196\n",
      "Epoch 194/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5598 - val_loss: 1.5774\n",
      "Epoch 195/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5459 - val_loss: 1.6295\n",
      "Epoch 196/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5782 - val_loss: 1.5435\n",
      "Epoch 197/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5456 - val_loss: 1.5692\n",
      "Epoch 198/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5612 - val_loss: 1.6001\n",
      "Epoch 199/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5511 - val_loss: 1.5803\n",
      "Epoch 200/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5541 - val_loss: 1.5738\n",
      "Epoch 201/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5604 - val_loss: 1.6654\n",
      "Epoch 202/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5494 - val_loss: 1.5485\n",
      "Epoch 203/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5440 - val_loss: 1.5732\n",
      "Epoch 204/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5418 - val_loss: 1.5608\n",
      "Epoch 205/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5477 - val_loss: 1.6348\n",
      "Epoch 206/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5474 - val_loss: 1.5747\n",
      "Epoch 207/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5286 - val_loss: 1.5818\n",
      "Epoch 208/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5412 - val_loss: 1.6233\n",
      "Epoch 209/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5473 - val_loss: 1.6448\n",
      "Epoch 210/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5495 - val_loss: 1.5289\n",
      "Epoch 211/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5368 - val_loss: 1.5508\n",
      "Epoch 212/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5336 - val_loss: 1.5112\n",
      "Epoch 213/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5305 - val_loss: 1.5419\n",
      "Epoch 214/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5260 - val_loss: 1.5771\n",
      "Epoch 215/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5314 - val_loss: 1.5491\n",
      "Epoch 216/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5333 - val_loss: 1.5924\n",
      "Epoch 217/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5348 - val_loss: 1.5826\n",
      "Epoch 218/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5236 - val_loss: 1.7196\n",
      "Epoch 219/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.5307 - val_loss: 1.5555\n",
      "Epoch 220/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.5252 - val_loss: 1.5665\n",
      "Epoch 221/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5153 - val_loss: 1.5515\n",
      "Epoch 222/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5187 - val_loss: 1.5664\n",
      "Epoch 223/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5140 - val_loss: 1.5571\n",
      "Epoch 224/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5118 - val_loss: 1.6595\n",
      "Epoch 225/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5254 - val_loss: 1.5727\n",
      "Epoch 226/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5100 - val_loss: 1.5975\n",
      "Epoch 227/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5190 - val_loss: 1.5236\n",
      "Epoch 228/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5287 - val_loss: 1.6050\n",
      "Epoch 229/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5141 - val_loss: 1.5625\n",
      "Epoch 230/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5049 - val_loss: 1.5413\n",
      "Epoch 231/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5082 - val_loss: 1.5546\n",
      "Epoch 232/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5181 - val_loss: 1.5280\n",
      "Epoch 233/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5095 - val_loss: 1.5526\n",
      "Epoch 234/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5097 - val_loss: 1.5754\n",
      "Epoch 235/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5061 - val_loss: 1.5031\n",
      "Epoch 236/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5100 - val_loss: 1.5587\n",
      "Epoch 237/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5011 - val_loss: 1.4939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4885 - val_loss: 1.5416\n",
      "Epoch 239/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5006 - val_loss: 1.5275\n",
      "Epoch 240/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4886 - val_loss: 1.5149\n",
      "Epoch 241/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5092 - val_loss: 1.5193\n",
      "Epoch 242/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4899 - val_loss: 1.5491\n",
      "Epoch 243/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4898 - val_loss: 1.6151\n",
      "Epoch 244/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4919 - val_loss: 1.5985\n",
      "Epoch 245/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4900 - val_loss: 1.5567\n",
      "Epoch 246/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4893 - val_loss: 1.5625\n",
      "Epoch 247/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4856 - val_loss: 1.5053\n",
      "Epoch 248/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4907 - val_loss: 1.6030\n",
      "Epoch 249/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4927 - val_loss: 1.5409\n",
      "Epoch 250/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4844 - val_loss: 1.5279\n",
      "Epoch 251/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4907 - val_loss: 1.5499\n",
      "Epoch 252/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4880 - val_loss: 1.5249\n",
      "Epoch 253/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4862 - val_loss: 1.5721\n",
      "Epoch 254/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4722 - val_loss: 1.5308\n",
      "Epoch 255/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4908 - val_loss: 1.5464\n",
      "Epoch 256/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4878 - val_loss: 1.5619\n",
      "Epoch 257/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4725 - val_loss: 1.4855\n",
      "Epoch 258/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4847 - val_loss: 1.5520\n",
      "Epoch 259/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4789 - val_loss: 1.5083\n",
      "Epoch 260/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4774 - val_loss: 1.5541\n",
      "Epoch 261/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4615 - val_loss: 1.5133\n",
      "Epoch 262/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4804 - val_loss: 1.4847\n",
      "Epoch 263/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4766 - val_loss: 1.5179\n",
      "Epoch 264/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4752 - val_loss: 1.4616\n",
      "Epoch 265/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4524 - val_loss: 1.4819\n",
      "Epoch 266/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4691 - val_loss: 1.4832\n",
      "Epoch 267/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4716 - val_loss: 1.4932\n",
      "Epoch 268/900\n",
      "432/432 [==============================] - 12s 28ms/step - loss: 1.4691 - val_loss: 1.4841\n",
      "Epoch 269/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4782 - val_loss: 1.4567\n",
      "Epoch 270/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4671 - val_loss: 1.4867\n",
      "Epoch 271/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4713 - val_loss: 1.4819\n",
      "Epoch 272/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4614 - val_loss: 1.4705\n",
      "Epoch 273/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4585 - val_loss: 1.5365\n",
      "Epoch 274/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4493 - val_loss: 1.5250\n",
      "Epoch 275/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4671 - val_loss: 1.5117\n",
      "Epoch 276/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4660 - val_loss: 1.5267\n",
      "Epoch 277/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4528 - val_loss: 1.5061\n",
      "Epoch 278/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4583 - val_loss: 1.4841\n",
      "Epoch 279/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4664 - val_loss: 1.4969\n",
      "Epoch 280/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4559 - val_loss: 1.4909\n",
      "Epoch 281/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4636 - val_loss: 1.5156\n",
      "Epoch 282/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4500 - val_loss: 1.4648\n",
      "Epoch 283/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4641 - val_loss: 1.4617\n",
      "Epoch 284/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4504 - val_loss: 1.5093\n",
      "Epoch 285/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.4502 - val_loss: 1.5076\n",
      "Epoch 286/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4698 - val_loss: 1.5190\n",
      "Epoch 287/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4420 - val_loss: 1.4904\n",
      "Epoch 288/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4511 - val_loss: 1.5213\n",
      "Epoch 289/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4472 - val_loss: 1.4810\n",
      "Epoch 290/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4486 - val_loss: 1.4800\n",
      "Epoch 291/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4378 - val_loss: 1.4662\n",
      "Epoch 292/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4350 - val_loss: 1.5298\n",
      "Epoch 293/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4377 - val_loss: 1.4645\n",
      "Epoch 294/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4465 - val_loss: 1.4787\n",
      "Epoch 295/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4494 - val_loss: 1.4768\n",
      "Epoch 296/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4519 - val_loss: 1.5042\n",
      "Epoch 297/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.4414 - val_loss: 1.5548\n",
      "Epoch 298/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4471 - val_loss: 1.4809\n",
      "Epoch 299/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4475 - val_loss: 1.4460\n",
      "Epoch 300/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4535 - val_loss: 1.4749\n",
      "Epoch 301/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4340 - val_loss: 1.4725\n",
      "Epoch 302/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4340 - val_loss: 1.4577\n",
      "Epoch 303/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4435 - val_loss: 1.4559\n",
      "Epoch 304/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4425 - val_loss: 1.5073\n",
      "Epoch 305/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.4295 - val_loss: 1.5696\n",
      "Epoch 306/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4361 - val_loss: 1.4996\n",
      "Epoch 307/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4335 - val_loss: 1.4922\n",
      "Epoch 308/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4254 - val_loss: 1.4765\n",
      "Epoch 309/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4292 - val_loss: 1.5088\n",
      "Epoch 310/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4349 - val_loss: 1.4538\n",
      "Epoch 311/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4240 - val_loss: 1.4978\n",
      "Epoch 312/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4410 - val_loss: 1.5121\n",
      "Epoch 313/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4356 - val_loss: 1.7043\n",
      "Epoch 314/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.4267 - val_loss: 1.4650\n",
      "Epoch 315/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4284 - val_loss: 1.4592\n",
      "Epoch 316/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4097 - val_loss: 1.4419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4313 - val_loss: 1.4812\n",
      "Epoch 318/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4316 - val_loss: 1.4631\n",
      "Epoch 319/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4300 - val_loss: 1.5675\n",
      "Epoch 320/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4206 - val_loss: 1.5445\n",
      "Epoch 321/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4490 - val_loss: 1.4902\n",
      "Epoch 322/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4150 - val_loss: 1.4398\n",
      "Epoch 323/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4161 - val_loss: 1.5045\n",
      "Epoch 324/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4262 - val_loss: 1.4681\n",
      "Epoch 325/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4171 - val_loss: 1.4856\n",
      "Epoch 326/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4354 - val_loss: 1.4690\n",
      "Epoch 327/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4199 - val_loss: 1.4995\n",
      "Epoch 328/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4091 - val_loss: 1.4340\n",
      "Epoch 329/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4202 - val_loss: 1.4941\n",
      "Epoch 330/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4178 - val_loss: 1.5685\n",
      "Epoch 331/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4057 - val_loss: 1.4168\n",
      "Epoch 332/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4167 - val_loss: 1.4953\n",
      "Epoch 333/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4266 - val_loss: 1.4897\n",
      "Epoch 334/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4210 - val_loss: 1.5263\n",
      "Epoch 335/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4172 - val_loss: 1.4743\n",
      "Epoch 336/900\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.4083 - val_loss: 1.4254\n",
      "Epoch 337/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4146 - val_loss: 1.4645\n",
      "Epoch 338/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4124 - val_loss: 1.4431\n",
      "Epoch 339/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4020 - val_loss: 1.4784\n",
      "Epoch 340/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4032 - val_loss: 1.4753\n",
      "Epoch 341/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4083 - val_loss: 1.4865\n",
      "Epoch 342/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4192 - val_loss: 1.5427\n",
      "Epoch 343/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4088 - val_loss: 1.4643\n",
      "Epoch 344/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4173 - val_loss: 1.4652\n",
      "Epoch 345/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3914 - val_loss: 1.5438\n",
      "Epoch 346/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3930 - val_loss: 1.4482\n",
      "Epoch 347/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4039 - val_loss: 1.4539\n",
      "Epoch 348/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3994 - val_loss: 1.4977\n",
      "Epoch 349/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4155 - val_loss: 1.4876\n",
      "Epoch 350/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4001 - val_loss: 1.4272\n",
      "Epoch 351/900\n",
      "432/432 [==============================] - 9s 21ms/step - loss: 1.4038 - val_loss: 1.4875\n",
      "Epoch 352/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3961 - val_loss: 1.4482\n",
      "Epoch 353/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3926 - val_loss: 1.5020\n",
      "Epoch 354/900\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 1.3949 - val_loss: 1.5566\n",
      "Epoch 355/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3946 - val_loss: 1.4307\n",
      "Epoch 356/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4006 - val_loss: 1.4278\n",
      "Epoch 357/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3974 - val_loss: 1.3945\n",
      "Epoch 358/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3960 - val_loss: 1.5144\n",
      "Epoch 359/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4013 - val_loss: 1.4143\n",
      "Epoch 360/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3786 - val_loss: 1.5464\n",
      "Epoch 361/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3975 - val_loss: 1.4875\n",
      "Epoch 362/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3837 - val_loss: 1.4501\n",
      "Epoch 363/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3847 - val_loss: 1.3890\n",
      "Epoch 364/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4130 - val_loss: 1.5222\n",
      "Epoch 365/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3833 - val_loss: 1.4412\n",
      "Epoch 366/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3872 - val_loss: 1.4371\n",
      "Epoch 367/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3858 - val_loss: 1.4858\n",
      "Epoch 368/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3907 - val_loss: 1.3889\n",
      "Epoch 369/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3932 - val_loss: 1.4465\n",
      "Epoch 370/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3899 - val_loss: 1.5116\n",
      "Epoch 371/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3939 - val_loss: 1.4493\n",
      "Epoch 372/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3768 - val_loss: 1.4195\n",
      "Epoch 373/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3787 - val_loss: 1.4290\n",
      "Epoch 374/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3763 - val_loss: 1.3827\n",
      "Epoch 375/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3857 - val_loss: 1.4133\n",
      "Epoch 376/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3928 - val_loss: 1.3874\n",
      "Epoch 377/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3803 - val_loss: 1.3897\n",
      "Epoch 378/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3776 - val_loss: 1.4658\n",
      "Epoch 379/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3837 - val_loss: 1.4280\n",
      "Epoch 380/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3797 - val_loss: 1.4935\n",
      "Epoch 381/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3806 - val_loss: 1.4730\n",
      "Epoch 382/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3793 - val_loss: 1.4392\n",
      "Epoch 383/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3769 - val_loss: 1.3999\n",
      "Epoch 384/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3724 - val_loss: 1.4221\n",
      "Epoch 385/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3724 - val_loss: 1.4000\n",
      "Epoch 386/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3712 - val_loss: 1.4167\n",
      "Epoch 387/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3689 - val_loss: 1.4131\n",
      "Epoch 388/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3916 - val_loss: 1.4671\n",
      "Epoch 389/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3651 - val_loss: 1.4303\n",
      "Epoch 390/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3652 - val_loss: 1.3686\n",
      "Epoch 391/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3787 - val_loss: 1.5455\n",
      "Epoch 392/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.3708 - val_loss: 1.4105\n",
      "Epoch 393/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.3762 - val_loss: 1.4381\n",
      "Epoch 394/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3846 - val_loss: 1.3978\n",
      "Epoch 395/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3633 - val_loss: 1.4287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3731 - val_loss: 1.4151\n",
      "Epoch 397/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3746 - val_loss: 1.4457\n",
      "Epoch 398/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3645 - val_loss: 1.4652\n",
      "Epoch 399/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3622 - val_loss: 1.4295\n",
      "Epoch 400/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3681 - val_loss: 1.4071\n",
      "Epoch 401/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3691 - val_loss: 1.4147\n",
      "Epoch 402/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3668 - val_loss: 1.4376\n",
      "Epoch 403/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3754 - val_loss: 1.4381\n",
      "Epoch 404/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3711 - val_loss: 1.4082\n",
      "Epoch 405/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3721 - val_loss: 1.4561\n",
      "Epoch 406/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3628 - val_loss: 1.4665\n",
      "Epoch 407/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3571 - val_loss: 1.3890\n",
      "Epoch 408/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3626 - val_loss: 1.3981\n",
      "Epoch 409/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3678 - val_loss: 1.4076\n",
      "Epoch 410/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3584 - val_loss: 1.3682\n",
      "Epoch 411/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3676 - val_loss: 1.3866\n",
      "Epoch 412/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3632 - val_loss: 1.4331\n",
      "Epoch 413/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3481 - val_loss: 1.4011\n",
      "Epoch 414/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3603 - val_loss: 1.3994\n",
      "Epoch 415/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3610 - val_loss: 1.4352\n",
      "Epoch 416/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3640 - val_loss: 1.4611\n",
      "Epoch 417/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3659 - val_loss: 1.3699\n",
      "Epoch 418/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3548 - val_loss: 1.3817\n",
      "Epoch 419/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3521 - val_loss: 1.4132\n",
      "Epoch 420/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.3552 - val_loss: 1.4179\n",
      "Epoch 421/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3547 - val_loss: 1.3856\n",
      "Epoch 422/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3499 - val_loss: 1.4194\n",
      "Epoch 423/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3500 - val_loss: 1.3950\n",
      "Epoch 424/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3579 - val_loss: 1.3797\n",
      "Epoch 425/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3527 - val_loss: 1.4175\n",
      "Epoch 426/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3447 - val_loss: 1.4277\n",
      "Epoch 427/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3504 - val_loss: 1.4119\n",
      "Epoch 428/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3363 - val_loss: 1.4215\n",
      "Epoch 429/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3488 - val_loss: 1.3523\n",
      "Epoch 430/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3491 - val_loss: 1.4035\n",
      "Epoch 431/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3468 - val_loss: 1.4960\n",
      "Epoch 432/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3543 - val_loss: 1.5330\n",
      "Epoch 433/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3580 - val_loss: 1.4088\n",
      "Epoch 434/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3554 - val_loss: 1.4215\n",
      "Epoch 435/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3402 - val_loss: 1.4063\n",
      "Epoch 436/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3490 - val_loss: 1.3597\n",
      "Epoch 437/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3537 - val_loss: 1.3898\n",
      "Epoch 438/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3437 - val_loss: 1.4190\n",
      "Epoch 439/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3485 - val_loss: 1.4110\n",
      "Epoch 440/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3501 - val_loss: 1.4349\n",
      "Epoch 441/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3430 - val_loss: 1.4121\n",
      "Epoch 442/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3477 - val_loss: 1.3574\n",
      "Epoch 443/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3393 - val_loss: 1.3806\n",
      "Epoch 444/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3514 - val_loss: 1.4328\n",
      "Epoch 445/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3454 - val_loss: 1.4131\n",
      "Epoch 446/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3351 - val_loss: 1.3976\n",
      "Epoch 447/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3362 - val_loss: 1.3661\n",
      "Epoch 448/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3376 - val_loss: 1.4182\n",
      "Epoch 449/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3375 - val_loss: 1.4378\n",
      "Epoch 450/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3472 - val_loss: 1.3726\n",
      "Epoch 451/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3351 - val_loss: 1.3867\n",
      "Epoch 452/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3544 - val_loss: 1.4074\n",
      "Epoch 453/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3318 - val_loss: 1.4141\n",
      "Epoch 454/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3356 - val_loss: 1.4374\n",
      "Epoch 455/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3427 - val_loss: 1.4175\n",
      "Epoch 456/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.3410 - val_loss: 1.4017\n",
      "Epoch 457/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3370 - val_loss: 1.3799\n",
      "Epoch 458/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3326 - val_loss: 1.4426\n",
      "Epoch 459/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3424 - val_loss: 1.3473\n",
      "Epoch 460/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3346 - val_loss: 1.3824\n",
      "Epoch 461/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3415 - val_loss: 1.3838\n",
      "Epoch 462/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3304 - val_loss: 1.3417\n",
      "Epoch 463/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3466 - val_loss: 1.3747\n",
      "Epoch 464/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3306 - val_loss: 1.4204\n",
      "Epoch 465/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3422 - val_loss: 1.4625\n",
      "Epoch 466/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3370 - val_loss: 1.4733\n",
      "Epoch 467/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3305 - val_loss: 1.4491\n",
      "Epoch 468/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3335 - val_loss: 1.3812\n",
      "Epoch 469/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3347 - val_loss: 1.3362\n",
      "Epoch 470/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3377 - val_loss: 1.4105\n",
      "Epoch 471/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3354 - val_loss: 1.4029\n",
      "Epoch 472/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3351 - val_loss: 1.4029\n",
      "Epoch 473/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3338 - val_loss: 1.3816\n",
      "Epoch 474/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3313 - val_loss: 1.3437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3436 - val_loss: 1.4053\n",
      "Epoch 476/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3182 - val_loss: 1.4507\n",
      "Epoch 477/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3388 - val_loss: 1.4117\n",
      "Epoch 478/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3330 - val_loss: 1.4444\n",
      "Epoch 479/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3320 - val_loss: 1.3431\n",
      "Epoch 480/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3239 - val_loss: 1.3262\n",
      "Epoch 481/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3292 - val_loss: 1.3530\n",
      "Epoch 482/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3341 - val_loss: 1.3860\n",
      "Epoch 483/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3318 - val_loss: 1.3657\n",
      "Epoch 484/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3230 - val_loss: 1.3848\n",
      "Epoch 485/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3302 - val_loss: 1.3710\n",
      "Epoch 486/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3276 - val_loss: 1.4241\n",
      "Epoch 487/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3111 - val_loss: 1.4093\n",
      "Epoch 488/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3299 - val_loss: 1.4467\n",
      "Epoch 489/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3223 - val_loss: 1.3868\n",
      "Epoch 490/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3285 - val_loss: 1.4149\n",
      "Epoch 491/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3262 - val_loss: 1.4166\n",
      "Epoch 492/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3381 - val_loss: 1.4594\n",
      "Epoch 493/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3207 - val_loss: 1.3726\n",
      "Epoch 494/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3157 - val_loss: 1.3557\n",
      "Epoch 495/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3167 - val_loss: 1.3621\n",
      "Epoch 496/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3332 - val_loss: 1.3437\n",
      "Epoch 497/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3337 - val_loss: 1.3972\n",
      "Epoch 498/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3245 - val_loss: 1.3446\n",
      "Epoch 499/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3177 - val_loss: 1.3599\n",
      "Epoch 500/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3175 - val_loss: 1.3927\n",
      "Epoch 501/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3208 - val_loss: 1.4211\n",
      "Epoch 502/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3124 - val_loss: 1.3681\n",
      "Epoch 503/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3225 - val_loss: 1.4082\n",
      "Epoch 504/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3231 - val_loss: 1.3452\n",
      "Epoch 505/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3225 - val_loss: 1.3416\n",
      "Epoch 506/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3278 - val_loss: 1.3802\n",
      "Epoch 507/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3138 - val_loss: 1.3515\n",
      "Epoch 508/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3127 - val_loss: 1.4909\n",
      "Epoch 509/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3136 - val_loss: 1.3232\n",
      "Epoch 510/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3291 - val_loss: 1.3652\n",
      "Epoch 511/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3140 - val_loss: 1.4403\n",
      "Epoch 512/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3165 - val_loss: 1.3956\n",
      "Epoch 513/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3136 - val_loss: 1.3668\n",
      "Epoch 514/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3155 - val_loss: 1.3539\n",
      "Epoch 515/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3162 - val_loss: 1.3496\n",
      "Epoch 516/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3248 - val_loss: 1.4096\n",
      "Epoch 517/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3208 - val_loss: 1.3653\n",
      "Epoch 518/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3097 - val_loss: 1.3583\n",
      "Epoch 519/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3172 - val_loss: 1.4073\n",
      "Epoch 520/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3199 - val_loss: 1.4119\n",
      "Epoch 521/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3067 - val_loss: 1.3975\n",
      "Epoch 522/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3202 - val_loss: 1.3901\n",
      "Epoch 523/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3104 - val_loss: 1.4048\n",
      "Epoch 524/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3071 - val_loss: 1.3575\n",
      "Epoch 525/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3174 - val_loss: 1.3518\n",
      "Epoch 526/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3116 - val_loss: 1.3566\n",
      "Epoch 527/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3022 - val_loss: 1.4040\n",
      "Epoch 528/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.3097 - val_loss: 1.4354\n",
      "Epoch 529/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3019 - val_loss: 1.3393\n",
      "Epoch 530/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3018 - val_loss: 1.3660\n",
      "Epoch 531/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3254 - val_loss: 1.3410\n",
      "Epoch 532/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3100 - val_loss: 1.3086\n",
      "Epoch 533/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3109 - val_loss: 1.3655\n",
      "Epoch 534/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3141 - val_loss: 1.3598\n",
      "Epoch 535/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3026 - val_loss: 1.4148\n",
      "Epoch 536/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3158 - val_loss: 1.4244\n",
      "Epoch 537/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3122 - val_loss: 1.3217\n",
      "Epoch 538/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3049 - val_loss: 1.3920\n",
      "Epoch 539/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3134 - val_loss: 1.3360\n",
      "Epoch 540/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3158 - val_loss: 1.3592\n",
      "Epoch 541/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3025 - val_loss: 1.3907\n",
      "Epoch 542/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.3018 - val_loss: 1.4038\n",
      "Epoch 543/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3021 - val_loss: 1.3363\n",
      "Epoch 544/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3107 - val_loss: 1.4633\n",
      "Epoch 545/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3105 - val_loss: 1.3441\n",
      "Epoch 546/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3081 - val_loss: 1.3287\n",
      "Epoch 547/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2931 - val_loss: 1.3406\n",
      "Epoch 548/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3047 - val_loss: 1.3894\n",
      "Epoch 549/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3097 - val_loss: 1.4611\n",
      "Epoch 550/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3119 - val_loss: 1.3428\n",
      "Epoch 551/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2928 - val_loss: 1.3176\n",
      "Epoch 552/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3008 - val_loss: 1.3678\n",
      "Epoch 553/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3047 - val_loss: 1.3966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2998 - val_loss: 1.3479\n",
      "Epoch 555/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3008 - val_loss: 1.3465\n",
      "Epoch 556/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3027 - val_loss: 1.3190\n",
      "Epoch 557/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2914 - val_loss: 1.3422\n",
      "Epoch 558/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3051 - val_loss: 1.3532\n",
      "Epoch 559/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.3038 - val_loss: 1.3435\n",
      "Epoch 560/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2980 - val_loss: 1.3431\n",
      "Epoch 561/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3063 - val_loss: 1.3539\n",
      "Epoch 562/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3001 - val_loss: 1.3146\n",
      "Epoch 563/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2819 - val_loss: 1.3368\n",
      "Epoch 564/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2924 - val_loss: 1.3421\n",
      "Epoch 565/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3039 - val_loss: 1.3373\n",
      "Epoch 566/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.2989 - val_loss: 1.3208\n",
      "Epoch 567/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3023 - val_loss: 1.3329\n",
      "Epoch 568/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2998 - val_loss: 1.3408\n",
      "Epoch 569/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2943 - val_loss: 1.3482\n",
      "Epoch 570/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2923 - val_loss: 1.3663\n",
      "Epoch 571/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2895 - val_loss: 1.2847\n",
      "Epoch 572/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2886 - val_loss: 1.3190\n",
      "Epoch 573/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2896 - val_loss: 1.3168\n",
      "Epoch 574/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2977 - val_loss: 1.3594\n",
      "Epoch 575/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3022 - val_loss: 1.3374\n",
      "Epoch 576/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2918 - val_loss: 1.3289\n",
      "Epoch 577/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2931 - val_loss: 1.3777\n",
      "Epoch 578/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2904 - val_loss: 1.4143\n",
      "Epoch 579/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2945 - val_loss: 1.3514\n",
      "Epoch 580/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2996 - val_loss: 1.3829\n",
      "Epoch 581/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2925 - val_loss: 1.3531\n",
      "Epoch 582/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2896 - val_loss: 1.3309\n",
      "Epoch 583/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2960 - val_loss: 1.3545\n",
      "Epoch 584/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2946 - val_loss: 1.3215\n",
      "Epoch 585/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2953 - val_loss: 1.3680\n",
      "Epoch 586/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2824 - val_loss: 1.3436\n",
      "Epoch 587/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2909 - val_loss: 1.2914\n",
      "Epoch 588/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2845 - val_loss: 1.3247\n",
      "Epoch 589/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2823 - val_loss: 1.4408\n",
      "Epoch 590/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2936 - val_loss: 1.3533\n",
      "Epoch 591/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.2995 - val_loss: 1.3355\n",
      "Epoch 592/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2893 - val_loss: 1.2928\n",
      "Epoch 593/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2996 - val_loss: 1.3009\n",
      "Epoch 594/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2882 - val_loss: 1.3642\n",
      "Epoch 595/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2976 - val_loss: 1.3719\n",
      "Epoch 596/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2928 - val_loss: 1.3440\n",
      "Epoch 597/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2858 - val_loss: 1.3158\n",
      "Epoch 598/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2794 - val_loss: 1.3750\n",
      "Epoch 599/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2867 - val_loss: 1.3654\n",
      "Epoch 600/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2941 - val_loss: 1.3784\n",
      "Epoch 601/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2830 - val_loss: 1.3022\n",
      "Epoch 602/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2813 - val_loss: 1.3258\n",
      "Epoch 603/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2864 - val_loss: 1.3044\n",
      "Epoch 604/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2820 - val_loss: 1.4253\n",
      "Epoch 605/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2772 - val_loss: 1.3010\n",
      "Epoch 606/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2869 - val_loss: 1.4333\n",
      "Epoch 607/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2814 - val_loss: 1.3911\n",
      "Epoch 608/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2758 - val_loss: 1.3743\n",
      "Epoch 609/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2959 - val_loss: 1.3237\n",
      "Epoch 610/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2839 - val_loss: 1.3096\n",
      "Epoch 611/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2782 - val_loss: 1.3283\n",
      "Epoch 612/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2745 - val_loss: 1.3426\n",
      "Epoch 613/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2817 - val_loss: 1.3258\n",
      "Epoch 614/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2774 - val_loss: 1.3191\n",
      "Epoch 615/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2857 - val_loss: 1.3096\n",
      "Epoch 616/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.2854 - val_loss: 1.3715\n",
      "Epoch 617/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2847 - val_loss: 1.3392\n",
      "Epoch 618/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2886 - val_loss: 1.3368\n",
      "Epoch 619/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2767 - val_loss: 1.3512\n",
      "Epoch 620/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2856 - val_loss: 1.3638\n",
      "Epoch 621/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2800 - val_loss: 1.3325\n",
      "Epoch 622/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2867 - val_loss: 1.3487\n",
      "Epoch 623/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2722 - val_loss: 1.3565\n",
      "Epoch 624/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2774 - val_loss: 1.3451\n",
      "Epoch 625/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2789 - val_loss: 1.3341\n",
      "Epoch 626/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2755 - val_loss: 1.2940\n",
      "Epoch 627/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2838 - val_loss: 1.2908\n",
      "Epoch 628/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2873 - val_loss: 1.3641\n",
      "Epoch 629/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2780 - val_loss: 1.3019\n",
      "Epoch 630/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.2749 - val_loss: 1.3132\n",
      "Epoch 631/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2926 - val_loss: 1.3086\n",
      "Epoch 632/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2690 - val_loss: 1.3172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2786 - val_loss: 1.3431\n",
      "Epoch 634/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2781 - val_loss: 1.3162\n",
      "Epoch 635/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2848 - val_loss: 1.3777\n",
      "Epoch 636/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2689 - val_loss: 1.3576\n",
      "Epoch 637/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2765 - val_loss: 1.4006\n",
      "Epoch 638/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2686 - val_loss: 1.3451\n",
      "Epoch 639/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2725 - val_loss: 1.2998\n",
      "Epoch 640/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2685 - val_loss: 1.2817\n",
      "Epoch 641/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2768 - val_loss: 1.3560\n",
      "Epoch 642/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2774 - val_loss: 1.3884\n",
      "Epoch 643/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2695 - val_loss: 1.3390\n",
      "Epoch 644/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2747 - val_loss: 1.3331\n",
      "Epoch 645/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2753 - val_loss: 1.3806\n",
      "Epoch 646/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2701 - val_loss: 1.3406\n",
      "Epoch 647/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2798 - val_loss: 1.3127\n",
      "Epoch 648/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2742 - val_loss: 1.3336\n",
      "Epoch 649/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2687 - val_loss: 1.3573\n",
      "Epoch 650/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2682 - val_loss: 1.3000\n",
      "Epoch 651/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2689 - val_loss: 1.3486\n",
      "Epoch 652/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2638 - val_loss: 1.3229\n",
      "Epoch 653/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2749 - val_loss: 1.3216\n",
      "Epoch 654/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2761 - val_loss: 1.3526\n",
      "Epoch 655/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2718 - val_loss: 1.3531\n",
      "Epoch 656/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2732 - val_loss: 1.3411\n",
      "Epoch 657/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2764 - val_loss: 1.3362\n",
      "Epoch 658/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2771 - val_loss: 1.3265\n",
      "Epoch 659/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2768 - val_loss: 1.3189\n",
      "Epoch 660/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2720 - val_loss: 1.3357\n",
      "Epoch 661/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2620 - val_loss: 1.3224\n",
      "Epoch 662/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2765 - val_loss: 1.3048\n",
      "Epoch 663/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2651 - val_loss: 1.2859\n",
      "Epoch 664/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2658 - val_loss: 1.3275\n",
      "Epoch 665/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2640 - val_loss: 1.3553\n",
      "Epoch 666/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2707 - val_loss: 1.2728\n",
      "Epoch 667/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2639 - val_loss: 1.2965\n",
      "Epoch 668/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2737 - val_loss: 1.3114\n",
      "Epoch 669/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.2776 - val_loss: 1.4388\n",
      "Epoch 670/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2796 - val_loss: 1.3447\n",
      "Epoch 671/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2762 - val_loss: 1.3194\n",
      "Epoch 672/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2775 - val_loss: 1.3176\n",
      "Epoch 673/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2655 - val_loss: 1.3468\n",
      "Epoch 674/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2679 - val_loss: 1.3491\n",
      "Epoch 675/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2706 - val_loss: 1.3355\n",
      "Epoch 676/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2714 - val_loss: 1.3176\n",
      "Epoch 677/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2719 - val_loss: 1.3183\n",
      "Epoch 678/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2597 - val_loss: 1.3413\n",
      "Epoch 679/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2668 - val_loss: 1.3466\n",
      "Epoch 680/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2562 - val_loss: 1.2870\n",
      "Epoch 681/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2621 - val_loss: 1.3394\n",
      "Epoch 682/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2707 - val_loss: 1.3486\n",
      "Epoch 683/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2630 - val_loss: 1.4136\n",
      "Epoch 684/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2794 - val_loss: 1.2870\n",
      "Epoch 685/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2576 - val_loss: 1.2865\n",
      "Epoch 686/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2666 - val_loss: 1.3259\n",
      "Epoch 687/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2619 - val_loss: 1.3971\n",
      "Epoch 688/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2655 - val_loss: 1.3373\n",
      "Epoch 689/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2747 - val_loss: 1.3031\n",
      "Epoch 690/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2576 - val_loss: 1.2902\n",
      "Epoch 691/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2695 - val_loss: 1.3282\n",
      "Epoch 692/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2588 - val_loss: 1.3175\n",
      "Epoch 693/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2597 - val_loss: 1.3030\n",
      "Epoch 694/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2582 - val_loss: 1.2906\n",
      "Epoch 695/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2668 - val_loss: 1.2937\n",
      "Epoch 696/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2529 - val_loss: 1.3343\n",
      "Epoch 697/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2678 - val_loss: 1.3024\n",
      "Epoch 698/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2487 - val_loss: 1.2641\n",
      "Epoch 699/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2579 - val_loss: 1.2779\n",
      "Epoch 700/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2684 - val_loss: 1.3577\n",
      "Epoch 701/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2576 - val_loss: 1.3534\n",
      "Epoch 702/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2673 - val_loss: 1.3207\n",
      "Epoch 703/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2673 - val_loss: 1.3305\n",
      "Epoch 704/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2670 - val_loss: 1.3542\n",
      "Epoch 705/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2744 - val_loss: 1.2820\n",
      "Epoch 706/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2462 - val_loss: 1.2670\n",
      "Epoch 707/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2638 - val_loss: 1.3391\n",
      "Epoch 708/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2531 - val_loss: 1.2930\n",
      "Epoch 709/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2780 - val_loss: 1.3059\n",
      "Epoch 710/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2538 - val_loss: 1.3240\n",
      "Epoch 711/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2620 - val_loss: 1.2609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2465 - val_loss: 1.3362\n",
      "Epoch 713/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2626 - val_loss: 1.2720\n",
      "Epoch 714/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2523 - val_loss: 1.3041\n",
      "Epoch 715/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2587 - val_loss: 1.3604\n",
      "Epoch 716/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2546 - val_loss: 1.3396\n",
      "Epoch 717/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2711 - val_loss: 1.3211\n",
      "Epoch 718/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2526 - val_loss: 1.2910\n",
      "Epoch 719/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2644 - val_loss: 1.3314\n",
      "Epoch 720/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2594 - val_loss: 1.3061\n",
      "Epoch 721/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2445 - val_loss: 1.2612\n",
      "Epoch 722/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2507 - val_loss: 1.3425\n",
      "Epoch 723/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2617 - val_loss: 1.4000\n",
      "Epoch 724/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2601 - val_loss: 1.3401\n",
      "Epoch 725/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2547 - val_loss: 1.3894\n",
      "Epoch 726/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2618 - val_loss: 1.2878\n",
      "Epoch 727/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2465 - val_loss: 1.2679\n",
      "Epoch 728/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2471 - val_loss: 1.2623\n",
      "Epoch 729/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2541 - val_loss: 1.3052\n",
      "Epoch 730/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2479 - val_loss: 1.3229\n",
      "Epoch 731/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2605 - val_loss: 1.2701\n",
      "Epoch 732/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2535 - val_loss: 1.2893\n",
      "Epoch 733/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2555 - val_loss: 1.2914\n",
      "Epoch 734/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2524 - val_loss: 1.2917\n",
      "Epoch 735/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2556 - val_loss: 1.2625\n",
      "Epoch 736/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2456 - val_loss: 1.2729\n",
      "Epoch 737/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2562 - val_loss: 1.3108\n",
      "Epoch 738/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2625 - val_loss: 1.2865\n",
      "Epoch 739/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.2546 - val_loss: 1.3232\n",
      "Epoch 740/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2510 - val_loss: 1.2603\n",
      "Epoch 741/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2494 - val_loss: 1.3078\n",
      "Epoch 742/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2480 - val_loss: 1.2825\n",
      "Epoch 743/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2530 - val_loss: 1.2900\n",
      "Epoch 744/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2516 - val_loss: 1.3538\n",
      "Epoch 745/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2542 - val_loss: 1.2704\n",
      "Epoch 746/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2648 - val_loss: 1.3845\n",
      "Epoch 747/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2485 - val_loss: 1.2872\n",
      "Epoch 748/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2491 - val_loss: 1.3897\n",
      "Epoch 749/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2561 - val_loss: 1.3002\n",
      "Epoch 750/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2516 - val_loss: 1.3102\n",
      "Epoch 751/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2523 - val_loss: 1.2914\n",
      "Epoch 752/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2510 - val_loss: 1.3103\n",
      "Epoch 753/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2532 - val_loss: 1.3225\n",
      "Epoch 754/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2491 - val_loss: 1.3120\n",
      "Epoch 755/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2616 - val_loss: 1.2961\n",
      "Epoch 756/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2496 - val_loss: 1.2858\n",
      "Epoch 757/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2430 - val_loss: 1.3880\n",
      "Epoch 758/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2419 - val_loss: 1.3423\n",
      "Epoch 759/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2552 - val_loss: 1.2879\n",
      "Epoch 760/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2597 - val_loss: 1.3129\n",
      "Epoch 761/900\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.2598 - val_loss: 1.2930\n",
      "Epoch 762/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2521 - val_loss: 1.2804\n",
      "Epoch 763/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2475 - val_loss: 1.2735\n",
      "Epoch 764/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2520 - val_loss: 1.3120\n",
      "Epoch 765/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2400 - val_loss: 1.3366\n",
      "Epoch 766/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2436 - val_loss: 1.2875\n",
      "Epoch 767/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.2485 - val_loss: 1.3148\n",
      "Epoch 768/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2447 - val_loss: 1.2818\n",
      "Epoch 769/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2478 - val_loss: 1.3141\n",
      "Epoch 770/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2467 - val_loss: 1.2512\n",
      "Epoch 771/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2481 - val_loss: 1.2830\n",
      "Epoch 772/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2430 - val_loss: 1.2785\n",
      "Epoch 773/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2347 - val_loss: 1.3007\n",
      "Epoch 774/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2416 - val_loss: 1.2742\n",
      "Epoch 775/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2431 - val_loss: 1.3025\n",
      "Epoch 776/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2519 - val_loss: 1.3209\n",
      "Epoch 777/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2378 - val_loss: 1.2620\n",
      "Epoch 778/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2527 - val_loss: 1.3059\n",
      "Epoch 779/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2333 - val_loss: 1.2667\n",
      "Epoch 780/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2451 - val_loss: 1.2584\n",
      "Epoch 781/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2366 - val_loss: 1.2770\n",
      "Epoch 782/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2456 - val_loss: 1.2590\n",
      "Epoch 783/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2479 - val_loss: 1.3175\n",
      "Epoch 784/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2467 - val_loss: 1.3123\n",
      "Epoch 785/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2487 - val_loss: 1.2593\n",
      "Epoch 786/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2458 - val_loss: 1.2811\n",
      "Epoch 787/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2475 - val_loss: 1.2952\n",
      "Epoch 788/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2392 - val_loss: 1.2887\n",
      "Epoch 789/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2379 - val_loss: 1.3633\n",
      "Epoch 790/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2382 - val_loss: 1.3027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2367 - val_loss: 1.3024\n",
      "Epoch 792/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2451 - val_loss: 1.2810\n",
      "Epoch 793/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2438 - val_loss: 1.3590\n",
      "Epoch 794/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2476 - val_loss: 1.3132\n",
      "Epoch 795/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2507 - val_loss: 1.3016\n",
      "Epoch 796/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2417 - val_loss: 1.3055\n",
      "Epoch 797/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2477 - val_loss: 1.3180\n",
      "Epoch 798/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2330 - val_loss: 1.3012\n",
      "Epoch 799/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2401 - val_loss: 1.3203\n",
      "Epoch 800/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2329 - val_loss: 1.3350\n",
      "Epoch 801/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2446 - val_loss: 1.2742\n",
      "Epoch 802/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2262 - val_loss: 1.2838\n",
      "Epoch 803/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2493 - val_loss: 1.3024\n",
      "Epoch 804/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2291 - val_loss: 1.2865\n",
      "Epoch 805/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2409 - val_loss: 1.3010\n",
      "Epoch 806/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2420 - val_loss: 1.2993\n",
      "Epoch 807/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2400 - val_loss: 1.3470\n",
      "Epoch 808/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2369 - val_loss: 1.2751\n",
      "Epoch 809/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2433 - val_loss: 1.3197\n",
      "Epoch 810/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2280 - val_loss: 1.3168\n",
      "Epoch 811/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2393 - val_loss: 1.3123\n",
      "Epoch 812/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2389 - val_loss: 1.3095\n",
      "Epoch 813/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2391 - val_loss: 1.3123\n",
      "Epoch 814/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2444 - val_loss: 1.3164\n",
      "Epoch 815/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2362 - val_loss: 1.2802\n",
      "Epoch 816/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2333 - val_loss: 1.2905\n",
      "Epoch 817/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2350 - val_loss: 1.2765\n",
      "Epoch 818/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2406 - val_loss: 1.3185\n",
      "Epoch 819/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2317 - val_loss: 1.2833\n",
      "Epoch 820/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2372 - val_loss: 1.2549\n",
      "Epoch 821/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2393 - val_loss: 1.2829\n",
      "Epoch 822/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2420 - val_loss: 1.2812\n",
      "Epoch 823/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2277 - val_loss: 1.3351\n",
      "Epoch 824/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2419 - val_loss: 1.3298\n",
      "Epoch 825/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2348 - val_loss: 1.2892\n",
      "Epoch 826/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2329 - val_loss: 1.2968\n",
      "Epoch 827/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2323 - val_loss: 1.2580\n",
      "Epoch 828/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2390 - val_loss: 1.3079\n",
      "Epoch 829/900\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.2362 - val_loss: 1.2420\n",
      "Epoch 830/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2406 - val_loss: 1.3060\n",
      "Epoch 831/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2318 - val_loss: 1.2806\n",
      "Epoch 832/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2362 - val_loss: 1.3084\n",
      "Epoch 833/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2387 - val_loss: 1.3169\n",
      "Epoch 834/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2404 - val_loss: 1.2870\n",
      "Epoch 835/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2298 - val_loss: 1.2904\n",
      "Epoch 836/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.2345 - val_loss: 1.3111\n",
      "Epoch 837/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2292 - val_loss: 1.3155\n",
      "Epoch 838/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2404 - val_loss: 1.2502\n",
      "Epoch 839/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2398 - val_loss: 1.3291\n",
      "Epoch 840/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2327 - val_loss: 1.2874\n",
      "Epoch 841/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2263 - val_loss: 1.2914\n",
      "Epoch 842/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2368 - val_loss: 1.2792\n",
      "Epoch 843/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2325 - val_loss: 1.2877\n",
      "Epoch 844/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2289 - val_loss: 1.3123\n",
      "Epoch 845/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2334 - val_loss: 1.2820\n",
      "Epoch 846/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2309 - val_loss: 1.3125\n",
      "Epoch 847/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2312 - val_loss: 1.3257\n",
      "Epoch 848/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2295 - val_loss: 1.3042\n",
      "Epoch 849/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2366 - val_loss: 1.3185\n",
      "Epoch 850/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2405 - val_loss: 1.3373\n",
      "Epoch 851/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2370 - val_loss: 1.2962\n",
      "Epoch 852/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2271 - val_loss: 1.3540\n",
      "Epoch 853/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2280 - val_loss: 1.3247\n",
      "Epoch 854/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2358 - val_loss: 1.3013\n",
      "Epoch 855/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2257 - val_loss: 1.2811\n",
      "Epoch 856/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2330 - val_loss: 1.2912\n",
      "Epoch 857/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2342 - val_loss: 1.3998\n",
      "Epoch 858/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2299 - val_loss: 1.2754\n",
      "Epoch 859/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2259 - val_loss: 1.3301\n",
      "Epoch 860/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2319 - val_loss: 1.3094\n",
      "Epoch 861/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2313 - val_loss: 1.2682\n",
      "Epoch 862/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2272 - val_loss: 1.2745\n",
      "Epoch 863/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2471 - val_loss: 1.2896\n",
      "Epoch 864/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2263 - val_loss: 1.3777\n",
      "Epoch 865/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2218 - val_loss: 1.2711\n",
      "Epoch 866/900\n",
      "432/432 [==============================] - 5s 10ms/step - loss: 1.2257 - val_loss: 1.3659\n",
      "Epoch 867/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2257 - val_loss: 1.2930\n",
      "Epoch 868/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2269 - val_loss: 1.3726\n",
      "Epoch 869/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2148 - val_loss: 1.3363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2221 - val_loss: 1.2685\n",
      "Epoch 871/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2293 - val_loss: 1.3471\n",
      "Epoch 872/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2243 - val_loss: 1.2821\n",
      "Epoch 873/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2193 - val_loss: 1.2652\n",
      "Epoch 874/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2422 - val_loss: 1.2576\n",
      "Epoch 875/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2240 - val_loss: 1.2692\n",
      "Epoch 876/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2248 - val_loss: 1.3090\n",
      "Epoch 877/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2272 - val_loss: 1.2790\n",
      "Epoch 878/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2318 - val_loss: 1.3232\n",
      "Epoch 879/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2219 - val_loss: 1.2456\n",
      "Epoch 880/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2174 - val_loss: 1.2613\n",
      "Epoch 881/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2250 - val_loss: 1.2995\n",
      "Epoch 882/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2328 - val_loss: 1.2493\n",
      "Epoch 883/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2185 - val_loss: 1.3693\n",
      "Epoch 884/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2182 - val_loss: 1.2466\n",
      "Epoch 885/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2244 - val_loss: 1.2888\n",
      "Epoch 886/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2245 - val_loss: 1.2646\n",
      "Epoch 887/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2285 - val_loss: 1.2858\n",
      "Epoch 888/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2184 - val_loss: 1.2972\n",
      "Epoch 889/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2249 - val_loss: 1.2907\n",
      "Epoch 890/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2289 - val_loss: 1.2927\n",
      "Epoch 891/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2257 - val_loss: 1.3262\n",
      "Epoch 892/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2270 - val_loss: 1.2595\n",
      "Epoch 893/900\n",
      "432/432 [==============================] - 8s 18ms/step - loss: 1.2213 - val_loss: 1.2760\n",
      "Epoch 894/900\n",
      "432/432 [==============================] - 7s 17ms/step - loss: 1.2256 - val_loss: 1.2817\n",
      "Epoch 895/900\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 1.2226 - val_loss: 1.2528\n",
      "Epoch 896/900\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 1.2139 - val_loss: 1.2702\n",
      "Epoch 897/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2325 - val_loss: 1.2423\n",
      "Epoch 898/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2159 - val_loss: 1.3098\n",
      "Epoch 899/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2182 - val_loss: 1.2863\n",
      "Epoch 900/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2254 - val_loss: 1.2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.283568118370446\n",
      "0.9757421479853203\n",
      "Epoch 1/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 11.0485 - val_loss: 5.4415\n",
      "Epoch 2/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 5.2747 - val_loss: 4.4416\n",
      "Epoch 3/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 5.1600 - val_loss: 4.8662\n",
      "Epoch 4/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.4751 - val_loss: 4.9257\n",
      "Epoch 5/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.3918 - val_loss: 3.9120\n",
      "Epoch 6/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.4461 - val_loss: 3.9383\n",
      "Epoch 7/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.3417 - val_loss: 6.5064\n",
      "Epoch 8/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 4.0243 - val_loss: 3.6172\n",
      "Epoch 9/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.9293 - val_loss: 3.4518\n",
      "Epoch 10/900\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 3.6930 - val_loss: 3.2353\n",
      "Epoch 11/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.4269 - val_loss: 3.3365\n",
      "Epoch 12/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.5466 - val_loss: 3.0314\n",
      "Epoch 13/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.2207 - val_loss: 3.1490\n",
      "Epoch 14/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 3.3778 - val_loss: 3.1987\n",
      "Epoch 15/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 3.1907 - val_loss: 3.4802\n",
      "Epoch 16/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.2209 - val_loss: 3.0379\n",
      "Epoch 17/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.2018 - val_loss: 2.9276\n",
      "Epoch 18/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.0522 - val_loss: 2.8549\n",
      "Epoch 19/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.0446 - val_loss: 2.8094\n",
      "Epoch 20/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.9593 - val_loss: 2.9358\n",
      "Epoch 21/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 3.0360 - val_loss: 2.6866\n",
      "Epoch 22/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.8958 - val_loss: 2.9020\n",
      "Epoch 23/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.9827 - val_loss: 2.6037\n",
      "Epoch 24/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.7546 - val_loss: 2.5924\n",
      "Epoch 25/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.7508 - val_loss: 2.5766\n",
      "Epoch 26/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.6374 - val_loss: 2.5183\n",
      "Epoch 27/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.7135 - val_loss: 2.5265\n",
      "Epoch 28/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.6586 - val_loss: 2.9020\n",
      "Epoch 29/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.5438 - val_loss: 2.5235\n",
      "Epoch 30/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.6461 - val_loss: 2.7939\n",
      "Epoch 31/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 2.5796 - val_loss: 2.4276\n",
      "Epoch 32/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4817 - val_loss: 2.4525\n",
      "Epoch 33/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4794 - val_loss: 3.1443\n",
      "Epoch 34/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4792 - val_loss: 2.3556\n",
      "Epoch 35/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 2.5041 - val_loss: 2.4483\n",
      "Epoch 36/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4211 - val_loss: 2.3694\n",
      "Epoch 37/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4340 - val_loss: 2.3738\n",
      "Epoch 38/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.4035 - val_loss: 2.7174\n",
      "Epoch 39/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3779 - val_loss: 2.2768\n",
      "Epoch 40/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3561 - val_loss: 2.7130\n",
      "Epoch 41/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3260 - val_loss: 2.2870\n",
      "Epoch 42/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3384 - val_loss: 2.2251\n",
      "Epoch 43/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2762 - val_loss: 2.2250\n",
      "Epoch 44/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.3083 - val_loss: 2.3100\n",
      "Epoch 45/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2950 - val_loss: 2.3963\n",
      "Epoch 46/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2355 - val_loss: 2.1205\n",
      "Epoch 47/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 2.2417 - val_loss: 2.1849\n",
      "Epoch 48/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2068 - val_loss: 2.1344\n",
      "Epoch 49/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.2219 - val_loss: 2.1584\n",
      "Epoch 50/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1670 - val_loss: 2.1183\n",
      "Epoch 51/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1589 - val_loss: 2.1410\n",
      "Epoch 52/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1672 - val_loss: 2.0919\n",
      "Epoch 53/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1162 - val_loss: 2.2698\n",
      "Epoch 54/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1095 - val_loss: 2.3866\n",
      "Epoch 55/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1004 - val_loss: 2.2352\n",
      "Epoch 56/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.1051 - val_loss: 2.0618\n",
      "Epoch 57/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0883 - val_loss: 2.0465\n",
      "Epoch 58/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0773 - val_loss: 2.0180\n",
      "Epoch 59/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0746 - val_loss: 2.2963\n",
      "Epoch 60/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0696 - val_loss: 2.0627\n",
      "Epoch 61/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 2.0707 - val_loss: 2.2253\n",
      "Epoch 62/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 2.0489 - val_loss: 2.1044\n",
      "Epoch 63/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 2.0450 - val_loss: 2.1296\n",
      "Epoch 64/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0478 - val_loss: 2.1961\n",
      "Epoch 65/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0154 - val_loss: 2.2424\n",
      "Epoch 66/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0129 - val_loss: 2.1178\n",
      "Epoch 67/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9942 - val_loss: 1.9931\n",
      "Epoch 68/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 2.0006 - val_loss: 1.9240\n",
      "Epoch 69/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9794 - val_loss: 1.9800\n",
      "Epoch 70/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9707 - val_loss: 1.9388\n",
      "Epoch 71/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9679 - val_loss: 1.9269\n",
      "Epoch 72/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9806 - val_loss: 1.9742\n",
      "Epoch 73/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9722 - val_loss: 1.9947\n",
      "Epoch 74/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9750 - val_loss: 1.9259\n",
      "Epoch 75/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9554 - val_loss: 1.9054\n",
      "Epoch 76/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9547 - val_loss: 2.1444\n",
      "Epoch 77/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9493 - val_loss: 1.8882\n",
      "Epoch 78/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.9143 - val_loss: 1.8702\n",
      "Epoch 79/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.9296 - val_loss: 1.9964\n",
      "Epoch 80/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.9418 - val_loss: 1.8981\n",
      "Epoch 81/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9113 - val_loss: 1.9922\n",
      "Epoch 82/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8896 - val_loss: 1.8742\n",
      "Epoch 83/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.9226 - val_loss: 1.9321\n",
      "Epoch 84/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8802 - val_loss: 1.8987\n",
      "Epoch 85/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8898 - val_loss: 2.2885\n",
      "Epoch 86/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8914 - val_loss: 2.0245\n",
      "Epoch 87/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8642 - val_loss: 1.9043\n",
      "Epoch 88/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8810 - val_loss: 1.8433\n",
      "Epoch 89/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8652 - val_loss: 1.8295\n",
      "Epoch 90/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8697 - val_loss: 2.0153\n",
      "Epoch 91/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8592 - val_loss: 1.7873\n",
      "Epoch 92/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8397 - val_loss: 1.8036\n",
      "Epoch 93/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8556 - val_loss: 1.8058\n",
      "Epoch 94/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.8432 - val_loss: 1.8819\n",
      "Epoch 95/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.8520 - val_loss: 1.9976\n",
      "Epoch 96/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8653 - val_loss: 2.1368\n",
      "Epoch 97/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8254 - val_loss: 1.8125\n",
      "Epoch 98/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8526 - val_loss: 1.8660\n",
      "Epoch 99/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8393 - val_loss: 1.8506\n",
      "Epoch 100/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8066 - val_loss: 1.8740\n",
      "Epoch 101/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.8167 - val_loss: 2.0730\n",
      "Epoch 102/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8243 - val_loss: 1.8627\n",
      "Epoch 103/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8079 - val_loss: 1.8679\n",
      "Epoch 104/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8044 - val_loss: 1.7693\n",
      "Epoch 105/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.8038 - val_loss: 1.7671\n",
      "Epoch 106/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7949 - val_loss: 1.8079\n",
      "Epoch 107/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7973 - val_loss: 1.8331\n",
      "Epoch 108/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7785 - val_loss: 1.7586\n",
      "Epoch 109/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.7964 - val_loss: 1.7987\n",
      "Epoch 110/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.7813 - val_loss: 1.8164\n",
      "Epoch 111/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.7726 - val_loss: 1.7790\n",
      "Epoch 112/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7886 - val_loss: 1.8336\n",
      "Epoch 113/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7641 - val_loss: 1.8147\n",
      "Epoch 114/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7617 - val_loss: 1.8142\n",
      "Epoch 115/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7775 - val_loss: 1.8522\n",
      "Epoch 116/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7697 - val_loss: 1.7657\n",
      "Epoch 117/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7700 - val_loss: 1.7051\n",
      "Epoch 118/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7427 - val_loss: 1.7393\n",
      "Epoch 119/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7700 - val_loss: 1.8026\n",
      "Epoch 120/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7490 - val_loss: 1.7326\n",
      "Epoch 121/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7500 - val_loss: 1.7113\n",
      "Epoch 122/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7474 - val_loss: 1.7782\n",
      "Epoch 123/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7467 - val_loss: 1.7160\n",
      "Epoch 124/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7464 - val_loss: 1.7228\n",
      "Epoch 125/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7294 - val_loss: 1.7601\n",
      "Epoch 126/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.7209 - val_loss: 1.7880\n",
      "Epoch 127/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.7032 - val_loss: 1.7320\n",
      "Epoch 128/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7069 - val_loss: 1.7971\n",
      "Epoch 129/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7219 - val_loss: 1.6966\n",
      "Epoch 130/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7349 - val_loss: 1.7416\n",
      "Epoch 131/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7349 - val_loss: 1.7161\n",
      "Epoch 132/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6859 - val_loss: 1.7036\n",
      "Epoch 133/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.7131 - val_loss: 1.7962\n",
      "Epoch 134/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6937 - val_loss: 1.7075\n",
      "Epoch 135/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6988 - val_loss: 1.6876\n",
      "Epoch 136/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6781 - val_loss: 1.8237\n",
      "Epoch 137/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.7089 - val_loss: 1.6958\n",
      "Epoch 138/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6782 - val_loss: 1.7390\n",
      "Epoch 139/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6887 - val_loss: 1.7123\n",
      "Epoch 140/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6804 - val_loss: 1.6582\n",
      "Epoch 141/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6828 - val_loss: 1.7123\n",
      "Epoch 142/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.6789 - val_loss: 1.7152\n",
      "Epoch 143/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6719 - val_loss: 1.6734\n",
      "Epoch 144/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6722 - val_loss: 1.7034\n",
      "Epoch 145/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6751 - val_loss: 1.7265\n",
      "Epoch 146/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6790 - val_loss: 1.6640\n",
      "Epoch 147/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6485 - val_loss: 1.6863\n",
      "Epoch 148/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6512 - val_loss: 1.6764\n",
      "Epoch 149/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6542 - val_loss: 1.6935\n",
      "Epoch 150/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6427 - val_loss: 1.7373\n",
      "Epoch 151/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6486 - val_loss: 1.7833\n",
      "Epoch 152/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6529 - val_loss: 1.6686\n",
      "Epoch 153/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6455 - val_loss: 1.6805\n",
      "Epoch 154/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6244 - val_loss: 1.6972\n",
      "Epoch 155/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6283 - val_loss: 1.6258\n",
      "Epoch 156/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6159 - val_loss: 1.6499\n",
      "Epoch 157/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6242 - val_loss: 1.6898\n",
      "Epoch 158/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.6349 - val_loss: 1.6497\n",
      "Epoch 159/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6315 - val_loss: 1.6404\n",
      "Epoch 160/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6330 - val_loss: 1.6397\n",
      "Epoch 161/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6085 - val_loss: 1.6522\n",
      "Epoch 162/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6215 - val_loss: 1.6917\n",
      "Epoch 163/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6255 - val_loss: 1.6897\n",
      "Epoch 164/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6118 - val_loss: 1.6219\n",
      "Epoch 165/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6123 - val_loss: 1.5575\n",
      "Epoch 166/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6101 - val_loss: 1.7621\n",
      "Epoch 167/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5840 - val_loss: 1.6285\n",
      "Epoch 168/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6210 - val_loss: 1.6624\n",
      "Epoch 169/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6027 - val_loss: 1.6676\n",
      "Epoch 170/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.6032 - val_loss: 1.6206\n",
      "Epoch 171/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5954 - val_loss: 1.7297\n",
      "Epoch 172/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5907 - val_loss: 1.6035\n",
      "Epoch 173/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6042 - val_loss: 1.6339\n",
      "Epoch 174/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.5930 - val_loss: 1.6338\n",
      "Epoch 175/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5848 - val_loss: 1.6397\n",
      "Epoch 176/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5871 - val_loss: 1.8364\n",
      "Epoch 177/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5884 - val_loss: 1.7377\n",
      "Epoch 178/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5864 - val_loss: 1.6220\n",
      "Epoch 179/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5992 - val_loss: 1.6275\n",
      "Epoch 180/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5664 - val_loss: 1.5947\n",
      "Epoch 181/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5813 - val_loss: 1.7577\n",
      "Epoch 182/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.6068 - val_loss: 1.6689\n",
      "Epoch 183/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5808 - val_loss: 1.5741\n",
      "Epoch 184/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5881 - val_loss: 1.5986\n",
      "Epoch 185/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5793 - val_loss: 1.6033\n",
      "Epoch 186/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5665 - val_loss: 1.6563\n",
      "Epoch 187/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5755 - val_loss: 1.5649\n",
      "Epoch 188/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5633 - val_loss: 1.6545\n",
      "Epoch 189/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5620 - val_loss: 1.5948\n",
      "Epoch 190/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.5723 - val_loss: 1.5970\n",
      "Epoch 191/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5650 - val_loss: 1.5633\n",
      "Epoch 192/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5745 - val_loss: 1.5851\n",
      "Epoch 193/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5591 - val_loss: 1.6344\n",
      "Epoch 194/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.5649 - val_loss: 1.5770\n",
      "Epoch 195/900\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.5614 - val_loss: 1.6494\n",
      "Epoch 196/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5518 - val_loss: 1.5726\n",
      "Epoch 197/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5634 - val_loss: 1.5868\n",
      "Epoch 198/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5394 - val_loss: 1.6425\n",
      "Epoch 199/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5379 - val_loss: 1.5576\n",
      "Epoch 200/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5388 - val_loss: 1.5515\n",
      "Epoch 201/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5458 - val_loss: 1.5659\n",
      "Epoch 202/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5408 - val_loss: 1.5999\n",
      "Epoch 203/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5552 - val_loss: 1.5855\n",
      "Epoch 204/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5278 - val_loss: 1.5462\n",
      "Epoch 205/900\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.5348 - val_loss: 1.5807\n",
      "Epoch 206/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5257 - val_loss: 1.5515\n",
      "Epoch 207/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5277 - val_loss: 1.5970\n",
      "Epoch 208/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5287 - val_loss: 1.5872\n",
      "Epoch 209/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5237 - val_loss: 1.6429\n",
      "Epoch 210/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5303 - val_loss: 1.7226\n",
      "Epoch 211/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5342 - val_loss: 1.5656\n",
      "Epoch 212/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5439 - val_loss: 1.5509\n",
      "Epoch 213/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.5131 - val_loss: 1.6011\n",
      "Epoch 214/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5267 - val_loss: 1.5435\n",
      "Epoch 215/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5196 - val_loss: 1.5254\n",
      "Epoch 216/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5069 - val_loss: 1.5716\n",
      "Epoch 217/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5364 - val_loss: 1.5451\n",
      "Epoch 218/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5156 - val_loss: 1.8929\n",
      "Epoch 219/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5199 - val_loss: 1.5332\n",
      "Epoch 220/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.5231 - val_loss: 1.5798\n",
      "Epoch 221/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.5157 - val_loss: 1.5978\n",
      "Epoch 222/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5264 - val_loss: 1.6426\n",
      "Epoch 223/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5139 - val_loss: 1.5763\n",
      "Epoch 224/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5112 - val_loss: 1.5968\n",
      "Epoch 225/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5174 - val_loss: 1.5695\n",
      "Epoch 226/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.5202 - val_loss: 1.6515\n",
      "Epoch 227/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5113 - val_loss: 1.6237\n",
      "Epoch 228/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5128 - val_loss: 1.5957\n",
      "Epoch 229/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5030 - val_loss: 1.5172\n",
      "Epoch 230/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.5011 - val_loss: 1.5176\n",
      "Epoch 231/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5080 - val_loss: 1.7389\n",
      "Epoch 232/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4900 - val_loss: 1.5042\n",
      "Epoch 233/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4957 - val_loss: 1.5856\n",
      "Epoch 234/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4849 - val_loss: 1.5371\n",
      "Epoch 235/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.5025 - val_loss: 1.5354\n",
      "Epoch 236/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.5033 - val_loss: 1.5654\n",
      "Epoch 237/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4858 - val_loss: 1.5674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4915 - val_loss: 1.4980\n",
      "Epoch 239/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4896 - val_loss: 1.5657\n",
      "Epoch 240/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.5042 - val_loss: 1.5634\n",
      "Epoch 241/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4877 - val_loss: 1.5202\n",
      "Epoch 242/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4877 - val_loss: 1.5838\n",
      "Epoch 243/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4846 - val_loss: 1.5021\n",
      "Epoch 244/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4868 - val_loss: 1.5386\n",
      "Epoch 245/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4983 - val_loss: 1.5539\n",
      "Epoch 246/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4990 - val_loss: 1.5783\n",
      "Epoch 247/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4803 - val_loss: 1.5015\n",
      "Epoch 248/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4832 - val_loss: 1.5179\n",
      "Epoch 249/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4794 - val_loss: 1.5856\n",
      "Epoch 250/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4883 - val_loss: 1.5248\n",
      "Epoch 251/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4813 - val_loss: 1.5153\n",
      "Epoch 252/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.4751 - val_loss: 1.5207\n",
      "Epoch 253/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4704 - val_loss: 1.5159\n",
      "Epoch 254/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4795 - val_loss: 1.6495\n",
      "Epoch 255/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4636 - val_loss: 1.5778\n",
      "Epoch 256/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4749 - val_loss: 1.5083\n",
      "Epoch 257/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4718 - val_loss: 1.5556\n",
      "Epoch 258/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4571 - val_loss: 1.5061\n",
      "Epoch 259/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4845 - val_loss: 1.4648\n",
      "Epoch 260/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4662 - val_loss: 1.4686\n",
      "Epoch 261/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4643 - val_loss: 1.5368\n",
      "Epoch 262/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4630 - val_loss: 1.5150\n",
      "Epoch 263/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4567 - val_loss: 1.5148\n",
      "Epoch 264/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4633 - val_loss: 1.4812\n",
      "Epoch 265/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4688 - val_loss: 1.5876\n",
      "Epoch 266/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4731 - val_loss: 1.4996\n",
      "Epoch 267/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4637 - val_loss: 1.5080\n",
      "Epoch 268/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.4646 - val_loss: 1.5259\n",
      "Epoch 269/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4697 - val_loss: 1.4712\n",
      "Epoch 270/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4532 - val_loss: 1.4716\n",
      "Epoch 271/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4638 - val_loss: 1.4791\n",
      "Epoch 272/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4635 - val_loss: 1.4789\n",
      "Epoch 273/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4501 - val_loss: 1.6159\n",
      "Epoch 274/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4577 - val_loss: 1.5832\n",
      "Epoch 275/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4581 - val_loss: 1.4828\n",
      "Epoch 276/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4729 - val_loss: 1.5639\n",
      "Epoch 277/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4580 - val_loss: 1.5106\n",
      "Epoch 278/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4600 - val_loss: 1.5177\n",
      "Epoch 279/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4549 - val_loss: 1.6012\n",
      "Epoch 280/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4536 - val_loss: 1.4913\n",
      "Epoch 281/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4426 - val_loss: 1.4409\n",
      "Epoch 282/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4473 - val_loss: 1.5115\n",
      "Epoch 283/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4475 - val_loss: 1.4680\n",
      "Epoch 284/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.4392 - val_loss: 1.5225\n",
      "Epoch 285/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4498 - val_loss: 1.5514\n",
      "Epoch 286/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4427 - val_loss: 1.4898\n",
      "Epoch 287/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4393 - val_loss: 1.4876\n",
      "Epoch 288/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4580 - val_loss: 1.4983\n",
      "Epoch 289/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4505 - val_loss: 1.5834\n",
      "Epoch 290/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4394 - val_loss: 1.5080\n",
      "Epoch 291/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4539 - val_loss: 1.4854\n",
      "Epoch 292/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4485 - val_loss: 1.5655\n",
      "Epoch 293/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4402 - val_loss: 1.4598\n",
      "Epoch 294/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4305 - val_loss: 1.4570\n",
      "Epoch 295/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4277 - val_loss: 1.5221\n",
      "Epoch 296/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4351 - val_loss: 1.5185\n",
      "Epoch 297/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4440 - val_loss: 1.4378\n",
      "Epoch 298/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4330 - val_loss: 1.5041\n",
      "Epoch 299/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.4321 - val_loss: 1.5589\n",
      "Epoch 300/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.4369 - val_loss: 1.5652\n",
      "Epoch 301/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4414 - val_loss: 1.5011\n",
      "Epoch 302/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4345 - val_loss: 1.4549\n",
      "Epoch 303/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4416 - val_loss: 1.5185\n",
      "Epoch 304/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4293 - val_loss: 1.4775\n",
      "Epoch 305/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4135 - val_loss: 1.4801\n",
      "Epoch 306/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4522 - val_loss: 1.4738\n",
      "Epoch 307/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4207 - val_loss: 1.4564\n",
      "Epoch 308/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4326 - val_loss: 1.6993\n",
      "Epoch 309/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4231 - val_loss: 1.4673\n",
      "Epoch 310/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4256 - val_loss: 1.4813\n",
      "Epoch 311/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4213 - val_loss: 1.5152\n",
      "Epoch 312/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4132 - val_loss: 1.4334\n",
      "Epoch 313/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4243 - val_loss: 1.4670\n",
      "Epoch 314/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4290 - val_loss: 1.4409\n",
      "Epoch 315/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4117 - val_loss: 1.5310\n",
      "Epoch 316/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4289 - val_loss: 1.6185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.4197 - val_loss: 1.4989\n",
      "Epoch 318/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4251 - val_loss: 1.4446\n",
      "Epoch 319/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4191 - val_loss: 1.4402\n",
      "Epoch 320/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4265 - val_loss: 1.4721\n",
      "Epoch 321/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4197 - val_loss: 1.5028\n",
      "Epoch 322/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4231 - val_loss: 1.4759\n",
      "Epoch 323/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4192 - val_loss: 1.4820\n",
      "Epoch 324/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4153 - val_loss: 1.5669\n",
      "Epoch 325/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4086 - val_loss: 1.4940\n",
      "Epoch 326/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4127 - val_loss: 1.4142\n",
      "Epoch 327/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4150 - val_loss: 1.4193\n",
      "Epoch 328/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4025 - val_loss: 1.4770\n",
      "Epoch 329/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.4246 - val_loss: 1.4617\n",
      "Epoch 330/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4079 - val_loss: 1.5316\n",
      "Epoch 331/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3925 - val_loss: 1.4314\n",
      "Epoch 332/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3939 - val_loss: 1.5178\n",
      "Epoch 333/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4031 - val_loss: 1.4433\n",
      "Epoch 334/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.4032 - val_loss: 1.4429\n",
      "Epoch 335/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3970 - val_loss: 1.4881\n",
      "Epoch 336/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4124 - val_loss: 1.4846\n",
      "Epoch 337/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4140 - val_loss: 1.4967\n",
      "Epoch 338/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3986 - val_loss: 1.4824\n",
      "Epoch 339/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3950 - val_loss: 1.4939\n",
      "Epoch 340/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3908 - val_loss: 1.4429\n",
      "Epoch 341/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3987 - val_loss: 1.4532\n",
      "Epoch 342/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3900 - val_loss: 1.4468\n",
      "Epoch 343/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3943 - val_loss: 1.4093\n",
      "Epoch 344/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3815 - val_loss: 1.4365\n",
      "Epoch 345/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4068 - val_loss: 1.4392\n",
      "Epoch 346/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3876 - val_loss: 1.4534\n",
      "Epoch 347/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3995 - val_loss: 1.4221\n",
      "Epoch 348/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3987 - val_loss: 1.5281\n",
      "Epoch 349/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4025 - val_loss: 1.4408\n",
      "Epoch 350/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3952 - val_loss: 1.4301\n",
      "Epoch 351/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.4056 - val_loss: 1.4286\n",
      "Epoch 352/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3789 - val_loss: 1.4159\n",
      "Epoch 353/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3845 - val_loss: 1.5965\n",
      "Epoch 354/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3874 - val_loss: 1.4328\n",
      "Epoch 355/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3720 - val_loss: 1.3881\n",
      "Epoch 356/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3939 - val_loss: 1.4387\n",
      "Epoch 357/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3948 - val_loss: 1.4447\n",
      "Epoch 358/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3709 - val_loss: 1.5203\n",
      "Epoch 359/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3842 - val_loss: 1.4428\n",
      "Epoch 360/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3801 - val_loss: 1.4422\n",
      "Epoch 361/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3760 - val_loss: 1.5504\n",
      "Epoch 362/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3693 - val_loss: 1.3917\n",
      "Epoch 363/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3785 - val_loss: 1.4341\n",
      "Epoch 364/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3769 - val_loss: 1.4497\n",
      "Epoch 365/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3779 - val_loss: 1.4610\n",
      "Epoch 366/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3856 - val_loss: 1.4152\n",
      "Epoch 367/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3729 - val_loss: 1.4949\n",
      "Epoch 368/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3769 - val_loss: 1.4222\n",
      "Epoch 369/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3872 - val_loss: 1.3974\n",
      "Epoch 370/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3638 - val_loss: 1.4140\n",
      "Epoch 371/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3896 - val_loss: 1.4576\n",
      "Epoch 372/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3770 - val_loss: 1.4937\n",
      "Epoch 373/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3773 - val_loss: 1.4465\n",
      "Epoch 374/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3682 - val_loss: 1.4574\n",
      "Epoch 375/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3648 - val_loss: 1.4164\n",
      "Epoch 376/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3659 - val_loss: 1.4362\n",
      "Epoch 377/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3954 - val_loss: 1.4627\n",
      "Epoch 378/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3631 - val_loss: 1.4761\n",
      "Epoch 379/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3685 - val_loss: 1.3997\n",
      "Epoch 380/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3658 - val_loss: 1.4103\n",
      "Epoch 381/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3707 - val_loss: 1.4282\n",
      "Epoch 382/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3588 - val_loss: 1.4340\n",
      "Epoch 383/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3664 - val_loss: 1.3921\n",
      "Epoch 384/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3534 - val_loss: 1.5021\n",
      "Epoch 385/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3720 - val_loss: 1.4046\n",
      "Epoch 386/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3564 - val_loss: 1.4543\n",
      "Epoch 387/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3589 - val_loss: 1.4738\n",
      "Epoch 388/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3755 - val_loss: 1.4136\n",
      "Epoch 389/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3502 - val_loss: 1.4293\n",
      "Epoch 390/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3597 - val_loss: 1.3565\n",
      "Epoch 391/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3525 - val_loss: 1.4223\n",
      "Epoch 392/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3552 - val_loss: 1.4007\n",
      "Epoch 393/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3580 - val_loss: 1.4335\n",
      "Epoch 394/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3578 - val_loss: 1.3774\n",
      "Epoch 395/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3622 - val_loss: 1.4237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3565 - val_loss: 1.3945\n",
      "Epoch 397/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3595 - val_loss: 1.3982\n",
      "Epoch 398/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3535 - val_loss: 1.4021\n",
      "Epoch 399/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3451 - val_loss: 1.4596\n",
      "Epoch 400/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3569 - val_loss: 1.3732\n",
      "Epoch 401/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3562 - val_loss: 1.6190\n",
      "Epoch 402/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3563 - val_loss: 1.3702\n",
      "Epoch 403/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3610 - val_loss: 1.4858\n",
      "Epoch 404/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3650 - val_loss: 1.4510\n",
      "Epoch 405/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3476 - val_loss: 1.4538\n",
      "Epoch 406/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3436 - val_loss: 1.3905\n",
      "Epoch 407/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3516 - val_loss: 1.4649\n",
      "Epoch 408/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3436 - val_loss: 1.4609\n",
      "Epoch 409/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3487 - val_loss: 1.3884\n",
      "Epoch 410/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3472 - val_loss: 1.4479\n",
      "Epoch 411/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3434 - val_loss: 1.3559\n",
      "Epoch 412/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3425 - val_loss: 1.6260\n",
      "Epoch 413/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3597 - val_loss: 1.3855\n",
      "Epoch 414/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3486 - val_loss: 1.4113\n",
      "Epoch 415/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3474 - val_loss: 1.3713\n",
      "Epoch 416/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3436 - val_loss: 1.4154\n",
      "Epoch 417/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3479 - val_loss: 1.3880\n",
      "Epoch 418/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3417 - val_loss: 1.3788\n",
      "Epoch 419/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3502 - val_loss: 1.3982\n",
      "Epoch 420/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3333 - val_loss: 1.4451\n",
      "Epoch 421/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3405 - val_loss: 1.3885\n",
      "Epoch 422/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3327 - val_loss: 1.4033\n",
      "Epoch 423/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3513 - val_loss: 1.4164\n",
      "Epoch 424/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3335 - val_loss: 1.4625\n",
      "Epoch 425/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3467 - val_loss: 1.4334\n",
      "Epoch 426/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3359 - val_loss: 1.4610\n",
      "Epoch 427/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3291 - val_loss: 1.4126\n",
      "Epoch 428/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3502 - val_loss: 1.4335\n",
      "Epoch 429/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3434 - val_loss: 1.3499\n",
      "Epoch 430/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3404 - val_loss: 1.3800\n",
      "Epoch 431/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3319 - val_loss: 1.4700\n",
      "Epoch 432/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3360 - val_loss: 1.4003\n",
      "Epoch 433/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3333 - val_loss: 1.4206\n",
      "Epoch 434/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3231 - val_loss: 1.3645\n",
      "Epoch 435/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3283 - val_loss: 1.3637\n",
      "Epoch 436/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3512 - val_loss: 1.3896\n",
      "Epoch 437/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3283 - val_loss: 1.3731\n",
      "Epoch 438/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3327 - val_loss: 1.4164\n",
      "Epoch 439/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3317 - val_loss: 1.3808\n",
      "Epoch 440/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3348 - val_loss: 1.4760\n",
      "Epoch 441/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3337 - val_loss: 1.4150\n",
      "Epoch 442/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3412 - val_loss: 1.3763\n",
      "Epoch 443/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3294 - val_loss: 1.4940\n",
      "Epoch 444/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3375 - val_loss: 1.4530\n",
      "Epoch 445/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3243 - val_loss: 1.3686\n",
      "Epoch 446/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3282 - val_loss: 1.4860\n",
      "Epoch 447/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3198 - val_loss: 1.3639\n",
      "Epoch 448/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3334 - val_loss: 1.3750\n",
      "Epoch 449/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3308 - val_loss: 1.4137\n",
      "Epoch 450/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3441 - val_loss: 1.4378\n",
      "Epoch 451/900\n",
      "346/346 [==============================] - 4s 10ms/step - loss: 1.3320 - val_loss: 1.4429\n",
      "Epoch 452/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3249 - val_loss: 1.3681\n",
      "Epoch 453/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3162 - val_loss: 1.4061\n",
      "Epoch 454/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3235 - val_loss: 1.5072\n",
      "Epoch 455/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3290 - val_loss: 1.3841\n",
      "Epoch 456/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3148 - val_loss: 1.3999\n",
      "Epoch 457/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3366 - val_loss: 1.3802\n",
      "Epoch 458/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3106 - val_loss: 1.3935\n",
      "Epoch 459/900\n",
      "346/346 [==============================] - 6s 16ms/step - loss: 1.3298 - val_loss: 1.3938\n",
      "Epoch 460/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3190 - val_loss: 1.3705\n",
      "Epoch 461/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3193 - val_loss: 1.3837\n",
      "Epoch 462/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3151 - val_loss: 1.4207\n",
      "Epoch 463/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3246 - val_loss: 1.4307\n",
      "Epoch 464/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3217 - val_loss: 1.4238\n",
      "Epoch 465/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3268 - val_loss: 1.3797\n",
      "Epoch 466/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3310 - val_loss: 1.3871\n",
      "Epoch 467/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3191 - val_loss: 1.3924\n",
      "Epoch 468/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3170 - val_loss: 1.4123\n",
      "Epoch 469/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3418 - val_loss: 1.3754\n",
      "Epoch 470/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3134 - val_loss: 1.3937\n",
      "Epoch 471/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3155 - val_loss: 1.3938\n",
      "Epoch 472/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3276 - val_loss: 1.4130\n",
      "Epoch 473/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.3082 - val_loss: 1.3678\n",
      "Epoch 474/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3176 - val_loss: 1.3595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3069 - val_loss: 1.4432\n",
      "Epoch 476/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3010 - val_loss: 1.4068\n",
      "Epoch 477/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3182 - val_loss: 1.3656\n",
      "Epoch 478/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3104 - val_loss: 1.4179\n",
      "Epoch 479/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3079 - val_loss: 1.3576\n",
      "Epoch 480/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3184 - val_loss: 1.3821\n",
      "Epoch 481/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3122 - val_loss: 1.3423\n",
      "Epoch 482/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3100 - val_loss: 1.3488\n",
      "Epoch 483/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3153 - val_loss: 1.3474\n",
      "Epoch 484/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3093 - val_loss: 1.3796\n",
      "Epoch 485/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3064 - val_loss: 1.4070\n",
      "Epoch 486/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3198 - val_loss: 1.3357\n",
      "Epoch 487/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3161 - val_loss: 1.3657\n",
      "Epoch 488/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3136 - val_loss: 1.4034\n",
      "Epoch 489/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3154 - val_loss: 1.3718\n",
      "Epoch 490/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3105 - val_loss: 1.3330\n",
      "Epoch 491/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3077 - val_loss: 1.3619\n",
      "Epoch 492/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3095 - val_loss: 1.3631\n",
      "Epoch 493/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3149 - val_loss: 1.3749\n",
      "Epoch 494/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3137 - val_loss: 1.3455\n",
      "Epoch 495/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2925 - val_loss: 1.3630\n",
      "Epoch 496/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3050 - val_loss: 1.3609\n",
      "Epoch 497/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3014 - val_loss: 1.4244\n",
      "Epoch 498/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3211 - val_loss: 1.3726\n",
      "Epoch 499/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2905 - val_loss: 1.4553\n",
      "Epoch 500/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.3142 - val_loss: 1.3367\n",
      "Epoch 501/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3066 - val_loss: 1.3863\n",
      "Epoch 502/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3105 - val_loss: 1.3733\n",
      "Epoch 503/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3118 - val_loss: 1.3309\n",
      "Epoch 504/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.3033 - val_loss: 1.3996\n",
      "Epoch 505/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3042 - val_loss: 1.3511\n",
      "Epoch 506/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2981 - val_loss: 1.3420\n",
      "Epoch 507/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3008 - val_loss: 1.3561\n",
      "Epoch 508/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3007 - val_loss: 1.4119\n",
      "Epoch 509/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3126 - val_loss: 1.3425\n",
      "Epoch 510/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2903 - val_loss: 1.4117\n",
      "Epoch 511/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2992 - val_loss: 1.3580\n",
      "Epoch 512/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2998 - val_loss: 1.3524\n",
      "Epoch 513/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2913 - val_loss: 1.3557\n",
      "Epoch 514/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3004 - val_loss: 1.3631\n",
      "Epoch 515/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2970 - val_loss: 1.3529\n",
      "Epoch 516/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2939 - val_loss: 1.3749\n",
      "Epoch 517/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2961 - val_loss: 1.3595\n",
      "Epoch 518/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2940 - val_loss: 1.3491\n",
      "Epoch 519/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.3047 - val_loss: 1.3818\n",
      "Epoch 520/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2962 - val_loss: 1.3847\n",
      "Epoch 521/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2996 - val_loss: 1.3998\n",
      "Epoch 522/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2998 - val_loss: 1.3675\n",
      "Epoch 523/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2951 - val_loss: 1.3795\n",
      "Epoch 524/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2866 - val_loss: 1.3815\n",
      "Epoch 525/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2891 - val_loss: 1.3881\n",
      "Epoch 526/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2965 - val_loss: 1.3844\n",
      "Epoch 527/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2899 - val_loss: 1.4781\n",
      "Epoch 528/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2941 - val_loss: 1.3799\n",
      "Epoch 529/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2925 - val_loss: 1.3443\n",
      "Epoch 530/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3066 - val_loss: 1.3661\n",
      "Epoch 531/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2994 - val_loss: 1.4675\n",
      "Epoch 532/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2909 - val_loss: 1.3405\n",
      "Epoch 533/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3069 - val_loss: 1.3827\n",
      "Epoch 534/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2875 - val_loss: 1.3621\n",
      "Epoch 535/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2948 - val_loss: 1.3217\n",
      "Epoch 536/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2905 - val_loss: 1.3482\n",
      "Epoch 537/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2977 - val_loss: 1.3379\n",
      "Epoch 538/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2830 - val_loss: 1.3850\n",
      "Epoch 539/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2780 - val_loss: 1.3207\n",
      "Epoch 540/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2900 - val_loss: 1.4177\n",
      "Epoch 541/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2928 - val_loss: 1.3767\n",
      "Epoch 542/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2791 - val_loss: 1.3318\n",
      "Epoch 543/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2810 - val_loss: 1.3743\n",
      "Epoch 544/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2913 - val_loss: 1.3498\n",
      "Epoch 545/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.3008 - val_loss: 1.3301\n",
      "Epoch 546/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2810 - val_loss: 1.3124\n",
      "Epoch 547/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2913 - val_loss: 1.3218\n",
      "Epoch 548/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2798 - val_loss: 1.3950\n",
      "Epoch 549/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2886 - val_loss: 1.3412\n",
      "Epoch 550/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2911 - val_loss: 1.3430\n",
      "Epoch 551/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2759 - val_loss: 1.3142\n",
      "Epoch 552/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2898 - val_loss: 1.3422\n",
      "Epoch 553/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2948 - val_loss: 1.4344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2779 - val_loss: 1.3880\n",
      "Epoch 555/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2822 - val_loss: 1.3892\n",
      "Epoch 556/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2847 - val_loss: 1.3669\n",
      "Epoch 557/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2900 - val_loss: 1.3870\n",
      "Epoch 558/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2823 - val_loss: 1.3597\n",
      "Epoch 559/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2937 - val_loss: 1.3741\n",
      "Epoch 560/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2935 - val_loss: 1.3284\n",
      "Epoch 561/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2863 - val_loss: 1.3220\n",
      "Epoch 562/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2829 - val_loss: 1.3389\n",
      "Epoch 563/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2821 - val_loss: 1.3207\n",
      "Epoch 564/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2832 - val_loss: 1.3559\n",
      "Epoch 565/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2900 - val_loss: 1.3865\n",
      "Epoch 566/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2759 - val_loss: 1.3291\n",
      "Epoch 567/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2762 - val_loss: 1.4540\n",
      "Epoch 568/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2769 - val_loss: 1.3325\n",
      "Epoch 569/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2746 - val_loss: 1.3646\n",
      "Epoch 570/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2851 - val_loss: 1.3015\n",
      "Epoch 571/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2689 - val_loss: 1.4152\n",
      "Epoch 572/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2770 - val_loss: 1.3060\n",
      "Epoch 573/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2709 - val_loss: 1.2838\n",
      "Epoch 574/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2716 - val_loss: 1.2931\n",
      "Epoch 575/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2716 - val_loss: 1.4009\n",
      "Epoch 576/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2784 - val_loss: 1.3320\n",
      "Epoch 577/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2763 - val_loss: 1.3141\n",
      "Epoch 578/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2763 - val_loss: 1.3621\n",
      "Epoch 579/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2809 - val_loss: 1.3745\n",
      "Epoch 580/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2668 - val_loss: 1.3290\n",
      "Epoch 581/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2873 - val_loss: 1.3971\n",
      "Epoch 582/900\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.2774 - val_loss: 1.3517\n",
      "Epoch 583/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2826 - val_loss: 1.3278\n",
      "Epoch 584/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2705 - val_loss: 1.3914\n",
      "Epoch 585/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2854 - val_loss: 1.3413\n",
      "Epoch 586/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2594 - val_loss: 1.3498\n",
      "Epoch 587/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2668 - val_loss: 1.3265\n",
      "Epoch 588/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2694 - val_loss: 1.3945\n",
      "Epoch 589/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2747 - val_loss: 1.3423\n",
      "Epoch 590/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2612 - val_loss: 1.4149\n",
      "Epoch 591/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2769 - val_loss: 1.3318\n",
      "Epoch 592/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2715 - val_loss: 1.3705\n",
      "Epoch 593/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2708 - val_loss: 1.3161\n",
      "Epoch 594/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2744 - val_loss: 1.3250\n",
      "Epoch 595/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2693 - val_loss: 1.2979\n",
      "Epoch 596/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2608 - val_loss: 1.3266\n",
      "Epoch 597/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2622 - val_loss: 1.3012\n",
      "Epoch 598/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2774 - val_loss: 1.3324\n",
      "Epoch 599/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2703 - val_loss: 1.3588\n",
      "Epoch 600/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2750 - val_loss: 1.3185\n",
      "Epoch 601/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2807 - val_loss: 1.3678\n",
      "Epoch 602/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2649 - val_loss: 1.3369\n",
      "Epoch 603/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2655 - val_loss: 1.3168\n",
      "Epoch 604/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2647 - val_loss: 1.3420\n",
      "Epoch 605/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2601 - val_loss: 1.3304\n",
      "Epoch 606/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2699 - val_loss: 1.3570\n",
      "Epoch 607/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2666 - val_loss: 1.3825\n",
      "Epoch 608/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2728 - val_loss: 1.3187\n",
      "Epoch 609/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2608 - val_loss: 1.3172\n",
      "Epoch 610/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2676 - val_loss: 1.3805\n",
      "Epoch 611/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2642 - val_loss: 1.2820\n",
      "Epoch 612/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2640 - val_loss: 1.3042\n",
      "Epoch 613/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2652 - val_loss: 1.3366\n",
      "Epoch 614/900\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.2646 - val_loss: 1.3278\n",
      "Epoch 615/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2756 - val_loss: 1.3632\n",
      "Epoch 616/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2748 - val_loss: 1.4546\n",
      "Epoch 617/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2590 - val_loss: 1.3508\n",
      "Epoch 618/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2560 - val_loss: 1.3415\n",
      "Epoch 619/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2520 - val_loss: 1.3695\n",
      "Epoch 620/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2619 - val_loss: 1.3448\n",
      "Epoch 621/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2734 - val_loss: 1.3721\n",
      "Epoch 622/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2614 - val_loss: 1.3217\n",
      "Epoch 623/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2606 - val_loss: 1.2928\n",
      "Epoch 624/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2690 - val_loss: 1.2956\n",
      "Epoch 625/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2668 - val_loss: 1.3944\n",
      "Epoch 626/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2619 - val_loss: 1.3376\n",
      "Epoch 627/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2624 - val_loss: 1.3206\n",
      "Epoch 628/900\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.2656 - val_loss: 1.2930\n",
      "Epoch 629/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2642 - val_loss: 1.2861\n",
      "Epoch 630/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2574 - val_loss: 1.2867\n",
      "Epoch 631/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2620 - val_loss: 1.3559\n",
      "Epoch 632/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2592 - val_loss: 1.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2556 - val_loss: 1.3060\n",
      "Epoch 634/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2497 - val_loss: 1.2966\n",
      "Epoch 635/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2601 - val_loss: 1.3882\n",
      "Epoch 636/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2675 - val_loss: 1.2970\n",
      "Epoch 637/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2640 - val_loss: 1.2955\n",
      "Epoch 638/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2519 - val_loss: 1.3193\n",
      "Epoch 639/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2650 - val_loss: 1.3390\n",
      "Epoch 640/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2716 - val_loss: 1.3031\n",
      "Epoch 641/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2591 - val_loss: 1.3067\n",
      "Epoch 642/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2508 - val_loss: 1.3068\n",
      "Epoch 643/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2624 - val_loss: 1.2758\n",
      "Epoch 644/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2606 - val_loss: 1.3190\n",
      "Epoch 645/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2568 - val_loss: 1.3270\n",
      "Epoch 646/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2366 - val_loss: 1.3277\n",
      "Epoch 647/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2497 - val_loss: 1.3281\n",
      "Epoch 648/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2491 - val_loss: 1.3048\n",
      "Epoch 649/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2480 - val_loss: 1.3166\n",
      "Epoch 650/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2605 - val_loss: 1.3649\n",
      "Epoch 651/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2445 - val_loss: 1.3623\n",
      "Epoch 652/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2542 - val_loss: 1.2961\n",
      "Epoch 653/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2554 - val_loss: 1.3160\n",
      "Epoch 654/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2574 - val_loss: 1.3075\n",
      "Epoch 655/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2475 - val_loss: 1.3422\n",
      "Epoch 656/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2598 - val_loss: 1.3109\n",
      "Epoch 657/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2628 - val_loss: 1.3105\n",
      "Epoch 658/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2411 - val_loss: 1.2918\n",
      "Epoch 659/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2558 - val_loss: 1.3033\n",
      "Epoch 660/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2493 - val_loss: 1.2989\n",
      "Epoch 661/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2670 - val_loss: 1.2707\n",
      "Epoch 662/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2578 - val_loss: 1.2945\n",
      "Epoch 663/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2556 - val_loss: 1.2596\n",
      "Epoch 664/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2430 - val_loss: 1.3336\n",
      "Epoch 665/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2551 - val_loss: 1.3209\n",
      "Epoch 666/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2549 - val_loss: 1.3150\n",
      "Epoch 667/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2552 - val_loss: 1.2967\n",
      "Epoch 668/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2453 - val_loss: 1.2781\n",
      "Epoch 669/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2428 - val_loss: 1.3246\n",
      "Epoch 670/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2517 - val_loss: 1.3851\n",
      "Epoch 671/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2687 - val_loss: 1.3252\n",
      "Epoch 672/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2414 - val_loss: 1.2737\n",
      "Epoch 673/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2538 - val_loss: 1.3368\n",
      "Epoch 674/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2533 - val_loss: 1.4002\n",
      "Epoch 675/900\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.2490 - val_loss: 1.3250\n",
      "Epoch 676/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2516 - val_loss: 1.3698\n",
      "Epoch 677/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2360 - val_loss: 1.2798\n",
      "Epoch 678/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2485 - val_loss: 1.3542\n",
      "Epoch 679/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2504 - val_loss: 1.3281\n",
      "Epoch 680/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2513 - val_loss: 1.2779\n",
      "Epoch 681/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2419 - val_loss: 1.2992\n",
      "Epoch 682/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2423 - val_loss: 1.3507\n",
      "Epoch 683/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2424 - val_loss: 1.3478\n",
      "Epoch 684/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2578 - val_loss: 1.2921\n",
      "Epoch 685/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2380 - val_loss: 1.3310\n",
      "Epoch 686/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2378 - val_loss: 1.3181\n",
      "Epoch 687/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2385 - val_loss: 1.3365\n",
      "Epoch 688/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2568 - val_loss: 1.3055\n",
      "Epoch 689/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2398 - val_loss: 1.2926\n",
      "Epoch 690/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2369 - val_loss: 1.2873\n",
      "Epoch 691/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2404 - val_loss: 1.3076\n",
      "Epoch 692/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2576 - val_loss: 1.3675\n",
      "Epoch 693/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2417 - val_loss: 1.2752\n",
      "Epoch 694/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2333 - val_loss: 1.3684\n",
      "Epoch 695/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2507 - val_loss: 1.3247\n",
      "Epoch 696/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2373 - val_loss: 1.3234\n",
      "Epoch 697/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2492 - val_loss: 1.3398\n",
      "Epoch 698/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2545 - val_loss: 1.3561\n",
      "Epoch 699/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2365 - val_loss: 1.3440\n",
      "Epoch 700/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2523 - val_loss: 1.3059\n",
      "Epoch 701/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2439 - val_loss: 1.2715\n",
      "Epoch 702/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2384 - val_loss: 1.3320\n",
      "Epoch 703/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2540 - val_loss: 1.4823\n",
      "Epoch 704/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2333 - val_loss: 1.2601\n",
      "Epoch 705/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2291 - val_loss: 1.3620\n",
      "Epoch 706/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2466 - val_loss: 1.2856\n",
      "Epoch 707/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2365 - val_loss: 1.3489\n",
      "Epoch 708/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2293 - val_loss: 1.2742\n",
      "Epoch 709/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2396 - val_loss: 1.2807\n",
      "Epoch 710/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2395 - val_loss: 1.2888\n",
      "Epoch 711/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2353 - val_loss: 1.2553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2461 - val_loss: 1.2629\n",
      "Epoch 713/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2327 - val_loss: 1.3046\n",
      "Epoch 714/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2286 - val_loss: 1.3138\n",
      "Epoch 715/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2392 - val_loss: 1.3303\n",
      "Epoch 716/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2425 - val_loss: 1.2997\n",
      "Epoch 717/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2372 - val_loss: 1.3017\n",
      "Epoch 718/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2281 - val_loss: 1.2961\n",
      "Epoch 719/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2480 - val_loss: 1.4946\n",
      "Epoch 720/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2388 - val_loss: 1.3238\n",
      "Epoch 721/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2322 - val_loss: 1.2992\n",
      "Epoch 722/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2401 - val_loss: 1.2919\n",
      "Epoch 723/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2371 - val_loss: 1.3140\n",
      "Epoch 724/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2390 - val_loss: 1.2558\n",
      "Epoch 725/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2355 - val_loss: 1.3101\n",
      "Epoch 726/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2410 - val_loss: 1.2929\n",
      "Epoch 727/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2277 - val_loss: 1.3915\n",
      "Epoch 728/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2374 - val_loss: 1.2712\n",
      "Epoch 729/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2306 - val_loss: 1.3221\n",
      "Epoch 730/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2442 - val_loss: 1.2600\n",
      "Epoch 731/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2320 - val_loss: 1.3927\n",
      "Epoch 732/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2327 - val_loss: 1.3235\n",
      "Epoch 733/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2352 - val_loss: 1.3684\n",
      "Epoch 734/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2354 - val_loss: 1.2816\n",
      "Epoch 735/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2397 - val_loss: 1.2925\n",
      "Epoch 736/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2325 - val_loss: 1.3073\n",
      "Epoch 737/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2287 - val_loss: 1.2992\n",
      "Epoch 738/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2302 - val_loss: 1.2901\n",
      "Epoch 739/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2321 - val_loss: 1.2583\n",
      "Epoch 740/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2254 - val_loss: 1.3185\n",
      "Epoch 741/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2394 - val_loss: 1.2736\n",
      "Epoch 742/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2314 - val_loss: 1.2711\n",
      "Epoch 743/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2309 - val_loss: 1.2531\n",
      "Epoch 744/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2263 - val_loss: 1.3064\n",
      "Epoch 745/900\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 1.2388 - val_loss: 1.2921\n",
      "Epoch 746/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2267 - val_loss: 1.3125\n",
      "Epoch 747/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2307 - val_loss: 1.2658\n",
      "Epoch 748/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2331 - val_loss: 1.2873\n",
      "Epoch 749/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2218 - val_loss: 1.3212\n",
      "Epoch 750/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2409 - val_loss: 1.2741\n",
      "Epoch 751/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2333 - val_loss: 1.3070\n",
      "Epoch 752/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2311 - val_loss: 1.3035\n",
      "Epoch 753/900\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.2259 - val_loss: 1.2904\n",
      "Epoch 754/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2358 - val_loss: 1.2832\n",
      "Epoch 755/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2250 - val_loss: 1.2979\n",
      "Epoch 756/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2336 - val_loss: 1.2944\n",
      "Epoch 757/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2290 - val_loss: 1.3297\n",
      "Epoch 758/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2241 - val_loss: 1.2647\n",
      "Epoch 759/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2245 - val_loss: 1.2724\n",
      "Epoch 760/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2294 - val_loss: 1.3091\n",
      "Epoch 761/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2378 - val_loss: 1.3294\n",
      "Epoch 762/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2256 - val_loss: 1.2491\n",
      "Epoch 763/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2251 - val_loss: 1.2700\n",
      "Epoch 764/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2342 - val_loss: 1.3115\n",
      "Epoch 765/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2273 - val_loss: 1.2716\n",
      "Epoch 766/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2191 - val_loss: 1.2711\n",
      "Epoch 767/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2357 - val_loss: 1.3095\n",
      "Epoch 768/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2240 - val_loss: 1.3038\n",
      "Epoch 769/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2379 - val_loss: 1.3746\n",
      "Epoch 770/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2269 - val_loss: 1.2600\n",
      "Epoch 771/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2249 - val_loss: 1.3035\n",
      "Epoch 772/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2094 - val_loss: 1.2600\n",
      "Epoch 773/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2223 - val_loss: 1.3196\n",
      "Epoch 774/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2207 - val_loss: 1.3050\n",
      "Epoch 775/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2328 - val_loss: 1.2894\n",
      "Epoch 776/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2129 - val_loss: 1.2562\n",
      "Epoch 777/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2172 - val_loss: 1.2620\n",
      "Epoch 778/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2228 - val_loss: 1.2584\n",
      "Epoch 779/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2270 - val_loss: 1.2950\n",
      "Epoch 780/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2228 - val_loss: 1.3026\n",
      "Epoch 781/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2213 - val_loss: 1.3449\n",
      "Epoch 782/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2105 - val_loss: 1.3171\n",
      "Epoch 783/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2217 - val_loss: 1.3202\n",
      "Epoch 784/900\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.2221 - val_loss: 1.2296\n",
      "Epoch 785/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2262 - val_loss: 1.3982\n",
      "Epoch 786/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2289 - val_loss: 1.3161\n",
      "Epoch 787/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2112 - val_loss: 1.2614\n",
      "Epoch 788/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2165 - val_loss: 1.2572\n",
      "Epoch 789/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2204 - val_loss: 1.3388\n",
      "Epoch 790/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2333 - val_loss: 1.3601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2165 - val_loss: 1.2952\n",
      "Epoch 792/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2263 - val_loss: 1.3108\n",
      "Epoch 793/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2215 - val_loss: 1.2775\n",
      "Epoch 794/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2290 - val_loss: 1.2895\n",
      "Epoch 795/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2212 - val_loss: 1.2935\n",
      "Epoch 796/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2186 - val_loss: 1.2902\n",
      "Epoch 797/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2239 - val_loss: 1.3447\n",
      "Epoch 798/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2221 - val_loss: 1.2727\n",
      "Epoch 799/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2113 - val_loss: 1.3933\n",
      "Epoch 800/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2212 - val_loss: 1.2682\n",
      "Epoch 801/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2127 - val_loss: 1.3038\n",
      "Epoch 802/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2332 - val_loss: 1.3336\n",
      "Epoch 803/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1997 - val_loss: 1.2578\n",
      "Epoch 804/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2096 - val_loss: 1.2808\n",
      "Epoch 805/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2213 - val_loss: 1.3246\n",
      "Epoch 806/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2152 - val_loss: 1.2505\n",
      "Epoch 807/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2245 - val_loss: 1.2784\n",
      "Epoch 808/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2222 - val_loss: 1.3863\n",
      "Epoch 809/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2151 - val_loss: 1.3582\n",
      "Epoch 810/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2201 - val_loss: 1.3610\n",
      "Epoch 811/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2213 - val_loss: 1.2686\n",
      "Epoch 812/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2155 - val_loss: 1.2807\n",
      "Epoch 813/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2150 - val_loss: 1.2878\n",
      "Epoch 814/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2140 - val_loss: 1.2832\n",
      "Epoch 815/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2138 - val_loss: 1.2654\n",
      "Epoch 816/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2208 - val_loss: 1.2886\n",
      "Epoch 817/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2263 - val_loss: 1.2812\n",
      "Epoch 818/900\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 1.2204 - val_loss: 1.2984\n",
      "Epoch 819/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2145 - val_loss: 1.2910\n",
      "Epoch 820/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2202 - val_loss: 1.3263\n",
      "Epoch 821/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2164 - val_loss: 1.2662\n",
      "Epoch 822/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2153 - val_loss: 1.2813\n",
      "Epoch 823/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2220 - val_loss: 1.3480\n",
      "Epoch 824/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2153 - val_loss: 1.3508\n",
      "Epoch 825/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2123 - val_loss: 1.2726\n",
      "Epoch 826/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2185 - val_loss: 1.2785\n",
      "Epoch 827/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2079 - val_loss: 1.3018\n",
      "Epoch 828/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2144 - val_loss: 1.2715\n",
      "Epoch 829/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2228 - val_loss: 1.4028\n",
      "Epoch 830/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2084 - val_loss: 1.3094\n",
      "Epoch 831/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2121 - val_loss: 1.2729\n",
      "Epoch 832/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2126 - val_loss: 1.3160\n",
      "Epoch 833/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2052 - val_loss: 1.2853\n",
      "Epoch 834/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2147 - val_loss: 1.2974\n",
      "Epoch 835/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2199 - val_loss: 1.3483\n",
      "Epoch 836/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2097 - val_loss: 1.2863\n",
      "Epoch 837/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2113 - val_loss: 1.2816\n",
      "Epoch 838/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2044 - val_loss: 1.2693\n",
      "Epoch 839/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2192 - val_loss: 1.2763\n",
      "Epoch 840/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2100 - val_loss: 1.2874\n",
      "Epoch 841/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2242 - val_loss: 1.3165\n",
      "Epoch 842/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2123 - val_loss: 1.3471\n",
      "Epoch 843/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2108 - val_loss: 1.3359\n",
      "Epoch 844/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2192 - val_loss: 1.2883\n",
      "Epoch 845/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2059 - val_loss: 1.2726\n",
      "Epoch 846/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2065 - val_loss: 1.3126\n",
      "Epoch 847/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2162 - val_loss: 1.2583\n",
      "Epoch 848/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2187 - val_loss: 1.2520\n",
      "Epoch 849/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2134 - val_loss: 1.2691\n",
      "Epoch 850/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2077 - val_loss: 1.2610\n",
      "Epoch 851/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2118 - val_loss: 1.2743\n",
      "Epoch 852/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2180 - val_loss: 1.2396\n",
      "Epoch 853/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1988 - val_loss: 1.3036\n",
      "Epoch 854/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2154 - val_loss: 1.2716\n",
      "Epoch 855/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2210 - val_loss: 1.3136\n",
      "Epoch 856/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2192 - val_loss: 1.2548\n",
      "Epoch 857/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2111 - val_loss: 1.2315\n",
      "Epoch 858/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2104 - val_loss: 1.2452\n",
      "Epoch 859/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2238 - val_loss: 1.2623\n",
      "Epoch 860/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2059 - val_loss: 1.2893\n",
      "Epoch 861/900\n",
      "346/346 [==============================] - 4s 13ms/step - loss: 1.2089 - val_loss: 1.2537\n",
      "Epoch 862/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2102 - val_loss: 1.3130\n",
      "Epoch 863/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2082 - val_loss: 1.3176\n",
      "Epoch 864/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2090 - val_loss: 1.2900\n",
      "Epoch 865/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2031 - val_loss: 1.2550\n",
      "Epoch 866/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2052 - val_loss: 1.2686\n",
      "Epoch 867/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2159 - val_loss: 1.2923\n",
      "Epoch 868/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2001 - val_loss: 1.2826\n",
      "Epoch 869/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2128 - val_loss: 1.2703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2120 - val_loss: 1.4193\n",
      "Epoch 871/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2033 - val_loss: 1.2927\n",
      "Epoch 872/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2008 - val_loss: 1.3112\n",
      "Epoch 873/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2151 - val_loss: 1.2542\n",
      "Epoch 874/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1966 - val_loss: 1.3327\n",
      "Epoch 875/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1996 - val_loss: 1.2831\n",
      "Epoch 876/900\n",
      "346/346 [==============================] - 5s 16ms/step - loss: 1.2070 - val_loss: 1.2739\n",
      "Epoch 877/900\n",
      "346/346 [==============================] - 5s 15ms/step - loss: 1.2141 - val_loss: 1.3256\n",
      "Epoch 878/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2143 - val_loss: 1.2949\n",
      "Epoch 879/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2099 - val_loss: 1.3026\n",
      "Epoch 880/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1981 - val_loss: 1.3342\n",
      "Epoch 881/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2086 - val_loss: 1.2929\n",
      "Epoch 882/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2120 - val_loss: 1.3332\n",
      "Epoch 883/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2035 - val_loss: 1.2292\n",
      "Epoch 884/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2028 - val_loss: 1.2728\n",
      "Epoch 885/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2075 - val_loss: 1.2373\n",
      "Epoch 886/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2018 - val_loss: 1.2495\n",
      "Epoch 887/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1977 - val_loss: 1.2850\n",
      "Epoch 888/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2126 - val_loss: 1.3351\n",
      "Epoch 889/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1965 - val_loss: 1.2773\n",
      "Epoch 890/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1991 - val_loss: 1.2515\n",
      "Epoch 891/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1933 - val_loss: 1.2458\n",
      "Epoch 892/900\n",
      "346/346 [==============================] - 5s 14ms/step - loss: 1.2105 - val_loss: 1.2693\n",
      "Epoch 893/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2030 - val_loss: 1.2301\n",
      "Epoch 894/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2097 - val_loss: 1.3043\n",
      "Epoch 895/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2118 - val_loss: 1.2621\n",
      "Epoch 896/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1965 - val_loss: 1.2787\n",
      "Epoch 897/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2062 - val_loss: 1.2852\n",
      "Epoch 898/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.2023 - val_loss: 1.2905\n",
      "Epoch 899/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1970 - val_loss: 1.2362\n",
      "Epoch 900/900\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 1.1948 - val_loss: 1.2831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2830542717195632\n",
      "0.9769971155575917\n",
      "Epoch 1/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 15.6690 - val_loss: 6.2157\n",
      "Epoch 2/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 6.3372 - val_loss: 4.2622\n",
      "Epoch 3/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 5.2595 - val_loss: 5.4028\n",
      "Epoch 4/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.5023 - val_loss: 3.9857\n",
      "Epoch 5/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 4.6841 - val_loss: 4.3314\n",
      "Epoch 6/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 4.5204 - val_loss: 4.5032\n",
      "Epoch 7/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.3476 - val_loss: 4.0708\n",
      "Epoch 8/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 4.3134 - val_loss: 3.9206\n",
      "Epoch 9/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.2909 - val_loss: 3.8960\n",
      "Epoch 10/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.2676 - val_loss: 4.2946\n",
      "Epoch 11/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.2684 - val_loss: 3.7141\n",
      "Epoch 12/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 4.1720 - val_loss: 3.4155\n",
      "Epoch 13/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.7643 - val_loss: 3.2747\n",
      "Epoch 14/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.7131 - val_loss: 3.2384\n",
      "Epoch 15/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.3012 - val_loss: 3.1992\n",
      "Epoch 16/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.2489 - val_loss: 3.2703\n",
      "Epoch 17/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.4455 - val_loss: 3.0831\n",
      "Epoch 18/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.0381 - val_loss: 2.9360\n",
      "Epoch 19/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.1506 - val_loss: 2.9892\n",
      "Epoch 20/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 3.0088 - val_loss: 2.8106\n",
      "Epoch 21/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 3.0457 - val_loss: 3.2934\n",
      "Epoch 22/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 3.0706 - val_loss: 3.4405\n",
      "Epoch 23/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.9923 - val_loss: 2.9321\n",
      "Epoch 24/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.8140 - val_loss: 2.9609\n",
      "Epoch 25/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.9023 - val_loss: 2.6503\n",
      "Epoch 26/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7726 - val_loss: 2.9292\n",
      "Epoch 27/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7887 - val_loss: 2.8887\n",
      "Epoch 28/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7373 - val_loss: 2.6699\n",
      "Epoch 29/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.6645 - val_loss: 2.6423\n",
      "Epoch 30/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.7174 - val_loss: 2.7660\n",
      "Epoch 31/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.6574 - val_loss: 2.5455\n",
      "Epoch 32/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.6231 - val_loss: 3.0340\n",
      "Epoch 33/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.6855 - val_loss: 2.6323\n",
      "Epoch 34/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5951 - val_loss: 2.5684\n",
      "Epoch 35/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.5703 - val_loss: 2.5384\n",
      "Epoch 36/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5498 - val_loss: 2.5890\n",
      "Epoch 37/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.5150 - val_loss: 2.4559\n",
      "Epoch 38/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 2.5438 - val_loss: 2.4292\n",
      "Epoch 39/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4941 - val_loss: 2.4326\n",
      "Epoch 40/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4579 - val_loss: 2.3574\n",
      "Epoch 41/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4164 - val_loss: 2.3826\n",
      "Epoch 42/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.4430 - val_loss: 2.3666\n",
      "Epoch 43/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3561 - val_loss: 2.3320\n",
      "Epoch 44/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3507 - val_loss: 2.3227\n",
      "Epoch 45/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3486 - val_loss: 2.2750\n",
      "Epoch 46/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.3072 - val_loss: 2.2277\n",
      "Epoch 47/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2950 - val_loss: 2.2395\n",
      "Epoch 48/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2970 - val_loss: 2.6242\n",
      "Epoch 49/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2765 - val_loss: 2.2243\n",
      "Epoch 50/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2584 - val_loss: 2.1822\n",
      "Epoch 51/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2986 - val_loss: 2.3108\n",
      "Epoch 52/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2101 - val_loss: 2.2173\n",
      "Epoch 53/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2139 - val_loss: 2.1027\n",
      "Epoch 54/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 2.2001 - val_loss: 2.2660\n",
      "Epoch 55/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.2186 - val_loss: 2.1859\n",
      "Epoch 56/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1548 - val_loss: 2.2027\n",
      "Epoch 57/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1847 - val_loss: 2.1899\n",
      "Epoch 58/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.1621 - val_loss: 2.0849\n",
      "Epoch 59/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1260 - val_loss: 2.0697\n",
      "Epoch 60/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1343 - val_loss: 2.1292\n",
      "Epoch 61/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1558 - val_loss: 2.2308\n",
      "Epoch 62/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1044 - val_loss: 2.1111\n",
      "Epoch 63/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1100 - val_loss: 2.0804\n",
      "Epoch 64/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.1328 - val_loss: 2.1095\n",
      "Epoch 65/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 2.0969 - val_loss: 2.1894\n",
      "Epoch 66/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0897 - val_loss: 2.0414\n",
      "Epoch 67/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0684 - val_loss: 2.1141\n",
      "Epoch 68/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0645 - val_loss: 2.0507\n",
      "Epoch 69/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0484 - val_loss: 2.0258\n",
      "Epoch 70/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 2.0490 - val_loss: 2.2825\n",
      "Epoch 71/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0425 - val_loss: 2.0460\n",
      "Epoch 72/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0186 - val_loss: 2.0136\n",
      "Epoch 73/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0315 - val_loss: 2.0752\n",
      "Epoch 74/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0481 - val_loss: 2.0014\n",
      "Epoch 75/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0255 - val_loss: 2.0387\n",
      "Epoch 76/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0092 - val_loss: 1.9738\n",
      "Epoch 77/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 2.0189 - val_loss: 1.9644\n",
      "Epoch 78/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9899 - val_loss: 1.9227\n",
      "Epoch 79/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9923 - val_loss: 1.9551\n",
      "Epoch 80/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9888 - val_loss: 1.9352\n",
      "Epoch 81/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9751 - val_loss: 1.9086\n",
      "Epoch 82/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9652 - val_loss: 1.9793\n",
      "Epoch 83/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9729 - val_loss: 2.0210\n",
      "Epoch 84/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9527 - val_loss: 1.9681\n",
      "Epoch 85/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9810 - val_loss: 1.9336\n",
      "Epoch 86/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.9708 - val_loss: 1.9675\n",
      "Epoch 87/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9683 - val_loss: 1.9183\n",
      "Epoch 88/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9336 - val_loss: 1.9586\n",
      "Epoch 89/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9316 - val_loss: 1.8938\n",
      "Epoch 90/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.9279 - val_loss: 1.8912\n",
      "Epoch 91/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9264 - val_loss: 2.1241\n",
      "Epoch 92/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9434 - val_loss: 1.9687\n",
      "Epoch 93/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9064 - val_loss: 1.9129\n",
      "Epoch 94/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9146 - val_loss: 1.9601\n",
      "Epoch 95/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9090 - val_loss: 1.8918\n",
      "Epoch 96/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.9133 - val_loss: 1.8892\n",
      "Epoch 97/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.8813 - val_loss: 1.9714\n",
      "Epoch 98/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8693 - val_loss: 1.9608\n",
      "Epoch 99/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8936 - val_loss: 2.0078\n",
      "Epoch 100/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8816 - val_loss: 1.8738\n",
      "Epoch 101/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8869 - val_loss: 1.9217\n",
      "Epoch 102/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.8643 - val_loss: 1.8849\n",
      "Epoch 103/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8562 - val_loss: 2.0038\n",
      "Epoch 104/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8520 - val_loss: 1.8282\n",
      "Epoch 105/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8522 - val_loss: 1.8604\n",
      "Epoch 106/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8628 - val_loss: 1.8381\n",
      "Epoch 107/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8439 - val_loss: 1.9183\n",
      "Epoch 108/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8452 - val_loss: 2.0338\n",
      "Epoch 109/900\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.8389 - val_loss: 1.8495\n",
      "Epoch 110/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8285 - val_loss: 1.8394\n",
      "Epoch 111/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8196 - val_loss: 1.8958\n",
      "Epoch 112/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8408 - val_loss: 1.8482\n",
      "Epoch 113/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8106 - val_loss: 1.8112\n",
      "Epoch 114/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8118 - val_loss: 1.7976\n",
      "Epoch 115/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7990 - val_loss: 1.7890\n",
      "Epoch 116/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8226 - val_loss: 1.9531\n",
      "Epoch 117/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8073 - val_loss: 1.7893\n",
      "Epoch 118/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.7915 - val_loss: 1.8780\n",
      "Epoch 119/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.8016 - val_loss: 1.8402\n",
      "Epoch 120/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7886 - val_loss: 1.8817\n",
      "Epoch 121/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7992 - val_loss: 1.8196\n",
      "Epoch 122/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7723 - val_loss: 1.8064\n",
      "Epoch 123/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7841 - val_loss: 1.7839\n",
      "Epoch 124/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7868 - val_loss: 1.7567\n",
      "Epoch 125/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7803 - val_loss: 2.0046\n",
      "Epoch 126/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7944 - val_loss: 1.7514\n",
      "Epoch 127/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7703 - val_loss: 1.8925\n",
      "Epoch 128/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.7556 - val_loss: 1.8666\n",
      "Epoch 129/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7716 - val_loss: 1.8002\n",
      "Epoch 130/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7820 - val_loss: 1.8401\n",
      "Epoch 131/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7835 - val_loss: 1.7839\n",
      "Epoch 132/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7604 - val_loss: 1.7495\n",
      "Epoch 133/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7648 - val_loss: 1.7949\n",
      "Epoch 134/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.7415 - val_loss: 1.7450\n",
      "Epoch 135/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.7378 - val_loss: 1.9249\n",
      "Epoch 136/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7407 - val_loss: 1.7858\n",
      "Epoch 137/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7380 - val_loss: 1.7298\n",
      "Epoch 138/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7387 - val_loss: 1.7408\n",
      "Epoch 139/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7353 - val_loss: 1.7556\n",
      "Epoch 140/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7432 - val_loss: 1.7807\n",
      "Epoch 141/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7447 - val_loss: 1.7217\n",
      "Epoch 142/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7075 - val_loss: 1.7034\n",
      "Epoch 143/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7108 - val_loss: 1.7528\n",
      "Epoch 144/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7116 - val_loss: 1.7028\n",
      "Epoch 145/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7034 - val_loss: 1.7591\n",
      "Epoch 146/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7085 - val_loss: 1.7683\n",
      "Epoch 147/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.7039 - val_loss: 1.7088\n",
      "Epoch 148/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7292 - val_loss: 1.8694\n",
      "Epoch 149/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.7029 - val_loss: 1.7035\n",
      "Epoch 150/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.7052 - val_loss: 1.7704\n",
      "Epoch 151/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6755 - val_loss: 1.6832\n",
      "Epoch 152/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6847 - val_loss: 1.6848\n",
      "Epoch 153/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6927 - val_loss: 1.7172\n",
      "Epoch 154/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6992 - val_loss: 1.7877\n",
      "Epoch 155/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6764 - val_loss: 1.6527\n",
      "Epoch 156/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6684 - val_loss: 1.6982\n",
      "Epoch 157/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6712 - val_loss: 1.7723\n",
      "Epoch 158/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6828 - val_loss: 1.7149\n",
      "Epoch 159/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6653 - val_loss: 1.6370\n",
      "Epoch 160/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6760 - val_loss: 1.6876\n",
      "Epoch 161/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6733 - val_loss: 1.6726\n",
      "Epoch 162/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6568 - val_loss: 1.7501\n",
      "Epoch 163/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6545 - val_loss: 1.6455\n",
      "Epoch 164/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6513 - val_loss: 1.7223\n",
      "Epoch 165/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6607 - val_loss: 1.7171\n",
      "Epoch 166/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6582 - val_loss: 1.7029\n",
      "Epoch 167/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6522 - val_loss: 1.6493\n",
      "Epoch 168/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6447 - val_loss: 1.7223\n",
      "Epoch 169/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6343 - val_loss: 1.6711\n",
      "Epoch 170/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6424 - val_loss: 1.7209\n",
      "Epoch 171/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6292 - val_loss: 1.6638\n",
      "Epoch 172/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6326 - val_loss: 1.6675\n",
      "Epoch 173/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6487 - val_loss: 1.6269\n",
      "Epoch 174/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6302 - val_loss: 1.6840\n",
      "Epoch 175/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6320 - val_loss: 1.6690\n",
      "Epoch 176/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6199 - val_loss: 1.6585\n",
      "Epoch 177/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6268 - val_loss: 1.6015\n",
      "Epoch 178/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6096 - val_loss: 1.6665\n",
      "Epoch 179/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6234 - val_loss: 1.6747\n",
      "Epoch 180/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6290 - val_loss: 1.6442\n",
      "Epoch 181/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6212 - val_loss: 1.6536\n",
      "Epoch 182/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.6071 - val_loss: 1.6961\n",
      "Epoch 183/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.6081 - val_loss: 1.6261\n",
      "Epoch 184/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5958 - val_loss: 1.6582\n",
      "Epoch 185/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6061 - val_loss: 1.5912\n",
      "Epoch 186/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6119 - val_loss: 1.6566\n",
      "Epoch 187/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6159 - val_loss: 1.6256\n",
      "Epoch 188/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5968 - val_loss: 1.7474\n",
      "Epoch 189/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5917 - val_loss: 1.6472\n",
      "Epoch 190/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.6091 - val_loss: 1.6359\n",
      "Epoch 191/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5775 - val_loss: 1.6143\n",
      "Epoch 192/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5947 - val_loss: 1.6126\n",
      "Epoch 193/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5908 - val_loss: 1.6181\n",
      "Epoch 194/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5959 - val_loss: 1.6131\n",
      "Epoch 195/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5702 - val_loss: 1.6757\n",
      "Epoch 196/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.6049 - val_loss: 1.6759\n",
      "Epoch 197/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5807 - val_loss: 1.5730\n",
      "Epoch 198/900\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.5735 - val_loss: 1.5814\n",
      "Epoch 199/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5699 - val_loss: 1.5991\n",
      "Epoch 200/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5760 - val_loss: 1.5906\n",
      "Epoch 201/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5749 - val_loss: 1.5739\n",
      "Epoch 202/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5692 - val_loss: 1.6419\n",
      "Epoch 203/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5762 - val_loss: 1.6140\n",
      "Epoch 204/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5574 - val_loss: 1.7567\n",
      "Epoch 205/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5643 - val_loss: 1.6574\n",
      "Epoch 206/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5641 - val_loss: 1.5789\n",
      "Epoch 207/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5576 - val_loss: 1.8124\n",
      "Epoch 208/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5634 - val_loss: 1.5824\n",
      "Epoch 209/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5431 - val_loss: 1.6529\n",
      "Epoch 210/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5415 - val_loss: 1.5691\n",
      "Epoch 211/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5541 - val_loss: 1.5337\n",
      "Epoch 212/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5466 - val_loss: 1.5922\n",
      "Epoch 213/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5623 - val_loss: 1.6525\n",
      "Epoch 214/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5395 - val_loss: 1.5716\n",
      "Epoch 215/900\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.5251 - val_loss: 1.5819\n",
      "Epoch 216/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5305 - val_loss: 1.5807\n",
      "Epoch 217/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5432 - val_loss: 1.5468\n",
      "Epoch 218/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5394 - val_loss: 1.5714\n",
      "Epoch 219/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5233 - val_loss: 1.6035\n",
      "Epoch 220/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5344 - val_loss: 1.7356\n",
      "Epoch 221/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.5378 - val_loss: 1.5897\n",
      "Epoch 222/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5326 - val_loss: 1.5646\n",
      "Epoch 223/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5183 - val_loss: 1.5728\n",
      "Epoch 224/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5230 - val_loss: 1.5223\n",
      "Epoch 225/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5131 - val_loss: 1.5278\n",
      "Epoch 226/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5274 - val_loss: 1.6193\n",
      "Epoch 227/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5239 - val_loss: 1.5964\n",
      "Epoch 228/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5291 - val_loss: 1.6252\n",
      "Epoch 229/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5219 - val_loss: 1.5854\n",
      "Epoch 230/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5088 - val_loss: 1.6412\n",
      "Epoch 231/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.5193 - val_loss: 1.5608\n",
      "Epoch 232/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5211 - val_loss: 1.6277\n",
      "Epoch 233/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5081 - val_loss: 1.5821\n",
      "Epoch 234/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5195 - val_loss: 1.6071\n",
      "Epoch 235/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5194 - val_loss: 1.5960\n",
      "Epoch 236/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5078 - val_loss: 1.5524\n",
      "Epoch 237/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5076 - val_loss: 1.5326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4964 - val_loss: 1.5516\n",
      "Epoch 239/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5031 - val_loss: 1.5530\n",
      "Epoch 240/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5214 - val_loss: 1.5940\n",
      "Epoch 241/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4920 - val_loss: 1.4746\n",
      "Epoch 242/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5151 - val_loss: 1.5696\n",
      "Epoch 243/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5007 - val_loss: 1.5742\n",
      "Epoch 244/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5067 - val_loss: 1.5535\n",
      "Epoch 245/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5078 - val_loss: 1.7436\n",
      "Epoch 246/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.5027 - val_loss: 1.5473\n",
      "Epoch 247/900\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.4984 - val_loss: 1.5485\n",
      "Epoch 248/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5054 - val_loss: 1.5749\n",
      "Epoch 249/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4935 - val_loss: 1.4807\n",
      "Epoch 250/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4967 - val_loss: 1.5489\n",
      "Epoch 251/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4964 - val_loss: 1.5234\n",
      "Epoch 252/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5049 - val_loss: 1.5211\n",
      "Epoch 253/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5012 - val_loss: 1.4898\n",
      "Epoch 254/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4794 - val_loss: 1.5186\n",
      "Epoch 255/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4985 - val_loss: 1.5918\n",
      "Epoch 256/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4883 - val_loss: 1.5366\n",
      "Epoch 257/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4790 - val_loss: 1.5302\n",
      "Epoch 258/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4788 - val_loss: 1.5773\n",
      "Epoch 259/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.5018 - val_loss: 1.6189\n",
      "Epoch 260/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4760 - val_loss: 1.5148\n",
      "Epoch 261/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4878 - val_loss: 1.5863\n",
      "Epoch 262/900\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.4917 - val_loss: 1.5646\n",
      "Epoch 263/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4811 - val_loss: 1.4728\n",
      "Epoch 264/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4752 - val_loss: 1.4572\n",
      "Epoch 265/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4922 - val_loss: 1.5126\n",
      "Epoch 266/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4682 - val_loss: 1.5507\n",
      "Epoch 267/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4647 - val_loss: 1.4771\n",
      "Epoch 268/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4814 - val_loss: 1.5033\n",
      "Epoch 269/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4594 - val_loss: 1.5153\n",
      "Epoch 270/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4675 - val_loss: 1.5880\n",
      "Epoch 271/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4740 - val_loss: 1.5101\n",
      "Epoch 272/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4620 - val_loss: 1.5990\n",
      "Epoch 273/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4758 - val_loss: 1.4832\n",
      "Epoch 274/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4624 - val_loss: 1.5381\n",
      "Epoch 275/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4720 - val_loss: 1.5531\n",
      "Epoch 276/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4626 - val_loss: 1.5065\n",
      "Epoch 277/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4636 - val_loss: 1.5553\n",
      "Epoch 278/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4539 - val_loss: 1.5247\n",
      "Epoch 279/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4732 - val_loss: 1.5221\n",
      "Epoch 280/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4513 - val_loss: 1.5338\n",
      "Epoch 281/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4692 - val_loss: 1.5684\n",
      "Epoch 282/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4630 - val_loss: 1.4895\n",
      "Epoch 283/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4509 - val_loss: 1.4665\n",
      "Epoch 284/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4465 - val_loss: 1.4816\n",
      "Epoch 285/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4542 - val_loss: 1.4592\n",
      "Epoch 286/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4471 - val_loss: 1.4767\n",
      "Epoch 287/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4437 - val_loss: 1.4826\n",
      "Epoch 288/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4580 - val_loss: 1.4990\n",
      "Epoch 289/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4498 - val_loss: 1.4922\n",
      "Epoch 290/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4403 - val_loss: 1.5287\n",
      "Epoch 291/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4551 - val_loss: 1.4978\n",
      "Epoch 292/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4381 - val_loss: 1.5518\n",
      "Epoch 293/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4480 - val_loss: 1.4677\n",
      "Epoch 294/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4361 - val_loss: 1.4711\n",
      "Epoch 295/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.4379 - val_loss: 1.4725\n",
      "Epoch 296/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4526 - val_loss: 1.4748\n",
      "Epoch 297/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4379 - val_loss: 1.5657\n",
      "Epoch 298/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4420 - val_loss: 1.4593\n",
      "Epoch 299/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4382 - val_loss: 1.4770\n",
      "Epoch 300/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4253 - val_loss: 1.4477\n",
      "Epoch 301/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4395 - val_loss: 1.4920\n",
      "Epoch 302/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4246 - val_loss: 1.4500\n",
      "Epoch 303/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4409 - val_loss: 1.4662\n",
      "Epoch 304/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4249 - val_loss: 1.4637\n",
      "Epoch 305/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4292 - val_loss: 1.5898\n",
      "Epoch 306/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4436 - val_loss: 1.5026\n",
      "Epoch 307/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4288 - val_loss: 1.4842\n",
      "Epoch 308/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4283 - val_loss: 1.5108\n",
      "Epoch 309/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4150 - val_loss: 1.4274\n",
      "Epoch 310/900\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.4223 - val_loss: 1.4770\n",
      "Epoch 311/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4195 - val_loss: 1.4606\n",
      "Epoch 312/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4360 - val_loss: 1.5225\n",
      "Epoch 313/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4205 - val_loss: 1.4817\n",
      "Epoch 314/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4338 - val_loss: 1.5282\n",
      "Epoch 315/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4124 - val_loss: 1.4512\n",
      "Epoch 316/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4158 - val_loss: 1.4570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4357 - val_loss: 1.4744\n",
      "Epoch 318/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4257 - val_loss: 1.4864\n",
      "Epoch 319/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4191 - val_loss: 1.4466\n",
      "Epoch 320/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4113 - val_loss: 1.4723\n",
      "Epoch 321/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4073 - val_loss: 1.4672\n",
      "Epoch 322/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4071 - val_loss: 1.4880\n",
      "Epoch 323/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4121 - val_loss: 1.4445\n",
      "Epoch 324/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4078 - val_loss: 1.4969\n",
      "Epoch 325/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4016 - val_loss: 1.4819\n",
      "Epoch 326/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4033 - val_loss: 1.4464\n",
      "Epoch 327/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3994 - val_loss: 1.4703\n",
      "Epoch 328/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4191 - val_loss: 1.4293\n",
      "Epoch 329/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.4002 - val_loss: 1.4664\n",
      "Epoch 330/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4022 - val_loss: 1.4225\n",
      "Epoch 331/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3953 - val_loss: 1.4451\n",
      "Epoch 332/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4017 - val_loss: 1.4185\n",
      "Epoch 333/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4137 - val_loss: 1.4415\n",
      "Epoch 334/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4005 - val_loss: 1.4205\n",
      "Epoch 335/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4000 - val_loss: 1.4356\n",
      "Epoch 336/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4140 - val_loss: 1.5023\n",
      "Epoch 337/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4170 - val_loss: 1.4704\n",
      "Epoch 338/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3929 - val_loss: 1.4254\n",
      "Epoch 339/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4009 - val_loss: 1.3940\n",
      "Epoch 340/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.4088 - val_loss: 1.4123\n",
      "Epoch 341/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.4024 - val_loss: 1.5027\n",
      "Epoch 342/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3877 - val_loss: 1.4363\n",
      "Epoch 343/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.4174 - val_loss: 1.4526\n",
      "Epoch 344/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3889 - val_loss: 1.4644\n",
      "Epoch 345/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3973 - val_loss: 1.4200\n",
      "Epoch 346/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3991 - val_loss: 1.4236\n",
      "Epoch 347/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3932 - val_loss: 1.4361\n",
      "Epoch 348/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3859 - val_loss: 1.4054\n",
      "Epoch 349/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3823 - val_loss: 1.4116\n",
      "Epoch 350/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3877 - val_loss: 1.4151\n",
      "Epoch 351/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3879 - val_loss: 1.4499\n",
      "Epoch 352/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3959 - val_loss: 1.4317\n",
      "Epoch 353/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3919 - val_loss: 1.4437\n",
      "Epoch 354/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3992 - val_loss: 1.4633\n",
      "Epoch 355/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3970 - val_loss: 1.4116\n",
      "Epoch 356/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3923 - val_loss: 1.4351\n",
      "Epoch 357/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3841 - val_loss: 1.5633\n",
      "Epoch 358/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3917 - val_loss: 1.4777\n",
      "Epoch 359/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.3788 - val_loss: 1.4664\n",
      "Epoch 360/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3905 - val_loss: 1.4787\n",
      "Epoch 361/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3872 - val_loss: 1.4595\n",
      "Epoch 362/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3829 - val_loss: 1.4604\n",
      "Epoch 363/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3785 - val_loss: 1.4515\n",
      "Epoch 364/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3895 - val_loss: 1.4273\n",
      "Epoch 365/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3884 - val_loss: 1.4665\n",
      "Epoch 366/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3985 - val_loss: 1.4444\n",
      "Epoch 367/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3800 - val_loss: 1.4112\n",
      "Epoch 368/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3751 - val_loss: 1.4529\n",
      "Epoch 369/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3750 - val_loss: 1.4192\n",
      "Epoch 370/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3797 - val_loss: 1.3768\n",
      "Epoch 371/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3732 - val_loss: 1.4368\n",
      "Epoch 372/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3763 - val_loss: 1.4045\n",
      "Epoch 373/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3801 - val_loss: 1.4257\n",
      "Epoch 374/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3791 - val_loss: 1.4189\n",
      "Epoch 375/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3664 - val_loss: 1.4178\n",
      "Epoch 376/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3636 - val_loss: 1.3882\n",
      "Epoch 377/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3773 - val_loss: 1.4221\n",
      "Epoch 378/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3785 - val_loss: 1.4541\n",
      "Epoch 379/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3684 - val_loss: 1.4686\n",
      "Epoch 380/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3805 - val_loss: 1.4580\n",
      "Epoch 381/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3633 - val_loss: 1.4212\n",
      "Epoch 382/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3903 - val_loss: 1.3833\n",
      "Epoch 383/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3611 - val_loss: 1.4256\n",
      "Epoch 384/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3560 - val_loss: 1.4216\n",
      "Epoch 385/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3630 - val_loss: 1.4604\n",
      "Epoch 386/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3736 - val_loss: 1.3948\n",
      "Epoch 387/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3752 - val_loss: 1.4070\n",
      "Epoch 388/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3667 - val_loss: 1.4342\n",
      "Epoch 389/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3570 - val_loss: 1.4019\n",
      "Epoch 390/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3565 - val_loss: 1.3939\n",
      "Epoch 391/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.3655 - val_loss: 1.4700\n",
      "Epoch 392/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3811 - val_loss: 1.4416\n",
      "Epoch 393/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3625 - val_loss: 1.3588\n",
      "Epoch 394/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3464 - val_loss: 1.3881\n",
      "Epoch 395/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3733 - val_loss: 1.4021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3664 - val_loss: 1.4105\n",
      "Epoch 397/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3390 - val_loss: 1.3867\n",
      "Epoch 398/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3619 - val_loss: 1.4114\n",
      "Epoch 399/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3600 - val_loss: 1.3882\n",
      "Epoch 400/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3502 - val_loss: 1.4225\n",
      "Epoch 401/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3475 - val_loss: 1.3616\n",
      "Epoch 402/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3679 - val_loss: 1.4068\n",
      "Epoch 403/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3605 - val_loss: 1.3723\n",
      "Epoch 404/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3580 - val_loss: 1.4064\n",
      "Epoch 405/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3418 - val_loss: 1.4056\n",
      "Epoch 406/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3431 - val_loss: 1.4276\n",
      "Epoch 407/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3571 - val_loss: 1.4093\n",
      "Epoch 408/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3433 - val_loss: 1.3622\n",
      "Epoch 409/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3444 - val_loss: 1.3626\n",
      "Epoch 410/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3536 - val_loss: 1.4178\n",
      "Epoch 411/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3582 - val_loss: 1.3751\n",
      "Epoch 412/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3492 - val_loss: 1.4285\n",
      "Epoch 413/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3498 - val_loss: 1.3810\n",
      "Epoch 414/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3471 - val_loss: 1.3794\n",
      "Epoch 415/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3678 - val_loss: 1.3631\n",
      "Epoch 416/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3438 - val_loss: 1.3902\n",
      "Epoch 417/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3557 - val_loss: 1.4423\n",
      "Epoch 418/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3500 - val_loss: 1.3777\n",
      "Epoch 419/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3355 - val_loss: 1.3912\n",
      "Epoch 420/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3299 - val_loss: 1.3866\n",
      "Epoch 421/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3487 - val_loss: 1.3560\n",
      "Epoch 422/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3534 - val_loss: 1.3798\n",
      "Epoch 423/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.3325 - val_loss: 1.4011\n",
      "Epoch 424/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3323 - val_loss: 1.4243\n",
      "Epoch 425/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3384 - val_loss: 1.3956\n",
      "Epoch 426/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3279 - val_loss: 1.3761\n",
      "Epoch 427/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3341 - val_loss: 1.3975\n",
      "Epoch 428/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3423 - val_loss: 1.5900\n",
      "Epoch 429/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3432 - val_loss: 1.4358\n",
      "Epoch 430/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3440 - val_loss: 1.3643\n",
      "Epoch 431/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3430 - val_loss: 1.3790\n",
      "Epoch 432/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3377 - val_loss: 1.3753\n",
      "Epoch 433/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3401 - val_loss: 1.4328\n",
      "Epoch 434/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3463 - val_loss: 1.4385\n",
      "Epoch 435/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3293 - val_loss: 1.4287\n",
      "Epoch 436/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3349 - val_loss: 1.3703\n",
      "Epoch 437/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3367 - val_loss: 1.3983\n",
      "Epoch 438/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3381 - val_loss: 1.3556\n",
      "Epoch 439/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.3251 - val_loss: 1.3934\n",
      "Epoch 440/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3231 - val_loss: 1.3960\n",
      "Epoch 441/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3346 - val_loss: 1.3780\n",
      "Epoch 442/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3255 - val_loss: 1.3617\n",
      "Epoch 443/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3261 - val_loss: 1.3245\n",
      "Epoch 444/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3226 - val_loss: 1.3328\n",
      "Epoch 445/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3313 - val_loss: 1.3934\n",
      "Epoch 446/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3297 - val_loss: 1.3466\n",
      "Epoch 447/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3296 - val_loss: 1.3497\n",
      "Epoch 448/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3265 - val_loss: 1.3842\n",
      "Epoch 449/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3206 - val_loss: 1.3982\n",
      "Epoch 450/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3354 - val_loss: 1.3918\n",
      "Epoch 451/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3223 - val_loss: 1.3956\n",
      "Epoch 452/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3280 - val_loss: 1.3684\n",
      "Epoch 453/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3280 - val_loss: 1.4049\n",
      "Epoch 454/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3115 - val_loss: 1.3991\n",
      "Epoch 455/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.3249 - val_loss: 1.3694\n",
      "Epoch 456/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3233 - val_loss: 1.3544\n",
      "Epoch 457/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3140 - val_loss: 1.3398\n",
      "Epoch 458/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3124 - val_loss: 1.3439\n",
      "Epoch 459/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3222 - val_loss: 1.3432\n",
      "Epoch 460/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3329 - val_loss: 1.4190\n",
      "Epoch 461/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3215 - val_loss: 1.4039\n",
      "Epoch 462/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3166 - val_loss: 1.4044\n",
      "Epoch 463/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3073 - val_loss: 1.3593\n",
      "Epoch 464/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3225 - val_loss: 1.3602\n",
      "Epoch 465/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3097 - val_loss: 1.4072\n",
      "Epoch 466/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3319 - val_loss: 1.3712\n",
      "Epoch 467/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3040 - val_loss: 1.3819\n",
      "Epoch 468/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3147 - val_loss: 1.3367\n",
      "Epoch 469/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3269 - val_loss: 1.3338\n",
      "Epoch 470/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3058 - val_loss: 1.4637\n",
      "Epoch 471/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.3145 - val_loss: 1.3489\n",
      "Epoch 472/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3190 - val_loss: 1.3205\n",
      "Epoch 473/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3348 - val_loss: 1.3440\n",
      "Epoch 474/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3185 - val_loss: 1.3691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2988 - val_loss: 1.3927\n",
      "Epoch 476/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3259 - val_loss: 1.3492\n",
      "Epoch 477/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3085 - val_loss: 1.3292\n",
      "Epoch 478/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3107 - val_loss: 1.3788\n",
      "Epoch 479/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3100 - val_loss: 1.3230\n",
      "Epoch 480/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3189 - val_loss: 1.3657\n",
      "Epoch 481/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3317 - val_loss: 1.4337\n",
      "Epoch 482/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3167 - val_loss: 1.3978\n",
      "Epoch 483/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3101 - val_loss: 1.3263\n",
      "Epoch 484/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3185 - val_loss: 1.3352\n",
      "Epoch 485/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2965 - val_loss: 1.3379\n",
      "Epoch 486/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.3068 - val_loss: 1.3780\n",
      "Epoch 487/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.3011 - val_loss: 1.3924\n",
      "Epoch 488/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3124 - val_loss: 1.4811\n",
      "Epoch 489/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3062 - val_loss: 1.4387\n",
      "Epoch 490/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3111 - val_loss: 1.3675\n",
      "Epoch 491/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3079 - val_loss: 1.3125\n",
      "Epoch 492/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2980 - val_loss: 1.3760\n",
      "Epoch 493/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2965 - val_loss: 1.3507\n",
      "Epoch 494/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3107 - val_loss: 1.3247\n",
      "Epoch 495/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3175 - val_loss: 1.3220\n",
      "Epoch 496/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3064 - val_loss: 1.4377\n",
      "Epoch 497/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.3189 - val_loss: 1.3630\n",
      "Epoch 498/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3021 - val_loss: 1.3645\n",
      "Epoch 499/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2957 - val_loss: 1.3563\n",
      "Epoch 500/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3107 - val_loss: 1.4104\n",
      "Epoch 501/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3141 - val_loss: 1.3257\n",
      "Epoch 502/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3114 - val_loss: 1.3249\n",
      "Epoch 503/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2903 - val_loss: 1.3945\n",
      "Epoch 504/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3066 - val_loss: 1.3742\n",
      "Epoch 505/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2978 - val_loss: 1.3217\n",
      "Epoch 506/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2826 - val_loss: 1.3702\n",
      "Epoch 507/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3119 - val_loss: 1.3644\n",
      "Epoch 508/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2936 - val_loss: 1.3367\n",
      "Epoch 509/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2949 - val_loss: 1.3430\n",
      "Epoch 510/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3097 - val_loss: 1.3431\n",
      "Epoch 511/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2945 - val_loss: 1.3760\n",
      "Epoch 512/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2970 - val_loss: 1.3362\n",
      "Epoch 513/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2988 - val_loss: 1.3656\n",
      "Epoch 514/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2846 - val_loss: 1.3499\n",
      "Epoch 515/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2895 - val_loss: 1.3054\n",
      "Epoch 516/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2773 - val_loss: 1.3702\n",
      "Epoch 517/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3041 - val_loss: 1.3323\n",
      "Epoch 518/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3015 - val_loss: 1.4823\n",
      "Epoch 519/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.3048 - val_loss: 1.4018\n",
      "Epoch 520/900\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.2973 - val_loss: 1.3347\n",
      "Epoch 521/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3025 - val_loss: 1.3295\n",
      "Epoch 522/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2867 - val_loss: 1.4085\n",
      "Epoch 523/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2946 - val_loss: 1.4002\n",
      "Epoch 524/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2963 - val_loss: 1.3223\n",
      "Epoch 525/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2931 - val_loss: 1.3395\n",
      "Epoch 526/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2919 - val_loss: 1.3195\n",
      "Epoch 527/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2903 - val_loss: 1.3402\n",
      "Epoch 528/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2955 - val_loss: 1.3549\n",
      "Epoch 529/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2844 - val_loss: 1.3120\n",
      "Epoch 530/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2862 - val_loss: 1.3135\n",
      "Epoch 531/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3014 - val_loss: 1.3153\n",
      "Epoch 532/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2929 - val_loss: 1.3646\n",
      "Epoch 533/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2922 - val_loss: 1.3632\n",
      "Epoch 534/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2941 - val_loss: 1.3485\n",
      "Epoch 535/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.2967 - val_loss: 1.3114\n",
      "Epoch 536/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2894 - val_loss: 1.3467\n",
      "Epoch 537/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2872 - val_loss: 1.2856\n",
      "Epoch 538/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2764 - val_loss: 1.3223\n",
      "Epoch 539/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2798 - val_loss: 1.3629\n",
      "Epoch 540/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2826 - val_loss: 1.3236\n",
      "Epoch 541/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2839 - val_loss: 1.2893\n",
      "Epoch 542/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2873 - val_loss: 1.3617\n",
      "Epoch 543/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2721 - val_loss: 1.3371\n",
      "Epoch 544/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2921 - val_loss: 1.4291\n",
      "Epoch 545/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.3005 - val_loss: 1.3144\n",
      "Epoch 546/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2780 - val_loss: 1.3066\n",
      "Epoch 547/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2860 - val_loss: 1.3060\n",
      "Epoch 548/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2850 - val_loss: 1.3149\n",
      "Epoch 549/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2723 - val_loss: 1.3047\n",
      "Epoch 550/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2794 - val_loss: 1.3627\n",
      "Epoch 551/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2804 - val_loss: 1.3350\n",
      "Epoch 552/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2862 - val_loss: 1.3465\n",
      "Epoch 553/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2789 - val_loss: 1.3035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2840 - val_loss: 1.3736\n",
      "Epoch 555/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2752 - val_loss: 1.3634\n",
      "Epoch 556/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2836 - val_loss: 1.3422\n",
      "Epoch 557/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2762 - val_loss: 1.3421\n",
      "Epoch 558/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2754 - val_loss: 1.3512\n",
      "Epoch 559/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2712 - val_loss: 1.3352\n",
      "Epoch 560/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2714 - val_loss: 1.4580\n",
      "Epoch 561/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2837 - val_loss: 1.3182\n",
      "Epoch 562/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2736 - val_loss: 1.3667\n",
      "Epoch 563/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2744 - val_loss: 1.3760\n",
      "Epoch 564/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2767 - val_loss: 1.3106\n",
      "Epoch 565/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2745 - val_loss: 1.3325\n",
      "Epoch 566/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.2714 - val_loss: 1.2802\n",
      "Epoch 567/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2815 - val_loss: 1.3103\n",
      "Epoch 568/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2808 - val_loss: 1.2986\n",
      "Epoch 569/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2693 - val_loss: 1.3415\n",
      "Epoch 570/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2768 - val_loss: 1.3433\n",
      "Epoch 571/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2712 - val_loss: 1.3086\n",
      "Epoch 572/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2763 - val_loss: 1.3049\n",
      "Epoch 573/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2677 - val_loss: 1.3349\n",
      "Epoch 574/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2656 - val_loss: 1.2864\n",
      "Epoch 575/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2761 - val_loss: 1.2968\n",
      "Epoch 576/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2714 - val_loss: 1.2825\n",
      "Epoch 577/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2703 - val_loss: 1.3988\n",
      "Epoch 578/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2706 - val_loss: 1.3404\n",
      "Epoch 579/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2738 - val_loss: 1.3390\n",
      "Epoch 580/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2660 - val_loss: 1.3287\n",
      "Epoch 581/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2773 - val_loss: 1.3417\n",
      "Epoch 582/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2756 - val_loss: 1.3924\n",
      "Epoch 583/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2850 - val_loss: 1.3185\n",
      "Epoch 584/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2741 - val_loss: 1.3070\n",
      "Epoch 585/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2658 - val_loss: 1.2959\n",
      "Epoch 586/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2806 - val_loss: 1.3267\n",
      "Epoch 587/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2714 - val_loss: 1.3015\n",
      "Epoch 588/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2679 - val_loss: 1.3303\n",
      "Epoch 589/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2627 - val_loss: 1.3193\n",
      "Epoch 590/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2634 - val_loss: 1.2852\n",
      "Epoch 591/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2737 - val_loss: 1.3430\n",
      "Epoch 592/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2608 - val_loss: 1.3075\n",
      "Epoch 593/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2732 - val_loss: 1.3282\n",
      "Epoch 594/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2694 - val_loss: 1.3070\n",
      "Epoch 595/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2534 - val_loss: 1.3301\n",
      "Epoch 596/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2667 - val_loss: 1.3157\n",
      "Epoch 597/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2700 - val_loss: 1.3586\n",
      "Epoch 598/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2648 - val_loss: 1.3077\n",
      "Epoch 599/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2605 - val_loss: 1.3053\n",
      "Epoch 600/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2593 - val_loss: 1.3117\n",
      "Epoch 601/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2714 - val_loss: 1.3457\n",
      "Epoch 602/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2689 - val_loss: 1.2934\n",
      "Epoch 603/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2774 - val_loss: 1.2735\n",
      "Epoch 604/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2516 - val_loss: 1.3028\n",
      "Epoch 605/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2581 - val_loss: 1.3101\n",
      "Epoch 606/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2572 - val_loss: 1.3316\n",
      "Epoch 607/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2696 - val_loss: 1.3095\n",
      "Epoch 608/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2724 - val_loss: 1.3291\n",
      "Epoch 609/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2716 - val_loss: 1.3378\n",
      "Epoch 610/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2590 - val_loss: 1.3052\n",
      "Epoch 611/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2524 - val_loss: 1.2948\n",
      "Epoch 612/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2574 - val_loss: 1.3138\n",
      "Epoch 613/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2582 - val_loss: 1.3198\n",
      "Epoch 614/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2697 - val_loss: 1.3377\n",
      "Epoch 615/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2527 - val_loss: 1.3548\n",
      "Epoch 616/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2597 - val_loss: 1.3139\n",
      "Epoch 617/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2534 - val_loss: 1.3751\n",
      "Epoch 618/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2552 - val_loss: 1.3403\n",
      "Epoch 619/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2597 - val_loss: 1.3565\n",
      "Epoch 620/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2536 - val_loss: 1.3407\n",
      "Epoch 621/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2607 - val_loss: 1.3274\n",
      "Epoch 622/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2528 - val_loss: 1.3497\n",
      "Epoch 623/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2679 - val_loss: 1.2725\n",
      "Epoch 624/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2534 - val_loss: 1.3098\n",
      "Epoch 625/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2668 - val_loss: 1.3017\n",
      "Epoch 626/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2511 - val_loss: 1.3033\n",
      "Epoch 627/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2452 - val_loss: 1.3074\n",
      "Epoch 628/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2610 - val_loss: 1.3253\n",
      "Epoch 629/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2559 - val_loss: 1.2927\n",
      "Epoch 630/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2562 - val_loss: 1.2848\n",
      "Epoch 631/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2473 - val_loss: 1.2761\n",
      "Epoch 632/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2706 - val_loss: 1.2905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2538 - val_loss: 1.3665\n",
      "Epoch 634/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2595 - val_loss: 1.3003\n",
      "Epoch 635/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2532 - val_loss: 1.2762\n",
      "Epoch 636/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2489 - val_loss: 1.3205\n",
      "Epoch 637/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2662 - val_loss: 1.2905\n",
      "Epoch 638/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2489 - val_loss: 1.2978\n",
      "Epoch 639/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2625 - val_loss: 1.3255\n",
      "Epoch 640/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2493 - val_loss: 1.3018\n",
      "Epoch 641/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2498 - val_loss: 1.2934\n",
      "Epoch 642/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2466 - val_loss: 1.2967\n",
      "Epoch 643/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2593 - val_loss: 1.2911\n",
      "Epoch 644/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2521 - val_loss: 1.2603\n",
      "Epoch 645/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2468 - val_loss: 1.2792\n",
      "Epoch 646/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2577 - val_loss: 1.2835\n",
      "Epoch 647/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2470 - val_loss: 1.3239\n",
      "Epoch 648/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2461 - val_loss: 1.2793\n",
      "Epoch 649/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2614 - val_loss: 1.3154\n",
      "Epoch 650/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2510 - val_loss: 1.3687\n",
      "Epoch 651/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2443 - val_loss: 1.2817\n",
      "Epoch 652/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2557 - val_loss: 1.2746\n",
      "Epoch 653/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2539 - val_loss: 1.3419\n",
      "Epoch 654/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2428 - val_loss: 1.2937\n",
      "Epoch 655/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2487 - val_loss: 1.3768\n",
      "Epoch 656/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2491 - val_loss: 1.2786\n",
      "Epoch 657/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2359 - val_loss: 1.3305\n",
      "Epoch 658/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2347 - val_loss: 1.2958\n",
      "Epoch 659/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2501 - val_loss: 1.3243\n",
      "Epoch 660/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2531 - val_loss: 1.3037\n",
      "Epoch 661/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2497 - val_loss: 1.2773\n",
      "Epoch 662/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2501 - val_loss: 1.3001\n",
      "Epoch 663/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.2358 - val_loss: 1.2658\n",
      "Epoch 664/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2411 - val_loss: 1.2799\n",
      "Epoch 665/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2467 - val_loss: 1.3775\n",
      "Epoch 666/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2505 - val_loss: 1.3281\n",
      "Epoch 667/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2501 - val_loss: 1.2748\n",
      "Epoch 668/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2445 - val_loss: 1.3138\n",
      "Epoch 669/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2405 - val_loss: 1.3026\n",
      "Epoch 670/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2484 - val_loss: 1.2771\n",
      "Epoch 671/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2375 - val_loss: 1.3472\n",
      "Epoch 672/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2572 - val_loss: 1.2878\n",
      "Epoch 673/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2469 - val_loss: 1.3073\n",
      "Epoch 674/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2373 - val_loss: 1.3141\n",
      "Epoch 675/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2420 - val_loss: 1.2401\n",
      "Epoch 676/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2456 - val_loss: 1.3248\n",
      "Epoch 677/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2478 - val_loss: 1.2779\n",
      "Epoch 678/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2510 - val_loss: 1.4131\n",
      "Epoch 679/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2485 - val_loss: 1.2733\n",
      "Epoch 680/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2365 - val_loss: 1.2741\n",
      "Epoch 681/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2514 - val_loss: 1.3407\n",
      "Epoch 682/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2302 - val_loss: 1.3405\n",
      "Epoch 683/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2315 - val_loss: 1.2793\n",
      "Epoch 684/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2438 - val_loss: 1.2769\n",
      "Epoch 685/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2341 - val_loss: 1.3110\n",
      "Epoch 686/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2460 - val_loss: 1.2954\n",
      "Epoch 687/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2525 - val_loss: 1.2913\n",
      "Epoch 688/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2389 - val_loss: 1.3242\n",
      "Epoch 689/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2398 - val_loss: 1.2917\n",
      "Epoch 690/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2410 - val_loss: 1.3150\n",
      "Epoch 691/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2436 - val_loss: 1.2973\n",
      "Epoch 692/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2386 - val_loss: 1.3014\n",
      "Epoch 693/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2300 - val_loss: 1.3178\n",
      "Epoch 694/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2370 - val_loss: 1.2438\n",
      "Epoch 695/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2361 - val_loss: 1.3221\n",
      "Epoch 696/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2405 - val_loss: 1.2549\n",
      "Epoch 697/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2385 - val_loss: 1.2796\n",
      "Epoch 698/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2337 - val_loss: 1.4017\n",
      "Epoch 699/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2389 - val_loss: 1.2780\n",
      "Epoch 700/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2374 - val_loss: 1.3006\n",
      "Epoch 701/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2418 - val_loss: 1.3320\n",
      "Epoch 702/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2375 - val_loss: 1.3016\n",
      "Epoch 703/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2386 - val_loss: 1.2988\n",
      "Epoch 704/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2344 - val_loss: 1.2782\n",
      "Epoch 705/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2269 - val_loss: 1.2771\n",
      "Epoch 706/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2217 - val_loss: 1.3193\n",
      "Epoch 707/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2406 - val_loss: 1.2582\n",
      "Epoch 708/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2277 - val_loss: 1.2600\n",
      "Epoch 709/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2312 - val_loss: 1.3146\n",
      "Epoch 710/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2321 - val_loss: 1.3152\n",
      "Epoch 711/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2317 - val_loss: 1.3117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2403 - val_loss: 1.2859\n",
      "Epoch 713/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2437 - val_loss: 1.3126\n",
      "Epoch 714/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2245 - val_loss: 1.2866\n",
      "Epoch 715/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2426 - val_loss: 1.2686\n",
      "Epoch 716/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2466 - val_loss: 1.3145\n",
      "Epoch 717/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2316 - val_loss: 1.2508\n",
      "Epoch 718/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2296 - val_loss: 1.3341\n",
      "Epoch 719/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2359 - val_loss: 1.2804\n",
      "Epoch 720/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2375 - val_loss: 1.2918\n",
      "Epoch 721/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2384 - val_loss: 1.3505\n",
      "Epoch 722/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2300 - val_loss: 1.3112\n",
      "Epoch 723/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2239 - val_loss: 1.2730\n",
      "Epoch 724/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2293 - val_loss: 1.3179\n",
      "Epoch 725/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2424 - val_loss: 1.3164\n",
      "Epoch 726/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2273 - val_loss: 1.2469\n",
      "Epoch 727/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2252 - val_loss: 1.2913\n",
      "Epoch 728/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2296 - val_loss: 1.2666\n",
      "Epoch 729/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2400 - val_loss: 1.2983\n",
      "Epoch 730/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2287 - val_loss: 1.2927\n",
      "Epoch 731/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2177 - val_loss: 1.3708\n",
      "Epoch 732/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2300 - val_loss: 1.2542\n",
      "Epoch 733/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2214 - val_loss: 1.3394\n",
      "Epoch 734/900\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 1.2349 - val_loss: 1.3179\n",
      "Epoch 735/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2274 - val_loss: 1.2920\n",
      "Epoch 736/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2163 - val_loss: 1.2849\n",
      "Epoch 737/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2327 - val_loss: 1.2912\n",
      "Epoch 738/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2262 - val_loss: 1.2779\n",
      "Epoch 739/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2272 - val_loss: 1.2710\n",
      "Epoch 740/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2206 - val_loss: 1.2696\n",
      "Epoch 741/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2265 - val_loss: 1.2689\n",
      "Epoch 742/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2245 - val_loss: 1.3066\n",
      "Epoch 743/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.2299 - val_loss: 1.2734\n",
      "Epoch 744/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2248 - val_loss: 1.3326\n",
      "Epoch 745/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2330 - val_loss: 1.3233\n",
      "Epoch 746/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2359 - val_loss: 1.2819\n",
      "Epoch 747/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2262 - val_loss: 1.2623\n",
      "Epoch 748/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2199 - val_loss: 1.2672\n",
      "Epoch 749/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2344 - val_loss: 1.2766\n",
      "Epoch 750/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2185 - val_loss: 1.2785\n",
      "Epoch 751/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2371 - val_loss: 1.2959\n",
      "Epoch 752/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2243 - val_loss: 1.3101\n",
      "Epoch 753/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2346 - val_loss: 1.2568\n",
      "Epoch 754/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2246 - val_loss: 1.2271\n",
      "Epoch 755/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2021 - val_loss: 1.2981\n",
      "Epoch 756/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2237 - val_loss: 1.2822\n",
      "Epoch 757/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2157 - val_loss: 1.2883\n",
      "Epoch 758/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2172 - val_loss: 1.2524\n",
      "Epoch 759/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.2199 - val_loss: 1.2935\n",
      "Epoch 760/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2287 - val_loss: 1.2760\n",
      "Epoch 761/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2338 - val_loss: 1.2803\n",
      "Epoch 762/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2195 - val_loss: 1.3248\n",
      "Epoch 763/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2279 - val_loss: 1.3311\n",
      "Epoch 764/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2159 - val_loss: 1.2976\n",
      "Epoch 765/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2141 - val_loss: 1.2447\n",
      "Epoch 766/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2242 - val_loss: 1.2975\n",
      "Epoch 767/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2156 - val_loss: 1.2510\n",
      "Epoch 768/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2335 - val_loss: 1.3578\n",
      "Epoch 769/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2261 - val_loss: 1.3054\n",
      "Epoch 770/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2180 - val_loss: 1.2729\n",
      "Epoch 771/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2303 - val_loss: 1.2310\n",
      "Epoch 772/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2174 - val_loss: 1.2693\n",
      "Epoch 773/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2120 - val_loss: 1.2628\n",
      "Epoch 774/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2210 - val_loss: 1.2594\n",
      "Epoch 775/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.2043 - val_loss: 1.3400\n",
      "Epoch 776/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2360 - val_loss: 1.3042\n",
      "Epoch 777/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2206 - val_loss: 1.2462\n",
      "Epoch 778/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2151 - val_loss: 1.3288\n",
      "Epoch 779/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2236 - val_loss: 1.2859\n",
      "Epoch 780/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2175 - val_loss: 1.2861\n",
      "Epoch 781/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2186 - val_loss: 1.2516\n",
      "Epoch 782/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2202 - val_loss: 1.2479\n",
      "Epoch 783/900\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.2203 - val_loss: 1.2469\n",
      "Epoch 784/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2315 - val_loss: 1.3010\n",
      "Epoch 785/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2138 - val_loss: 1.2353\n",
      "Epoch 786/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2136 - val_loss: 1.2468\n",
      "Epoch 787/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2140 - val_loss: 1.2748\n",
      "Epoch 788/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2161 - val_loss: 1.2701\n",
      "Epoch 789/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2288 - val_loss: 1.2862\n",
      "Epoch 790/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2140 - val_loss: 1.3353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2228 - val_loss: 1.2881\n",
      "Epoch 792/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2157 - val_loss: 1.2555\n",
      "Epoch 793/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2154 - val_loss: 1.3425\n",
      "Epoch 794/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2242 - val_loss: 1.3135\n",
      "Epoch 795/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2276 - val_loss: 1.2430\n",
      "Epoch 796/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2144 - val_loss: 1.2405\n",
      "Epoch 797/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2184 - val_loss: 1.2999\n",
      "Epoch 798/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2097 - val_loss: 1.2879\n",
      "Epoch 799/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2109 - val_loss: 1.2610\n",
      "Epoch 800/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2117 - val_loss: 1.2781\n",
      "Epoch 801/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2183 - val_loss: 1.2313\n",
      "Epoch 802/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2159 - val_loss: 1.2244\n",
      "Epoch 803/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2094 - val_loss: 1.3645\n",
      "Epoch 804/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2230 - val_loss: 1.2917\n",
      "Epoch 805/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2163 - val_loss: 1.2448\n",
      "Epoch 806/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2176 - val_loss: 1.2320\n",
      "Epoch 807/900\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.2144 - val_loss: 1.2961\n",
      "Epoch 808/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2169 - val_loss: 1.2908\n",
      "Epoch 809/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2080 - val_loss: 1.2444\n",
      "Epoch 810/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2216 - val_loss: 1.2704\n",
      "Epoch 811/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2158 - val_loss: 1.2481\n",
      "Epoch 812/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2127 - val_loss: 1.2437\n",
      "Epoch 813/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2089 - val_loss: 1.2805\n",
      "Epoch 814/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2123 - val_loss: 1.2489\n",
      "Epoch 815/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2213 - val_loss: 1.2615\n",
      "Epoch 816/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2152 - val_loss: 1.2539\n",
      "Epoch 817/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2165 - val_loss: 1.2756\n",
      "Epoch 818/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1933 - val_loss: 1.2758\n",
      "Epoch 819/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2059 - val_loss: 1.2642\n",
      "Epoch 820/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2093 - val_loss: 1.2757\n",
      "Epoch 821/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2103 - val_loss: 1.3012\n",
      "Epoch 822/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2067 - val_loss: 1.2732\n",
      "Epoch 823/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2218 - val_loss: 1.2526\n",
      "Epoch 824/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2137 - val_loss: 1.2824\n",
      "Epoch 825/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2136 - val_loss: 1.2670\n",
      "Epoch 826/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2092 - val_loss: 1.2403\n",
      "Epoch 827/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2034 - val_loss: 1.2548\n",
      "Epoch 828/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2148 - val_loss: 1.3052\n",
      "Epoch 829/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2155 - val_loss: 1.2532\n",
      "Epoch 830/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2031 - val_loss: 1.2623\n",
      "Epoch 831/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2176 - val_loss: 1.2526\n",
      "Epoch 832/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2149 - val_loss: 1.2676\n",
      "Epoch 833/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2068 - val_loss: 1.2500\n",
      "Epoch 834/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2086 - val_loss: 1.2932\n",
      "Epoch 835/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2032 - val_loss: 1.2686\n",
      "Epoch 836/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2046 - val_loss: 1.2786\n",
      "Epoch 837/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2070 - val_loss: 1.2653\n",
      "Epoch 838/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2027 - val_loss: 1.3188\n",
      "Epoch 839/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.2077 - val_loss: 1.2775\n",
      "Epoch 840/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.2060 - val_loss: 1.2718\n",
      "Epoch 841/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2197 - val_loss: 1.3402\n",
      "Epoch 842/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2052 - val_loss: 1.2712\n",
      "Epoch 843/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.2135 - val_loss: 1.2448\n",
      "Epoch 844/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2086 - val_loss: 1.2394\n",
      "Epoch 845/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2022 - val_loss: 1.2903\n",
      "Epoch 846/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.1980 - val_loss: 1.2940\n",
      "Epoch 847/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2163 - val_loss: 1.2720\n",
      "Epoch 848/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2045 - val_loss: 1.2755\n",
      "Epoch 849/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2086 - val_loss: 1.2931\n",
      "Epoch 850/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1990 - val_loss: 1.2320\n",
      "Epoch 851/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2025 - val_loss: 1.2838\n",
      "Epoch 852/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2053 - val_loss: 1.2635\n",
      "Epoch 853/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2045 - val_loss: 1.2194\n",
      "Epoch 854/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1986 - val_loss: 1.2301\n",
      "Epoch 855/900\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 1.2030 - val_loss: 1.2833\n",
      "Epoch 856/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.1963 - val_loss: 1.2561\n",
      "Epoch 857/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2096 - val_loss: 1.2739\n",
      "Epoch 858/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2001 - val_loss: 1.2703\n",
      "Epoch 859/900\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 1.1993 - val_loss: 1.2842\n",
      "Epoch 860/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2141 - val_loss: 1.3108\n",
      "Epoch 861/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2004 - val_loss: 1.2712\n",
      "Epoch 862/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2086 - val_loss: 1.2586\n",
      "Epoch 863/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2134 - val_loss: 1.2171\n",
      "Epoch 864/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1900 - val_loss: 1.2556\n",
      "Epoch 865/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1961 - val_loss: 1.3031\n",
      "Epoch 866/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2009 - val_loss: 1.2433\n",
      "Epoch 867/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2054 - val_loss: 1.2155\n",
      "Epoch 868/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2004 - val_loss: 1.2597\n",
      "Epoch 869/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1907 - val_loss: 1.2572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2060 - val_loss: 1.3121\n",
      "Epoch 871/900\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.2032 - val_loss: 1.2573\n",
      "Epoch 872/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1932 - val_loss: 1.3005\n",
      "Epoch 873/900\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 1.1976 - val_loss: 1.2606\n",
      "Epoch 874/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2088 - val_loss: 1.2573\n",
      "Epoch 875/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2088 - val_loss: 1.2706\n",
      "Epoch 876/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2121 - val_loss: 1.2873\n",
      "Epoch 877/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1913 - val_loss: 1.2602\n",
      "Epoch 878/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1841 - val_loss: 1.2442\n",
      "Epoch 879/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1994 - val_loss: 1.2783\n",
      "Epoch 880/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2021 - val_loss: 1.2993\n",
      "Epoch 881/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1985 - val_loss: 1.2393\n",
      "Epoch 882/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2029 - val_loss: 1.2654\n",
      "Epoch 883/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1953 - val_loss: 1.2576\n",
      "Epoch 884/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2001 - val_loss: 1.2598\n",
      "Epoch 885/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2056 - val_loss: 1.2313\n",
      "Epoch 886/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2000 - val_loss: 1.2906\n",
      "Epoch 887/900\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.2010 - val_loss: 1.2187\n",
      "Epoch 888/900\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 1.1874 - val_loss: 1.2251\n",
      "Epoch 889/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1994 - val_loss: 1.2147\n",
      "Epoch 890/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1914 - val_loss: 1.3198\n",
      "Epoch 891/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1968 - val_loss: 1.2823\n",
      "Epoch 892/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2111 - val_loss: 1.3116\n",
      "Epoch 893/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1923 - val_loss: 1.2925\n",
      "Epoch 894/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.2016 - val_loss: 1.2146\n",
      "Epoch 895/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1964 - val_loss: 1.2389\n",
      "Epoch 896/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1951 - val_loss: 1.2893\n",
      "Epoch 897/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1989 - val_loss: 1.2460\n",
      "Epoch 898/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1831 - val_loss: 1.2588\n",
      "Epoch 899/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1994 - val_loss: 1.2486\n",
      "Epoch 900/900\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 1.1948 - val_loss: 1.2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2347355906971382\n",
      "0.9784086398212167\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lstm model\n",
    "epoc=[100,300,500,700,900]\n",
    "batch=[50, 100, 150, 200, 250, 300]\n",
    "\n",
    "for e in epoc:\n",
    "    if e==100:\n",
    "        co='red'\n",
    "    elif e==300:\n",
    "        co='magenta'\n",
    "    elif e==500:\n",
    "        co='orange'\n",
    "    elif e==700:\n",
    "        co='blue'\n",
    "    elif e==900:\n",
    "        co='green'\n",
    "     \n",
    "    for b in batch:\n",
    "        lstm1_model = keras.Sequential([\n",
    "                # the hidden ReLU layers\n",
    "                layers.Dense(units=250, activation='relu', input_shape=[37]),\n",
    "                layers.Dense(units=250, activation='relu'),\n",
    "                # the linear output layer \n",
    "                layers.Dense(units=1),\n",
    "            ])\n",
    "        lstm1_model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"mae\",)\n",
    "        lstm1_model.fit(\n",
    "            train_X5, train_y5,\n",
    "            validation_data=(val_X5, val_y5),\n",
    "            batch_size=b,\n",
    "            epochs=e,)\n",
    "\n",
    "        lstm1_preds=lstm1_model.predict(val_X5)\n",
    "        lstm1_model.reset_states()\n",
    "        print(mean_absolute_error(val_y5, lstm1_preds))\n",
    "        print(r2_score(val_y5, lstm1_preds))\n",
    "        plt.xlabel('Batch size')\n",
    "        plt.ylabel('Mean absolute error')\n",
    "        plt.legend(title='Number of epochs')\n",
    "        plt.legend(['100', '300', '500', '700', '900'])\n",
    "        plt.title('Impact plot for the LSTM model')\n",
    "        plt.scatter(b, mean_absolute_error(val_y5, lstm1_preds), c=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 11.9054 - val_loss: 5.2460\n",
      "Epoch 2/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 6.1536 - val_loss: 3.7787\n",
      "Epoch 3/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 5.5994 - val_loss: 4.1951\n",
      "Epoch 4/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 4.4845 - val_loss: 4.3274\n",
      "Epoch 5/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 4.5264 - val_loss: 5.6620\n",
      "Epoch 6/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 4.9335 - val_loss: 6.5179\n",
      "Epoch 7/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 4.2324 - val_loss: 5.7334\n",
      "Epoch 8/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 4.4312 - val_loss: 5.0034\n",
      "Epoch 9/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 3.7308 - val_loss: 3.1383\n",
      "Epoch 10/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 3.8913 - val_loss: 3.3321\n",
      "Epoch 11/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 3.2127 - val_loss: 2.6806\n",
      "Epoch 12/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 3.3153 - val_loss: 2.5435\n",
      "Epoch 13/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.7597 - val_loss: 2.9548\n",
      "Epoch 14/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.7860 - val_loss: 3.4305\n",
      "Epoch 15/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.7567 - val_loss: 3.7612\n",
      "Epoch 16/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.7660 - val_loss: 2.4349\n",
      "Epoch 17/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.4043 - val_loss: 2.2436\n",
      "Epoch 18/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.5004 - val_loss: 2.3370\n",
      "Epoch 19/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.3652 - val_loss: 2.1020\n",
      "Epoch 20/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.3519 - val_loss: 2.0749\n",
      "Epoch 21/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.2839 - val_loss: 2.4152\n",
      "Epoch 22/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.1901 - val_loss: 2.9203\n",
      "Epoch 23/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.1957 - val_loss: 2.0911\n",
      "Epoch 24/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.1519 - val_loss: 1.9191\n",
      "Epoch 25/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 2.0694 - val_loss: 2.2915\n",
      "Epoch 26/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 2.0083 - val_loss: 2.0389\n",
      "Epoch 27/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.9153 - val_loss: 1.8716\n",
      "Epoch 28/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.9113 - val_loss: 1.7232\n",
      "Epoch 29/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.8689 - val_loss: 1.6901\n",
      "Epoch 30/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.7977 - val_loss: 1.7115\n",
      "Epoch 31/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.7923 - val_loss: 1.6479\n",
      "Epoch 32/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.7020 - val_loss: 1.6892\n",
      "Epoch 33/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.6928 - val_loss: 1.7430\n",
      "Epoch 34/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.6969 - val_loss: 1.6724\n",
      "Epoch 35/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.6762 - val_loss: 1.6990\n",
      "Epoch 36/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.6579 - val_loss: 2.3135\n",
      "Epoch 37/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.6688 - val_loss: 1.6450\n",
      "Epoch 38/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.6046 - val_loss: 1.6810\n",
      "Epoch 39/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.6068 - val_loss: 2.2220\n",
      "Epoch 40/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.5860 - val_loss: 1.5521\n",
      "Epoch 41/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.5799 - val_loss: 1.5552\n",
      "Epoch 42/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.5731 - val_loss: 1.6188\n",
      "Epoch 43/950\n",
      "413/413 [==============================] - 5s 13ms/step - loss: 1.5653 - val_loss: 1.5268\n",
      "Epoch 44/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.5537 - val_loss: 1.6464\n",
      "Epoch 45/950\n",
      "413/413 [==============================] - 5s 13ms/step - loss: 1.5483 - val_loss: 1.7096\n",
      "Epoch 46/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.5156 - val_loss: 1.4299\n",
      "Epoch 47/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.5135 - val_loss: 1.5556\n",
      "Epoch 48/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.4933 - val_loss: 1.5232\n",
      "Epoch 49/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.5125 - val_loss: 1.4980\n",
      "Epoch 50/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.5019 - val_loss: 1.6794\n",
      "Epoch 51/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.4783 - val_loss: 1.4588\n",
      "Epoch 52/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.4572 - val_loss: 1.4537\n",
      "Epoch 53/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.4547 - val_loss: 1.4138\n",
      "Epoch 54/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.4504 - val_loss: 1.3938\n",
      "Epoch 55/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.4537 - val_loss: 1.7008\n",
      "Epoch 56/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.4502 - val_loss: 1.4321\n",
      "Epoch 57/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.4303 - val_loss: 1.5224\n",
      "Epoch 58/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.4336 - val_loss: 1.4203\n",
      "Epoch 59/950\n",
      "413/413 [==============================] - 5s 13ms/step - loss: 1.4068 - val_loss: 1.4018\n",
      "Epoch 60/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.4049 - val_loss: 1.4178\n",
      "Epoch 61/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.4133 - val_loss: 1.3637\n",
      "Epoch 62/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.4187 - val_loss: 1.4499\n",
      "Epoch 63/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3906 - val_loss: 1.3657\n",
      "Epoch 64/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.3879 - val_loss: 1.3596\n",
      "Epoch 65/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3660 - val_loss: 1.4173\n",
      "Epoch 66/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3663 - val_loss: 1.3953\n",
      "Epoch 67/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3583 - val_loss: 1.3799\n",
      "Epoch 68/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3575 - val_loss: 1.2779\n",
      "Epoch 69/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.3396 - val_loss: 1.3405\n",
      "Epoch 70/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3507 - val_loss: 1.3473\n",
      "Epoch 71/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.3469 - val_loss: 1.4065\n",
      "Epoch 72/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.3405 - val_loss: 1.4104\n",
      "Epoch 73/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.3433 - val_loss: 1.3360\n",
      "Epoch 74/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.3294 - val_loss: 1.2947\n",
      "Epoch 75/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3237 - val_loss: 1.4759\n",
      "Epoch 76/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3392 - val_loss: 1.4424\n",
      "Epoch 77/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3324 - val_loss: 1.3666\n",
      "Epoch 78/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3188 - val_loss: 1.2995\n",
      "Epoch 79/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3132 - val_loss: 1.2741\n",
      "Epoch 80/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3076 - val_loss: 1.3111\n",
      "Epoch 81/950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3184 - val_loss: 1.4957\n",
      "Epoch 82/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3047 - val_loss: 1.3571\n",
      "Epoch 83/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.3082 - val_loss: 1.2717\n",
      "Epoch 84/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.3031 - val_loss: 1.2665\n",
      "Epoch 85/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.2883 - val_loss: 1.3380\n",
      "Epoch 86/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2861 - val_loss: 1.2343\n",
      "Epoch 87/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2855 - val_loss: 1.2436\n",
      "Epoch 88/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2796 - val_loss: 1.4261\n",
      "Epoch 89/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2808 - val_loss: 1.2412\n",
      "Epoch 90/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2909 - val_loss: 1.2543\n",
      "Epoch 91/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2775 - val_loss: 1.2531\n",
      "Epoch 92/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.2714 - val_loss: 1.4082\n",
      "Epoch 93/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2773 - val_loss: 1.2660\n",
      "Epoch 94/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2622 - val_loss: 1.2378\n",
      "Epoch 95/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2753 - val_loss: 1.2389\n",
      "Epoch 96/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2613 - val_loss: 1.2906\n",
      "Epoch 97/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2604 - val_loss: 1.2707\n",
      "Epoch 98/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2686 - val_loss: 1.2142\n",
      "Epoch 99/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2591 - val_loss: 1.2924\n",
      "Epoch 100/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2621 - val_loss: 1.3453\n",
      "Epoch 101/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2546 - val_loss: 1.2942\n",
      "Epoch 102/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.2676 - val_loss: 1.2723\n",
      "Epoch 103/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2457 - val_loss: 1.2042\n",
      "Epoch 104/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2408 - val_loss: 1.4047\n",
      "Epoch 105/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2611 - val_loss: 1.2858\n",
      "Epoch 106/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2512 - val_loss: 1.2160\n",
      "Epoch 107/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2469 - val_loss: 1.3484\n",
      "Epoch 108/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2450 - val_loss: 1.2738\n",
      "Epoch 109/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2431 - val_loss: 1.4671\n",
      "Epoch 110/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2368 - val_loss: 1.2114\n",
      "Epoch 111/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.2371 - val_loss: 1.2636\n",
      "Epoch 112/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2367 - val_loss: 1.2112\n",
      "Epoch 113/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2439 - val_loss: 1.2388\n",
      "Epoch 114/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2348 - val_loss: 1.2653\n",
      "Epoch 115/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2418 - val_loss: 1.2351\n",
      "Epoch 116/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2160 - val_loss: 1.2262\n",
      "Epoch 117/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2285 - val_loss: 1.2250\n",
      "Epoch 118/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2223 - val_loss: 1.2007\n",
      "Epoch 119/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2178 - val_loss: 1.2189\n",
      "Epoch 120/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2278 - val_loss: 1.2328\n",
      "Epoch 121/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2185 - val_loss: 1.2937\n",
      "Epoch 122/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2283 - val_loss: 1.3002\n",
      "Epoch 123/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2290 - val_loss: 1.2388\n",
      "Epoch 124/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2251 - val_loss: 1.2461\n",
      "Epoch 125/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2192 - val_loss: 1.2070\n",
      "Epoch 126/950\n",
      "413/413 [==============================] - 5s 13ms/step - loss: 1.2227 - val_loss: 1.2085\n",
      "Epoch 127/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2175 - val_loss: 1.2311\n",
      "Epoch 128/950\n",
      "413/413 [==============================] - 5s 13ms/step - loss: 1.2232 - val_loss: 1.2724\n",
      "Epoch 129/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.2058 - val_loss: 1.2041\n",
      "Epoch 130/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2153 - val_loss: 1.2306\n",
      "Epoch 131/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2193 - val_loss: 1.3593\n",
      "Epoch 132/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2194 - val_loss: 1.2139\n",
      "Epoch 133/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1997 - val_loss: 1.3073\n",
      "Epoch 134/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2043 - val_loss: 1.2695\n",
      "Epoch 135/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2149 - val_loss: 1.1634\n",
      "Epoch 136/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2021 - val_loss: 1.4416\n",
      "Epoch 137/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2109 - val_loss: 1.3992\n",
      "Epoch 138/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1931 - val_loss: 1.2263\n",
      "Epoch 139/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1988 - val_loss: 1.2314\n",
      "Epoch 140/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1902 - val_loss: 1.1879\n",
      "Epoch 141/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2092 - val_loss: 1.2216\n",
      "Epoch 142/950\n",
      "413/413 [==============================] - 5s 13ms/step - loss: 1.1950 - val_loss: 1.1962\n",
      "Epoch 143/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1972 - val_loss: 1.1747\n",
      "Epoch 144/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1913 - val_loss: 1.2114\n",
      "Epoch 145/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2058 - val_loss: 1.1944\n",
      "Epoch 146/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1987 - val_loss: 1.2198\n",
      "Epoch 147/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1833 - val_loss: 1.2397\n",
      "Epoch 148/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1930 - val_loss: 1.1889\n",
      "Epoch 149/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.2103 - val_loss: 1.2345\n",
      "Epoch 150/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1943 - val_loss: 1.2049\n",
      "Epoch 151/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1913 - val_loss: 1.1906\n",
      "Epoch 152/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1858 - val_loss: 1.1861\n",
      "Epoch 153/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1952 - val_loss: 1.2199\n",
      "Epoch 154/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1749 - val_loss: 1.2220\n",
      "Epoch 155/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1947 - val_loss: 1.2176\n",
      "Epoch 156/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1771 - val_loss: 1.1803\n",
      "Epoch 157/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1737 - val_loss: 1.2415\n",
      "Epoch 158/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1914 - val_loss: 1.1707\n",
      "Epoch 159/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1800 - val_loss: 1.2371\n",
      "Epoch 160/950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1681 - val_loss: 1.2072\n",
      "Epoch 161/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1756 - val_loss: 1.1890\n",
      "Epoch 162/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1829 - val_loss: 1.2019\n",
      "Epoch 163/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1717 - val_loss: 1.1878\n",
      "Epoch 164/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1809 - val_loss: 1.1908\n",
      "Epoch 165/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1787 - val_loss: 1.1689\n",
      "Epoch 166/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1709 - val_loss: 1.2242\n",
      "Epoch 167/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1826 - val_loss: 1.2273\n",
      "Epoch 168/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1613 - val_loss: 1.1475\n",
      "Epoch 169/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1716 - val_loss: 1.1870\n",
      "Epoch 170/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1703 - val_loss: 1.1553\n",
      "Epoch 171/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1641 - val_loss: 1.1686\n",
      "Epoch 172/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1728 - val_loss: 1.2147\n",
      "Epoch 173/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1761 - val_loss: 1.1601\n",
      "Epoch 174/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1721 - val_loss: 1.1856\n",
      "Epoch 175/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1561 - val_loss: 1.1483\n",
      "Epoch 176/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1677 - val_loss: 1.1807\n",
      "Epoch 177/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1667 - val_loss: 1.1513\n",
      "Epoch 178/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1636 - val_loss: 1.2450\n",
      "Epoch 179/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1600 - val_loss: 1.1687\n",
      "Epoch 180/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1569 - val_loss: 1.2047\n",
      "Epoch 181/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1533 - val_loss: 1.1609\n",
      "Epoch 182/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1593 - val_loss: 1.2120\n",
      "Epoch 183/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1575 - val_loss: 1.1946\n",
      "Epoch 184/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.1598 - val_loss: 1.2915\n",
      "Epoch 185/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.1524 - val_loss: 1.1533\n",
      "Epoch 186/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1458 - val_loss: 1.1725\n",
      "Epoch 187/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1577 - val_loss: 1.3254\n",
      "Epoch 188/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1472 - val_loss: 1.1494\n",
      "Epoch 189/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1478 - val_loss: 1.2015\n",
      "Epoch 190/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1538 - val_loss: 1.2908\n",
      "Epoch 191/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1546 - val_loss: 1.2038\n",
      "Epoch 192/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1532 - val_loss: 1.1254\n",
      "Epoch 193/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1396 - val_loss: 1.1718\n",
      "Epoch 194/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1471 - val_loss: 1.1335\n",
      "Epoch 195/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1491 - val_loss: 1.2022\n",
      "Epoch 196/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1464 - val_loss: 1.1527\n",
      "Epoch 197/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1434 - val_loss: 1.1347\n",
      "Epoch 198/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1538 - val_loss: 1.1905\n",
      "Epoch 199/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1324 - val_loss: 1.1408\n",
      "Epoch 200/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1460 - val_loss: 1.1264\n",
      "Epoch 201/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1450 - val_loss: 1.1401\n",
      "Epoch 202/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1346 - val_loss: 1.1664\n",
      "Epoch 203/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1344 - val_loss: 1.1375\n",
      "Epoch 204/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.1526 - val_loss: 1.1735\n",
      "Epoch 205/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.1383 - val_loss: 1.2508\n",
      "Epoch 206/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1333 - val_loss: 1.1654\n",
      "Epoch 207/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1423 - val_loss: 1.1427\n",
      "Epoch 208/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1454 - val_loss: 1.1759\n",
      "Epoch 209/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1381 - val_loss: 1.2177\n",
      "Epoch 210/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1328 - val_loss: 1.1494\n",
      "Epoch 211/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1287 - val_loss: 1.1553\n",
      "Epoch 212/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1359 - val_loss: 1.3770\n",
      "Epoch 213/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1384 - val_loss: 1.1147\n",
      "Epoch 214/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1476 - val_loss: 1.2442\n",
      "Epoch 215/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1357 - val_loss: 1.1771\n",
      "Epoch 216/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1338 - val_loss: 1.2133\n",
      "Epoch 217/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1351 - val_loss: 1.1277\n",
      "Epoch 218/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1337 - val_loss: 1.2143\n",
      "Epoch 219/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1280 - val_loss: 1.1432\n",
      "Epoch 220/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1323 - val_loss: 1.2290\n",
      "Epoch 221/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1230 - val_loss: 1.1646\n",
      "Epoch 222/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1342 - val_loss: 1.1624\n",
      "Epoch 223/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1376 - val_loss: 1.2860\n",
      "Epoch 224/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.1346 - val_loss: 1.1685\n",
      "Epoch 225/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1300 - val_loss: 1.1902\n",
      "Epoch 226/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1385 - val_loss: 1.2391\n",
      "Epoch 227/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1296 - val_loss: 1.1377\n",
      "Epoch 228/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1270 - val_loss: 1.1418\n",
      "Epoch 229/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1279 - val_loss: 1.1347\n",
      "Epoch 230/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1247 - val_loss: 1.1705\n",
      "Epoch 231/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1253 - val_loss: 1.1591\n",
      "Epoch 232/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1330 - val_loss: 1.2229\n",
      "Epoch 233/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1271 - val_loss: 1.1767\n",
      "Epoch 234/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1245 - val_loss: 1.1412\n",
      "Epoch 235/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1272 - val_loss: 1.1253\n",
      "Epoch 236/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1246 - val_loss: 1.1290\n",
      "Epoch 237/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1243 - val_loss: 1.2490\n",
      "Epoch 238/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1212 - val_loss: 1.1463\n",
      "Epoch 239/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1195 - val_loss: 1.1172\n",
      "Epoch 240/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1142 - val_loss: 1.1400\n",
      "Epoch 241/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1175 - val_loss: 1.1676\n",
      "Epoch 242/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1375 - val_loss: 1.1574\n",
      "Epoch 243/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1168 - val_loss: 1.1354\n",
      "Epoch 244/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.1102 - val_loss: 1.1771\n",
      "Epoch 245/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1224 - val_loss: 1.1290\n",
      "Epoch 246/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1223 - val_loss: 1.1353\n",
      "Epoch 247/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1204 - val_loss: 1.1022\n",
      "Epoch 248/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1136 - val_loss: 1.1103\n",
      "Epoch 249/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1120 - val_loss: 1.1281\n",
      "Epoch 250/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1137 - val_loss: 1.1122\n",
      "Epoch 251/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1253 - val_loss: 1.1858\n",
      "Epoch 252/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1195 - val_loss: 1.2005\n",
      "Epoch 253/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.1243 - val_loss: 1.1306\n",
      "Epoch 254/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.1082 - val_loss: 1.1164\n",
      "Epoch 255/950\n",
      "413/413 [==============================] - 6s 14ms/step - loss: 1.1033 - val_loss: 1.1228\n",
      "Epoch 256/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1155 - val_loss: 1.1471\n",
      "Epoch 257/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1174 - val_loss: 1.1440\n",
      "Epoch 258/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1225 - val_loss: 1.2016\n",
      "Epoch 259/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1065 - val_loss: 1.1424\n",
      "Epoch 260/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1113 - val_loss: 1.1682\n",
      "Epoch 261/950\n",
      "413/413 [==============================] - 5s 13ms/step - loss: 1.1175 - val_loss: 1.1095\n",
      "Epoch 262/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1186 - val_loss: 1.1323\n",
      "Epoch 263/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1174 - val_loss: 1.1758\n",
      "Epoch 264/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1085 - val_loss: 1.1382\n",
      "Epoch 265/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1096 - val_loss: 1.1515\n",
      "Epoch 266/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1062 - val_loss: 1.1993\n",
      "Epoch 267/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1163 - val_loss: 1.1311\n",
      "Epoch 268/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1057 - val_loss: 1.1682\n",
      "Epoch 269/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1123 - val_loss: 1.1774\n",
      "Epoch 270/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1176 - val_loss: 1.2172\n",
      "Epoch 271/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1187 - val_loss: 1.1214\n",
      "Epoch 272/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1041 - val_loss: 1.1440\n",
      "Epoch 273/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1074 - val_loss: 1.1333\n",
      "Epoch 274/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1043 - val_loss: 1.1108\n",
      "Epoch 275/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1093 - val_loss: 1.1032\n",
      "Epoch 276/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1018 - val_loss: 1.1389\n",
      "Epoch 277/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1066 - val_loss: 1.1028\n",
      "Epoch 278/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1026 - val_loss: 1.2016\n",
      "Epoch 279/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1115 - val_loss: 1.0992\n",
      "Epoch 280/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0996 - val_loss: 1.1177\n",
      "Epoch 281/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1063 - val_loss: 1.1982\n",
      "Epoch 282/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1071 - val_loss: 1.1268\n",
      "Epoch 283/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0937 - val_loss: 1.2072\n",
      "Epoch 284/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1014 - val_loss: 1.1422\n",
      "Epoch 285/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1002 - val_loss: 1.1371\n",
      "Epoch 286/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1062 - val_loss: 1.1350\n",
      "Epoch 287/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1020 - val_loss: 1.1190\n",
      "Epoch 288/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1082 - val_loss: 1.1317\n",
      "Epoch 289/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1044 - val_loss: 1.2081\n",
      "Epoch 290/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0979 - val_loss: 1.1220\n",
      "Epoch 291/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0925 - val_loss: 1.1367\n",
      "Epoch 292/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1009 - val_loss: 1.1321\n",
      "Epoch 293/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1018 - val_loss: 1.1207\n",
      "Epoch 294/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0979 - val_loss: 1.1085\n",
      "Epoch 295/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0964 - val_loss: 1.1474\n",
      "Epoch 296/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1104 - val_loss: 1.1134\n",
      "Epoch 297/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0919 - val_loss: 1.1772\n",
      "Epoch 298/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.1075 - val_loss: 1.1385\n",
      "Epoch 299/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0942 - val_loss: 1.1559\n",
      "Epoch 300/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0938 - val_loss: 1.0890\n",
      "Epoch 301/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0998 - val_loss: 1.1582\n",
      "Epoch 302/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0955 - val_loss: 1.0920\n",
      "Epoch 303/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0952 - val_loss: 1.1564\n",
      "Epoch 304/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0987 - val_loss: 1.1343\n",
      "Epoch 305/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0928 - val_loss: 1.1142\n",
      "Epoch 306/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1074 - val_loss: 1.1602\n",
      "Epoch 307/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0961 - val_loss: 1.1244\n",
      "Epoch 308/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.1016 - val_loss: 1.0981\n",
      "Epoch 309/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0793 - val_loss: 1.1456\n",
      "Epoch 310/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0991 - val_loss: 1.0879\n",
      "Epoch 311/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0916 - val_loss: 1.1087\n",
      "Epoch 312/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0897 - val_loss: 1.1088\n",
      "Epoch 313/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0954 - val_loss: 1.0855\n",
      "Epoch 314/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0882 - val_loss: 1.1992\n",
      "Epoch 315/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0998 - val_loss: 1.1034\n",
      "Epoch 316/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0940 - val_loss: 1.1393\n",
      "Epoch 317/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0947 - val_loss: 1.1052\n",
      "Epoch 318/950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 5s 12ms/step - loss: 1.1019 - val_loss: 1.1191\n",
      "Epoch 319/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0896 - val_loss: 1.0918\n",
      "Epoch 320/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0786 - val_loss: 1.1825\n",
      "Epoch 321/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0915 - val_loss: 1.1509\n",
      "Epoch 322/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0905 - val_loss: 1.1886\n",
      "Epoch 323/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0889 - val_loss: 1.0737\n",
      "Epoch 324/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0959 - val_loss: 1.1228\n",
      "Epoch 325/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0912 - val_loss: 1.1039\n",
      "Epoch 326/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0913 - val_loss: 1.1130\n",
      "Epoch 327/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0900 - val_loss: 1.1867\n",
      "Epoch 328/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0860 - val_loss: 1.1225\n",
      "Epoch 329/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0885 - val_loss: 1.1017\n",
      "Epoch 330/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0792 - val_loss: 1.1280\n",
      "Epoch 331/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0851 - val_loss: 1.1625\n",
      "Epoch 332/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0867 - val_loss: 1.0814\n",
      "Epoch 333/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0835 - val_loss: 1.1806\n",
      "Epoch 334/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0903 - val_loss: 1.1216\n",
      "Epoch 335/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0928 - val_loss: 1.1443\n",
      "Epoch 336/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0781 - val_loss: 1.0845\n",
      "Epoch 337/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0725 - val_loss: 1.1059\n",
      "Epoch 338/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0901 - val_loss: 1.1194\n",
      "Epoch 339/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0868 - val_loss: 1.2382\n",
      "Epoch 340/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0824 - val_loss: 1.1531\n",
      "Epoch 341/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0746 - val_loss: 1.0864\n",
      "Epoch 342/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0820 - val_loss: 1.1244\n",
      "Epoch 343/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0826 - val_loss: 1.0987\n",
      "Epoch 344/950\n",
      "413/413 [==============================] - 5s 11ms/step - loss: 1.0821 - val_loss: 1.0944\n",
      "Epoch 345/950\n",
      "413/413 [==============================] - 5s 13ms/step - loss: 1.0863 - val_loss: 1.1668\n",
      "Epoch 346/950\n",
      "413/413 [==============================] - 5s 13ms/step - loss: 1.0792 - val_loss: 1.0983\n",
      "Epoch 347/950\n",
      "413/413 [==============================] - 7s 17ms/step - loss: 1.0823 - val_loss: 1.1574\n",
      "Epoch 348/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0846 - val_loss: 1.1125\n",
      "Epoch 349/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0735 - val_loss: 1.1554\n",
      "Epoch 350/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0792 - val_loss: 1.1503\n",
      "Epoch 351/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0827 - val_loss: 1.1672\n",
      "Epoch 352/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0836 - val_loss: 1.1185\n",
      "Epoch 353/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0808 - val_loss: 1.0685\n",
      "Epoch 354/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0744 - val_loss: 1.0914\n",
      "Epoch 355/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0828 - val_loss: 1.1681\n",
      "Epoch 356/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0738 - val_loss: 1.1092\n",
      "Epoch 357/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0780 - val_loss: 1.1456\n",
      "Epoch 358/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0741 - val_loss: 1.0885\n",
      "Epoch 359/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0788 - val_loss: 1.1117\n",
      "Epoch 360/950\n",
      "413/413 [==============================] - 5s 13ms/step - loss: 1.0808 - val_loss: 1.0907\n",
      "Epoch 361/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0718 - val_loss: 1.0836\n",
      "Epoch 362/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0805 - val_loss: 1.1249\n",
      "Epoch 363/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0796 - val_loss: 1.0746\n",
      "Epoch 364/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0774 - val_loss: 1.1140\n",
      "Epoch 365/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0760 - val_loss: 1.1038\n",
      "Epoch 366/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0721 - val_loss: 1.0905\n",
      "Epoch 367/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0785 - val_loss: 1.0829\n",
      "Epoch 368/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0709 - val_loss: 1.1197\n",
      "Epoch 369/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0758 - val_loss: 1.1124\n",
      "Epoch 370/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0726 - val_loss: 1.0759\n",
      "Epoch 371/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0814 - val_loss: 1.1166\n",
      "Epoch 372/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0820 - val_loss: 1.0994\n",
      "Epoch 373/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0760 - val_loss: 1.1011\n",
      "Epoch 374/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0760 - val_loss: 1.1163\n",
      "Epoch 375/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0715 - val_loss: 1.0731\n",
      "Epoch 376/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0692 - val_loss: 1.0881\n",
      "Epoch 377/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0757 - val_loss: 1.1296\n",
      "Epoch 378/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0697 - val_loss: 1.1397\n",
      "Epoch 379/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0676 - val_loss: 1.1443\n",
      "Epoch 380/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0777 - val_loss: 1.1076\n",
      "Epoch 381/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0682 - val_loss: 1.0651\n",
      "Epoch 382/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0724 - val_loss: 1.1103\n",
      "Epoch 383/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0720 - val_loss: 1.0967\n",
      "Epoch 384/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0695 - val_loss: 1.1532\n",
      "Epoch 385/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0658 - val_loss: 1.0748\n",
      "Epoch 386/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0762 - val_loss: 1.0892\n",
      "Epoch 387/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0656 - val_loss: 1.1002\n",
      "Epoch 388/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0674 - val_loss: 1.1186\n",
      "Epoch 389/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0617 - val_loss: 1.1492\n",
      "Epoch 390/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0737 - val_loss: 1.0903\n",
      "Epoch 391/950\n",
      "413/413 [==============================] - 5s 12ms/step - loss: 1.0586 - val_loss: 1.0820\n",
      "Epoch 392/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0679 - val_loss: 1.0804\n",
      "Epoch 393/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0630 - val_loss: 1.0998\n",
      "Epoch 394/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0681 - val_loss: 1.4627\n",
      "Epoch 395/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0851 - val_loss: 1.0824\n",
      "Epoch 396/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0656 - val_loss: 1.0827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0620 - val_loss: 1.0946\n",
      "Epoch 398/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0740 - val_loss: 1.0887\n",
      "Epoch 399/950\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 1.0689 - val_loss: 1.0937\n",
      "Epoch 400/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0762 - val_loss: 1.0827\n",
      "Epoch 401/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0607 - val_loss: 1.1081\n",
      "Epoch 402/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0731 - val_loss: 1.0985\n",
      "Epoch 403/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0593 - val_loss: 1.0765\n",
      "Epoch 404/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0642 - val_loss: 1.1166\n",
      "Epoch 405/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0684 - val_loss: 1.0814\n",
      "Epoch 406/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0602 - val_loss: 1.1233\n",
      "Epoch 407/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0648 - val_loss: 1.0819\n",
      "Epoch 408/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0618 - val_loss: 1.1180\n",
      "Epoch 409/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0620 - val_loss: 1.1233\n",
      "Epoch 410/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0713 - val_loss: 1.1027\n",
      "Epoch 411/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0732 - val_loss: 1.1441\n",
      "Epoch 412/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0629 - val_loss: 1.0929\n",
      "Epoch 413/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0641 - val_loss: 1.1773\n",
      "Epoch 414/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0649 - val_loss: 1.1040\n",
      "Epoch 415/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0716 - val_loss: 1.0916\n",
      "Epoch 416/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0596 - val_loss: 1.0740\n",
      "Epoch 417/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0595 - val_loss: 1.0826\n",
      "Epoch 418/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0642 - val_loss: 1.1142\n",
      "Epoch 419/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0593 - val_loss: 1.0701\n",
      "Epoch 420/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0668 - val_loss: 1.0769\n",
      "Epoch 421/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0585 - val_loss: 1.0737\n",
      "Epoch 422/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0607 - val_loss: 1.0742\n",
      "Epoch 423/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0588 - val_loss: 1.0841\n",
      "Epoch 424/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0587 - val_loss: 1.1102\n",
      "Epoch 425/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0613 - val_loss: 1.1880\n",
      "Epoch 426/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0606 - val_loss: 1.0981\n",
      "Epoch 427/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0623 - val_loss: 1.0895\n",
      "Epoch 428/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0615 - val_loss: 1.0737\n",
      "Epoch 429/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0543 - val_loss: 1.1079\n",
      "Epoch 430/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0650 - val_loss: 1.1354\n",
      "Epoch 431/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0620 - val_loss: 1.0922\n",
      "Epoch 432/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0493 - val_loss: 1.1043\n",
      "Epoch 433/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0539 - val_loss: 1.0759\n",
      "Epoch 434/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0610 - val_loss: 1.0739\n",
      "Epoch 435/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0592 - val_loss: 1.0885\n",
      "Epoch 436/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0533 - val_loss: 1.1588\n",
      "Epoch 437/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0615 - val_loss: 1.0772\n",
      "Epoch 438/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0607 - val_loss: 1.1511\n",
      "Epoch 439/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0622 - val_loss: 1.0873\n",
      "Epoch 440/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0597 - val_loss: 1.0981\n",
      "Epoch 441/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0539 - val_loss: 1.0536\n",
      "Epoch 442/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0549 - val_loss: 1.0730\n",
      "Epoch 443/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0560 - val_loss: 1.0844\n",
      "Epoch 444/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0497 - val_loss: 1.0531\n",
      "Epoch 445/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0579 - val_loss: 1.0794\n",
      "Epoch 446/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0569 - val_loss: 1.0776\n",
      "Epoch 447/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0510 - val_loss: 1.0785\n",
      "Epoch 448/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0586 - val_loss: 1.0894\n",
      "Epoch 449/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0599 - val_loss: 1.1052\n",
      "Epoch 450/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0467 - val_loss: 1.0799\n",
      "Epoch 451/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0548 - val_loss: 1.0967\n",
      "Epoch 452/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0581 - val_loss: 1.1225\n",
      "Epoch 453/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0540 - val_loss: 1.1108\n",
      "Epoch 454/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0615 - val_loss: 1.0605\n",
      "Epoch 455/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0551 - val_loss: 1.0926\n",
      "Epoch 456/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0539 - val_loss: 1.0687\n",
      "Epoch 457/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0439 - val_loss: 1.0666\n",
      "Epoch 458/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0493 - val_loss: 1.1050\n",
      "Epoch 459/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0496 - val_loss: 1.0893\n",
      "Epoch 460/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0596 - val_loss: 1.0724\n",
      "Epoch 461/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0568 - val_loss: 1.0750\n",
      "Epoch 462/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0469 - val_loss: 1.0885\n",
      "Epoch 463/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0481 - val_loss: 1.1105\n",
      "Epoch 464/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0486 - val_loss: 1.0668\n",
      "Epoch 465/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0520 - val_loss: 1.0892\n",
      "Epoch 466/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0532 - val_loss: 1.0819\n",
      "Epoch 467/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0478 - val_loss: 1.0933\n",
      "Epoch 468/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0557 - val_loss: 1.0783\n",
      "Epoch 469/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0585 - val_loss: 1.0966\n",
      "Epoch 470/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0421 - val_loss: 1.0767\n",
      "Epoch 471/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0512 - val_loss: 1.0563\n",
      "Epoch 472/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0513 - val_loss: 1.2917\n",
      "Epoch 473/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0488 - val_loss: 1.0841\n",
      "Epoch 474/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0496 - val_loss: 1.1442\n",
      "Epoch 475/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0590 - val_loss: 1.0995\n",
      "Epoch 476/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0465 - val_loss: 1.0845\n",
      "Epoch 477/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0393 - val_loss: 1.2236\n",
      "Epoch 478/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0441 - val_loss: 1.0859\n",
      "Epoch 479/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0514 - val_loss: 1.0910\n",
      "Epoch 480/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0465 - val_loss: 1.1003\n",
      "Epoch 481/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0499 - val_loss: 1.1104\n",
      "Epoch 482/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0476 - val_loss: 1.1084\n",
      "Epoch 483/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0501 - val_loss: 1.0843\n",
      "Epoch 484/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0453 - val_loss: 1.0694\n",
      "Epoch 485/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0501 - val_loss: 1.0666\n",
      "Epoch 486/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0583 - val_loss: 1.0879\n",
      "Epoch 487/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0438 - val_loss: 1.1001\n",
      "Epoch 488/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0556 - val_loss: 1.0666\n",
      "Epoch 489/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0453 - val_loss: 1.0871\n",
      "Epoch 490/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0495 - val_loss: 1.1025\n",
      "Epoch 491/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0514 - val_loss: 1.0971\n",
      "Epoch 492/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0433 - val_loss: 1.1242\n",
      "Epoch 493/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0451 - val_loss: 1.1120\n",
      "Epoch 494/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0463 - val_loss: 1.1306\n",
      "Epoch 495/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0471 - val_loss: 1.1355\n",
      "Epoch 496/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0503 - val_loss: 1.0666\n",
      "Epoch 497/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0422 - val_loss: 1.0949\n",
      "Epoch 498/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0427 - val_loss: 1.1080\n",
      "Epoch 499/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0573 - val_loss: 1.1458\n",
      "Epoch 500/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0533 - val_loss: 1.1356\n",
      "Epoch 501/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0514 - val_loss: 1.0810\n",
      "Epoch 502/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0535 - val_loss: 1.0714\n",
      "Epoch 503/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0508 - val_loss: 1.1287\n",
      "Epoch 504/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0487 - val_loss: 1.1108\n",
      "Epoch 505/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0411 - val_loss: 1.0485\n",
      "Epoch 506/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0384 - val_loss: 1.0937\n",
      "Epoch 507/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0487 - val_loss: 1.0963\n",
      "Epoch 508/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0448 - val_loss: 1.1084\n",
      "Epoch 509/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0476 - val_loss: 1.0833\n",
      "Epoch 510/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0379 - val_loss: 1.0606\n",
      "Epoch 511/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0473 - val_loss: 1.0905\n",
      "Epoch 512/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0401 - val_loss: 1.1141\n",
      "Epoch 513/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0474 - val_loss: 1.0644\n",
      "Epoch 514/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0402 - val_loss: 1.1546\n",
      "Epoch 515/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0421 - val_loss: 1.0911\n",
      "Epoch 516/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0476 - val_loss: 1.0771\n",
      "Epoch 517/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0447 - val_loss: 1.1188\n",
      "Epoch 518/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0426 - val_loss: 1.1138\n",
      "Epoch 519/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0463 - val_loss: 1.1187\n",
      "Epoch 520/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0411 - val_loss: 1.0613\n",
      "Epoch 521/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0490 - val_loss: 1.1213\n",
      "Epoch 522/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0376 - val_loss: 1.1012\n",
      "Epoch 523/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0431 - val_loss: 1.0938\n",
      "Epoch 524/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0526 - val_loss: 1.0737\n",
      "Epoch 525/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0401 - val_loss: 1.0598\n",
      "Epoch 526/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0457 - val_loss: 1.0606\n",
      "Epoch 527/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0384 - val_loss: 1.0501\n",
      "Epoch 528/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0415 - val_loss: 1.0945\n",
      "Epoch 529/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0323 - val_loss: 1.1140\n",
      "Epoch 530/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0399 - val_loss: 1.0888\n",
      "Epoch 531/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0385 - val_loss: 1.0799\n",
      "Epoch 532/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0466 - val_loss: 1.1193\n",
      "Epoch 533/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0377 - val_loss: 1.0860\n",
      "Epoch 534/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0414 - val_loss: 1.1281\n",
      "Epoch 535/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0514 - val_loss: 1.0803\n",
      "Epoch 536/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0452 - val_loss: 1.0707\n",
      "Epoch 537/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0357 - val_loss: 1.0960\n",
      "Epoch 538/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0370 - val_loss: 1.0938\n",
      "Epoch 539/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0465 - val_loss: 1.0935\n",
      "Epoch 540/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0389 - val_loss: 1.0712\n",
      "Epoch 541/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0422 - val_loss: 1.1031\n",
      "Epoch 542/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0342 - val_loss: 1.0854\n",
      "Epoch 543/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0339 - val_loss: 1.0481\n",
      "Epoch 544/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0460 - val_loss: 1.0647\n",
      "Epoch 545/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0501 - val_loss: 1.1090\n",
      "Epoch 546/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0384 - val_loss: 1.0553\n",
      "Epoch 547/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0353 - val_loss: 1.0584\n",
      "Epoch 548/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0411 - val_loss: 1.0616\n",
      "Epoch 549/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0382 - val_loss: 1.0627\n",
      "Epoch 550/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0421 - val_loss: 1.0831\n",
      "Epoch 551/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0361 - val_loss: 1.1090\n",
      "Epoch 552/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0375 - val_loss: 1.0965\n",
      "Epoch 553/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0463 - val_loss: 1.0628\n",
      "Epoch 554/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0434 - val_loss: 1.0816\n",
      "Epoch 555/950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0386 - val_loss: 1.0764\n",
      "Epoch 556/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0339 - val_loss: 1.0540\n",
      "Epoch 557/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0399 - val_loss: 1.0466\n",
      "Epoch 558/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0336 - val_loss: 1.0828\n",
      "Epoch 559/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0407 - val_loss: 1.0543\n",
      "Epoch 560/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0427 - val_loss: 1.0536\n",
      "Epoch 561/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0342 - val_loss: 1.0752\n",
      "Epoch 562/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0383 - val_loss: 1.1076\n",
      "Epoch 563/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0359 - val_loss: 1.1315\n",
      "Epoch 564/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0438 - val_loss: 1.0903\n",
      "Epoch 565/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0361 - val_loss: 1.0776\n",
      "Epoch 566/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0299 - val_loss: 1.0628\n",
      "Epoch 567/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0346 - val_loss: 1.1090\n",
      "Epoch 568/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0410 - val_loss: 1.0671\n",
      "Epoch 569/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0355 - val_loss: 1.0563\n",
      "Epoch 570/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0308 - val_loss: 1.0796\n",
      "Epoch 571/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0380 - val_loss: 1.0952\n",
      "Epoch 572/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0330 - val_loss: 1.0721\n",
      "Epoch 573/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0401 - val_loss: 1.0723\n",
      "Epoch 574/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0320 - val_loss: 1.0530\n",
      "Epoch 575/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0315 - val_loss: 1.0614\n",
      "Epoch 576/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0415 - val_loss: 1.1353\n",
      "Epoch 577/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0345 - val_loss: 1.0423\n",
      "Epoch 578/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0296 - val_loss: 1.1217\n",
      "Epoch 579/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0439 - val_loss: 1.0442\n",
      "Epoch 580/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0371 - val_loss: 1.0823\n",
      "Epoch 581/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0270 - val_loss: 1.0895\n",
      "Epoch 582/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0336 - val_loss: 1.0717\n",
      "Epoch 583/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0364 - val_loss: 1.0624\n",
      "Epoch 584/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0330 - val_loss: 1.0508\n",
      "Epoch 585/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0361 - val_loss: 1.0784\n",
      "Epoch 586/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0459 - val_loss: 1.0580\n",
      "Epoch 587/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0332 - val_loss: 1.0744\n",
      "Epoch 588/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0393 - val_loss: 1.0357\n",
      "Epoch 589/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0355 - val_loss: 1.0784\n",
      "Epoch 590/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0389 - val_loss: 1.0621\n",
      "Epoch 591/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0282 - val_loss: 1.0921\n",
      "Epoch 592/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0309 - val_loss: 1.0425\n",
      "Epoch 593/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0306 - val_loss: 1.0861\n",
      "Epoch 594/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0350 - val_loss: 1.0814\n",
      "Epoch 595/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0304 - val_loss: 1.1089\n",
      "Epoch 596/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0311 - val_loss: 1.0499\n",
      "Epoch 597/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0234 - val_loss: 1.0656\n",
      "Epoch 598/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0255 - val_loss: 1.0639\n",
      "Epoch 599/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0375 - val_loss: 1.0714\n",
      "Epoch 600/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0310 - val_loss: 1.0631\n",
      "Epoch 601/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0336 - val_loss: 1.0789\n",
      "Epoch 602/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0331 - val_loss: 1.0452\n",
      "Epoch 603/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0386 - val_loss: 1.0670\n",
      "Epoch 604/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0317 - val_loss: 1.1044\n",
      "Epoch 605/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0317 - val_loss: 1.1175\n",
      "Epoch 606/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0369 - val_loss: 1.0870\n",
      "Epoch 607/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0274 - val_loss: 1.0766\n",
      "Epoch 608/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0392 - val_loss: 1.0732\n",
      "Epoch 609/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0355 - val_loss: 1.0782\n",
      "Epoch 610/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0291 - val_loss: 1.1413\n",
      "Epoch 611/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0347 - val_loss: 1.0567\n",
      "Epoch 612/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0270 - val_loss: 1.0694\n",
      "Epoch 613/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0310 - val_loss: 1.0940\n",
      "Epoch 614/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0351 - val_loss: 1.0721\n",
      "Epoch 615/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0266 - val_loss: 1.0492\n",
      "Epoch 616/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0391 - val_loss: 1.0596\n",
      "Epoch 617/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0328 - val_loss: 1.0586\n",
      "Epoch 618/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0358 - val_loss: 1.0746\n",
      "Epoch 619/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0286 - val_loss: 1.0528\n",
      "Epoch 620/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0276 - val_loss: 1.0665\n",
      "Epoch 621/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0395 - val_loss: 1.0949\n",
      "Epoch 622/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0229 - val_loss: 1.0846\n",
      "Epoch 623/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0285 - val_loss: 1.0401\n",
      "Epoch 624/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0305 - val_loss: 1.0827\n",
      "Epoch 625/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0274 - val_loss: 1.1186\n",
      "Epoch 626/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0295 - val_loss: 1.0992\n",
      "Epoch 627/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0303 - val_loss: 1.0636\n",
      "Epoch 628/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0240 - val_loss: 1.0770\n",
      "Epoch 629/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0324 - val_loss: 1.0692\n",
      "Epoch 630/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0274 - val_loss: 1.0506\n",
      "Epoch 631/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0300 - val_loss: 1.0865\n",
      "Epoch 632/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0299 - val_loss: 1.0596\n",
      "Epoch 633/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0329 - val_loss: 1.0553\n",
      "Epoch 634/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0337 - val_loss: 1.0682\n",
      "Epoch 635/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0311 - val_loss: 1.0829\n",
      "Epoch 636/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0313 - val_loss: 1.0436\n",
      "Epoch 637/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0285 - val_loss: 1.0535\n",
      "Epoch 638/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0266 - val_loss: 1.0671\n",
      "Epoch 639/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0255 - val_loss: 1.1077\n",
      "Epoch 640/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0305 - val_loss: 1.0541\n",
      "Epoch 641/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0305 - val_loss: 1.0749\n",
      "Epoch 642/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0298 - val_loss: 1.0502\n",
      "Epoch 643/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0196 - val_loss: 1.1022\n",
      "Epoch 644/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0276 - val_loss: 1.0970\n",
      "Epoch 645/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0278 - val_loss: 1.1325\n",
      "Epoch 646/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0311 - val_loss: 1.0968\n",
      "Epoch 647/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0250 - val_loss: 1.0513\n",
      "Epoch 648/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0224 - val_loss: 1.1644\n",
      "Epoch 649/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0307 - val_loss: 1.0813\n",
      "Epoch 650/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0288 - val_loss: 1.0504\n",
      "Epoch 651/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0330 - val_loss: 1.1789\n",
      "Epoch 652/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0307 - val_loss: 1.0556\n",
      "Epoch 653/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0253 - val_loss: 1.1001\n",
      "Epoch 654/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0192 - val_loss: 1.0400\n",
      "Epoch 655/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0248 - val_loss: 1.0939\n",
      "Epoch 656/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0355 - val_loss: 1.0907\n",
      "Epoch 657/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0245 - val_loss: 1.1002\n",
      "Epoch 658/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0196 - val_loss: 1.1341\n",
      "Epoch 659/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0275 - val_loss: 1.0556\n",
      "Epoch 660/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0245 - val_loss: 1.0773\n",
      "Epoch 661/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0270 - val_loss: 1.0972\n",
      "Epoch 662/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0213 - val_loss: 1.0838\n",
      "Epoch 663/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0258 - val_loss: 1.1391\n",
      "Epoch 664/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0243 - val_loss: 1.0707\n",
      "Epoch 665/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0218 - val_loss: 1.0576\n",
      "Epoch 666/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0259 - val_loss: 1.1388\n",
      "Epoch 667/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0303 - val_loss: 1.0754\n",
      "Epoch 668/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0245 - val_loss: 1.0493\n",
      "Epoch 669/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0267 - val_loss: 1.0971\n",
      "Epoch 670/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0215 - val_loss: 1.0709\n",
      "Epoch 671/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0354 - val_loss: 1.0556\n",
      "Epoch 672/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0210 - val_loss: 1.0755\n",
      "Epoch 673/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0264 - val_loss: 1.1009\n",
      "Epoch 674/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0218 - val_loss: 1.1723\n",
      "Epoch 675/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0251 - val_loss: 1.0681\n",
      "Epoch 676/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0236 - val_loss: 1.0562\n",
      "Epoch 677/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0222 - val_loss: 1.0505\n",
      "Epoch 678/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0185 - val_loss: 1.0423\n",
      "Epoch 679/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0199 - val_loss: 1.0599\n",
      "Epoch 680/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0215 - val_loss: 1.0824\n",
      "Epoch 681/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0283 - val_loss: 1.0595\n",
      "Epoch 682/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0243 - val_loss: 1.0652\n",
      "Epoch 683/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0245 - val_loss: 1.1062\n",
      "Epoch 684/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0248 - val_loss: 1.0788\n",
      "Epoch 685/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0162 - val_loss: 1.0765\n",
      "Epoch 686/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0216 - val_loss: 1.0589\n",
      "Epoch 687/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0245 - val_loss: 1.0592\n",
      "Epoch 688/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0224 - val_loss: 1.0409\n",
      "Epoch 689/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0281 - val_loss: 1.1394\n",
      "Epoch 690/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0225 - val_loss: 1.0405\n",
      "Epoch 691/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0190 - val_loss: 1.0422\n",
      "Epoch 692/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0217 - val_loss: 1.0851\n",
      "Epoch 693/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0276 - val_loss: 1.0734\n",
      "Epoch 694/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0238 - val_loss: 1.0437\n",
      "Epoch 695/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0194 - val_loss: 1.0656\n",
      "Epoch 696/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0181 - val_loss: 1.0616\n",
      "Epoch 697/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0273 - val_loss: 1.0611\n",
      "Epoch 698/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0179 - val_loss: 1.0523\n",
      "Epoch 699/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0235 - val_loss: 1.0794\n",
      "Epoch 700/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0257 - val_loss: 1.0720\n",
      "Epoch 701/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0192 - val_loss: 1.0912\n",
      "Epoch 702/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0193 - val_loss: 1.0768\n",
      "Epoch 703/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0218 - val_loss: 1.0377\n",
      "Epoch 704/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0218 - val_loss: 1.0485\n",
      "Epoch 705/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0289 - val_loss: 1.0846\n",
      "Epoch 706/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0223 - val_loss: 1.0566\n",
      "Epoch 707/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0135 - val_loss: 1.0678\n",
      "Epoch 708/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0179 - val_loss: 1.0382\n",
      "Epoch 709/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0251 - val_loss: 1.0885\n",
      "Epoch 710/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0286 - val_loss: 1.0643\n",
      "Epoch 711/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0248 - val_loss: 1.0678\n",
      "Epoch 712/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0179 - val_loss: 1.0309\n",
      "Epoch 713/950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0158 - val_loss: 1.0615\n",
      "Epoch 714/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0270 - val_loss: 1.0862\n",
      "Epoch 715/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0266 - val_loss: 1.0660\n",
      "Epoch 716/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0206 - val_loss: 1.0392\n",
      "Epoch 717/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0237 - val_loss: 1.0547\n",
      "Epoch 718/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0144 - val_loss: 1.0932\n",
      "Epoch 719/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0178 - val_loss: 1.0539\n",
      "Epoch 720/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0179 - val_loss: 1.0426\n",
      "Epoch 721/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0274 - val_loss: 1.0614\n",
      "Epoch 722/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0192 - val_loss: 1.0494\n",
      "Epoch 723/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0237 - val_loss: 1.0645\n",
      "Epoch 724/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0181 - val_loss: 1.0464\n",
      "Epoch 725/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0239 - val_loss: 1.0566\n",
      "Epoch 726/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0208 - val_loss: 1.0466\n",
      "Epoch 727/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0270 - val_loss: 1.0651\n",
      "Epoch 728/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0150 - val_loss: 1.0399\n",
      "Epoch 729/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0281 - val_loss: 1.0733\n",
      "Epoch 730/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0175 - val_loss: 1.0621\n",
      "Epoch 731/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0217 - val_loss: 1.0511\n",
      "Epoch 732/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0219 - val_loss: 1.0442\n",
      "Epoch 733/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0173 - val_loss: 1.0435\n",
      "Epoch 734/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0137 - val_loss: 1.0437\n",
      "Epoch 735/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0172 - val_loss: 1.0661\n",
      "Epoch 736/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0187 - val_loss: 1.1414\n",
      "Epoch 737/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0173 - val_loss: 1.0676\n",
      "Epoch 738/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0199 - val_loss: 1.0443\n",
      "Epoch 739/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0272 - val_loss: 1.0898\n",
      "Epoch 740/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0270 - val_loss: 1.1042\n",
      "Epoch 741/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0186 - val_loss: 1.0573\n",
      "Epoch 742/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0170 - val_loss: 1.0701\n",
      "Epoch 743/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0180 - val_loss: 1.0632\n",
      "Epoch 744/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0144 - val_loss: 1.0914\n",
      "Epoch 745/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0197 - val_loss: 1.0475\n",
      "Epoch 746/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0216 - val_loss: 1.0394\n",
      "Epoch 747/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0187 - val_loss: 1.0781\n",
      "Epoch 748/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0153 - val_loss: 1.0833\n",
      "Epoch 749/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0186 - val_loss: 1.0621\n",
      "Epoch 750/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0203 - val_loss: 1.1474\n",
      "Epoch 751/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0209 - val_loss: 1.1052\n",
      "Epoch 752/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0153 - val_loss: 1.0520\n",
      "Epoch 753/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0110 - val_loss: 1.0438\n",
      "Epoch 754/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0149 - val_loss: 1.1052\n",
      "Epoch 755/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0150 - val_loss: 1.1002\n",
      "Epoch 756/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0151 - val_loss: 1.0729\n",
      "Epoch 757/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0125 - val_loss: 1.0764\n",
      "Epoch 758/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0180 - val_loss: 1.0556\n",
      "Epoch 759/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0226 - val_loss: 1.0611\n",
      "Epoch 760/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0170 - val_loss: 1.0588\n",
      "Epoch 761/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0158 - val_loss: 1.0798\n",
      "Epoch 762/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0195 - val_loss: 1.0902\n",
      "Epoch 763/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0180 - val_loss: 1.1081\n",
      "Epoch 764/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0181 - val_loss: 1.1133\n",
      "Epoch 765/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0218 - val_loss: 1.0922\n",
      "Epoch 766/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0193 - val_loss: 1.0619\n",
      "Epoch 767/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0107 - val_loss: 1.0271\n",
      "Epoch 768/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0174 - val_loss: 1.0623\n",
      "Epoch 769/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0167 - val_loss: 1.0386\n",
      "Epoch 770/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0127 - val_loss: 1.0826\n",
      "Epoch 771/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0229 - val_loss: 1.0601\n",
      "Epoch 772/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0235 - val_loss: 1.0626\n",
      "Epoch 773/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0241 - val_loss: 1.0711\n",
      "Epoch 774/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0027 - val_loss: 1.0496\n",
      "Epoch 775/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0140 - val_loss: 1.0448\n",
      "Epoch 776/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0133 - val_loss: 1.0600\n",
      "Epoch 777/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0127 - val_loss: 1.0446\n",
      "Epoch 778/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0193 - val_loss: 1.1075\n",
      "Epoch 779/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0232 - val_loss: 1.0362\n",
      "Epoch 780/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0078 - val_loss: 1.0765\n",
      "Epoch 781/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0135 - val_loss: 1.0653\n",
      "Epoch 782/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0257 - val_loss: 1.0877\n",
      "Epoch 783/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0171 - val_loss: 1.1263\n",
      "Epoch 784/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0126 - val_loss: 1.0837\n",
      "Epoch 785/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0170 - val_loss: 1.0815\n",
      "Epoch 786/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0114 - val_loss: 1.0586\n",
      "Epoch 787/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0117 - val_loss: 1.0548\n",
      "Epoch 788/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0089 - val_loss: 1.0895\n",
      "Epoch 789/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0209 - val_loss: 1.1134\n",
      "Epoch 790/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0191 - val_loss: 1.0497\n",
      "Epoch 791/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0165 - val_loss: 1.0576\n",
      "Epoch 792/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0186 - val_loss: 1.0429\n",
      "Epoch 793/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0177 - val_loss: 1.0809\n",
      "Epoch 794/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0134 - val_loss: 1.0998\n",
      "Epoch 795/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0099 - val_loss: 1.1128\n",
      "Epoch 796/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0193 - val_loss: 1.0395\n",
      "Epoch 797/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0144 - val_loss: 1.1249\n",
      "Epoch 798/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0194 - val_loss: 1.0587\n",
      "Epoch 799/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0128 - val_loss: 1.0789\n",
      "Epoch 800/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0213 - val_loss: 1.0182\n",
      "Epoch 801/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0175 - val_loss: 1.0616\n",
      "Epoch 802/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0111 - val_loss: 1.0634\n",
      "Epoch 803/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0108 - val_loss: 1.0560\n",
      "Epoch 804/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0121 - val_loss: 1.0527\n",
      "Epoch 805/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0151 - val_loss: 1.0348\n",
      "Epoch 806/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0161 - val_loss: 1.0352\n",
      "Epoch 807/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0087 - val_loss: 1.0886\n",
      "Epoch 808/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0123 - val_loss: 1.0647\n",
      "Epoch 809/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0144 - val_loss: 1.0509\n",
      "Epoch 810/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0242 - val_loss: 1.0594\n",
      "Epoch 811/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0113 - val_loss: 1.0375\n",
      "Epoch 812/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0137 - val_loss: 1.0545\n",
      "Epoch 813/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0180 - val_loss: 1.0698\n",
      "Epoch 814/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0107 - val_loss: 1.0711\n",
      "Epoch 815/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0121 - val_loss: 1.0388\n",
      "Epoch 816/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0137 - val_loss: 1.0489\n",
      "Epoch 817/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0119 - val_loss: 1.0333\n",
      "Epoch 818/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0158 - val_loss: 1.0539\n",
      "Epoch 819/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0132 - val_loss: 1.0372\n",
      "Epoch 820/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0084 - val_loss: 1.0668\n",
      "Epoch 821/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0165 - val_loss: 1.1179\n",
      "Epoch 822/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0117 - val_loss: 1.0827\n",
      "Epoch 823/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0055 - val_loss: 1.0916\n",
      "Epoch 824/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0095 - val_loss: 1.0516\n",
      "Epoch 825/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0211 - val_loss: 1.0465\n",
      "Epoch 826/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0104 - val_loss: 1.0445\n",
      "Epoch 827/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0122 - val_loss: 1.0800\n",
      "Epoch 828/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0173 - val_loss: 1.0422\n",
      "Epoch 829/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0053 - val_loss: 1.0606\n",
      "Epoch 830/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0070 - val_loss: 1.0516\n",
      "Epoch 831/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0132 - val_loss: 1.1133\n",
      "Epoch 832/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0095 - val_loss: 1.0329\n",
      "Epoch 833/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0149 - val_loss: 1.0520\n",
      "Epoch 834/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0158 - val_loss: 1.1214\n",
      "Epoch 835/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0144 - val_loss: 1.0796\n",
      "Epoch 836/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0127 - val_loss: 1.0437\n",
      "Epoch 837/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0101 - val_loss: 1.0317\n",
      "Epoch 838/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0142 - val_loss: 1.0362\n",
      "Epoch 839/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0107 - val_loss: 1.0544\n",
      "Epoch 840/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0173 - val_loss: 1.0522\n",
      "Epoch 841/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0176 - val_loss: 1.0433\n",
      "Epoch 842/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0096 - val_loss: 1.0579\n",
      "Epoch 843/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0107 - val_loss: 1.0379\n",
      "Epoch 844/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0172 - val_loss: 1.0615\n",
      "Epoch 845/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0034 - val_loss: 1.0378\n",
      "Epoch 846/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0060 - val_loss: 1.0540\n",
      "Epoch 847/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0149 - val_loss: 1.0483\n",
      "Epoch 848/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0164 - val_loss: 1.0679\n",
      "Epoch 849/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0034 - val_loss: 1.0296\n",
      "Epoch 850/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0054 - val_loss: 1.0481\n",
      "Epoch 851/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0150 - val_loss: 1.0953\n",
      "Epoch 852/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0102 - val_loss: 1.0540\n",
      "Epoch 853/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0099 - val_loss: 1.0395\n",
      "Epoch 854/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0113 - val_loss: 1.0842\n",
      "Epoch 855/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0084 - val_loss: 1.1265\n",
      "Epoch 856/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0054 - val_loss: 1.0678\n",
      "Epoch 857/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0157 - val_loss: 1.0399\n",
      "Epoch 858/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0108 - val_loss: 1.0371\n",
      "Epoch 859/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0109 - val_loss: 1.0706\n",
      "Epoch 860/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0102 - val_loss: 1.0428\n",
      "Epoch 861/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0062 - val_loss: 1.0856\n",
      "Epoch 862/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0100 - val_loss: 1.0645\n",
      "Epoch 863/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0048 - val_loss: 1.0574\n",
      "Epoch 864/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0142 - val_loss: 1.0753\n",
      "Epoch 865/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0072 - val_loss: 1.0623\n",
      "Epoch 866/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0168 - val_loss: 1.0624\n",
      "Epoch 867/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0124 - val_loss: 1.1102\n",
      "Epoch 868/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0129 - val_loss: 1.0600\n",
      "Epoch 869/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0129 - val_loss: 1.0627\n",
      "Epoch 870/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0084 - val_loss: 1.0440\n",
      "Epoch 871/950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0014 - val_loss: 1.1116\n",
      "Epoch 872/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0044 - val_loss: 1.0278\n",
      "Epoch 873/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0081 - val_loss: 1.0635\n",
      "Epoch 874/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0107 - val_loss: 1.0465\n",
      "Epoch 875/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0108 - val_loss: 1.0524\n",
      "Epoch 876/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0086 - val_loss: 1.0997\n",
      "Epoch 877/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0091 - val_loss: 1.0429\n",
      "Epoch 878/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0066 - val_loss: 1.0404\n",
      "Epoch 879/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0056 - val_loss: 1.0652\n",
      "Epoch 880/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0082 - val_loss: 1.0611\n",
      "Epoch 881/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0080 - val_loss: 1.0381\n",
      "Epoch 882/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0081 - val_loss: 1.0716\n",
      "Epoch 883/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0051 - val_loss: 1.0644\n",
      "Epoch 884/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0028 - val_loss: 1.0501\n",
      "Epoch 885/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0011 - val_loss: 1.0408\n",
      "Epoch 886/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0053 - val_loss: 1.0663\n",
      "Epoch 887/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0059 - val_loss: 1.0425\n",
      "Epoch 888/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0137 - val_loss: 1.0478\n",
      "Epoch 889/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0064 - val_loss: 1.0732\n",
      "Epoch 890/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0043 - val_loss: 1.0518\n",
      "Epoch 891/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0110 - val_loss: 1.0375\n",
      "Epoch 892/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0098 - val_loss: 1.0606\n",
      "Epoch 893/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0100 - val_loss: 1.0474\n",
      "Epoch 894/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0062 - val_loss: 1.0686\n",
      "Epoch 895/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0090 - val_loss: 1.0872\n",
      "Epoch 896/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0032 - val_loss: 1.0490\n",
      "Epoch 897/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0140 - val_loss: 1.0522\n",
      "Epoch 898/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0034 - val_loss: 1.0780\n",
      "Epoch 899/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0172 - val_loss: 1.0253\n",
      "Epoch 900/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0028 - val_loss: 1.0392\n",
      "Epoch 901/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0003 - val_loss: 1.0459\n",
      "Epoch 902/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0036 - val_loss: 1.0471\n",
      "Epoch 903/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0102 - val_loss: 1.0900\n",
      "Epoch 904/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0172 - val_loss: 1.0428\n",
      "Epoch 905/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0179 - val_loss: 1.0746\n",
      "Epoch 906/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0079 - val_loss: 1.0922\n",
      "Epoch 907/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0055 - val_loss: 1.0486\n",
      "Epoch 908/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0065 - val_loss: 1.0988\n",
      "Epoch 909/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0079 - val_loss: 1.0953\n",
      "Epoch 910/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0062 - val_loss: 1.0594\n",
      "Epoch 911/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0041 - val_loss: 1.0989\n",
      "Epoch 912/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0112 - val_loss: 1.0361\n",
      "Epoch 913/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0036 - val_loss: 1.0670\n",
      "Epoch 914/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0056 - val_loss: 1.0436\n",
      "Epoch 915/950\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 1.0114 - val_loss: 1.0849\n",
      "Epoch 916/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0020 - val_loss: 1.0788\n",
      "Epoch 917/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0037 - val_loss: 1.0329\n",
      "Epoch 918/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0114 - val_loss: 1.0499\n",
      "Epoch 919/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0125 - val_loss: 1.0713\n",
      "Epoch 920/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 0.9998 - val_loss: 1.0613\n",
      "Epoch 921/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0066 - val_loss: 1.0399\n",
      "Epoch 922/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 0.9981 - val_loss: 1.0902\n",
      "Epoch 923/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0009 - val_loss: 1.0489\n",
      "Epoch 924/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0054 - val_loss: 1.0445\n",
      "Epoch 925/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0032 - val_loss: 1.0578\n",
      "Epoch 926/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0026 - val_loss: 1.1100\n",
      "Epoch 927/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0117 - val_loss: 1.0427\n",
      "Epoch 928/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0045 - val_loss: 1.0432\n",
      "Epoch 929/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0084 - val_loss: 1.0516\n",
      "Epoch 930/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 0.9991 - val_loss: 1.0446\n",
      "Epoch 931/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0072 - val_loss: 1.0270\n",
      "Epoch 932/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0009 - val_loss: 1.0593\n",
      "Epoch 933/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0050 - val_loss: 1.0476\n",
      "Epoch 934/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0089 - val_loss: 1.0521\n",
      "Epoch 935/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 1.0028 - val_loss: 1.0371\n",
      "Epoch 936/950\n",
      "413/413 [==============================] - 4s 9ms/step - loss: 0.9962 - val_loss: 1.0453\n",
      "Epoch 937/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0003 - val_loss: 1.0676\n",
      "Epoch 938/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 0.9986 - val_loss: 1.0810\n",
      "Epoch 939/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0037 - val_loss: 1.0309\n",
      "Epoch 940/950\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 1.0139 - val_loss: 1.0926\n",
      "Epoch 941/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0055 - val_loss: 1.0913\n",
      "Epoch 942/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0082 - val_loss: 1.0657\n",
      "Epoch 943/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0022 - val_loss: 1.0355\n",
      "Epoch 944/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0006 - val_loss: 1.0740\n",
      "Epoch 945/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0002 - val_loss: 1.0899\n",
      "Epoch 946/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0070 - val_loss: 1.0665\n",
      "Epoch 947/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0007 - val_loss: 1.0881\n",
      "Epoch 948/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0051 - val_loss: 1.0846\n",
      "Epoch 949/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0037 - val_loss: 1.0622\n",
      "Epoch 950/950\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 1.0010 - val_loss: 1.0670\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dec1_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-f59d17a1c197>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m compare1={'model':['multiple regression', 'decision tree', 'random forest', 'gradient boosting regressor', 'lightgbm', 'lstm'],\n\u001b[1;32m---> 41\u001b[1;33m         'MAE':[mean_absolute_error(val_y1, reg1_preds), mean_absolute_error(val_y1, dec1_preds), mean_absolute_error(val_y1, ran1_preds),\n\u001b[0m\u001b[0;32m     42\u001b[0m               mean_absolute_error(val_y1, grad1_preds), mean_absolute_error(val_y1, lpreds1), mean_absolute_error(val_y1, lstm1_preds)],\n\u001b[0;32m     43\u001b[0m         'R^2':[r2_score(val_y1, reg1_preds), r2_score(val_y1, dec1_preds), r2_score(val_y1, ran1_preds), \n",
      "\u001b[1;31mNameError\u001b[0m: name 'dec1_preds' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "reg1=LinearRegression()     #initiating linear regression\n",
    "reg1.fit(train_X1,train_y1)\n",
    "reg1_preds=reg1.predict(val_X1)\n",
    "\n",
    "dtree = DecisionTreeRegressor(max_depth=40, min_samples_leaf=5, random_state=1)\n",
    "dtree.fit(train_X1, train_y1)\n",
    "dec1_preds= dtree.predict(val_X1)\n",
    "        \n",
    "forest_model1 = RandomForestRegressor(n_estimators=350, random_state=1)\n",
    "forest_model1.fit(train_X1, train_y1)\n",
    "forest1_preds = forest_model1.predict(val_X1)\n",
    "\n",
    "grad=GradientBoostingRegressor(learning_rate=lr, n_estimators=nes, subsample=1)\n",
    "grad.fit(train_X1, train_y1)\n",
    "grad1_preds=grad.predict(val_X1)\n",
    "\n",
    "light = lgm.LGBMClassifier(num_leaves=20, n_estimators=5)\n",
    "light.fit(train_X1, train_y1)\n",
    "lpreds1=light.predict(val_X1)\n",
    "\n",
    "lstm1_model = keras.Sequential([\n",
    "    # the hidden ReLU layers\n",
    "    layers.Dense(units=250, activation='relu', input_shape=[37]),\n",
    "    layers.Dense(units=250, activation='relu'),\n",
    "    # the linear output layer \n",
    "    layers.Dense(units=1)\n",
    "])\n",
    "lstm1_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mae\")\n",
    "\n",
    "lstm1_model.fit(\n",
    "            train_X1, train_y1,\n",
    "            validation_data=(val_X1, val_y1),\n",
    "            batch_size=210,\n",
    "            epochs=950)\n",
    "lstm1_preds=lstm1_model.predict(val_X1)\n",
    "\n",
    "\n",
    "compare1={'model':['multiple regression', 'decision tree', 'random forest', 'gradient boosting regressor', 'lightgbm', 'lstm'],\n",
    "        'MAE':[mean_absolute_error(val_y1, reg1_preds), mean_absolute_error(val_y1, dec1_preds), mean_absolute_error(val_y1, ran1_preds),\n",
    "              mean_absolute_error(val_y1, grad1_preds), mean_absolute_error(val_y1, lpreds1), mean_absolute_error(val_y1, lstm1_preds)],\n",
    "        'R^2':[r2_score(val_y1, reg1_preds), r2_score(val_y1, dec1_preds), r2_score(val_y1, ran1_preds), \n",
    "               r2_score(val_y1, grad1_preds), r2_score(val_y1, lpreds1), r2_score(val_y1, lstm1_preds)]}\n",
    "compare1_df=pd.DataFrame(compare1, columns=['model', 'MAE', 'R^2'])\n",
    "compare1_df=compare1_df.sort_values(by=['MAE'])\n",
    "compare1_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.761064</td>\n",
       "      <td>0.992570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.876403</td>\n",
       "      <td>0.989248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gradient boosting regressor</td>\n",
       "      <td>1.024178</td>\n",
       "      <td>0.986555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1.066999</td>\n",
       "      <td>0.984511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>1.634464</td>\n",
       "      <td>0.902756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multiple regression</td>\n",
       "      <td>3.661538</td>\n",
       "      <td>0.859880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model       MAE       R^2\n",
       "2                random forest  0.761064  0.992570\n",
       "1                decision tree  0.876403  0.989248\n",
       "3  gradient boosting regressor  1.024178  0.986555\n",
       "5                         lstm  1.066999  0.984511\n",
       "4                     lightgbm  1.634464  0.902756\n",
       "0          multiple regression  3.661538  0.859880"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeRegressor(max_depth=40, min_samples_leaf=5, random_state=1)\n",
    "dtree.fit(train_X1, train_y1)\n",
    "dec1_preds= dtree.predict(val_X1)\n",
    "compare1={'model':['multiple regression', 'decision tree', 'random forest', 'gradient boosting regressor', 'lightgbm', 'lstm'],\n",
    "        'MAE':[mean_absolute_error(val_y1, reg1_preds), mean_absolute_error(val_y1, dec1_preds), mean_absolute_error(val_y1, forest1_preds),\n",
    "              mean_absolute_error(val_y1, grad1_preds), mean_absolute_error(val_y1, lpreds1), mean_absolute_error(val_y1, lstm1_preds)],\n",
    "        'R^2':[r2_score(val_y1, reg1_preds), r2_score(val_y1, dec1_preds), r2_score(val_y1, forest1_preds), \n",
    "               r2_score(val_y1, grad1_preds), r2_score(val_y1, lpreds1), r2_score(val_y1, lstm1_preds)]}\n",
    "compare1_df=pd.DataFrame(compare1, columns=['model', 'MAE', 'R^2'])\n",
    "compare1_df=compare1_df.sort_values(by=['MAE'])\n",
    "compare1_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#decision tree\n",
    "depth=[1, 5, 10, 20, 40, 100]\n",
    "samples=[1, 5, 10, 20, 50, 100]\n",
    "for d in depth:\n",
    "    if d==1:\n",
    "        co='green'\n",
    "    elif d==5:\n",
    "        co='blue'\n",
    "    elif d==10:\n",
    "        co='red'\n",
    "    elif d==20:\n",
    "        co='orange'\n",
    "    elif d==40:\n",
    "        co='yellow'\n",
    "    elif d==100:\n",
    "        co='magenta'\n",
    "    for s in samples:\n",
    "        dtree5 = DecisionTreeRegressor(max_depth=d, min_samples_leaf=s, random_state=1)\n",
    "        dtree5.fit(train_X5, train_y5)\n",
    "        dec_preds5= dtree5.predict(val_X5)\n",
    "        plt.xlabel('Samples size')\n",
    "        plt.ylabel('Mean absolute error')\n",
    "        plt.scatter(s, mean_absolute_error(val_y5, dec_preds5), c=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators=[50, 250, 450, 650]\n",
    "for n in n_estimators:\n",
    "    forest_model5 = RandomForestRegressor(n_estimators=n, random_state=1)\n",
    "    forest_model5.fit(train_X5, train_y5)\n",
    "    forest5_preds = forest_model5.predict(val_X5)\n",
    "    plt.scatter(n, mean_absolute_error(val_y5, forest5_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#gradient boost\n",
    "nest=[1200, 1800]\n",
    "lra=[0.1, 0.5, 1]\n",
    "for nes in nest:\n",
    "    if nes==1200:\n",
    "        co='red'\n",
    "    elif nes==1800:\n",
    "        co='blue'\n",
    "            \n",
    "    for lr in lra:    \n",
    "        grad5=GradientBoostingRegressor(learning_rate=lr, n_estimators=nes, subsample=1)\n",
    "        grad5.fit(train_X5, train_y5)\n",
    "        grad5_preds=grad5.predict(val_X5)\n",
    "        plt.scatter(lr, mean_absolute_error(val_y5, grad5_preds), c=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#light       \n",
    "lnes=[1, 5, 10, 50, 100, 500]\n",
    "leaves=[2, 5, 20, 50, 100]\n",
    "for lne in lnes:\n",
    "    if lne==1:\n",
    "        co='red'\n",
    "    elif lne==5:\n",
    "        co='blue'\n",
    "    elif lne==10:\n",
    "        co='green'\n",
    "    elif lne==50:\n",
    "        co='orange'\n",
    "    elif lne==100:\n",
    "        co='magenta'\n",
    "    elif lne==500:\n",
    "        co='yellow'\n",
    "    \n",
    "    for le in leaves:\n",
    "        light5 = lgm.LGBMClassifier(num_leaves=le, n_estimators=lne)\n",
    "        light5.fit(train_X5, train_y5)\n",
    "        lpreds5=light5.predict(val_X5)\n",
    "        plt.scatter(le, mean_absolute_error(val_y5, lpreds5), c=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 9.6139 - val_loss: 3.9981\n",
      "Epoch 2/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 5.0128 - val_loss: 5.9820\n",
      "Epoch 3/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 4.8768 - val_loss: 5.2168\n",
      "Epoch 4/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 4.4232 - val_loss: 5.8479\n",
      "Epoch 5/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 4.0936 - val_loss: 3.7988\n",
      "Epoch 6/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 3.7211 - val_loss: 3.2685\n",
      "Epoch 7/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 3.3945 - val_loss: 3.1938\n",
      "Epoch 8/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 3.2320 - val_loss: 3.0880\n",
      "Epoch 9/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 3.1932 - val_loss: 2.9636\n",
      "Epoch 10/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.9920 - val_loss: 3.0525\n",
      "Epoch 11/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.9258 - val_loss: 2.7287\n",
      "Epoch 12/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.8101 - val_loss: 2.6280\n",
      "Epoch 13/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.7458 - val_loss: 2.7399\n",
      "Epoch 14/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.6764 - val_loss: 2.5633\n",
      "Epoch 15/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.6265 - val_loss: 2.5636\n",
      "Epoch 16/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.6244 - val_loss: 2.5103\n",
      "Epoch 17/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.5852 - val_loss: 2.9973\n",
      "Epoch 18/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.5449 - val_loss: 2.6031\n",
      "Epoch 19/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.5374 - val_loss: 2.5369\n",
      "Epoch 20/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.4857 - val_loss: 2.4536\n",
      "Epoch 21/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.4600 - val_loss: 2.4194\n",
      "Epoch 22/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.4386 - val_loss: 2.4083\n",
      "Epoch 23/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3964 - val_loss: 2.3941\n",
      "Epoch 24/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.3288 - val_loss: 2.2558\n",
      "Epoch 25/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.3322 - val_loss: 2.3541\n",
      "Epoch 26/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2741 - val_loss: 2.2532\n",
      "Epoch 27/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2764 - val_loss: 2.1577\n",
      "Epoch 28/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.2279 - val_loss: 2.2399\n",
      "Epoch 29/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2282 - val_loss: 2.1331\n",
      "Epoch 30/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1805 - val_loss: 2.1671\n",
      "Epoch 31/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1945 - val_loss: 2.3743\n",
      "Epoch 32/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1732 - val_loss: 2.1529\n",
      "Epoch 33/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1388 - val_loss: 2.1474\n",
      "Epoch 34/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1600 - val_loss: 2.0755\n",
      "Epoch 35/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1228 - val_loss: 2.1929\n",
      "Epoch 36/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1168 - val_loss: 2.3249\n",
      "Epoch 37/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0939 - val_loss: 2.3877\n",
      "Epoch 38/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.1226 - val_loss: 2.0289\n",
      "Epoch 39/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0904 - val_loss: 2.1126\n",
      "Epoch 40/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0794 - val_loss: 2.0752\n",
      "Epoch 41/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0723 - val_loss: 2.1117\n",
      "Epoch 42/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0753 - val_loss: 2.0136\n",
      "Epoch 43/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0564 - val_loss: 2.0212\n",
      "Epoch 44/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0609 - val_loss: 1.9712\n",
      "Epoch 45/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0522 - val_loss: 2.0228\n",
      "Epoch 46/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0422 - val_loss: 1.9718\n",
      "Epoch 47/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0380 - val_loss: 2.3242\n",
      "Epoch 48/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0271 - val_loss: 2.1225\n",
      "Epoch 49/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0209 - val_loss: 1.9895\n",
      "Epoch 50/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0095 - val_loss: 2.0190\n",
      "Epoch 51/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0232 - val_loss: 2.0374\n",
      "Epoch 52/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9981 - val_loss: 2.0972\n",
      "Epoch 53/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9912 - val_loss: 2.0067\n",
      "Epoch 54/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9973 - val_loss: 1.9459\n",
      "Epoch 55/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9814 - val_loss: 1.9621\n",
      "Epoch 56/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9879 - val_loss: 1.9675\n",
      "Epoch 57/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9922 - val_loss: 1.9304\n",
      "Epoch 58/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9559 - val_loss: 2.0213\n",
      "Epoch 59/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9697 - val_loss: 1.9079\n",
      "Epoch 60/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9513 - val_loss: 1.9920\n",
      "Epoch 61/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9519 - val_loss: 1.9905\n",
      "Epoch 62/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9546 - val_loss: 1.9273\n",
      "Epoch 63/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9637 - val_loss: 1.9456\n",
      "Epoch 64/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9493 - val_loss: 1.9862\n",
      "Epoch 65/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9395 - val_loss: 1.9367\n",
      "Epoch 66/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9342 - val_loss: 1.8911\n",
      "Epoch 67/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9220 - val_loss: 1.9106\n",
      "Epoch 68/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9335 - val_loss: 2.0147\n",
      "Epoch 69/500\n",
      "864/864 [==============================] - 7s 9ms/step - loss: 1.9189 - val_loss: 1.9812\n",
      "Epoch 70/500\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.9056 - val_loss: 1.8799\n",
      "Epoch 71/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9041 - val_loss: 1.8729\n",
      "Epoch 72/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9035 - val_loss: 1.8859\n",
      "Epoch 73/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9001 - val_loss: 1.9400\n",
      "Epoch 74/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9118 - val_loss: 1.9592\n",
      "Epoch 75/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8903 - val_loss: 1.9428\n",
      "Epoch 76/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8894 - val_loss: 1.8850\n",
      "Epoch 77/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8945 - val_loss: 1.8762\n",
      "Epoch 78/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8849 - val_loss: 1.9194\n",
      "Epoch 79/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8800 - val_loss: 1.9371\n",
      "Epoch 80/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.8776 - val_loss: 1.9204\n",
      "Epoch 81/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8741 - val_loss: 1.9473\n",
      "Epoch 82/500\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.8835 - val_loss: 1.9467\n",
      "Epoch 83/500\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.8527 - val_loss: 1.8570\n",
      "Epoch 84/500\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.8618 - val_loss: 1.8877\n",
      "Epoch 85/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8657 - val_loss: 1.8880\n",
      "Epoch 86/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8483 - val_loss: 1.7969\n",
      "Epoch 87/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8536 - val_loss: 1.8343\n",
      "Epoch 88/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8535 - val_loss: 1.8368\n",
      "Epoch 89/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8468 - val_loss: 1.8478\n",
      "Epoch 90/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8510 - val_loss: 1.8129\n",
      "Epoch 91/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8433 - val_loss: 1.8536\n",
      "Epoch 92/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8458 - val_loss: 1.8712\n",
      "Epoch 93/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.8301 - val_loss: 1.8436\n",
      "Epoch 94/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.8428 - val_loss: 1.9185\n",
      "Epoch 95/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.8231 - val_loss: 1.7796\n",
      "Epoch 96/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8243 - val_loss: 2.0224\n",
      "Epoch 97/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.8229 - val_loss: 1.7568\n",
      "Epoch 98/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.8124 - val_loss: 1.8272\n",
      "Epoch 99/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8104 - val_loss: 1.8180\n",
      "Epoch 100/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.8130 - val_loss: 1.8788\n",
      "Epoch 101/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8254 - val_loss: 1.8755\n",
      "Epoch 102/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8146 - val_loss: 1.8334\n",
      "Epoch 103/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8023 - val_loss: 1.9390\n",
      "Epoch 104/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8072 - val_loss: 1.7869\n",
      "Epoch 105/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7884 - val_loss: 1.8154\n",
      "Epoch 106/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8015 - val_loss: 1.7893\n",
      "Epoch 107/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7964 - val_loss: 1.7738\n",
      "Epoch 108/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7927 - val_loss: 1.8519\n",
      "Epoch 109/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7918 - val_loss: 1.8019\n",
      "Epoch 110/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7901 - val_loss: 1.7538\n",
      "Epoch 111/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7961 - val_loss: 1.8837\n",
      "Epoch 112/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7807 - val_loss: 1.7979\n",
      "Epoch 113/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7778 - val_loss: 1.7705\n",
      "Epoch 114/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7739 - val_loss: 1.7356\n",
      "Epoch 115/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7586 - val_loss: 1.8062\n",
      "Epoch 116/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7706 - val_loss: 1.7651\n",
      "Epoch 117/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7606 - val_loss: 1.7565\n",
      "Epoch 118/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7676 - val_loss: 1.7333\n",
      "Epoch 119/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7665 - val_loss: 1.7126\n",
      "Epoch 120/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7536 - val_loss: 1.8385\n",
      "Epoch 121/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7415 - val_loss: 1.7209\n",
      "Epoch 122/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7414 - val_loss: 1.7702\n",
      "Epoch 123/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7495 - val_loss: 1.8605\n",
      "Epoch 124/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7337 - val_loss: 1.7229\n",
      "Epoch 125/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7458 - val_loss: 1.8923\n",
      "Epoch 126/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7350 - val_loss: 1.8350\n",
      "Epoch 127/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7453 - val_loss: 1.7445\n",
      "Epoch 128/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7255 - val_loss: 1.7267\n",
      "Epoch 129/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7349 - val_loss: 1.8662\n",
      "Epoch 130/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7307 - val_loss: 1.6907\n",
      "Epoch 131/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7300 - val_loss: 1.7730\n",
      "Epoch 132/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7189 - val_loss: 1.7020\n",
      "Epoch 133/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7217 - val_loss: 1.8370\n",
      "Epoch 134/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7191 - val_loss: 1.6997\n",
      "Epoch 135/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7154 - val_loss: 1.7107\n",
      "Epoch 136/500\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 1.7190 - val_loss: 1.7900\n",
      "Epoch 137/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7115 - val_loss: 1.7076\n",
      "Epoch 138/500\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 1.7029 - val_loss: 1.7581\n",
      "Epoch 139/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7088 - val_loss: 1.7084\n",
      "Epoch 140/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7174 - val_loss: 1.7268\n",
      "Epoch 141/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7006 - val_loss: 1.6863\n",
      "Epoch 142/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6976 - val_loss: 1.6896\n",
      "Epoch 143/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6992 - val_loss: 1.6858\n",
      "Epoch 144/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7002 - val_loss: 1.7152\n",
      "Epoch 145/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6938 - val_loss: 1.6960\n",
      "Epoch 146/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6999 - val_loss: 1.7687\n",
      "Epoch 147/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6861 - val_loss: 1.7113\n",
      "Epoch 148/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6881 - val_loss: 1.8137\n",
      "Epoch 149/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6991 - val_loss: 1.7412\n",
      "Epoch 150/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6871 - val_loss: 1.7060\n",
      "Epoch 151/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6828 - val_loss: 1.6759\n",
      "Epoch 152/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6924 - val_loss: 1.6355\n",
      "Epoch 153/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6797 - val_loss: 1.6334\n",
      "Epoch 154/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6788 - val_loss: 1.7452\n",
      "Epoch 155/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6789 - val_loss: 1.7003\n",
      "Epoch 156/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6807 - val_loss: 1.7303\n",
      "Epoch 157/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6718 - val_loss: 1.6898\n",
      "Epoch 158/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6767 - val_loss: 1.6755\n",
      "Epoch 159/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6739 - val_loss: 1.7169\n",
      "Epoch 160/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6739 - val_loss: 1.7041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6661 - val_loss: 1.6912\n",
      "Epoch 162/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6680 - val_loss: 1.6920\n",
      "Epoch 163/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6656 - val_loss: 1.7154\n",
      "Epoch 164/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6656 - val_loss: 1.6865\n",
      "Epoch 165/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6585 - val_loss: 1.6819\n",
      "Epoch 166/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6628 - val_loss: 1.6573\n",
      "Epoch 167/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6541 - val_loss: 1.6948\n",
      "Epoch 168/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6486 - val_loss: 1.7532\n",
      "Epoch 169/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6509 - val_loss: 1.7014\n",
      "Epoch 170/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6516 - val_loss: 1.6993\n",
      "Epoch 171/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6554 - val_loss: 1.7052\n",
      "Epoch 172/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6505 - val_loss: 1.6753\n",
      "Epoch 173/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6444 - val_loss: 1.6515\n",
      "Epoch 174/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6474 - val_loss: 1.6530\n",
      "Epoch 175/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6433 - val_loss: 1.6814\n",
      "Epoch 176/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6425 - val_loss: 1.6759\n",
      "Epoch 177/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6372 - val_loss: 1.6651\n",
      "Epoch 178/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6435 - val_loss: 1.6624\n",
      "Epoch 179/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6460 - val_loss: 1.7148\n",
      "Epoch 180/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6469 - val_loss: 1.7748\n",
      "Epoch 181/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6413 - val_loss: 1.6653\n",
      "Epoch 182/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6384 - val_loss: 1.6540\n",
      "Epoch 183/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6285 - val_loss: 1.7882\n",
      "Epoch 184/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6495 - val_loss: 1.6242\n",
      "Epoch 185/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6414 - val_loss: 1.7046\n",
      "Epoch 186/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6336 - val_loss: 1.6897\n",
      "Epoch 187/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6249 - val_loss: 1.6528\n",
      "Epoch 188/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6343 - val_loss: 1.6669\n",
      "Epoch 189/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6322 - val_loss: 1.6708\n",
      "Epoch 190/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6252 - val_loss: 1.6803\n",
      "Epoch 191/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6325 - val_loss: 1.7246\n",
      "Epoch 192/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6184 - val_loss: 1.6708\n",
      "Epoch 193/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6296 - val_loss: 1.5732\n",
      "Epoch 194/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6202 - val_loss: 1.6683\n",
      "Epoch 195/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6191 - val_loss: 1.6506\n",
      "Epoch 196/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6211 - val_loss: 1.7338\n",
      "Epoch 197/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6185 - val_loss: 1.6747\n",
      "Epoch 198/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6141 - val_loss: 1.6878\n",
      "Epoch 199/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6198 - val_loss: 1.6082\n",
      "Epoch 200/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6245 - val_loss: 1.5872\n",
      "Epoch 201/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6097 - val_loss: 1.7003\n",
      "Epoch 202/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6199 - val_loss: 1.6365\n",
      "Epoch 203/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6080 - val_loss: 1.6304\n",
      "Epoch 204/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6034 - val_loss: 1.6392\n",
      "Epoch 205/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6047 - val_loss: 1.6658\n",
      "Epoch 206/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6062 - val_loss: 1.5986\n",
      "Epoch 207/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6068 - val_loss: 1.6294\n",
      "Epoch 208/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6167 - val_loss: 1.6607\n",
      "Epoch 209/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6052 - val_loss: 1.6362\n",
      "Epoch 210/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6038 - val_loss: 1.7133\n",
      "Epoch 211/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6004 - val_loss: 1.6919\n",
      "Epoch 212/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6111 - val_loss: 1.6246\n",
      "Epoch 213/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6073 - val_loss: 1.5975\n",
      "Epoch 214/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6040 - val_loss: 1.5754\n",
      "Epoch 215/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6009 - val_loss: 1.6344\n",
      "Epoch 216/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5928 - val_loss: 1.7659\n",
      "Epoch 217/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5962 - val_loss: 1.5786\n",
      "Epoch 218/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5977 - val_loss: 1.5787\n",
      "Epoch 219/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5963 - val_loss: 1.6800\n",
      "Epoch 220/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5992 - val_loss: 1.5795\n",
      "Epoch 221/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5943 - val_loss: 1.6351\n",
      "Epoch 222/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6047 - val_loss: 1.6241\n",
      "Epoch 223/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5978 - val_loss: 1.6613\n",
      "Epoch 224/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5879 - val_loss: 1.5866\n",
      "Epoch 225/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5889 - val_loss: 1.6373\n",
      "Epoch 226/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5849 - val_loss: 1.5889\n",
      "Epoch 227/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5870 - val_loss: 1.6470\n",
      "Epoch 228/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5964 - val_loss: 1.7063\n",
      "Epoch 229/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5952 - val_loss: 1.5752\n",
      "Epoch 230/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5897 - val_loss: 1.6554\n",
      "Epoch 231/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5851 - val_loss: 1.5842\n",
      "Epoch 232/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5807 - val_loss: 1.5793\n",
      "Epoch 233/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5777 - val_loss: 1.6393\n",
      "Epoch 234/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5860 - val_loss: 1.6046\n",
      "Epoch 235/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5824 - val_loss: 1.6185\n",
      "Epoch 236/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5923 - val_loss: 1.5651\n",
      "Epoch 237/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5835 - val_loss: 1.6395\n",
      "Epoch 238/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5880 - val_loss: 1.7534\n",
      "Epoch 239/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5865 - val_loss: 1.5878\n",
      "Epoch 240/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5772 - val_loss: 1.5647\n",
      "Epoch 241/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5739 - val_loss: 1.6676\n",
      "Epoch 242/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5875 - val_loss: 1.5918\n",
      "Epoch 243/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5808 - val_loss: 1.6957\n",
      "Epoch 244/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5764 - val_loss: 1.6654\n",
      "Epoch 245/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5622 - val_loss: 1.6452\n",
      "Epoch 246/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5882 - val_loss: 1.5918\n",
      "Epoch 247/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5776 - val_loss: 1.6854\n",
      "Epoch 248/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5698 - val_loss: 1.5672\n",
      "Epoch 249/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5744 - val_loss: 1.6709\n",
      "Epoch 250/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5776 - val_loss: 1.5526\n",
      "Epoch 251/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5708 - val_loss: 1.5937\n",
      "Epoch 252/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5753 - val_loss: 1.6176\n",
      "Epoch 253/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5663 - val_loss: 1.5874\n",
      "Epoch 254/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5697 - val_loss: 1.6238\n",
      "Epoch 255/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5785 - val_loss: 1.5574\n",
      "Epoch 256/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5576 - val_loss: 1.6185\n",
      "Epoch 257/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5717 - val_loss: 1.5540\n",
      "Epoch 258/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5740 - val_loss: 1.6142\n",
      "Epoch 259/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5700 - val_loss: 1.5739\n",
      "Epoch 260/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5661 - val_loss: 1.6135\n",
      "Epoch 261/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5678 - val_loss: 1.6114\n",
      "Epoch 262/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5628 - val_loss: 1.5189\n",
      "Epoch 263/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5648 - val_loss: 1.5386\n",
      "Epoch 264/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5585 - val_loss: 1.6118\n",
      "Epoch 265/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5587 - val_loss: 1.5838\n",
      "Epoch 266/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5743 - val_loss: 1.6735\n",
      "Epoch 267/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5574 - val_loss: 1.5836\n",
      "Epoch 268/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5574 - val_loss: 1.6796\n",
      "Epoch 269/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5610 - val_loss: 1.6578\n",
      "Epoch 270/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5562 - val_loss: 1.5592\n",
      "Epoch 271/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5609 - val_loss: 1.6542\n",
      "Epoch 272/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5565 - val_loss: 1.5985\n",
      "Epoch 273/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5500 - val_loss: 1.5400\n",
      "Epoch 274/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5632 - val_loss: 1.5635\n",
      "Epoch 275/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5558 - val_loss: 1.6001\n",
      "Epoch 276/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5526 - val_loss: 1.5856\n",
      "Epoch 277/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5500 - val_loss: 1.6412\n",
      "Epoch 278/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5553 - val_loss: 1.6822\n",
      "Epoch 279/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5512 - val_loss: 1.6148\n",
      "Epoch 280/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5600 - val_loss: 1.5640\n",
      "Epoch 281/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5605 - val_loss: 1.5976\n",
      "Epoch 282/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5520 - val_loss: 1.5469\n",
      "Epoch 283/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5498 - val_loss: 1.6454\n",
      "Epoch 284/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5465 - val_loss: 1.5997\n",
      "Epoch 285/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5459 - val_loss: 1.6735\n",
      "Epoch 286/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5424 - val_loss: 1.5606\n",
      "Epoch 287/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5470 - val_loss: 1.5956\n",
      "Epoch 288/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5413 - val_loss: 1.6156\n",
      "Epoch 289/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5407 - val_loss: 1.6005\n",
      "Epoch 290/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5473 - val_loss: 1.5645\n",
      "Epoch 291/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5457 - val_loss: 1.5439\n",
      "Epoch 292/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5525 - val_loss: 1.5730\n",
      "Epoch 293/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5457 - val_loss: 1.6978\n",
      "Epoch 294/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5459 - val_loss: 1.5829\n",
      "Epoch 295/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5321 - val_loss: 1.5335\n",
      "Epoch 296/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5432 - val_loss: 1.5401\n",
      "Epoch 297/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5435 - val_loss: 1.5086\n",
      "Epoch 298/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5396 - val_loss: 1.5829\n",
      "Epoch 299/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5474 - val_loss: 1.5861\n",
      "Epoch 300/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5342 - val_loss: 1.6794\n",
      "Epoch 301/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5510 - val_loss: 1.5423\n",
      "Epoch 302/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5365 - val_loss: 1.5302\n",
      "Epoch 303/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5373 - val_loss: 1.5867\n",
      "Epoch 304/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5325 - val_loss: 1.6319\n",
      "Epoch 305/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5345 - val_loss: 1.6824\n",
      "Epoch 306/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5401 - val_loss: 1.5503\n",
      "Epoch 307/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5375 - val_loss: 1.5511\n",
      "Epoch 308/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5387 - val_loss: 1.6276\n",
      "Epoch 309/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5291 - val_loss: 1.6395\n",
      "Epoch 310/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5334 - val_loss: 1.5655\n",
      "Epoch 311/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5352 - val_loss: 1.5602\n",
      "Epoch 312/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5329 - val_loss: 1.5434\n",
      "Epoch 313/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5349 - val_loss: 1.5593\n",
      "Epoch 314/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5262 - val_loss: 1.5246\n",
      "Epoch 315/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5309 - val_loss: 1.6597\n",
      "Epoch 316/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5253 - val_loss: 1.6043\n",
      "Epoch 317/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5348 - val_loss: 1.5285\n",
      "Epoch 318/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5319 - val_loss: 1.5693\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5311 - val_loss: 1.7279\n",
      "Epoch 320/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5187 - val_loss: 1.5459\n",
      "Epoch 321/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5223 - val_loss: 1.5206\n",
      "Epoch 322/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5253 - val_loss: 1.5570\n",
      "Epoch 323/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5288 - val_loss: 1.5376\n",
      "Epoch 324/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5265 - val_loss: 1.5481\n",
      "Epoch 325/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5233 - val_loss: 1.6301\n",
      "Epoch 326/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5219 - val_loss: 1.5469\n",
      "Epoch 327/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5239 - val_loss: 1.6779\n",
      "Epoch 328/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5265 - val_loss: 1.5272\n",
      "Epoch 329/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5195 - val_loss: 1.5598\n",
      "Epoch 330/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5311 - val_loss: 1.5416\n",
      "Epoch 331/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5209 - val_loss: 1.5239\n",
      "Epoch 332/500\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5229 - val_loss: 1.4937\n",
      "Epoch 333/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5258 - val_loss: 1.4968\n",
      "Epoch 334/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5250 - val_loss: 1.5298\n",
      "Epoch 335/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5181 - val_loss: 1.5431\n",
      "Epoch 336/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5201 - val_loss: 1.5745\n",
      "Epoch 337/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5136 - val_loss: 1.5586\n",
      "Epoch 338/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5213 - val_loss: 1.5722\n",
      "Epoch 339/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5122 - val_loss: 1.6256\n",
      "Epoch 340/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5191 - val_loss: 1.5525\n",
      "Epoch 341/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5102 - val_loss: 1.5475\n",
      "Epoch 342/500\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5178 - val_loss: 1.5674\n",
      "Epoch 343/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5099 - val_loss: 1.5928\n",
      "Epoch 344/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5203 - val_loss: 1.5430\n",
      "Epoch 345/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5145 - val_loss: 1.5579\n",
      "Epoch 346/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5153 - val_loss: 1.5150\n",
      "Epoch 347/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5268 - val_loss: 1.4983\n",
      "Epoch 348/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4978 - val_loss: 1.4835\n",
      "Epoch 349/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5126 - val_loss: 1.5314\n",
      "Epoch 350/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5103 - val_loss: 1.5300\n",
      "Epoch 351/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5091 - val_loss: 1.5086\n",
      "Epoch 352/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5141 - val_loss: 1.5353\n",
      "Epoch 353/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5142 - val_loss: 1.5406\n",
      "Epoch 354/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5021 - val_loss: 1.5552\n",
      "Epoch 355/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5034 - val_loss: 1.6365\n",
      "Epoch 356/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5077 - val_loss: 1.5156\n",
      "Epoch 357/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4979 - val_loss: 1.5220\n",
      "Epoch 358/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5174 - val_loss: 1.5638\n",
      "Epoch 359/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5054 - val_loss: 1.5453\n",
      "Epoch 360/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5019 - val_loss: 1.5499\n",
      "Epoch 361/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5018 - val_loss: 1.5456\n",
      "Epoch 362/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5082 - val_loss: 1.5065\n",
      "Epoch 363/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5004 - val_loss: 1.5443\n",
      "Epoch 364/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5055 - val_loss: 1.6018\n",
      "Epoch 365/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5079 - val_loss: 1.4941\n",
      "Epoch 366/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5016 - val_loss: 1.5071\n",
      "Epoch 367/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4943 - val_loss: 1.5429\n",
      "Epoch 368/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4997 - val_loss: 1.4984\n",
      "Epoch 369/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5013 - val_loss: 1.5025\n",
      "Epoch 370/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4897 - val_loss: 1.5149\n",
      "Epoch 371/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5060 - val_loss: 1.5223\n",
      "Epoch 372/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4958 - val_loss: 1.5638\n",
      "Epoch 373/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4969 - val_loss: 1.5303\n",
      "Epoch 374/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4976 - val_loss: 1.4875\n",
      "Epoch 375/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4920 - val_loss: 1.5585\n",
      "Epoch 376/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4979 - val_loss: 1.5145\n",
      "Epoch 377/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4914 - val_loss: 1.5721\n",
      "Epoch 378/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4895 - val_loss: 1.5709\n",
      "Epoch 379/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4971 - val_loss: 1.5549\n",
      "Epoch 380/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4860 - val_loss: 1.5527\n",
      "Epoch 381/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5125 - val_loss: 1.5429\n",
      "Epoch 382/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4892 - val_loss: 1.5245\n",
      "Epoch 383/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4909 - val_loss: 1.5330\n",
      "Epoch 384/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4946 - val_loss: 1.4771\n",
      "Epoch 385/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4921 - val_loss: 1.5091\n",
      "Epoch 386/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5017 - val_loss: 1.5320\n",
      "Epoch 387/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4876 - val_loss: 1.5446\n",
      "Epoch 388/500\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4803 - val_loss: 1.5272\n",
      "Epoch 389/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4844 - val_loss: 1.4902\n",
      "Epoch 390/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4959 - val_loss: 1.5351\n",
      "Epoch 391/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4898 - val_loss: 1.4868\n",
      "Epoch 392/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4913 - val_loss: 1.5227\n",
      "Epoch 393/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4906 - val_loss: 1.5179\n",
      "Epoch 394/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4937 - val_loss: 1.5003\n",
      "Epoch 395/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4875 - val_loss: 1.4798\n",
      "Epoch 396/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4848 - val_loss: 1.5534\n",
      "Epoch 397/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4812 - val_loss: 1.4800\n",
      "Epoch 398/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4896 - val_loss: 1.5475\n",
      "Epoch 399/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4889 - val_loss: 1.4992\n",
      "Epoch 400/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4962 - val_loss: 1.5423\n",
      "Epoch 401/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4852 - val_loss: 1.5119\n",
      "Epoch 402/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4807 - val_loss: 1.5211\n",
      "Epoch 403/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4824 - val_loss: 1.4771\n",
      "Epoch 404/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4795 - val_loss: 1.5556\n",
      "Epoch 405/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4766 - val_loss: 1.5649\n",
      "Epoch 406/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4805 - val_loss: 1.4984\n",
      "Epoch 407/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4737 - val_loss: 1.5203\n",
      "Epoch 408/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4879 - val_loss: 1.5133\n",
      "Epoch 409/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4769 - val_loss: 1.5096\n",
      "Epoch 410/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4797 - val_loss: 1.4979\n",
      "Epoch 411/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4769 - val_loss: 1.5108\n",
      "Epoch 412/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4791 - val_loss: 1.5068\n",
      "Epoch 413/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4774 - val_loss: 1.4845\n",
      "Epoch 414/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4708 - val_loss: 1.5093\n",
      "Epoch 415/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4755 - val_loss: 1.4984\n",
      "Epoch 416/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4739 - val_loss: 1.5466\n",
      "Epoch 417/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4737 - val_loss: 1.5755\n",
      "Epoch 418/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4723 - val_loss: 1.5143\n",
      "Epoch 419/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4739 - val_loss: 1.4988\n",
      "Epoch 420/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4725 - val_loss: 1.4783\n",
      "Epoch 421/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4790 - val_loss: 1.4651\n",
      "Epoch 422/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4683 - val_loss: 1.4768\n",
      "Epoch 423/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4752 - val_loss: 1.4702\n",
      "Epoch 424/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4695 - val_loss: 1.5876\n",
      "Epoch 425/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4697 - val_loss: 1.5481\n",
      "Epoch 426/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4733 - val_loss: 1.4648\n",
      "Epoch 427/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4731 - val_loss: 1.5137\n",
      "Epoch 428/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4618 - val_loss: 1.4978\n",
      "Epoch 429/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4836 - val_loss: 1.5399\n",
      "Epoch 430/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4655 - val_loss: 1.5939\n",
      "Epoch 431/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4731 - val_loss: 1.5052\n",
      "Epoch 432/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4740 - val_loss: 1.5106\n",
      "Epoch 433/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4665 - val_loss: 1.5046\n",
      "Epoch 434/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4722 - val_loss: 1.5413\n",
      "Epoch 435/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4626 - val_loss: 1.4881\n",
      "Epoch 436/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4600 - val_loss: 1.4575\n",
      "Epoch 437/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4674 - val_loss: 1.5986\n",
      "Epoch 438/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4733 - val_loss: 1.5136\n",
      "Epoch 439/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4606 - val_loss: 1.5552\n",
      "Epoch 440/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4723 - val_loss: 1.5041\n",
      "Epoch 441/500\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4676 - val_loss: 1.5338\n",
      "Epoch 442/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4706 - val_loss: 1.5137\n",
      "Epoch 443/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4643 - val_loss: 1.4620\n",
      "Epoch 444/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4766 - val_loss: 1.4840\n",
      "Epoch 445/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4735 - val_loss: 1.4661\n",
      "Epoch 446/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4711 - val_loss: 1.4658\n",
      "Epoch 447/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4560 - val_loss: 1.5024\n",
      "Epoch 448/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4695 - val_loss: 1.4579\n",
      "Epoch 449/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4565 - val_loss: 1.5009\n",
      "Epoch 450/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4695 - val_loss: 1.5206\n",
      "Epoch 451/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4618 - val_loss: 1.4878\n",
      "Epoch 452/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4635 - val_loss: 1.5056\n",
      "Epoch 453/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4490 - val_loss: 1.4919\n",
      "Epoch 454/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4620 - val_loss: 1.4403\n",
      "Epoch 455/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4567 - val_loss: 1.6161\n",
      "Epoch 456/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4562 - val_loss: 1.4827\n",
      "Epoch 457/500\n",
      "864/864 [==============================] - 6s 8ms/step - loss: 1.4575 - val_loss: 1.5029\n",
      "Epoch 458/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4569 - val_loss: 1.4811\n",
      "Epoch 459/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4616 - val_loss: 1.5011\n",
      "Epoch 460/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4538 - val_loss: 1.5458\n",
      "Epoch 461/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4587 - val_loss: 1.5550\n",
      "Epoch 462/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4541 - val_loss: 1.5168\n",
      "Epoch 463/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4480 - val_loss: 1.6582\n",
      "Epoch 464/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4604 - val_loss: 1.5868\n",
      "Epoch 465/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4570 - val_loss: 1.4969\n",
      "Epoch 466/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4503 - val_loss: 1.5050\n",
      "Epoch 467/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4598 - val_loss: 1.4909\n",
      "Epoch 468/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4582 - val_loss: 1.5211\n",
      "Epoch 469/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4527 - val_loss: 1.4791\n",
      "Epoch 470/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4579 - val_loss: 1.5021\n",
      "Epoch 471/500\n",
      "864/864 [==============================] - 7s 9ms/step - loss: 1.4523 - val_loss: 1.4505\n",
      "Epoch 472/500\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 1.4495 - val_loss: 1.4501\n",
      "Epoch 473/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4705 - val_loss: 1.5139\n",
      "Epoch 474/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4532 - val_loss: 1.5654\n",
      "Epoch 475/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4590 - val_loss: 1.5317\n",
      "Epoch 476/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4439 - val_loss: 1.5167\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4537 - val_loss: 1.4471\n",
      "Epoch 478/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4496 - val_loss: 1.5139\n",
      "Epoch 479/500\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4573 - val_loss: 1.4944\n",
      "Epoch 480/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4474 - val_loss: 1.4936\n",
      "Epoch 481/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4518 - val_loss: 1.5249\n",
      "Epoch 482/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4462 - val_loss: 1.5305\n",
      "Epoch 483/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4515 - val_loss: 1.5281\n",
      "Epoch 484/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4551 - val_loss: 1.5076\n",
      "Epoch 485/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4446 - val_loss: 1.5035\n",
      "Epoch 486/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4487 - val_loss: 1.5397\n",
      "Epoch 487/500\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4462 - val_loss: 1.4607\n",
      "Epoch 488/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4533 - val_loss: 1.4457\n",
      "Epoch 489/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4369 - val_loss: 1.4403\n",
      "Epoch 490/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4464 - val_loss: 1.4606\n",
      "Epoch 491/500\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4441 - val_loss: 1.4770\n",
      "Epoch 492/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4436 - val_loss: 1.5069\n",
      "Epoch 493/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4524 - val_loss: 1.4798\n",
      "Epoch 494/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4418 - val_loss: 1.5881\n",
      "Epoch 495/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4435 - val_loss: 1.4892\n",
      "Epoch 496/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4420 - val_loss: 1.5151\n",
      "Epoch 497/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4404 - val_loss: 1.4394\n",
      "Epoch 498/500\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4437 - val_loss: 1.5246\n",
      "Epoch 499/500\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4474 - val_loss: 1.4825\n",
      "Epoch 500/500\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4503 - val_loss: 1.4959\n",
      "1.4958860150116962\n",
      "0.9643460224442605\n",
      "Epoch 1/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 9.1200 - val_loss: 7.7101\n",
      "Epoch 2/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 5.9324 - val_loss: 4.6224\n",
      "Epoch 3/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 4.9422 - val_loss: 4.2994\n",
      "Epoch 4/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 4.4838 - val_loss: 3.9375\n",
      "Epoch 5/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 4.3920 - val_loss: 4.0406\n",
      "Epoch 6/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 4.3332 - val_loss: 3.9134\n",
      "Epoch 7/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 4.1660 - val_loss: 3.8504\n",
      "Epoch 8/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 4.1794 - val_loss: 3.7004\n",
      "Epoch 9/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 3.9038 - val_loss: 3.4458\n",
      "Epoch 10/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 3.6504 - val_loss: 3.1616\n",
      "Epoch 11/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 3.4047 - val_loss: 3.7897\n",
      "Epoch 12/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 3.1972 - val_loss: 3.1926\n",
      "Epoch 13/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 3.1180 - val_loss: 3.0543\n",
      "Epoch 14/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 3.0358 - val_loss: 2.8936\n",
      "Epoch 15/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 3.0020 - val_loss: 3.1866\n",
      "Epoch 16/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.8742 - val_loss: 3.4396\n",
      "Epoch 17/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.8030 - val_loss: 2.6183\n",
      "Epoch 18/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.7059 - val_loss: 2.8619\n",
      "Epoch 19/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.6691 - val_loss: 2.5219\n",
      "Epoch 20/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.6212 - val_loss: 2.5417\n",
      "Epoch 21/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.5330 - val_loss: 2.7926\n",
      "Epoch 22/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.5535 - val_loss: 2.7447\n",
      "Epoch 23/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.5022 - val_loss: 2.4639\n",
      "Epoch 24/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.4691 - val_loss: 2.5235\n",
      "Epoch 25/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.4574 - val_loss: 2.5366\n",
      "Epoch 26/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.4471 - val_loss: 2.3118\n",
      "Epoch 27/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.3857 - val_loss: 2.7311\n",
      "Epoch 28/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.3949 - val_loss: 2.2687\n",
      "Epoch 29/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.3760 - val_loss: 2.2504\n",
      "Epoch 30/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.3378 - val_loss: 2.2325\n",
      "Epoch 31/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.3407 - val_loss: 2.4371\n",
      "Epoch 32/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.3322 - val_loss: 2.3827\n",
      "Epoch 33/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.3008 - val_loss: 2.2933\n",
      "Epoch 34/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.2821 - val_loss: 2.1586\n",
      "Epoch 35/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.2616 - val_loss: 2.1567\n",
      "Epoch 36/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.2613 - val_loss: 2.3535\n",
      "Epoch 37/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.2030 - val_loss: 2.1974\n",
      "Epoch 38/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1908 - val_loss: 2.1443\n",
      "Epoch 39/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1825 - val_loss: 2.1946\n",
      "Epoch 40/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.1489 - val_loss: 2.1374\n",
      "Epoch 41/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.1478 - val_loss: 2.1478\n",
      "Epoch 42/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.1364 - val_loss: 2.1511\n",
      "Epoch 43/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.1297 - val_loss: 2.0401\n",
      "Epoch 44/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.1050 - val_loss: 2.1081\n",
      "Epoch 45/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.0812 - val_loss: 2.0321\n",
      "Epoch 46/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.0810 - val_loss: 2.1525\n",
      "Epoch 47/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.0639 - val_loss: 1.9757\n",
      "Epoch 48/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.0700 - val_loss: 1.9822\n",
      "Epoch 49/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.0624 - val_loss: 1.9846\n",
      "Epoch 50/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.0232 - val_loss: 1.9863\n",
      "Epoch 51/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.0363 - val_loss: 1.9985\n",
      "Epoch 52/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.0189 - val_loss: 2.0252\n",
      "Epoch 53/500\n",
      "576/576 [==============================] - 7s 11ms/step - loss: 2.0314 - val_loss: 1.9708\n",
      "Epoch 54/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0029 - val_loss: 2.0052\n",
      "Epoch 55/500\n",
      "576/576 [==============================] - 8s 15ms/step - loss: 1.9915 - val_loss: 1.9807\n",
      "Epoch 56/500\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.9932 - val_loss: 1.9488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9699 - val_loss: 2.0533\n",
      "Epoch 58/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.9914 - val_loss: 1.9757\n",
      "Epoch 59/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.9767 - val_loss: 2.0398\n",
      "Epoch 60/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9612 - val_loss: 1.9780\n",
      "Epoch 61/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9536 - val_loss: 2.0519\n",
      "Epoch 62/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9506 - val_loss: 2.0060\n",
      "Epoch 63/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9409 - val_loss: 2.1695\n",
      "Epoch 64/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9307 - val_loss: 1.8882\n",
      "Epoch 65/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9416 - val_loss: 2.1133\n",
      "Epoch 66/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9303 - val_loss: 1.8629\n",
      "Epoch 67/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.9241 - val_loss: 1.9421\n",
      "Epoch 68/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9119 - val_loss: 1.8564\n",
      "Epoch 69/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.8909 - val_loss: 1.8673\n",
      "Epoch 70/500\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.8821 - val_loss: 1.8671\n",
      "Epoch 71/500\n",
      "576/576 [==============================] - 7s 12ms/step - loss: 1.8728 - val_loss: 1.9542\n",
      "Epoch 72/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.8919 - val_loss: 1.8962\n",
      "Epoch 73/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.8759 - val_loss: 1.8380\n",
      "Epoch 74/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8699 - val_loss: 1.8939\n",
      "Epoch 75/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8705 - val_loss: 1.8645\n",
      "Epoch 76/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8755 - val_loss: 1.8140\n",
      "Epoch 77/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8514 - val_loss: 1.8329\n",
      "Epoch 78/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8365 - val_loss: 1.8477\n",
      "Epoch 79/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.8507 - val_loss: 1.8979\n",
      "Epoch 80/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8604 - val_loss: 1.8811\n",
      "Epoch 81/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8544 - val_loss: 1.8282\n",
      "Epoch 82/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8434 - val_loss: 1.8494\n",
      "Epoch 83/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8390 - val_loss: 1.9194\n",
      "Epoch 84/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8291 - val_loss: 1.9338\n",
      "Epoch 85/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8237 - val_loss: 1.8130\n",
      "Epoch 86/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8131 - val_loss: 1.9334\n",
      "Epoch 87/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8162 - val_loss: 1.7779\n",
      "Epoch 88/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7980 - val_loss: 1.8561\n",
      "Epoch 89/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.7925 - val_loss: 1.7655\n",
      "Epoch 90/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8080 - val_loss: 1.7845\n",
      "Epoch 91/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.8019 - val_loss: 1.7955\n",
      "Epoch 92/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7805 - val_loss: 1.7702\n",
      "Epoch 93/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7721 - val_loss: 1.7718\n",
      "Epoch 94/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7802 - val_loss: 1.8149\n",
      "Epoch 95/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7838 - val_loss: 1.7527\n",
      "Epoch 96/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7820 - val_loss: 1.7503\n",
      "Epoch 97/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7796 - val_loss: 1.7999\n",
      "Epoch 98/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7628 - val_loss: 1.7338\n",
      "Epoch 99/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7639 - val_loss: 1.7824\n",
      "Epoch 100/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7656 - val_loss: 1.7452\n",
      "Epoch 101/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7624 - val_loss: 1.9085\n",
      "Epoch 102/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7526 - val_loss: 1.7710\n",
      "Epoch 103/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7489 - val_loss: 1.7753\n",
      "Epoch 104/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.7629 - val_loss: 1.7140\n",
      "Epoch 105/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7433 - val_loss: 1.8280\n",
      "Epoch 106/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7547 - val_loss: 1.8234\n",
      "Epoch 107/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7424 - val_loss: 1.7145\n",
      "Epoch 108/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7299 - val_loss: 1.7425\n",
      "Epoch 109/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7366 - val_loss: 1.8775\n",
      "Epoch 110/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7322 - val_loss: 1.7134\n",
      "Epoch 111/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7199 - val_loss: 1.6813\n",
      "Epoch 112/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7165 - val_loss: 1.7782\n",
      "Epoch 113/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7229 - val_loss: 1.7200\n",
      "Epoch 114/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7333 - val_loss: 1.7178\n",
      "Epoch 115/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7062 - val_loss: 1.6910\n",
      "Epoch 116/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6988 - val_loss: 1.7526\n",
      "Epoch 117/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.7020 - val_loss: 1.7041\n",
      "Epoch 118/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7047 - val_loss: 1.7762\n",
      "Epoch 119/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6960 - val_loss: 1.7446\n",
      "Epoch 120/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6942 - val_loss: 1.7474\n",
      "Epoch 121/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7032 - val_loss: 1.6867\n",
      "Epoch 122/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6899 - val_loss: 1.6987\n",
      "Epoch 123/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6876 - val_loss: 1.7532\n",
      "Epoch 124/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7070 - val_loss: 1.6292\n",
      "Epoch 125/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6983 - val_loss: 1.7082\n",
      "Epoch 126/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.6758 - val_loss: 1.6795\n",
      "Epoch 127/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6771 - val_loss: 1.7254\n",
      "Epoch 128/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6714 - val_loss: 1.7380\n",
      "Epoch 129/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.6671 - val_loss: 1.7066\n",
      "Epoch 130/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6756 - val_loss: 1.7011\n",
      "Epoch 131/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6661 - val_loss: 1.6741\n",
      "Epoch 132/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6640 - val_loss: 1.6754\n",
      "Epoch 133/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6709 - val_loss: 1.6839\n",
      "Epoch 134/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6526 - val_loss: 1.6815\n",
      "Epoch 135/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6578 - val_loss: 1.6044\n",
      "Epoch 136/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6552 - val_loss: 1.6157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6452 - val_loss: 1.7799\n",
      "Epoch 138/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6502 - val_loss: 1.7308\n",
      "Epoch 139/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6669 - val_loss: 1.6245\n",
      "Epoch 140/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6333 - val_loss: 1.6339\n",
      "Epoch 141/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6303 - val_loss: 1.6494\n",
      "Epoch 142/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.6399 - val_loss: 1.7034\n",
      "Epoch 143/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6593 - val_loss: 1.6003\n",
      "Epoch 144/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6281 - val_loss: 1.6482\n",
      "Epoch 145/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6316 - val_loss: 1.6163\n",
      "Epoch 146/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6255 - val_loss: 1.6607\n",
      "Epoch 147/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6405 - val_loss: 1.6068\n",
      "Epoch 148/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6258 - val_loss: 1.6711\n",
      "Epoch 149/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6080 - val_loss: 1.6488\n",
      "Epoch 150/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6283 - val_loss: 1.6273\n",
      "Epoch 151/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6246 - val_loss: 1.5938\n",
      "Epoch 152/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.6186 - val_loss: 1.6181\n",
      "Epoch 153/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6108 - val_loss: 1.6534\n",
      "Epoch 154/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.6220 - val_loss: 1.6607\n",
      "Epoch 155/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6162 - val_loss: 1.6594\n",
      "Epoch 156/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6167 - val_loss: 1.6870\n",
      "Epoch 157/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6040 - val_loss: 1.5940\n",
      "Epoch 158/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6016 - val_loss: 1.6111\n",
      "Epoch 159/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6172 - val_loss: 1.6184\n",
      "Epoch 160/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6073 - val_loss: 1.5917\n",
      "Epoch 161/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5899 - val_loss: 1.5826\n",
      "Epoch 162/500\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.6051 - val_loss: 1.6071\n",
      "Epoch 163/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6061 - val_loss: 1.6404\n",
      "Epoch 164/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6059 - val_loss: 1.6173\n",
      "Epoch 165/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5960 - val_loss: 1.6040\n",
      "Epoch 166/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5918 - val_loss: 1.5784\n",
      "Epoch 167/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.5896 - val_loss: 1.6824\n",
      "Epoch 168/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.6013 - val_loss: 1.6685\n",
      "Epoch 169/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5910 - val_loss: 1.6298\n",
      "Epoch 170/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5840 - val_loss: 1.5700\n",
      "Epoch 171/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5768 - val_loss: 1.5807\n",
      "Epoch 172/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5951 - val_loss: 1.6292\n",
      "Epoch 173/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5813 - val_loss: 1.5962\n",
      "Epoch 174/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5862 - val_loss: 1.6305\n",
      "Epoch 175/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5749 - val_loss: 1.5962\n",
      "Epoch 176/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5768 - val_loss: 1.5818\n",
      "Epoch 177/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5798 - val_loss: 1.5270\n",
      "Epoch 178/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5611 - val_loss: 1.5112\n",
      "Epoch 179/500\n",
      "576/576 [==============================] - 7s 12ms/step - loss: 1.5685 - val_loss: 1.5969\n",
      "Epoch 180/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5804 - val_loss: 1.6807\n",
      "Epoch 181/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5728 - val_loss: 1.5861\n",
      "Epoch 182/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5621 - val_loss: 1.5877\n",
      "Epoch 183/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5620 - val_loss: 1.6443\n",
      "Epoch 184/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5667 - val_loss: 1.6586\n",
      "Epoch 185/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5667 - val_loss: 1.5551\n",
      "Epoch 186/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5643 - val_loss: 1.5955\n",
      "Epoch 187/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5677 - val_loss: 1.6043\n",
      "Epoch 188/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5576 - val_loss: 1.5437\n",
      "Epoch 189/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5518 - val_loss: 1.6017\n",
      "Epoch 190/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5602 - val_loss: 1.5181\n",
      "Epoch 191/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5564 - val_loss: 1.5422\n",
      "Epoch 192/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5421 - val_loss: 1.6148\n",
      "Epoch 193/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5464 - val_loss: 1.5911\n",
      "Epoch 194/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5499 - val_loss: 1.5853\n",
      "Epoch 195/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5532 - val_loss: 1.5494\n",
      "Epoch 196/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5423 - val_loss: 1.6474\n",
      "Epoch 197/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5346 - val_loss: 1.6418\n",
      "Epoch 198/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5428 - val_loss: 1.5599\n",
      "Epoch 199/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5495 - val_loss: 1.5594\n",
      "Epoch 200/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5422 - val_loss: 1.5830\n",
      "Epoch 201/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5393 - val_loss: 1.6583\n",
      "Epoch 202/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5422 - val_loss: 1.5747\n",
      "Epoch 203/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5347 - val_loss: 1.5629\n",
      "Epoch 204/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5420 - val_loss: 1.6140\n",
      "Epoch 205/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5431 - val_loss: 1.5340\n",
      "Epoch 206/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5267 - val_loss: 1.5654\n",
      "Epoch 207/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5217 - val_loss: 1.5096\n",
      "Epoch 208/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5219 - val_loss: 1.5124\n",
      "Epoch 209/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5228 - val_loss: 1.6867\n",
      "Epoch 210/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5266 - val_loss: 1.4931\n",
      "Epoch 211/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5206 - val_loss: 1.5302\n",
      "Epoch 212/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5228 - val_loss: 1.5988\n",
      "Epoch 213/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5247 - val_loss: 1.5475\n",
      "Epoch 214/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5261 - val_loss: 1.5667\n",
      "Epoch 215/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5224 - val_loss: 1.5071\n",
      "Epoch 216/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5206 - val_loss: 1.6352\n",
      "Epoch 217/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5106 - val_loss: 1.5298\n",
      "Epoch 218/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5205 - val_loss: 1.5316\n",
      "Epoch 219/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5193 - val_loss: 1.5108\n",
      "Epoch 220/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5107 - val_loss: 1.6054\n",
      "Epoch 221/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5189 - val_loss: 1.5307\n",
      "Epoch 222/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5070 - val_loss: 1.5579\n",
      "Epoch 223/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5008 - val_loss: 1.5401\n",
      "Epoch 224/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5145 - val_loss: 1.5270\n",
      "Epoch 225/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5046 - val_loss: 1.5330\n",
      "Epoch 226/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5131 - val_loss: 1.5595\n",
      "Epoch 227/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5074 - val_loss: 1.5782\n",
      "Epoch 228/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5189 - val_loss: 1.6185\n",
      "Epoch 229/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5053 - val_loss: 1.5040\n",
      "Epoch 230/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.5009 - val_loss: 1.5073\n",
      "Epoch 231/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4889 - val_loss: 1.6026\n",
      "Epoch 232/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5014 - val_loss: 1.5012\n",
      "Epoch 233/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4986 - val_loss: 1.5528\n",
      "Epoch 234/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4923 - val_loss: 1.5299\n",
      "Epoch 235/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5014 - val_loss: 1.5824\n",
      "Epoch 236/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4860 - val_loss: 1.5708\n",
      "Epoch 237/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4983 - val_loss: 1.4707\n",
      "Epoch 238/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4899 - val_loss: 1.5167\n",
      "Epoch 239/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4908 - val_loss: 1.6270\n",
      "Epoch 240/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4867 - val_loss: 1.6355\n",
      "Epoch 241/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4967 - val_loss: 1.5067\n",
      "Epoch 242/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5003 - val_loss: 1.5222\n",
      "Epoch 243/500\n",
      "576/576 [==============================] - 7s 12ms/step - loss: 1.4803 - val_loss: 1.4910\n",
      "Epoch 244/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4926 - val_loss: 1.4657\n",
      "Epoch 245/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4732 - val_loss: 1.4574\n",
      "Epoch 246/500\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.5028 - val_loss: 1.5044\n",
      "Epoch 247/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4700 - val_loss: 1.5779\n",
      "Epoch 248/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4864 - val_loss: 1.5509\n",
      "Epoch 249/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4722 - val_loss: 1.5175\n",
      "Epoch 250/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4679 - val_loss: 1.5174\n",
      "Epoch 251/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4845 - val_loss: 1.5092\n",
      "Epoch 252/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4919 - val_loss: 1.4974\n",
      "Epoch 253/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4831 - val_loss: 1.5023\n",
      "Epoch 254/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4664 - val_loss: 1.5774\n",
      "Epoch 255/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.5005 - val_loss: 1.4698\n",
      "Epoch 256/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4709 - val_loss: 1.4517\n",
      "Epoch 257/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4770 - val_loss: 1.5033\n",
      "Epoch 258/500\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.4856 - val_loss: 1.4753\n",
      "Epoch 259/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4681 - val_loss: 1.5120\n",
      "Epoch 260/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4671 - val_loss: 1.5497\n",
      "Epoch 261/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4729 - val_loss: 1.4747\n",
      "Epoch 262/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4637 - val_loss: 1.5279\n",
      "Epoch 263/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4741 - val_loss: 1.7289\n",
      "Epoch 264/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4786 - val_loss: 1.4847\n",
      "Epoch 265/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4683 - val_loss: 1.4635\n",
      "Epoch 266/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4615 - val_loss: 1.5951\n",
      "Epoch 267/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4702 - val_loss: 1.4972\n",
      "Epoch 268/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4542 - val_loss: 1.5499\n",
      "Epoch 269/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4763 - val_loss: 1.5264\n",
      "Epoch 270/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4640 - val_loss: 1.5177\n",
      "Epoch 271/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.4663 - val_loss: 1.5866\n",
      "Epoch 272/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4607 - val_loss: 1.5116\n",
      "Epoch 273/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4609 - val_loss: 1.4911\n",
      "Epoch 274/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4615 - val_loss: 1.4516\n",
      "Epoch 275/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4470 - val_loss: 1.4815\n",
      "Epoch 276/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4560 - val_loss: 1.4603\n",
      "Epoch 277/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4560 - val_loss: 1.4757\n",
      "Epoch 278/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4492 - val_loss: 1.5304\n",
      "Epoch 279/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4710 - val_loss: 1.4591\n",
      "Epoch 280/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4509 - val_loss: 1.4904\n",
      "Epoch 281/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4597 - val_loss: 1.4716\n",
      "Epoch 282/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4534 - val_loss: 1.4868\n",
      "Epoch 283/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4514 - val_loss: 1.4791\n",
      "Epoch 284/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4535 - val_loss: 1.4248\n",
      "Epoch 285/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4631 - val_loss: 1.5042\n",
      "Epoch 286/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4387 - val_loss: 1.4858\n",
      "Epoch 287/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4500 - val_loss: 1.4969\n",
      "Epoch 288/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4576 - val_loss: 1.5810\n",
      "Epoch 289/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4473 - val_loss: 1.6021\n",
      "Epoch 290/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4548 - val_loss: 1.4422\n",
      "Epoch 291/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4485 - val_loss: 1.5291\n",
      "Epoch 292/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4388 - val_loss: 1.4449\n",
      "Epoch 293/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4429 - val_loss: 1.5030\n",
      "Epoch 294/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4370 - val_loss: 1.4584\n",
      "Epoch 295/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4536 - val_loss: 1.5197\n",
      "Epoch 296/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4445 - val_loss: 1.4866\n",
      "Epoch 297/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4350 - val_loss: 1.5738\n",
      "Epoch 298/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4558 - val_loss: 1.5005\n",
      "Epoch 299/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4520 - val_loss: 1.4794\n",
      "Epoch 300/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4368 - val_loss: 1.4853\n",
      "Epoch 301/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4364 - val_loss: 1.4460\n",
      "Epoch 302/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4389 - val_loss: 1.4399\n",
      "Epoch 303/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4329 - val_loss: 1.5055\n",
      "Epoch 304/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4301 - val_loss: 1.5942\n",
      "Epoch 305/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4323 - val_loss: 1.4414\n",
      "Epoch 306/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4365 - val_loss: 1.4482\n",
      "Epoch 307/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4256 - val_loss: 1.4401\n",
      "Epoch 308/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4429 - val_loss: 1.4686\n",
      "Epoch 309/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4423 - val_loss: 1.4364\n",
      "Epoch 310/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4311 - val_loss: 1.4527\n",
      "Epoch 311/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4425 - val_loss: 1.4442\n",
      "Epoch 312/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4395 - val_loss: 1.5523\n",
      "Epoch 313/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4433 - val_loss: 1.4495\n",
      "Epoch 314/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4244 - val_loss: 1.4924\n",
      "Epoch 315/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4320 - val_loss: 1.4795\n",
      "Epoch 316/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4206 - val_loss: 1.4202\n",
      "Epoch 317/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4233 - val_loss: 1.4674\n",
      "Epoch 318/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4230 - val_loss: 1.4801\n",
      "Epoch 319/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4268 - val_loss: 1.4829\n",
      "Epoch 320/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4229 - val_loss: 1.4762\n",
      "Epoch 321/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4137 - val_loss: 1.5139\n",
      "Epoch 322/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4363 - val_loss: 1.4346\n",
      "Epoch 323/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4202 - val_loss: 1.4740\n",
      "Epoch 324/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4301 - val_loss: 1.4585\n",
      "Epoch 325/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4233 - val_loss: 1.4301\n",
      "Epoch 326/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4205 - val_loss: 1.4849\n",
      "Epoch 327/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4182 - val_loss: 1.4714\n",
      "Epoch 328/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4281 - val_loss: 1.4457\n",
      "Epoch 329/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4407 - val_loss: 1.4147\n",
      "Epoch 330/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4120 - val_loss: 1.4783\n",
      "Epoch 331/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4266 - val_loss: 1.4203\n",
      "Epoch 332/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4140 - val_loss: 1.4431\n",
      "Epoch 333/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.4233 - val_loss: 1.4038\n",
      "Epoch 334/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4214 - val_loss: 1.4479\n",
      "Epoch 335/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4130 - val_loss: 1.4463\n",
      "Epoch 336/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4219 - val_loss: 1.4451\n",
      "Epoch 337/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4330 - val_loss: 1.4986\n",
      "Epoch 338/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4082 - val_loss: 1.4410\n",
      "Epoch 339/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4211 - val_loss: 1.5966\n",
      "Epoch 340/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4288 - val_loss: 1.5984\n",
      "Epoch 341/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4181 - val_loss: 1.4177\n",
      "Epoch 342/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4072 - val_loss: 1.4630\n",
      "Epoch 343/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4235 - val_loss: 1.4352\n",
      "Epoch 344/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4085 - val_loss: 1.5928\n",
      "Epoch 345/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4203 - val_loss: 1.4574\n",
      "Epoch 346/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4064 - val_loss: 1.4542\n",
      "Epoch 347/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4131 - val_loss: 1.4738\n",
      "Epoch 348/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4023 - val_loss: 1.5131\n",
      "Epoch 349/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4095 - val_loss: 1.4198\n",
      "Epoch 350/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4199 - val_loss: 1.4402\n",
      "Epoch 351/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4040 - val_loss: 1.4504\n",
      "Epoch 352/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4001 - val_loss: 1.4725\n",
      "Epoch 353/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3914 - val_loss: 1.4221\n",
      "Epoch 354/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4169 - val_loss: 1.4591\n",
      "Epoch 355/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4008 - val_loss: 1.4048\n",
      "Epoch 356/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4142 - val_loss: 1.4658\n",
      "Epoch 357/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4089 - val_loss: 1.4562\n",
      "Epoch 358/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4105 - val_loss: 1.4197\n",
      "Epoch 359/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4135 - val_loss: 1.5128\n",
      "Epoch 360/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4081 - val_loss: 1.4586\n",
      "Epoch 361/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3997 - val_loss: 1.4085\n",
      "Epoch 362/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3969 - val_loss: 1.4152\n",
      "Epoch 363/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4039 - val_loss: 1.4180\n",
      "Epoch 364/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3995 - val_loss: 1.4270\n",
      "Epoch 365/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3987 - val_loss: 1.4681\n",
      "Epoch 366/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.4026 - val_loss: 1.4375\n",
      "Epoch 367/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3953 - val_loss: 1.5033\n",
      "Epoch 368/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4078 - val_loss: 1.4374\n",
      "Epoch 369/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3873 - val_loss: 1.4274\n",
      "Epoch 370/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3958 - val_loss: 1.4151\n",
      "Epoch 371/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3912 - val_loss: 1.4283\n",
      "Epoch 372/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3983 - val_loss: 1.4240\n",
      "Epoch 373/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3883 - val_loss: 1.4312\n",
      "Epoch 374/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3949 - val_loss: 1.4084\n",
      "Epoch 375/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4008 - val_loss: 1.4318\n",
      "Epoch 376/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4072 - val_loss: 1.4703\n",
      "Epoch 377/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3828 - val_loss: 1.4162\n",
      "Epoch 378/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3850 - val_loss: 1.4200\n",
      "Epoch 379/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3925 - val_loss: 1.4277\n",
      "Epoch 380/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4025 - val_loss: 1.3700\n",
      "Epoch 381/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3861 - val_loss: 1.4659\n",
      "Epoch 382/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3867 - val_loss: 1.4228\n",
      "Epoch 383/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3917 - val_loss: 1.4265\n",
      "Epoch 384/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3974 - val_loss: 1.4622\n",
      "Epoch 385/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3812 - val_loss: 1.4809\n",
      "Epoch 386/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3932 - val_loss: 1.3812\n",
      "Epoch 387/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3887 - val_loss: 1.4508\n",
      "Epoch 388/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3870 - val_loss: 1.5096\n",
      "Epoch 389/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4004 - val_loss: 1.4118\n",
      "Epoch 390/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3861 - val_loss: 1.4776\n",
      "Epoch 391/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3875 - val_loss: 1.4266\n",
      "Epoch 392/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3873 - val_loss: 1.4387\n",
      "Epoch 393/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3876 - val_loss: 1.3745\n",
      "Epoch 394/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3891 - val_loss: 1.4155\n",
      "Epoch 395/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3925 - val_loss: 1.3987\n",
      "Epoch 396/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3829 - val_loss: 1.4202\n",
      "Epoch 397/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3824 - val_loss: 1.4333\n",
      "Epoch 398/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3887 - val_loss: 1.4275\n",
      "Epoch 399/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3994 - val_loss: 1.4522\n",
      "Epoch 400/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3900 - val_loss: 1.3942\n",
      "Epoch 401/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3837 - val_loss: 1.4698\n",
      "Epoch 402/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3825 - val_loss: 1.4433\n",
      "Epoch 403/500\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3887 - val_loss: 1.3967\n",
      "Epoch 404/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3831 - val_loss: 1.5226\n",
      "Epoch 405/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3903 - val_loss: 1.4444\n",
      "Epoch 406/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3788 - val_loss: 1.4191\n",
      "Epoch 407/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3761 - val_loss: 1.4570\n",
      "Epoch 408/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3704 - val_loss: 1.4521\n",
      "Epoch 409/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3857 - val_loss: 1.4684\n",
      "Epoch 410/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3801 - val_loss: 1.4889\n",
      "Epoch 411/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3735 - val_loss: 1.3916\n",
      "Epoch 412/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3830 - val_loss: 1.4025\n",
      "Epoch 413/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3778 - val_loss: 1.3833\n",
      "Epoch 414/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3789 - val_loss: 1.4147\n",
      "Epoch 415/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3758 - val_loss: 1.5012\n",
      "Epoch 416/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3768 - val_loss: 1.3733\n",
      "Epoch 417/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3760 - val_loss: 1.4786\n",
      "Epoch 418/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3719 - val_loss: 1.3799\n",
      "Epoch 419/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3714 - val_loss: 1.5065\n",
      "Epoch 420/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3769 - val_loss: 1.4244\n",
      "Epoch 421/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3657 - val_loss: 1.3963\n",
      "Epoch 422/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3659 - val_loss: 1.3738\n",
      "Epoch 423/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3735 - val_loss: 1.4153\n",
      "Epoch 424/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3763 - val_loss: 1.3936\n",
      "Epoch 425/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3790 - val_loss: 1.4461\n",
      "Epoch 426/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3788 - val_loss: 1.3634\n",
      "Epoch 427/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3748 - val_loss: 1.4169\n",
      "Epoch 428/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3857 - val_loss: 1.4035\n",
      "Epoch 429/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3732 - val_loss: 1.3744\n",
      "Epoch 430/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3735 - val_loss: 1.4068\n",
      "Epoch 431/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3681 - val_loss: 1.3758\n",
      "Epoch 432/500\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3770 - val_loss: 1.4043\n",
      "Epoch 433/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3614 - val_loss: 1.4696\n",
      "Epoch 434/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3827 - val_loss: 1.4140\n",
      "Epoch 435/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3655 - val_loss: 1.4178\n",
      "Epoch 436/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3572 - val_loss: 1.3587\n",
      "Epoch 437/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3678 - val_loss: 1.3938\n",
      "Epoch 438/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3766 - val_loss: 1.4414\n",
      "Epoch 439/500\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3787 - val_loss: 1.4284\n",
      "Epoch 440/500\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3711 - val_loss: 1.4976\n",
      "Epoch 441/500\n",
      "576/576 [==============================] - 7s 12ms/step - loss: 1.3594 - val_loss: 1.4764\n",
      "Epoch 442/500\n",
      "576/576 [==============================] - 7s 12ms/step - loss: 1.3690 - val_loss: 1.3610\n",
      "Epoch 443/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3637 - val_loss: 1.4401\n",
      "Epoch 444/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3697 - val_loss: 1.4147\n",
      "Epoch 445/500\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.3606 - val_loss: 1.4391\n",
      "Epoch 446/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3660 - val_loss: 1.4193\n",
      "Epoch 447/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3724 - val_loss: 1.4061\n",
      "Epoch 448/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3547 - val_loss: 1.3973\n",
      "Epoch 449/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3708 - val_loss: 1.3918\n",
      "Epoch 450/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3560 - val_loss: 1.4052\n",
      "Epoch 451/500\n",
      "576/576 [==============================] - 5s 10ms/step - loss: 1.3611 - val_loss: 1.3755\n",
      "Epoch 452/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3500 - val_loss: 1.4263\n",
      "Epoch 453/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3629 - val_loss: 1.4510\n",
      "Epoch 454/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3597 - val_loss: 1.3871\n",
      "Epoch 455/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3650 - val_loss: 1.4068\n",
      "Epoch 456/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3577 - val_loss: 1.4005\n",
      "Epoch 457/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3602 - val_loss: 1.3757\n",
      "Epoch 458/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3623 - val_loss: 1.4177\n",
      "Epoch 459/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3497 - val_loss: 1.3797\n",
      "Epoch 460/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3566 - val_loss: 1.3902\n",
      "Epoch 461/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3588 - val_loss: 1.4383\n",
      "Epoch 462/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3491 - val_loss: 1.3881\n",
      "Epoch 463/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3608 - val_loss: 1.4290\n",
      "Epoch 464/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3580 - val_loss: 1.4600\n",
      "Epoch 465/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3671 - val_loss: 1.3850\n",
      "Epoch 466/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3474 - val_loss: 1.4865\n",
      "Epoch 467/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3594 - val_loss: 1.4153\n",
      "Epoch 468/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3465 - val_loss: 1.3595\n",
      "Epoch 469/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3524 - val_loss: 1.4216\n",
      "Epoch 470/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3536 - val_loss: 1.4073\n",
      "Epoch 471/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3600 - val_loss: 1.4276\n",
      "Epoch 472/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3485 - val_loss: 1.4466\n",
      "Epoch 473/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3588 - val_loss: 1.4295\n",
      "Epoch 474/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3438 - val_loss: 1.3753\n",
      "Epoch 475/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3551 - val_loss: 1.4021\n",
      "Epoch 476/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3509 - val_loss: 1.4240\n",
      "Epoch 477/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3571 - val_loss: 1.4252\n",
      "Epoch 478/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3424 - val_loss: 1.3570\n",
      "Epoch 479/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3480 - val_loss: 1.4435\n",
      "Epoch 480/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3514 - val_loss: 1.4256\n",
      "Epoch 481/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3567 - val_loss: 1.3647\n",
      "Epoch 482/500\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.3463 - val_loss: 1.4544\n",
      "Epoch 483/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3525 - val_loss: 1.3653\n",
      "Epoch 484/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3525 - val_loss: 1.4152\n",
      "Epoch 485/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3479 - val_loss: 1.3812\n",
      "Epoch 486/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3438 - val_loss: 1.4145\n",
      "Epoch 487/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3507 - val_loss: 1.3641\n",
      "Epoch 488/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3458 - val_loss: 1.3946\n",
      "Epoch 489/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3450 - val_loss: 1.3974\n",
      "Epoch 490/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3546 - val_loss: 1.3924\n",
      "Epoch 491/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3490 - val_loss: 1.4199\n",
      "Epoch 492/500\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 1.3523 - val_loss: 1.3871\n",
      "Epoch 493/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3371 - val_loss: 1.3855\n",
      "Epoch 494/500\n",
      "576/576 [==============================] - 6s 11ms/step - loss: 1.3437 - val_loss: 1.3417\n",
      "Epoch 495/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3494 - val_loss: 1.3774\n",
      "Epoch 496/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3456 - val_loss: 1.3639\n",
      "Epoch 497/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3463 - val_loss: 1.3747\n",
      "Epoch 498/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3437 - val_loss: 1.3844\n",
      "Epoch 499/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3286 - val_loss: 1.3966\n",
      "Epoch 500/500\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.3463 - val_loss: 1.4975\n",
      "1.4974812761302656\n",
      "0.9667873987624329\n",
      "Epoch 1/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 11.6679 - val_loss: 3.9912\n",
      "Epoch 2/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 5.8342 - val_loss: 7.5864\n",
      "Epoch 3/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 4.9272 - val_loss: 4.4125\n",
      "Epoch 4/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 4.6864 - val_loss: 6.6925\n",
      "Epoch 5/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 4.4627 - val_loss: 5.3156\n",
      "Epoch 6/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 4.3628 - val_loss: 4.3615\n",
      "Epoch 7/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 4.2407 - val_loss: 3.8737\n",
      "Epoch 8/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 4.3658 - val_loss: 5.4590\n",
      "Epoch 9/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 4.1270 - val_loss: 4.0975\n",
      "Epoch 10/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 3.8339 - val_loss: 3.7983\n",
      "Epoch 11/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 3.5705 - val_loss: 3.3898\n",
      "Epoch 12/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 3.3677 - val_loss: 3.1857\n",
      "Epoch 13/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 3.1790 - val_loss: 3.2683\n",
      "Epoch 14/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 3.2403 - val_loss: 3.0907\n",
      "Epoch 15/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 3.0444 - val_loss: 3.4028\n",
      "Epoch 16/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.9708 - val_loss: 2.7941\n",
      "Epoch 17/500\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 2.9524 - val_loss: 2.8311\n",
      "Epoch 18/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.8708 - val_loss: 2.8323\n",
      "Epoch 19/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.8576 - val_loss: 2.6936\n",
      "Epoch 20/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.7342 - val_loss: 2.6028\n",
      "Epoch 21/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.7201 - val_loss: 2.9104\n",
      "Epoch 22/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.7005 - val_loss: 2.5172\n",
      "Epoch 23/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.6354 - val_loss: 2.5054\n",
      "Epoch 24/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.5998 - val_loss: 2.4808\n",
      "Epoch 25/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.5600 - val_loss: 2.7731\n",
      "Epoch 26/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.5541 - val_loss: 2.4058\n",
      "Epoch 27/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.5056 - val_loss: 2.4289\n",
      "Epoch 28/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.5054 - val_loss: 2.4857\n",
      "Epoch 29/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.4990 - val_loss: 2.3786\n",
      "Epoch 30/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.4362 - val_loss: 2.4543\n",
      "Epoch 31/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.4468 - val_loss: 2.3339\n",
      "Epoch 32/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.4440 - val_loss: 2.3242\n",
      "Epoch 33/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.3864 - val_loss: 2.3649\n",
      "Epoch 34/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.3431 - val_loss: 2.2943\n",
      "Epoch 35/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.3380 - val_loss: 2.2862\n",
      "Epoch 36/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.3222 - val_loss: 2.4557\n",
      "Epoch 37/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.3362 - val_loss: 2.3008\n",
      "Epoch 38/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.2966 - val_loss: 2.3196\n",
      "Epoch 39/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.2966 - val_loss: 2.4182\n",
      "Epoch 40/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.2816 - val_loss: 2.2183\n",
      "Epoch 41/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.2399 - val_loss: 2.2005\n",
      "Epoch 42/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.2343 - val_loss: 2.1168\n",
      "Epoch 43/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 2.2346 - val_loss: 2.3021\n",
      "Epoch 44/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 2.2167 - val_loss: 2.3007\n",
      "Epoch 45/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.1856 - val_loss: 2.1809\n",
      "Epoch 46/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.1675 - val_loss: 2.2016\n",
      "Epoch 47/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.1926 - val_loss: 2.2909\n",
      "Epoch 48/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 2.1403 - val_loss: 2.1243\n",
      "Epoch 49/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 2.1142 - val_loss: 2.1345\n",
      "Epoch 50/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1462 - val_loss: 2.1950\n",
      "Epoch 51/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.1207 - val_loss: 2.1216\n",
      "Epoch 52/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0911 - val_loss: 2.0959\n",
      "Epoch 53/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 2.1115 - val_loss: 2.0486\n",
      "Epoch 54/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 2.0860 - val_loss: 2.0691\n",
      "Epoch 55/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 2.0805 - val_loss: 2.0254\n",
      "Epoch 56/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0505 - val_loss: 2.0090\n",
      "Epoch 57/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0616 - val_loss: 2.0678\n",
      "Epoch 58/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0534 - val_loss: 2.0689\n",
      "Epoch 59/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 2.0302 - val_loss: 2.0174\n",
      "Epoch 60/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0349 - val_loss: 2.0347\n",
      "Epoch 61/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0135 - val_loss: 2.1099\n",
      "Epoch 62/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.9960 - val_loss: 2.0743\n",
      "Epoch 63/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9909 - val_loss: 1.9744\n",
      "Epoch 64/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0010 - val_loss: 1.9905\n",
      "Epoch 65/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9768 - val_loss: 2.0440\n",
      "Epoch 66/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9977 - val_loss: 1.9521\n",
      "Epoch 67/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9833 - val_loss: 1.9691\n",
      "Epoch 68/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9560 - val_loss: 1.9364\n",
      "Epoch 69/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9630 - val_loss: 1.9323\n",
      "Epoch 70/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9459 - val_loss: 1.9368\n",
      "Epoch 71/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9537 - val_loss: 1.8905\n",
      "Epoch 72/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9431 - val_loss: 1.9748\n",
      "Epoch 73/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9296 - val_loss: 1.9657\n",
      "Epoch 74/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9316 - val_loss: 1.9861\n",
      "Epoch 75/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.9039 - val_loss: 1.8613\n",
      "Epoch 76/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.9339 - val_loss: 1.8747\n",
      "Epoch 77/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.9081 - val_loss: 2.0416\n",
      "Epoch 78/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8829 - val_loss: 2.0924\n",
      "Epoch 79/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.8957 - val_loss: 1.9115\n",
      "Epoch 80/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.8804 - val_loss: 2.2155\n",
      "Epoch 81/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.8966 - val_loss: 1.8696\n",
      "Epoch 82/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.8940 - val_loss: 1.9181\n",
      "Epoch 83/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8627 - val_loss: 1.8618\n",
      "Epoch 84/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.8835 - val_loss: 1.8809\n",
      "Epoch 85/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8477 - val_loss: 1.8269\n",
      "Epoch 86/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8530 - val_loss: 1.9270\n",
      "Epoch 87/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8559 - val_loss: 1.8065\n",
      "Epoch 88/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.8302 - val_loss: 1.8061\n",
      "Epoch 89/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8379 - val_loss: 1.7967\n",
      "Epoch 90/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.8317 - val_loss: 1.8059\n",
      "Epoch 91/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8287 - val_loss: 1.8148\n",
      "Epoch 92/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.8179 - val_loss: 1.7510\n",
      "Epoch 93/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8312 - val_loss: 2.0200\n",
      "Epoch 94/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.8089 - val_loss: 1.8279\n",
      "Epoch 95/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.8094 - val_loss: 1.8073\n",
      "Epoch 96/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8054 - val_loss: 1.7662\n",
      "Epoch 97/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7914 - val_loss: 1.8546\n",
      "Epoch 98/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7905 - val_loss: 1.7944\n",
      "Epoch 99/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7796 - val_loss: 1.8790\n",
      "Epoch 100/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7954 - val_loss: 1.8390\n",
      "Epoch 101/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7799 - val_loss: 1.7878\n",
      "Epoch 102/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7631 - val_loss: 1.7887\n",
      "Epoch 103/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7647 - val_loss: 1.8045\n",
      "Epoch 104/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7648 - val_loss: 1.8182\n",
      "Epoch 105/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7905 - val_loss: 1.9171\n",
      "Epoch 106/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7581 - val_loss: 1.8092\n",
      "Epoch 107/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7519 - val_loss: 1.7903\n",
      "Epoch 108/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7325 - val_loss: 1.7311\n",
      "Epoch 109/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7500 - val_loss: 1.8038\n",
      "Epoch 110/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7594 - val_loss: 1.7234\n",
      "Epoch 111/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7446 - val_loss: 1.7674\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 4s 10ms/step - loss: 1.7364 - val_loss: 1.7104\n",
      "Epoch 113/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7386 - val_loss: 1.7848\n",
      "Epoch 114/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7284 - val_loss: 1.7647\n",
      "Epoch 115/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7359 - val_loss: 1.7509\n",
      "Epoch 116/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7422 - val_loss: 1.6881\n",
      "Epoch 117/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7073 - val_loss: 1.7188\n",
      "Epoch 118/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7328 - val_loss: 1.6755\n",
      "Epoch 119/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7005 - val_loss: 1.7391\n",
      "Epoch 120/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7079 - val_loss: 1.7735\n",
      "Epoch 121/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7012 - val_loss: 1.7186\n",
      "Epoch 122/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7174 - val_loss: 1.7538\n",
      "Epoch 123/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6984 - val_loss: 1.6971\n",
      "Epoch 124/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6932 - val_loss: 1.6606\n",
      "Epoch 125/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6877 - val_loss: 1.6638\n",
      "Epoch 126/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6841 - val_loss: 1.6864\n",
      "Epoch 127/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6906 - val_loss: 1.7048\n",
      "Epoch 128/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6898 - val_loss: 1.7643\n",
      "Epoch 129/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6699 - val_loss: 1.7901\n",
      "Epoch 130/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6781 - val_loss: 1.6992\n",
      "Epoch 131/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6677 - val_loss: 1.7390\n",
      "Epoch 132/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6637 - val_loss: 1.6618\n",
      "Epoch 133/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6715 - val_loss: 1.7144\n",
      "Epoch 134/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6627 - val_loss: 1.6457\n",
      "Epoch 135/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6603 - val_loss: 1.6433\n",
      "Epoch 136/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6616 - val_loss: 1.6774\n",
      "Epoch 137/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6580 - val_loss: 1.6579\n",
      "Epoch 138/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6419 - val_loss: 1.6666\n",
      "Epoch 139/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6807 - val_loss: 1.6841\n",
      "Epoch 140/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6464 - val_loss: 1.6807\n",
      "Epoch 141/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6403 - val_loss: 1.7157\n",
      "Epoch 142/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6463 - val_loss: 1.6906\n",
      "Epoch 143/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6461 - val_loss: 1.8808\n",
      "Epoch 144/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6496 - val_loss: 1.6611\n",
      "Epoch 145/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6538 - val_loss: 1.6484\n",
      "Epoch 146/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6378 - val_loss: 1.7687\n",
      "Epoch 147/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6314 - val_loss: 1.7066\n",
      "Epoch 148/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6208 - val_loss: 1.6212\n",
      "Epoch 149/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.6183 - val_loss: 1.6484\n",
      "Epoch 150/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6251 - val_loss: 1.6949\n",
      "Epoch 151/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6280 - val_loss: 1.6731\n",
      "Epoch 152/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.6303 - val_loss: 1.6156\n",
      "Epoch 153/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6216 - val_loss: 1.6436\n",
      "Epoch 154/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6231 - val_loss: 1.8104\n",
      "Epoch 155/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6077 - val_loss: 1.6942\n",
      "Epoch 156/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.6049 - val_loss: 1.5690\n",
      "Epoch 157/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6097 - val_loss: 1.7090\n",
      "Epoch 158/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.6250 - val_loss: 1.6582\n",
      "Epoch 159/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.5951 - val_loss: 1.6136\n",
      "Epoch 160/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5926 - val_loss: 1.6992\n",
      "Epoch 161/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.5961 - val_loss: 1.6155\n",
      "Epoch 162/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6302 - val_loss: 1.7846\n",
      "Epoch 163/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6103 - val_loss: 1.5967\n",
      "Epoch 164/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5906 - val_loss: 1.6049\n",
      "Epoch 165/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.5761 - val_loss: 1.6914\n",
      "Epoch 166/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5823 - val_loss: 1.5910\n",
      "Epoch 167/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5836 - val_loss: 1.6322\n",
      "Epoch 168/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5948 - val_loss: 1.5356\n",
      "Epoch 169/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.5846 - val_loss: 1.6208\n",
      "Epoch 170/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5805 - val_loss: 1.5719\n",
      "Epoch 171/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5768 - val_loss: 1.7226\n",
      "Epoch 172/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5996 - val_loss: 1.7364\n",
      "Epoch 173/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.5759 - val_loss: 1.6232\n",
      "Epoch 174/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5763 - val_loss: 1.6205\n",
      "Epoch 175/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5554 - val_loss: 1.5783\n",
      "Epoch 176/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5821 - val_loss: 1.6080\n",
      "Epoch 177/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5698 - val_loss: 1.6808\n",
      "Epoch 178/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5503 - val_loss: 1.6583\n",
      "Epoch 179/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6070 - val_loss: 1.5643\n",
      "Epoch 180/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5532 - val_loss: 1.5784\n",
      "Epoch 181/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.5593 - val_loss: 1.5984\n",
      "Epoch 182/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 1.5566 - val_loss: 1.5932\n",
      "Epoch 183/500\n",
      "432/432 [==============================] - 16s 38ms/step - loss: 1.5600 - val_loss: 1.5528\n",
      "Epoch 184/500\n",
      "432/432 [==============================] - 13s 30ms/step - loss: 1.5662 - val_loss: 1.5969\n",
      "Epoch 185/500\n",
      "432/432 [==============================] - 8s 19ms/step - loss: 1.5515 - val_loss: 1.5631\n",
      "Epoch 186/500\n",
      "432/432 [==============================] - 7s 16ms/step - loss: 1.5507 - val_loss: 1.5538\n",
      "Epoch 187/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 1.5549 - val_loss: 1.5704\n",
      "Epoch 188/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.5485 - val_loss: 1.5049\n",
      "Epoch 189/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.5521 - val_loss: 1.5376\n",
      "Epoch 190/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5475 - val_loss: 1.5624\n",
      "Epoch 191/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.5470 - val_loss: 1.5623\n",
      "Epoch 192/500\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 1.5502 - val_loss: 1.5828\n",
      "Epoch 193/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.5368 - val_loss: 1.5930\n",
      "Epoch 194/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5548 - val_loss: 1.5880\n",
      "Epoch 195/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5354 - val_loss: 1.5941\n",
      "Epoch 196/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5373 - val_loss: 1.6013\n",
      "Epoch 197/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5263 - val_loss: 1.6013\n",
      "Epoch 198/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5255 - val_loss: 1.5516\n",
      "Epoch 199/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5352 - val_loss: 1.6134\n",
      "Epoch 200/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5378 - val_loss: 1.5689\n",
      "Epoch 201/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5276 - val_loss: 1.5916\n",
      "Epoch 202/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.5202 - val_loss: 1.5151\n",
      "Epoch 203/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5421 - val_loss: 1.5996\n",
      "Epoch 204/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5251 - val_loss: 1.5526\n",
      "Epoch 205/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5280 - val_loss: 1.5896\n",
      "Epoch 206/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.5287 - val_loss: 1.5878\n",
      "Epoch 207/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5159 - val_loss: 1.5789\n",
      "Epoch 208/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5260 - val_loss: 1.5357\n",
      "Epoch 209/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5083 - val_loss: 1.5560\n",
      "Epoch 210/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5055 - val_loss: 1.5719\n",
      "Epoch 211/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5188 - val_loss: 1.5275\n",
      "Epoch 212/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5127 - val_loss: 1.5322\n",
      "Epoch 213/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5167 - val_loss: 1.5423\n",
      "Epoch 214/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5146 - val_loss: 1.5754\n",
      "Epoch 215/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5268 - val_loss: 1.5662\n",
      "Epoch 216/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5000 - val_loss: 1.5330\n",
      "Epoch 217/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4934 - val_loss: 1.5382\n",
      "Epoch 218/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4989 - val_loss: 1.4835\n",
      "Epoch 219/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.5029 - val_loss: 1.6424\n",
      "Epoch 220/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4877 - val_loss: 1.5184\n",
      "Epoch 221/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4903 - val_loss: 1.5067\n",
      "Epoch 222/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4913 - val_loss: 1.4962\n",
      "Epoch 223/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.5013 - val_loss: 1.5641\n",
      "Epoch 224/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4996 - val_loss: 1.5440\n",
      "Epoch 225/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4966 - val_loss: 1.5787\n",
      "Epoch 226/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4909 - val_loss: 1.4988\n",
      "Epoch 227/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4979 - val_loss: 1.5670\n",
      "Epoch 228/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4859 - val_loss: 1.5674\n",
      "Epoch 229/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4922 - val_loss: 1.5306\n",
      "Epoch 230/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4960 - val_loss: 1.5231\n",
      "Epoch 231/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4825 - val_loss: 1.5427\n",
      "Epoch 232/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4820 - val_loss: 1.5261\n",
      "Epoch 233/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4824 - val_loss: 1.5353\n",
      "Epoch 234/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4857 - val_loss: 1.4633\n",
      "Epoch 235/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4848 - val_loss: 1.5841\n",
      "Epoch 236/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4802 - val_loss: 1.4895\n",
      "Epoch 237/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4847 - val_loss: 1.5842\n",
      "Epoch 238/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4747 - val_loss: 1.4887\n",
      "Epoch 239/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4747 - val_loss: 1.5263\n",
      "Epoch 240/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4798 - val_loss: 1.5012\n",
      "Epoch 241/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4762 - val_loss: 1.5388\n",
      "Epoch 242/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4844 - val_loss: 1.5058\n",
      "Epoch 243/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4830 - val_loss: 1.4835\n",
      "Epoch 244/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4811 - val_loss: 1.5555\n",
      "Epoch 245/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4667 - val_loss: 1.4753\n",
      "Epoch 246/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.4660 - val_loss: 1.5818\n",
      "Epoch 247/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4947 - val_loss: 1.5441\n",
      "Epoch 248/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4653 - val_loss: 1.5085\n",
      "Epoch 249/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4600 - val_loss: 1.5114\n",
      "Epoch 250/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4648 - val_loss: 1.4616\n",
      "Epoch 251/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4597 - val_loss: 1.5324\n",
      "Epoch 252/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4561 - val_loss: 1.5188\n",
      "Epoch 253/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4784 - val_loss: 1.6289\n",
      "Epoch 254/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4603 - val_loss: 1.5170\n",
      "Epoch 255/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4667 - val_loss: 1.5260\n",
      "Epoch 256/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4560 - val_loss: 1.5094\n",
      "Epoch 257/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4589 - val_loss: 1.4877\n",
      "Epoch 258/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4704 - val_loss: 1.4828\n",
      "Epoch 259/500\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 1.4532 - val_loss: 1.4708\n",
      "Epoch 260/500\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 1.4566 - val_loss: 1.4872\n",
      "Epoch 261/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4578 - val_loss: 1.4968\n",
      "Epoch 262/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4528 - val_loss: 1.4694\n",
      "Epoch 263/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.4584 - val_loss: 1.4346\n",
      "Epoch 264/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4438 - val_loss: 1.4708\n",
      "Epoch 265/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4466 - val_loss: 1.4924\n",
      "Epoch 266/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4538 - val_loss: 1.4993\n",
      "Epoch 267/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4483 - val_loss: 1.4694\n",
      "Epoch 268/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4524 - val_loss: 1.4545\n",
      "Epoch 269/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4615 - val_loss: 1.5330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4463 - val_loss: 1.6252\n",
      "Epoch 271/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4613 - val_loss: 1.5838\n",
      "Epoch 272/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4331 - val_loss: 1.4581\n",
      "Epoch 273/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4295 - val_loss: 1.5336\n",
      "Epoch 274/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4477 - val_loss: 1.4824\n",
      "Epoch 275/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4435 - val_loss: 1.5193\n",
      "Epoch 276/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4539 - val_loss: 1.5013\n",
      "Epoch 277/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4345 - val_loss: 1.4710\n",
      "Epoch 278/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4230 - val_loss: 1.4532\n",
      "Epoch 279/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4321 - val_loss: 1.5246\n",
      "Epoch 280/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4402 - val_loss: 1.4542\n",
      "Epoch 281/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4359 - val_loss: 1.4287\n",
      "Epoch 282/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4412 - val_loss: 1.4698\n",
      "Epoch 283/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4252 - val_loss: 1.5127\n",
      "Epoch 284/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4353 - val_loss: 1.4415\n",
      "Epoch 285/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4222 - val_loss: 1.4327\n",
      "Epoch 286/500\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 1.4392 - val_loss: 1.4511\n",
      "Epoch 287/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4250 - val_loss: 1.4670\n",
      "Epoch 288/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4267 - val_loss: 1.4605\n",
      "Epoch 289/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4402 - val_loss: 1.5285\n",
      "Epoch 290/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4278 - val_loss: 1.5754\n",
      "Epoch 291/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4372 - val_loss: 1.5572\n",
      "Epoch 292/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4233 - val_loss: 1.4355\n",
      "Epoch 293/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4338 - val_loss: 1.5178\n",
      "Epoch 294/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4195 - val_loss: 1.4676\n",
      "Epoch 295/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4292 - val_loss: 1.4929\n",
      "Epoch 296/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4220 - val_loss: 1.4914\n",
      "Epoch 297/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4241 - val_loss: 1.5757\n",
      "Epoch 298/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4188 - val_loss: 1.4279\n",
      "Epoch 299/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.4278 - val_loss: 1.4009\n",
      "Epoch 300/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4192 - val_loss: 1.4830\n",
      "Epoch 301/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4122 - val_loss: 1.4430\n",
      "Epoch 302/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4114 - val_loss: 1.4651\n",
      "Epoch 303/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4074 - val_loss: 1.4344\n",
      "Epoch 304/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4207 - val_loss: 1.5282\n",
      "Epoch 305/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4193 - val_loss: 1.4219\n",
      "Epoch 306/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4097 - val_loss: 1.4412\n",
      "Epoch 307/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4190 - val_loss: 1.4193\n",
      "Epoch 308/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4196 - val_loss: 1.4130\n",
      "Epoch 309/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3996 - val_loss: 1.4669\n",
      "Epoch 310/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4104 - val_loss: 1.4478\n",
      "Epoch 311/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4230 - val_loss: 1.4716\n",
      "Epoch 312/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4192 - val_loss: 1.5634\n",
      "Epoch 313/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.3936 - val_loss: 1.6521\n",
      "Epoch 314/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.4132 - val_loss: 1.4424\n",
      "Epoch 315/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4172 - val_loss: 1.4990\n",
      "Epoch 316/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4001 - val_loss: 1.4688\n",
      "Epoch 317/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4009 - val_loss: 1.4304\n",
      "Epoch 318/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4033 - val_loss: 1.4140\n",
      "Epoch 319/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4074 - val_loss: 1.4028\n",
      "Epoch 320/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3898 - val_loss: 1.4103\n",
      "Epoch 321/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3999 - val_loss: 1.4338\n",
      "Epoch 322/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4002 - val_loss: 1.4583\n",
      "Epoch 323/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4024 - val_loss: 1.4154\n",
      "Epoch 324/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3898 - val_loss: 1.4045\n",
      "Epoch 325/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3865 - val_loss: 1.4705\n",
      "Epoch 326/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.4052 - val_loss: 1.4413\n",
      "Epoch 327/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3979 - val_loss: 1.4483\n",
      "Epoch 328/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3883 - val_loss: 1.4052\n",
      "Epoch 329/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4009 - val_loss: 1.5251\n",
      "Epoch 330/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4184 - val_loss: 1.4507\n",
      "Epoch 331/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3944 - val_loss: 1.3857\n",
      "Epoch 332/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3857 - val_loss: 1.4386\n",
      "Epoch 333/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4003 - val_loss: 1.4476\n",
      "Epoch 334/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3928 - val_loss: 1.4641\n",
      "Epoch 335/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3966 - val_loss: 1.3943\n",
      "Epoch 336/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3912 - val_loss: 1.4887\n",
      "Epoch 337/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.4010 - val_loss: 1.4270\n",
      "Epoch 338/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3897 - val_loss: 1.4112\n",
      "Epoch 339/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.3890 - val_loss: 1.3785\n",
      "Epoch 340/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3922 - val_loss: 1.5873\n",
      "Epoch 341/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3926 - val_loss: 1.4038\n",
      "Epoch 342/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3765 - val_loss: 1.4175\n",
      "Epoch 343/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3870 - val_loss: 1.3894\n",
      "Epoch 344/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3938 - val_loss: 1.4528\n",
      "Epoch 345/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3791 - val_loss: 1.3898\n",
      "Epoch 346/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3835 - val_loss: 1.4333\n",
      "Epoch 347/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3837 - val_loss: 1.4504\n",
      "Epoch 348/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3909 - val_loss: 1.3847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3698 - val_loss: 1.4601\n",
      "Epoch 350/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3962 - val_loss: 1.3949\n",
      "Epoch 351/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3792 - val_loss: 1.4678\n",
      "Epoch 352/500\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 1.3811 - val_loss: 1.4838\n",
      "Epoch 353/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3804 - val_loss: 1.5143\n",
      "Epoch 354/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3847 - val_loss: 1.4614\n",
      "Epoch 355/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3726 - val_loss: 1.4079\n",
      "Epoch 356/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3816 - val_loss: 1.4079\n",
      "Epoch 357/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3855 - val_loss: 1.5581\n",
      "Epoch 358/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3789 - val_loss: 1.3908\n",
      "Epoch 359/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3722 - val_loss: 1.4098\n",
      "Epoch 360/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3774 - val_loss: 1.3977\n",
      "Epoch 361/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3809 - val_loss: 1.3938\n",
      "Epoch 362/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3697 - val_loss: 1.4015\n",
      "Epoch 363/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3756 - val_loss: 1.4138\n",
      "Epoch 364/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3714 - val_loss: 1.4917\n",
      "Epoch 365/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3754 - val_loss: 1.4224\n",
      "Epoch 366/500\n",
      "432/432 [==============================] - 6s 15ms/step - loss: 1.3691 - val_loss: 1.4068\n",
      "Epoch 367/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3812 - val_loss: 1.3612\n",
      "Epoch 368/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3668 - val_loss: 1.3907\n",
      "Epoch 369/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3677 - val_loss: 1.4252\n",
      "Epoch 370/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3748 - val_loss: 1.4454\n",
      "Epoch 371/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3650 - val_loss: 1.3972\n",
      "Epoch 372/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3727 - val_loss: 1.3672\n",
      "Epoch 373/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3725 - val_loss: 1.3841\n",
      "Epoch 374/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3595 - val_loss: 1.3676\n",
      "Epoch 375/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3787 - val_loss: 1.4467\n",
      "Epoch 376/500\n",
      "432/432 [==============================] - 6s 15ms/step - loss: 1.3549 - val_loss: 1.3988\n",
      "Epoch 377/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3689 - val_loss: 1.4165\n",
      "Epoch 378/500\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 1.3710 - val_loss: 1.3642\n",
      "Epoch 379/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3705 - val_loss: 1.4498\n",
      "Epoch 380/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3644 - val_loss: 1.4137\n",
      "Epoch 381/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3586 - val_loss: 1.3691\n",
      "Epoch 382/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3680 - val_loss: 1.3519\n",
      "Epoch 383/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3548 - val_loss: 1.4023\n",
      "Epoch 384/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3562 - val_loss: 1.4973\n",
      "Epoch 385/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.3623 - val_loss: 1.3887\n",
      "Epoch 386/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3686 - val_loss: 1.4017\n",
      "Epoch 387/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3765 - val_loss: 1.4709\n",
      "Epoch 388/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3569 - val_loss: 1.3716\n",
      "Epoch 389/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3692 - val_loss: 1.4333\n",
      "Epoch 390/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3686 - val_loss: 1.4458\n",
      "Epoch 391/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 1.3669 - val_loss: 1.3950\n",
      "Epoch 392/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3518 - val_loss: 1.3890\n",
      "Epoch 393/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3637 - val_loss: 1.3915\n",
      "Epoch 394/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3580 - val_loss: 1.4354\n",
      "Epoch 395/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3555 - val_loss: 1.3903\n",
      "Epoch 396/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3502 - val_loss: 1.4011\n",
      "Epoch 397/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3620 - val_loss: 1.4214\n",
      "Epoch 398/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3542 - val_loss: 1.3522\n",
      "Epoch 399/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3543 - val_loss: 1.3762\n",
      "Epoch 400/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3552 - val_loss: 1.3651\n",
      "Epoch 401/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3651 - val_loss: 1.4043\n",
      "Epoch 402/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3579 - val_loss: 1.4368\n",
      "Epoch 403/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3477 - val_loss: 1.4326\n",
      "Epoch 404/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3564 - val_loss: 1.4844\n",
      "Epoch 405/500\n",
      "432/432 [==============================] - 5s 13ms/step - loss: 1.3473 - val_loss: 1.4071\n",
      "Epoch 406/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3502 - val_loss: 1.3955\n",
      "Epoch 407/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3567 - val_loss: 1.5035\n",
      "Epoch 408/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3460 - val_loss: 1.3750\n",
      "Epoch 409/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3536 - val_loss: 1.3469\n",
      "Epoch 410/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3492 - val_loss: 1.4137\n",
      "Epoch 411/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3410 - val_loss: 1.3655\n",
      "Epoch 412/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3554 - val_loss: 1.4204\n",
      "Epoch 413/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3406 - val_loss: 1.3733\n",
      "Epoch 414/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3492 - val_loss: 1.4081\n",
      "Epoch 415/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3444 - val_loss: 1.4191\n",
      "Epoch 416/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3566 - val_loss: 1.4045\n",
      "Epoch 417/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3395 - val_loss: 1.3937\n",
      "Epoch 418/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3399 - val_loss: 1.3578\n",
      "Epoch 419/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3369 - val_loss: 1.3742\n",
      "Epoch 420/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3451 - val_loss: 1.3933\n",
      "Epoch 421/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3332 - val_loss: 1.3921\n",
      "Epoch 422/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3503 - val_loss: 1.3938\n",
      "Epoch 423/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3383 - val_loss: 1.3945\n",
      "Epoch 424/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3354 - val_loss: 1.3536\n",
      "Epoch 425/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3410 - val_loss: 1.3453\n",
      "Epoch 426/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3320 - val_loss: 1.4712\n",
      "Epoch 427/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3351 - val_loss: 1.4116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3390 - val_loss: 1.3419\n",
      "Epoch 429/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3275 - val_loss: 1.3995\n",
      "Epoch 430/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3375 - val_loss: 1.4006\n",
      "Epoch 431/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3314 - val_loss: 1.3802\n",
      "Epoch 432/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3499 - val_loss: 1.3624\n",
      "Epoch 433/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3336 - val_loss: 1.3907\n",
      "Epoch 434/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3307 - val_loss: 1.3382\n",
      "Epoch 435/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3368 - val_loss: 1.3861\n",
      "Epoch 436/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3455 - val_loss: 1.4207\n",
      "Epoch 437/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3333 - val_loss: 1.4021\n",
      "Epoch 438/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3268 - val_loss: 1.4253\n",
      "Epoch 439/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3371 - val_loss: 1.3757\n",
      "Epoch 440/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3346 - val_loss: 1.3393\n",
      "Epoch 441/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3219 - val_loss: 1.3848\n",
      "Epoch 442/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3387 - val_loss: 1.3894\n",
      "Epoch 443/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3317 - val_loss: 1.3545\n",
      "Epoch 444/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3267 - val_loss: 1.3441\n",
      "Epoch 445/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3282 - val_loss: 1.3756\n",
      "Epoch 446/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3331 - val_loss: 1.3990\n",
      "Epoch 447/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3299 - val_loss: 1.3979\n",
      "Epoch 448/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3355 - val_loss: 1.3648\n",
      "Epoch 449/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3248 - val_loss: 1.3907\n",
      "Epoch 450/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3209 - val_loss: 1.4636\n",
      "Epoch 451/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3352 - val_loss: 1.3643\n",
      "Epoch 452/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3203 - val_loss: 1.4519\n",
      "Epoch 453/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3314 - val_loss: 1.3600\n",
      "Epoch 454/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3222 - val_loss: 1.3939\n",
      "Epoch 455/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3256 - val_loss: 1.4161\n",
      "Epoch 456/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3296 - val_loss: 1.3767\n",
      "Epoch 457/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3269 - val_loss: 1.3847\n",
      "Epoch 458/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3306 - val_loss: 1.3707\n",
      "Epoch 459/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3252 - val_loss: 1.4082\n",
      "Epoch 460/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3213 - val_loss: 1.3845\n",
      "Epoch 461/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3246 - val_loss: 1.3936\n",
      "Epoch 462/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3230 - val_loss: 1.3189\n",
      "Epoch 463/500\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.3335 - val_loss: 1.4284\n",
      "Epoch 464/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3351 - val_loss: 1.3628\n",
      "Epoch 465/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3237 - val_loss: 1.3609\n",
      "Epoch 466/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3220 - val_loss: 1.3905\n",
      "Epoch 467/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3222 - val_loss: 1.3484\n",
      "Epoch 468/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3256 - val_loss: 1.4452\n",
      "Epoch 469/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3310 - val_loss: 1.3447\n",
      "Epoch 470/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3013 - val_loss: 1.3762\n",
      "Epoch 471/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3193 - val_loss: 1.3477\n",
      "Epoch 472/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3142 - val_loss: 1.3662\n",
      "Epoch 473/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3249 - val_loss: 1.3535\n",
      "Epoch 474/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3207 - val_loss: 1.3520\n",
      "Epoch 475/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3150 - val_loss: 1.3761\n",
      "Epoch 476/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3238 - val_loss: 1.3965\n",
      "Epoch 477/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3254 - val_loss: 1.3989\n",
      "Epoch 478/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3120 - val_loss: 1.3653\n",
      "Epoch 479/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3167 - val_loss: 1.3956\n",
      "Epoch 480/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3042 - val_loss: 1.3397\n",
      "Epoch 481/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3142 - val_loss: 1.3882\n",
      "Epoch 482/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3166 - val_loss: 1.4212\n",
      "Epoch 483/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3205 - val_loss: 1.3621\n",
      "Epoch 484/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3058 - val_loss: 1.3637\n",
      "Epoch 485/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3158 - val_loss: 1.3965\n",
      "Epoch 486/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3133 - val_loss: 1.3946\n",
      "Epoch 487/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3089 - val_loss: 1.4759\n",
      "Epoch 488/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3161 - val_loss: 1.3746\n",
      "Epoch 489/500\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3143 - val_loss: 1.3663\n",
      "Epoch 490/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3150 - val_loss: 1.3978\n",
      "Epoch 491/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3131 - val_loss: 1.3888\n",
      "Epoch 492/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3047 - val_loss: 1.3436\n",
      "Epoch 493/500\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3108 - val_loss: 1.3572\n",
      "Epoch 494/500\n",
      "432/432 [==============================] - 5s 12ms/step - loss: 1.3136 - val_loss: 1.3440\n",
      "Epoch 495/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3132 - val_loss: 1.3495\n",
      "Epoch 496/500\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2979 - val_loss: 1.3488\n",
      "Epoch 497/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3073 - val_loss: 1.3749\n",
      "Epoch 498/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3230 - val_loss: 1.3348\n",
      "Epoch 499/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3070 - val_loss: 1.3443\n",
      "Epoch 500/500\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2915 - val_loss: 1.3636\n",
      "1.3635585326791335\n",
      "0.9719575195139804\n",
      "Epoch 1/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 8.3249 - val_loss: 4.1547\n",
      "Epoch 2/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 5.1025 - val_loss: 4.3518\n",
      "Epoch 3/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 4.6060 - val_loss: 5.0334\n",
      "Epoch 4/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 4.1782 - val_loss: 3.6903\n",
      "Epoch 5/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 3.7089 - val_loss: 3.0286\n",
      "Epoch 6/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 3.4232 - val_loss: 3.3445\n",
      "Epoch 7/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 3.3017 - val_loss: 4.0495\n",
      "Epoch 8/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 3.1669 - val_loss: 2.9835\n",
      "Epoch 9/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 3.0429 - val_loss: 2.7853\n",
      "Epoch 10/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.9655 - val_loss: 2.6755\n",
      "Epoch 11/750\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.8077 - val_loss: 2.6230\n",
      "Epoch 12/750\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.7661 - val_loss: 2.7175\n",
      "Epoch 13/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.6725 - val_loss: 2.6609\n",
      "Epoch 14/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.6311 - val_loss: 2.6012\n",
      "Epoch 15/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.5716 - val_loss: 2.7596\n",
      "Epoch 16/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.5444 - val_loss: 2.3970\n",
      "Epoch 17/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.5118 - val_loss: 2.5768\n",
      "Epoch 18/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.4949 - val_loss: 2.4804\n",
      "Epoch 19/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.4505 - val_loss: 2.3950\n",
      "Epoch 20/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.4318 - val_loss: 2.3678\n",
      "Epoch 21/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.4002 - val_loss: 2.5797\n",
      "Epoch 22/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3767 - val_loss: 2.3026\n",
      "Epoch 23/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3641 - val_loss: 2.3084\n",
      "Epoch 24/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3364 - val_loss: 2.2579\n",
      "Epoch 25/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3048 - val_loss: 2.3049\n",
      "Epoch 26/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2965 - val_loss: 2.4367\n",
      "Epoch 27/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2930 - val_loss: 2.3905\n",
      "Epoch 28/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2478 - val_loss: 2.4930\n",
      "Epoch 29/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2120 - val_loss: 2.1721\n",
      "Epoch 30/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.2035 - val_loss: 2.3146\n",
      "Epoch 31/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1944 - val_loss: 2.2023\n",
      "Epoch 32/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1647 - val_loss: 2.1087\n",
      "Epoch 33/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1275 - val_loss: 2.0490\n",
      "Epoch 34/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1290 - val_loss: 2.0817\n",
      "Epoch 35/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1063 - val_loss: 2.1129\n",
      "Epoch 36/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1087 - val_loss: 2.1271\n",
      "Epoch 37/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0881 - val_loss: 2.0264\n",
      "Epoch 38/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0930 - val_loss: 2.0030\n",
      "Epoch 39/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0849 - val_loss: 2.0700\n",
      "Epoch 40/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0575 - val_loss: 2.0194\n",
      "Epoch 41/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.0745 - val_loss: 2.0445\n",
      "Epoch 42/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0558 - val_loss: 1.9564\n",
      "Epoch 43/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0350 - val_loss: 1.9864\n",
      "Epoch 44/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0527 - val_loss: 2.0820\n",
      "Epoch 45/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0161 - val_loss: 2.1050\n",
      "Epoch 46/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0173 - val_loss: 1.9464\n",
      "Epoch 47/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0236 - val_loss: 1.9885\n",
      "Epoch 48/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0137 - val_loss: 2.1258\n",
      "Epoch 49/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9961 - val_loss: 2.1207\n",
      "Epoch 50/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0050 - val_loss: 1.9923\n",
      "Epoch 51/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9915 - val_loss: 2.0212\n",
      "Epoch 52/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9793 - val_loss: 1.9749\n",
      "Epoch 53/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.9717 - val_loss: 2.0343\n",
      "Epoch 54/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.9686 - val_loss: 2.1802\n",
      "Epoch 55/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.9628 - val_loss: 2.1636\n",
      "Epoch 56/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.9766 - val_loss: 2.2850\n",
      "Epoch 57/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.9549 - val_loss: 1.9826\n",
      "Epoch 58/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.9400 - val_loss: 1.9184\n",
      "Epoch 59/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.9322 - val_loss: 1.9256\n",
      "Epoch 60/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9378 - val_loss: 2.1179\n",
      "Epoch 61/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9278 - val_loss: 1.8793\n",
      "Epoch 62/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.9287 - val_loss: 2.0063\n",
      "Epoch 63/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9191 - val_loss: 1.8994\n",
      "Epoch 64/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9025 - val_loss: 1.9453\n",
      "Epoch 65/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9010 - val_loss: 2.0205\n",
      "Epoch 66/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9122 - val_loss: 1.8437\n",
      "Epoch 67/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9043 - val_loss: 1.8985\n",
      "Epoch 68/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8790 - val_loss: 1.9408\n",
      "Epoch 69/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8877 - val_loss: 1.8084\n",
      "Epoch 70/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8765 - val_loss: 1.9656\n",
      "Epoch 71/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8905 - val_loss: 1.9221\n",
      "Epoch 72/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8812 - val_loss: 1.8298\n",
      "Epoch 73/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8885 - val_loss: 1.8629\n",
      "Epoch 74/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8719 - val_loss: 1.8317\n",
      "Epoch 75/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8669 - val_loss: 1.8030\n",
      "Epoch 76/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8641 - val_loss: 1.8960\n",
      "Epoch 77/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8571 - val_loss: 1.8636\n",
      "Epoch 78/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.8601 - val_loss: 1.8380\n",
      "Epoch 79/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8607 - val_loss: 1.8180\n",
      "Epoch 80/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8422 - val_loss: 1.8278\n",
      "Epoch 81/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8408 - val_loss: 1.8417\n",
      "Epoch 82/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8452 - val_loss: 1.9074\n",
      "Epoch 83/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8355 - val_loss: 1.8087\n",
      "Epoch 84/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8374 - val_loss: 1.9067\n",
      "Epoch 85/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8248 - val_loss: 1.8070\n",
      "Epoch 86/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.8273 - val_loss: 1.7823\n",
      "Epoch 87/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8251 - val_loss: 1.8014\n",
      "Epoch 88/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.8187 - val_loss: 1.7700\n",
      "Epoch 89/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8108 - val_loss: 1.8316\n",
      "Epoch 90/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8030 - val_loss: 1.7997\n",
      "Epoch 91/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8265 - val_loss: 1.8836\n",
      "Epoch 92/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.8208 - val_loss: 1.8221\n",
      "Epoch 93/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7992 - val_loss: 1.8424\n",
      "Epoch 94/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.8045 - val_loss: 1.8299\n",
      "Epoch 95/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7965 - val_loss: 1.7802\n",
      "Epoch 96/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7979 - val_loss: 1.7532\n",
      "Epoch 97/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7894 - val_loss: 1.8597\n",
      "Epoch 98/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7829 - val_loss: 1.7845\n",
      "Epoch 99/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7707 - val_loss: 1.7749\n",
      "Epoch 100/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7897 - val_loss: 1.7706\n",
      "Epoch 101/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7753 - val_loss: 1.7063\n",
      "Epoch 102/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7830 - val_loss: 1.7982\n",
      "Epoch 103/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7741 - val_loss: 1.8367\n",
      "Epoch 104/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7870 - val_loss: 1.8322\n",
      "Epoch 105/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7676 - val_loss: 1.7391\n",
      "Epoch 106/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7787 - val_loss: 1.8071\n",
      "Epoch 107/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7709 - val_loss: 1.8700\n",
      "Epoch 108/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7712 - val_loss: 1.7376\n",
      "Epoch 109/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7553 - val_loss: 1.7289\n",
      "Epoch 110/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7660 - val_loss: 1.7636\n",
      "Epoch 111/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7527 - val_loss: 1.7256\n",
      "Epoch 112/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.7596 - val_loss: 1.7235\n",
      "Epoch 113/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7671 - val_loss: 1.7294\n",
      "Epoch 114/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7458 - val_loss: 1.8671\n",
      "Epoch 115/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7542 - val_loss: 1.7324\n",
      "Epoch 116/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7471 - val_loss: 1.7537\n",
      "Epoch 117/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7475 - val_loss: 1.8054\n",
      "Epoch 118/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7511 - val_loss: 1.7391\n",
      "Epoch 119/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7532 - val_loss: 1.6980\n",
      "Epoch 120/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7426 - val_loss: 1.7676\n",
      "Epoch 121/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7471 - val_loss: 1.7241\n",
      "Epoch 122/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7361 - val_loss: 1.7461\n",
      "Epoch 123/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7369 - val_loss: 1.7481\n",
      "Epoch 124/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7456 - val_loss: 1.8670\n",
      "Epoch 125/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7380 - val_loss: 1.8838\n",
      "Epoch 126/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7256 - val_loss: 1.6800\n",
      "Epoch 127/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7278 - val_loss: 1.7505\n",
      "Epoch 128/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.7260 - val_loss: 1.6906\n",
      "Epoch 129/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7153 - val_loss: 1.7128\n",
      "Epoch 130/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7216 - val_loss: 1.7056\n",
      "Epoch 131/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7244 - val_loss: 1.8129\n",
      "Epoch 132/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7088 - val_loss: 1.6797\n",
      "Epoch 133/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7315 - val_loss: 1.7328\n",
      "Epoch 134/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7189 - val_loss: 1.7636\n",
      "Epoch 135/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.6995 - val_loss: 1.8162\n",
      "Epoch 136/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7207 - val_loss: 1.7135\n",
      "Epoch 137/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7200 - val_loss: 1.6665\n",
      "Epoch 138/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.7062 - val_loss: 1.6945\n",
      "Epoch 139/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7065 - val_loss: 1.7515\n",
      "Epoch 140/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7015 - val_loss: 1.7123\n",
      "Epoch 141/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7034 - val_loss: 1.6738\n",
      "Epoch 142/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6987 - val_loss: 1.6850\n",
      "Epoch 143/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7091 - val_loss: 1.6951\n",
      "Epoch 144/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7053 - val_loss: 1.7777\n",
      "Epoch 145/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6988 - val_loss: 1.7365\n",
      "Epoch 146/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7005 - val_loss: 1.7354\n",
      "Epoch 147/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.6947 - val_loss: 1.8279\n",
      "Epoch 148/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6937 - val_loss: 1.7308\n",
      "Epoch 149/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6936 - val_loss: 1.7229\n",
      "Epoch 150/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6982 - val_loss: 1.6827\n",
      "Epoch 151/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6938 - val_loss: 1.8040\n",
      "Epoch 152/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.7047 - val_loss: 1.7457\n",
      "Epoch 153/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6801 - val_loss: 1.7259\n",
      "Epoch 154/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6786 - val_loss: 1.6850\n",
      "Epoch 155/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6920 - val_loss: 1.6829\n",
      "Epoch 156/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6871 - val_loss: 1.7113\n",
      "Epoch 157/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6845 - val_loss: 1.7121\n",
      "Epoch 158/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6798 - val_loss: 1.7135\n",
      "Epoch 159/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6807 - val_loss: 1.7522\n",
      "Epoch 160/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6703 - val_loss: 1.7015\n",
      "Epoch 161/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6767 - val_loss: 1.7001\n",
      "Epoch 162/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6737 - val_loss: 1.6657\n",
      "Epoch 163/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6761 - val_loss: 1.6791\n",
      "Epoch 164/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6691 - val_loss: 1.7380\n",
      "Epoch 165/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6610 - val_loss: 1.6754\n",
      "Epoch 166/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6697 - val_loss: 1.7267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6722 - val_loss: 1.8191\n",
      "Epoch 168/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6708 - val_loss: 1.6750\n",
      "Epoch 169/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6671 - val_loss: 1.7513\n",
      "Epoch 170/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6620 - val_loss: 1.6626\n",
      "Epoch 171/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6447 - val_loss: 1.6851\n",
      "Epoch 172/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.6643 - val_loss: 1.7092\n",
      "Epoch 173/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6633 - val_loss: 1.8124\n",
      "Epoch 174/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6522 - val_loss: 1.7023\n",
      "Epoch 175/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6601 - val_loss: 1.6773\n",
      "Epoch 176/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6716 - val_loss: 1.7259\n",
      "Epoch 177/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6585 - val_loss: 1.6694\n",
      "Epoch 178/750\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6526 - val_loss: 1.6406\n",
      "Epoch 179/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6546 - val_loss: 1.6609\n",
      "Epoch 180/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6514 - val_loss: 1.6305\n",
      "Epoch 181/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6538 - val_loss: 1.6854\n",
      "Epoch 182/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6539 - val_loss: 1.6821\n",
      "Epoch 183/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6516 - val_loss: 1.6833\n",
      "Epoch 184/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6563 - val_loss: 1.7156\n",
      "Epoch 185/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6550 - val_loss: 1.6453\n",
      "Epoch 186/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6581 - val_loss: 1.6977\n",
      "Epoch 187/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6471 - val_loss: 1.7254\n",
      "Epoch 188/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6435 - val_loss: 1.6610\n",
      "Epoch 189/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6426 - val_loss: 1.6884\n",
      "Epoch 190/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6418 - val_loss: 1.6654\n",
      "Epoch 191/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6431 - val_loss: 1.6514\n",
      "Epoch 192/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6501 - val_loss: 1.6261\n",
      "Epoch 193/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6372 - val_loss: 1.6599\n",
      "Epoch 194/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6334 - val_loss: 1.6223\n",
      "Epoch 195/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6321 - val_loss: 1.6175\n",
      "Epoch 196/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6363 - val_loss: 1.6696\n",
      "Epoch 197/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6441 - val_loss: 1.6427\n",
      "Epoch 198/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6317 - val_loss: 1.7515\n",
      "Epoch 199/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6384 - val_loss: 1.7307\n",
      "Epoch 200/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6333 - val_loss: 1.7450\n",
      "Epoch 201/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6415 - val_loss: 1.6495\n",
      "Epoch 202/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6329 - val_loss: 1.6303\n",
      "Epoch 203/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6198 - val_loss: 1.6183\n",
      "Epoch 204/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6270 - val_loss: 1.6342\n",
      "Epoch 205/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6238 - val_loss: 1.5903\n",
      "Epoch 206/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6347 - val_loss: 1.5946\n",
      "Epoch 207/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6276 - val_loss: 1.6126\n",
      "Epoch 208/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6236 - val_loss: 1.5825\n",
      "Epoch 209/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6246 - val_loss: 1.6162\n",
      "Epoch 210/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6323 - val_loss: 1.6472\n",
      "Epoch 211/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6223 - val_loss: 1.6155\n",
      "Epoch 212/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6219 - val_loss: 1.6113\n",
      "Epoch 213/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6335 - val_loss: 1.7246\n",
      "Epoch 214/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6170 - val_loss: 1.7153\n",
      "Epoch 215/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6135 - val_loss: 1.5865\n",
      "Epoch 216/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6194 - val_loss: 1.6596\n",
      "Epoch 217/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5989 - val_loss: 1.6242\n",
      "Epoch 218/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6140 - val_loss: 1.7767\n",
      "Epoch 219/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6068 - val_loss: 1.6304\n",
      "Epoch 220/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6075 - val_loss: 1.6554\n",
      "Epoch 221/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.6101 - val_loss: 1.5959\n",
      "Epoch 222/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6256 - val_loss: 1.7125\n",
      "Epoch 223/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6057 - val_loss: 1.7282\n",
      "Epoch 224/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6086 - val_loss: 1.7019\n",
      "Epoch 225/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6055 - val_loss: 1.5556\n",
      "Epoch 226/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6032 - val_loss: 1.6332\n",
      "Epoch 227/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6100 - val_loss: 1.6417\n",
      "Epoch 228/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.6085 - val_loss: 1.6523\n",
      "Epoch 229/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6066 - val_loss: 1.6763\n",
      "Epoch 230/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5993 - val_loss: 1.5878\n",
      "Epoch 231/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6101 - val_loss: 1.6390\n",
      "Epoch 232/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6044 - val_loss: 1.6455\n",
      "Epoch 233/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6034 - val_loss: 1.6574\n",
      "Epoch 234/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6050 - val_loss: 1.5964\n",
      "Epoch 235/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6016 - val_loss: 1.6324\n",
      "Epoch 236/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6086 - val_loss: 1.5988\n",
      "Epoch 237/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5932 - val_loss: 1.7938\n",
      "Epoch 238/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6067 - val_loss: 1.6486\n",
      "Epoch 239/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.5919 - val_loss: 1.6369\n",
      "Epoch 240/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5910 - val_loss: 1.6250\n",
      "Epoch 241/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6027 - val_loss: 1.5906\n",
      "Epoch 242/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5955 - val_loss: 1.6640\n",
      "Epoch 243/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5950 - val_loss: 1.5626\n",
      "Epoch 244/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5979 - val_loss: 1.6671\n",
      "Epoch 245/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6075 - val_loss: 1.6150\n",
      "Epoch 246/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5833 - val_loss: 1.6759\n",
      "Epoch 247/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5940 - val_loss: 1.5735\n",
      "Epoch 248/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5903 - val_loss: 1.6678\n",
      "Epoch 249/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5836 - val_loss: 1.5886\n",
      "Epoch 250/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5938 - val_loss: 1.6044\n",
      "Epoch 251/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5860 - val_loss: 1.6758\n",
      "Epoch 252/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5883 - val_loss: 1.6033\n",
      "Epoch 253/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5882 - val_loss: 1.6099\n",
      "Epoch 254/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5807 - val_loss: 1.6521\n",
      "Epoch 255/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5839 - val_loss: 1.6264\n",
      "Epoch 256/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5852 - val_loss: 1.5868\n",
      "Epoch 257/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5877 - val_loss: 1.6485\n",
      "Epoch 258/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5792 - val_loss: 1.6282\n",
      "Epoch 259/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5876 - val_loss: 1.6593\n",
      "Epoch 260/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5742 - val_loss: 1.6768\n",
      "Epoch 261/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5811 - val_loss: 1.5943\n",
      "Epoch 262/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5845 - val_loss: 1.6184\n",
      "Epoch 263/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5781 - val_loss: 1.6036\n",
      "Epoch 264/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5738 - val_loss: 1.5920\n",
      "Epoch 265/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5837 - val_loss: 1.6041\n",
      "Epoch 266/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5826 - val_loss: 1.6762\n",
      "Epoch 267/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5799 - val_loss: 1.5424\n",
      "Epoch 268/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5697 - val_loss: 1.5864\n",
      "Epoch 269/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5745 - val_loss: 1.5933\n",
      "Epoch 270/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5863 - val_loss: 1.6375\n",
      "Epoch 271/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5706 - val_loss: 1.6037\n",
      "Epoch 272/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5738 - val_loss: 1.6083\n",
      "Epoch 273/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.5757 - val_loss: 1.5531\n",
      "Epoch 274/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5719 - val_loss: 1.6846\n",
      "Epoch 275/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5696 - val_loss: 1.5638\n",
      "Epoch 276/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5662 - val_loss: 1.6545\n",
      "Epoch 277/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5595 - val_loss: 1.5893\n",
      "Epoch 278/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5708 - val_loss: 1.6950\n",
      "Epoch 279/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5749 - val_loss: 1.7222\n",
      "Epoch 280/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5688 - val_loss: 1.5800\n",
      "Epoch 281/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5689 - val_loss: 1.6053\n",
      "Epoch 282/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5689 - val_loss: 1.6266\n",
      "Epoch 283/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5678 - val_loss: 1.6178\n",
      "Epoch 284/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.5678 - val_loss: 1.6098\n",
      "Epoch 285/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5587 - val_loss: 1.6188\n",
      "Epoch 286/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5674 - val_loss: 1.5731\n",
      "Epoch 287/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5694 - val_loss: 1.5920\n",
      "Epoch 288/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5596 - val_loss: 1.7013\n",
      "Epoch 289/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.5632 - val_loss: 1.5904\n",
      "Epoch 290/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5705 - val_loss: 1.6295\n",
      "Epoch 291/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5643 - val_loss: 1.5999\n",
      "Epoch 292/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5671 - val_loss: 1.6155\n",
      "Epoch 293/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5564 - val_loss: 1.6235\n",
      "Epoch 294/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5665 - val_loss: 1.6302\n",
      "Epoch 295/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5566 - val_loss: 1.6173\n",
      "Epoch 296/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5472 - val_loss: 1.6032\n",
      "Epoch 297/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5591 - val_loss: 1.6062\n",
      "Epoch 298/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5581 - val_loss: 1.5502\n",
      "Epoch 299/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5561 - val_loss: 1.6186\n",
      "Epoch 300/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5600 - val_loss: 1.6359\n",
      "Epoch 301/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5590 - val_loss: 1.6086\n",
      "Epoch 302/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5564 - val_loss: 1.5801\n",
      "Epoch 303/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5516 - val_loss: 1.7424\n",
      "Epoch 304/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5585 - val_loss: 1.5590\n",
      "Epoch 305/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5512 - val_loss: 1.5724\n",
      "Epoch 306/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5494 - val_loss: 1.6297\n",
      "Epoch 307/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5602 - val_loss: 1.5668\n",
      "Epoch 308/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5447 - val_loss: 1.5888\n",
      "Epoch 309/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5465 - val_loss: 1.5719\n",
      "Epoch 310/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5474 - val_loss: 1.6407\n",
      "Epoch 311/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5507 - val_loss: 1.5751\n",
      "Epoch 312/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5547 - val_loss: 1.5614\n",
      "Epoch 313/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5440 - val_loss: 1.5356\n",
      "Epoch 314/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5574 - val_loss: 1.5967\n",
      "Epoch 315/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.5494 - val_loss: 1.6076\n",
      "Epoch 316/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5465 - val_loss: 1.6320\n",
      "Epoch 317/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.5499 - val_loss: 1.6319\n",
      "Epoch 318/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5530 - val_loss: 1.5889\n",
      "Epoch 319/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5490 - val_loss: 1.6452\n",
      "Epoch 320/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5499 - val_loss: 1.6170\n",
      "Epoch 321/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5533 - val_loss: 1.5483\n",
      "Epoch 322/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5478 - val_loss: 1.5555\n",
      "Epoch 323/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5485 - val_loss: 1.5988\n",
      "Epoch 324/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5362 - val_loss: 1.6082\n",
      "Epoch 325/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5444 - val_loss: 1.5392\n",
      "Epoch 326/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5478 - val_loss: 1.5121\n",
      "Epoch 327/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5341 - val_loss: 1.7114\n",
      "Epoch 328/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5352 - val_loss: 1.5377\n",
      "Epoch 329/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5511 - val_loss: 1.6328\n",
      "Epoch 330/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5388 - val_loss: 1.5396\n",
      "Epoch 331/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5426 - val_loss: 1.5763\n",
      "Epoch 332/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5342 - val_loss: 1.5764\n",
      "Epoch 333/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5443 - val_loss: 1.5235\n",
      "Epoch 334/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5357 - val_loss: 1.5869\n",
      "Epoch 335/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5408 - val_loss: 1.6183\n",
      "Epoch 336/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5348 - val_loss: 1.5380\n",
      "Epoch 337/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5425 - val_loss: 1.6166\n",
      "Epoch 338/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5355 - val_loss: 1.5457\n",
      "Epoch 339/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5319 - val_loss: 1.6142\n",
      "Epoch 340/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5425 - val_loss: 1.5453\n",
      "Epoch 341/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5384 - val_loss: 1.5174\n",
      "Epoch 342/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5337 - val_loss: 1.5770\n",
      "Epoch 343/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5311 - val_loss: 1.5910\n",
      "Epoch 344/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5342 - val_loss: 1.5189\n",
      "Epoch 345/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5298 - val_loss: 1.5498\n",
      "Epoch 346/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5313 - val_loss: 1.5524\n",
      "Epoch 347/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5322 - val_loss: 1.5694\n",
      "Epoch 348/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5308 - val_loss: 1.6110\n",
      "Epoch 349/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5305 - val_loss: 1.5418\n",
      "Epoch 350/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5293 - val_loss: 1.6078\n",
      "Epoch 351/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5407 - val_loss: 1.5535\n",
      "Epoch 352/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5339 - val_loss: 1.5450\n",
      "Epoch 353/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5313 - val_loss: 1.5275\n",
      "Epoch 354/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5334 - val_loss: 1.5350\n",
      "Epoch 355/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5185 - val_loss: 1.5484\n",
      "Epoch 356/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5217 - val_loss: 1.5548\n",
      "Epoch 357/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5244 - val_loss: 1.5456\n",
      "Epoch 358/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5314 - val_loss: 1.5864\n",
      "Epoch 359/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5238 - val_loss: 1.5107\n",
      "Epoch 360/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5213 - val_loss: 1.5345\n",
      "Epoch 361/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5338 - val_loss: 1.5404\n",
      "Epoch 362/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5252 - val_loss: 1.5423\n",
      "Epoch 363/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5203 - val_loss: 1.5776\n",
      "Epoch 364/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5314 - val_loss: 1.5641\n",
      "Epoch 365/750\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5238 - val_loss: 1.5358\n",
      "Epoch 366/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5170 - val_loss: 1.5487\n",
      "Epoch 367/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5199 - val_loss: 1.5435\n",
      "Epoch 368/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5180 - val_loss: 1.5535\n",
      "Epoch 369/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5199 - val_loss: 1.5448\n",
      "Epoch 370/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5349 - val_loss: 1.5307\n",
      "Epoch 371/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5163 - val_loss: 1.5326\n",
      "Epoch 372/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5266 - val_loss: 1.5256\n",
      "Epoch 373/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5128 - val_loss: 1.5684\n",
      "Epoch 374/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5101 - val_loss: 1.5504\n",
      "Epoch 375/750\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5163 - val_loss: 1.5273\n",
      "Epoch 376/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5202 - val_loss: 1.6090\n",
      "Epoch 377/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5287 - val_loss: 1.5580\n",
      "Epoch 378/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5252 - val_loss: 1.5501\n",
      "Epoch 379/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5115 - val_loss: 1.4993\n",
      "Epoch 380/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5178 - val_loss: 1.5710\n",
      "Epoch 381/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5182 - val_loss: 1.5775\n",
      "Epoch 382/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5201 - val_loss: 1.5858\n",
      "Epoch 383/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5113 - val_loss: 1.5274\n",
      "Epoch 384/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5181 - val_loss: 1.4905\n",
      "Epoch 385/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5291 - val_loss: 1.5792\n",
      "Epoch 386/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5144 - val_loss: 1.5552\n",
      "Epoch 387/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5063 - val_loss: 1.5638\n",
      "Epoch 388/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5181 - val_loss: 1.5357\n",
      "Epoch 389/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5069 - val_loss: 1.5407\n",
      "Epoch 390/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5218 - val_loss: 1.4972\n",
      "Epoch 391/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5136 - val_loss: 1.5251\n",
      "Epoch 392/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5040 - val_loss: 1.5362\n",
      "Epoch 393/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5078 - val_loss: 1.5248\n",
      "Epoch 394/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5052 - val_loss: 1.5554\n",
      "Epoch 395/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5059 - val_loss: 1.5234\n",
      "Epoch 396/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5185 - val_loss: 1.4891\n",
      "Epoch 397/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5050 - val_loss: 1.5040\n",
      "Epoch 398/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5034 - val_loss: 1.5530\n",
      "Epoch 399/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5062 - val_loss: 1.5455\n",
      "Epoch 400/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.5098 - val_loss: 1.5210\n",
      "Epoch 401/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5043 - val_loss: 1.6070\n",
      "Epoch 402/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5025 - val_loss: 1.5255\n",
      "Epoch 403/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5045 - val_loss: 1.5870\n",
      "Epoch 404/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5104 - val_loss: 1.5546\n",
      "Epoch 405/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5000 - val_loss: 1.5966\n",
      "Epoch 406/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5055 - val_loss: 1.4979\n",
      "Epoch 407/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5064 - val_loss: 1.5640\n",
      "Epoch 408/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5154 - val_loss: 1.6480\n",
      "Epoch 409/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4997 - val_loss: 1.5264\n",
      "Epoch 410/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5062 - val_loss: 1.5322\n",
      "Epoch 411/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5068 - val_loss: 1.5569\n",
      "Epoch 412/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5023 - val_loss: 1.5285\n",
      "Epoch 413/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5018 - val_loss: 1.5393\n",
      "Epoch 414/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5004 - val_loss: 1.5493\n",
      "Epoch 415/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5000 - val_loss: 1.5553\n",
      "Epoch 416/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4998 - val_loss: 1.5208\n",
      "Epoch 417/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4987 - val_loss: 1.5323\n",
      "Epoch 418/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.5001 - val_loss: 1.5370\n",
      "Epoch 419/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5002 - val_loss: 1.5537\n",
      "Epoch 420/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4982 - val_loss: 1.5309\n",
      "Epoch 421/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4932 - val_loss: 1.5049\n",
      "Epoch 422/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4976 - val_loss: 1.5268\n",
      "Epoch 423/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5006 - val_loss: 1.4984\n",
      "Epoch 424/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5003 - val_loss: 1.4895\n",
      "Epoch 425/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4939 - val_loss: 1.5669\n",
      "Epoch 426/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4987 - val_loss: 1.5806\n",
      "Epoch 427/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4952 - val_loss: 1.5757\n",
      "Epoch 428/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.5015 - val_loss: 1.5081\n",
      "Epoch 429/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4977 - val_loss: 1.6580\n",
      "Epoch 430/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.5003 - val_loss: 1.6519\n",
      "Epoch 431/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4950 - val_loss: 1.5295\n",
      "Epoch 432/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4964 - val_loss: 1.6328\n",
      "Epoch 433/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4910 - val_loss: 1.5077\n",
      "Epoch 434/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4993 - val_loss: 1.5847\n",
      "Epoch 435/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4995 - val_loss: 1.5194\n",
      "Epoch 436/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4931 - val_loss: 1.5048\n",
      "Epoch 437/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4959 - val_loss: 1.4961\n",
      "Epoch 438/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4965 - val_loss: 1.5428\n",
      "Epoch 439/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4885 - val_loss: 1.5705\n",
      "Epoch 440/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4900 - val_loss: 1.4758\n",
      "Epoch 441/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4961 - val_loss: 1.5146\n",
      "Epoch 442/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4987 - val_loss: 1.5837\n",
      "Epoch 443/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4882 - val_loss: 1.5133\n",
      "Epoch 444/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4961 - val_loss: 1.5864\n",
      "Epoch 445/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4969 - val_loss: 1.5049\n",
      "Epoch 446/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4877 - val_loss: 1.5090\n",
      "Epoch 447/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4885 - val_loss: 1.4962\n",
      "Epoch 448/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4893 - val_loss: 1.4945\n",
      "Epoch 449/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4863 - val_loss: 1.5173\n",
      "Epoch 450/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4984 - val_loss: 1.5387\n",
      "Epoch 451/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4857 - val_loss: 1.5502\n",
      "Epoch 452/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4885 - val_loss: 1.5141\n",
      "Epoch 453/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4924 - val_loss: 1.5007\n",
      "Epoch 454/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4862 - val_loss: 1.5090\n",
      "Epoch 455/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4851 - val_loss: 1.6138\n",
      "Epoch 456/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4878 - val_loss: 1.5380\n",
      "Epoch 457/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4817 - val_loss: 1.5119\n",
      "Epoch 458/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4951 - val_loss: 1.4991\n",
      "Epoch 459/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4858 - val_loss: 1.4662\n",
      "Epoch 460/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4928 - val_loss: 1.5017\n",
      "Epoch 461/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4811 - val_loss: 1.5044\n",
      "Epoch 462/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4827 - val_loss: 1.5297\n",
      "Epoch 463/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4816 - val_loss: 1.5706\n",
      "Epoch 464/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4906 - val_loss: 1.5281\n",
      "Epoch 465/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4873 - val_loss: 1.4978\n",
      "Epoch 466/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4773 - val_loss: 1.5235\n",
      "Epoch 467/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4835 - val_loss: 1.5044\n",
      "Epoch 468/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4876 - val_loss: 1.5368\n",
      "Epoch 469/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4889 - val_loss: 1.4889\n",
      "Epoch 470/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4862 - val_loss: 1.5151\n",
      "Epoch 471/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4852 - val_loss: 1.5261\n",
      "Epoch 472/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4852 - val_loss: 1.6036\n",
      "Epoch 473/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4794 - val_loss: 1.5372\n",
      "Epoch 474/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4817 - val_loss: 1.6722\n",
      "Epoch 475/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4815 - val_loss: 1.5080\n",
      "Epoch 476/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4801 - val_loss: 1.5541\n",
      "Epoch 477/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4849 - val_loss: 1.5328\n",
      "Epoch 478/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4807 - val_loss: 1.5272\n",
      "Epoch 479/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4726 - val_loss: 1.5120\n",
      "Epoch 480/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4803 - val_loss: 1.5366\n",
      "Epoch 481/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4783 - val_loss: 1.5035\n",
      "Epoch 482/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4863 - val_loss: 1.5061\n",
      "Epoch 483/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4787 - val_loss: 1.4830\n",
      "Epoch 484/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4707 - val_loss: 1.5045\n",
      "Epoch 485/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4806 - val_loss: 1.5294\n",
      "Epoch 486/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4728 - val_loss: 1.5506\n",
      "Epoch 487/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4764 - val_loss: 1.4768\n",
      "Epoch 488/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4773 - val_loss: 1.4740\n",
      "Epoch 489/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4821 - val_loss: 1.4871\n",
      "Epoch 490/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4704 - val_loss: 1.4943\n",
      "Epoch 491/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4745 - val_loss: 1.5112\n",
      "Epoch 492/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4680 - val_loss: 1.5272\n",
      "Epoch 493/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4846 - val_loss: 1.5573\n",
      "Epoch 494/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4633 - val_loss: 1.5128\n",
      "Epoch 495/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4753 - val_loss: 1.5059\n",
      "Epoch 496/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4671 - val_loss: 1.5385\n",
      "Epoch 497/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4773 - val_loss: 1.4804\n",
      "Epoch 498/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4662 - val_loss: 1.5235\n",
      "Epoch 499/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4709 - val_loss: 1.4738\n",
      "Epoch 500/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4867 - val_loss: 1.5674\n",
      "Epoch 501/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4714 - val_loss: 1.5201\n",
      "Epoch 502/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4708 - val_loss: 1.5748\n",
      "Epoch 503/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4614 - val_loss: 1.5401\n",
      "Epoch 504/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4724 - val_loss: 1.5315\n",
      "Epoch 505/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4806 - val_loss: 1.4848\n",
      "Epoch 506/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4738 - val_loss: 1.4790\n",
      "Epoch 507/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4713 - val_loss: 1.5656\n",
      "Epoch 508/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4773 - val_loss: 1.5078\n",
      "Epoch 509/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4629 - val_loss: 1.4943\n",
      "Epoch 510/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4752 - val_loss: 1.5360\n",
      "Epoch 511/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4740 - val_loss: 1.4637\n",
      "Epoch 512/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4692 - val_loss: 1.5160\n",
      "Epoch 513/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4732 - val_loss: 1.4728\n",
      "Epoch 514/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4718 - val_loss: 1.5241\n",
      "Epoch 515/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4708 - val_loss: 1.5345\n",
      "Epoch 516/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4763 - val_loss: 1.4983\n",
      "Epoch 517/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4573 - val_loss: 1.4920\n",
      "Epoch 518/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4746 - val_loss: 1.5259\n",
      "Epoch 519/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4676 - val_loss: 1.4941\n",
      "Epoch 520/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4684 - val_loss: 1.5110\n",
      "Epoch 521/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4635 - val_loss: 1.5240\n",
      "Epoch 522/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4658 - val_loss: 1.4931\n",
      "Epoch 523/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4670 - val_loss: 1.4748\n",
      "Epoch 524/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4608 - val_loss: 1.4941\n",
      "Epoch 525/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4713 - val_loss: 1.5949\n",
      "Epoch 526/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4754 - val_loss: 1.4552\n",
      "Epoch 527/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4646 - val_loss: 1.5281\n",
      "Epoch 528/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4711 - val_loss: 1.5590\n",
      "Epoch 529/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4697 - val_loss: 1.4514\n",
      "Epoch 530/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4851 - val_loss: 1.4851\n",
      "Epoch 531/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4645 - val_loss: 1.5277\n",
      "Epoch 532/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4602 - val_loss: 1.5307\n",
      "Epoch 533/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4626 - val_loss: 1.4685\n",
      "Epoch 534/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4644 - val_loss: 1.4703\n",
      "Epoch 535/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4634 - val_loss: 1.5409\n",
      "Epoch 536/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4660 - val_loss: 1.4987\n",
      "Epoch 537/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4626 - val_loss: 1.5390\n",
      "Epoch 538/750\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4622 - val_loss: 1.5336\n",
      "Epoch 539/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4637 - val_loss: 1.4566\n",
      "Epoch 540/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4638 - val_loss: 1.5078\n",
      "Epoch 541/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4572 - val_loss: 1.4859\n",
      "Epoch 542/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4571 - val_loss: 1.4856\n",
      "Epoch 543/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4622 - val_loss: 1.4961\n",
      "Epoch 544/750\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4679 - val_loss: 1.4732\n",
      "Epoch 545/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4654 - val_loss: 1.5882\n",
      "Epoch 546/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4642 - val_loss: 1.4809\n",
      "Epoch 547/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4635 - val_loss: 1.5243\n",
      "Epoch 548/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4631 - val_loss: 1.4787\n",
      "Epoch 549/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4549 - val_loss: 1.5422\n",
      "Epoch 550/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4679 - val_loss: 1.5642\n",
      "Epoch 551/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4624 - val_loss: 1.5689\n",
      "Epoch 552/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4631 - val_loss: 1.4911\n",
      "Epoch 553/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4584 - val_loss: 1.4919\n",
      "Epoch 554/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4562 - val_loss: 1.5479\n",
      "Epoch 555/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4674 - val_loss: 1.4988\n",
      "Epoch 556/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4593 - val_loss: 1.5130\n",
      "Epoch 557/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4587 - val_loss: 1.5278\n",
      "Epoch 558/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4605 - val_loss: 1.5079\n",
      "Epoch 559/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4606 - val_loss: 1.5329\n",
      "Epoch 560/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4605 - val_loss: 1.4690\n",
      "Epoch 561/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4546 - val_loss: 1.5092\n",
      "Epoch 562/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4534 - val_loss: 1.4768\n",
      "Epoch 563/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4506 - val_loss: 1.6501\n",
      "Epoch 564/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4631 - val_loss: 1.5835\n",
      "Epoch 565/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4442 - val_loss: 1.4877\n",
      "Epoch 566/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4573 - val_loss: 1.5050\n",
      "Epoch 567/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4504 - val_loss: 1.5079\n",
      "Epoch 568/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4569 - val_loss: 1.4844\n",
      "Epoch 569/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4536 - val_loss: 1.5240\n",
      "Epoch 570/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4569 - val_loss: 1.4595\n",
      "Epoch 571/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4581 - val_loss: 1.5776\n",
      "Epoch 572/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4530 - val_loss: 1.4930\n",
      "Epoch 573/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4590 - val_loss: 1.5123\n",
      "Epoch 574/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4477 - val_loss: 1.4465\n",
      "Epoch 575/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4519 - val_loss: 1.5199\n",
      "Epoch 576/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4599 - val_loss: 1.5382\n",
      "Epoch 577/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4573 - val_loss: 1.5366\n",
      "Epoch 578/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4571 - val_loss: 1.4414\n",
      "Epoch 579/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4473 - val_loss: 1.4602\n",
      "Epoch 580/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4595 - val_loss: 1.5197\n",
      "Epoch 581/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4619 - val_loss: 1.5044\n",
      "Epoch 582/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4499 - val_loss: 1.4840\n",
      "Epoch 583/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4500 - val_loss: 1.5168\n",
      "Epoch 584/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4504 - val_loss: 1.5203\n",
      "Epoch 585/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4429 - val_loss: 1.5267\n",
      "Epoch 586/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4528 - val_loss: 1.5508\n",
      "Epoch 587/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4516 - val_loss: 1.4846\n",
      "Epoch 588/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4499 - val_loss: 1.5346\n",
      "Epoch 589/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4530 - val_loss: 1.5236\n",
      "Epoch 590/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4496 - val_loss: 1.4844\n",
      "Epoch 591/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4443 - val_loss: 1.5214\n",
      "Epoch 592/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4498 - val_loss: 1.4957\n",
      "Epoch 593/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4650 - val_loss: 1.5625\n",
      "Epoch 594/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4493 - val_loss: 1.5061\n",
      "Epoch 595/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4485 - val_loss: 1.5441\n",
      "Epoch 596/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4438 - val_loss: 1.4842\n",
      "Epoch 597/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4509 - val_loss: 1.4735\n",
      "Epoch 598/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4499 - val_loss: 1.4811\n",
      "Epoch 599/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4486 - val_loss: 1.4913\n",
      "Epoch 600/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4535 - val_loss: 1.4666\n",
      "Epoch 601/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4418 - val_loss: 1.5139\n",
      "Epoch 602/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4506 - val_loss: 1.5282\n",
      "Epoch 603/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4421 - val_loss: 1.5248\n",
      "Epoch 604/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4416 - val_loss: 1.4699\n",
      "Epoch 605/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4496 - val_loss: 1.5170\n",
      "Epoch 606/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4510 - val_loss: 1.4767\n",
      "Epoch 607/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4452 - val_loss: 1.4808\n",
      "Epoch 608/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4445 - val_loss: 1.4772\n",
      "Epoch 609/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4404 - val_loss: 1.4987\n",
      "Epoch 610/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4498 - val_loss: 1.4525\n",
      "Epoch 611/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4476 - val_loss: 1.5570\n",
      "Epoch 612/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4512 - val_loss: 1.4759\n",
      "Epoch 613/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4396 - val_loss: 1.4703\n",
      "Epoch 614/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4446 - val_loss: 1.4437\n",
      "Epoch 615/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4376 - val_loss: 1.5091\n",
      "Epoch 616/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4468 - val_loss: 1.4791\n",
      "Epoch 617/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4432 - val_loss: 1.4920\n",
      "Epoch 618/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4420 - val_loss: 1.4542\n",
      "Epoch 619/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4465 - val_loss: 1.4826\n",
      "Epoch 620/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4408 - val_loss: 1.5388\n",
      "Epoch 621/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4461 - val_loss: 1.4512\n",
      "Epoch 622/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4383 - val_loss: 1.4432\n",
      "Epoch 623/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4354 - val_loss: 1.4932\n",
      "Epoch 624/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4441 - val_loss: 1.4792\n",
      "Epoch 625/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4396 - val_loss: 1.4890\n",
      "Epoch 626/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4441 - val_loss: 1.6204\n",
      "Epoch 627/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4457 - val_loss: 1.4431\n",
      "Epoch 628/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4430 - val_loss: 1.4878\n",
      "Epoch 629/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4340 - val_loss: 1.5303\n",
      "Epoch 630/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4487 - val_loss: 1.4974\n",
      "Epoch 631/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4367 - val_loss: 1.4949\n",
      "Epoch 632/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4362 - val_loss: 1.4994\n",
      "Epoch 633/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4382 - val_loss: 1.4651\n",
      "Epoch 634/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4381 - val_loss: 1.5228\n",
      "Epoch 635/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4388 - val_loss: 1.5360\n",
      "Epoch 636/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4411 - val_loss: 1.4371\n",
      "Epoch 637/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4427 - val_loss: 1.4320\n",
      "Epoch 638/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4396 - val_loss: 1.5619\n",
      "Epoch 639/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4376 - val_loss: 1.5670\n",
      "Epoch 640/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4415 - val_loss: 1.5710\n",
      "Epoch 641/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4358 - val_loss: 1.4540\n",
      "Epoch 642/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4386 - val_loss: 1.4932\n",
      "Epoch 643/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4323 - val_loss: 1.4237\n",
      "Epoch 644/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4322 - val_loss: 1.4652\n",
      "Epoch 645/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4506 - val_loss: 1.5088\n",
      "Epoch 646/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4284 - val_loss: 1.4597\n",
      "Epoch 647/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4388 - val_loss: 1.5739\n",
      "Epoch 648/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4374 - val_loss: 1.4686\n",
      "Epoch 649/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4304 - val_loss: 1.5585\n",
      "Epoch 650/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4421 - val_loss: 1.5392\n",
      "Epoch 651/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4304 - val_loss: 1.4645\n",
      "Epoch 652/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4400 - val_loss: 1.4533\n",
      "Epoch 653/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4355 - val_loss: 1.6525\n",
      "Epoch 654/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4340 - val_loss: 1.5034\n",
      "Epoch 655/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4484 - val_loss: 1.4719\n",
      "Epoch 656/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4316 - val_loss: 1.5187\n",
      "Epoch 657/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4363 - val_loss: 1.4306\n",
      "Epoch 658/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4405 - val_loss: 1.4823\n",
      "Epoch 659/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4333 - val_loss: 1.5855\n",
      "Epoch 660/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4345 - val_loss: 1.5431\n",
      "Epoch 661/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4410 - val_loss: 1.4579\n",
      "Epoch 662/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4318 - val_loss: 1.4820\n",
      "Epoch 663/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4362 - val_loss: 1.4749\n",
      "Epoch 664/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4332 - val_loss: 1.4804\n",
      "Epoch 665/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4342 - val_loss: 1.4625\n",
      "Epoch 666/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4288 - val_loss: 1.4830\n",
      "Epoch 667/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4352 - val_loss: 1.4604\n",
      "Epoch 668/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4380 - val_loss: 1.4561\n",
      "Epoch 669/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4339 - val_loss: 1.4515\n",
      "Epoch 670/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4330 - val_loss: 1.5609\n",
      "Epoch 671/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4319 - val_loss: 1.4436\n",
      "Epoch 672/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4275 - val_loss: 1.4406\n",
      "Epoch 673/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4390 - val_loss: 1.4834\n",
      "Epoch 674/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4299 - val_loss: 1.4517\n",
      "Epoch 675/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4280 - val_loss: 1.5309\n",
      "Epoch 676/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4314 - val_loss: 1.4544\n",
      "Epoch 677/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4339 - val_loss: 1.4254\n",
      "Epoch 678/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4272 - val_loss: 1.5283\n",
      "Epoch 679/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4239 - val_loss: 1.5268\n",
      "Epoch 680/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4347 - val_loss: 1.4330\n",
      "Epoch 681/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4219 - val_loss: 1.5298\n",
      "Epoch 682/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4256 - val_loss: 1.4704\n",
      "Epoch 683/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4359 - val_loss: 1.4899\n",
      "Epoch 684/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4327 - val_loss: 1.4283\n",
      "Epoch 685/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4319 - val_loss: 1.5423\n",
      "Epoch 686/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4277 - val_loss: 1.5701\n",
      "Epoch 687/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4262 - val_loss: 1.4217\n",
      "Epoch 688/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4310 - val_loss: 1.5197\n",
      "Epoch 689/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4259 - val_loss: 1.4512\n",
      "Epoch 690/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4382 - val_loss: 1.4871\n",
      "Epoch 691/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4314 - val_loss: 1.5121\n",
      "Epoch 692/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4211 - val_loss: 1.4614\n",
      "Epoch 693/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4299 - val_loss: 1.4914\n",
      "Epoch 694/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4272 - val_loss: 1.5330\n",
      "Epoch 695/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4306 - val_loss: 1.4930\n",
      "Epoch 696/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4208 - val_loss: 1.4650\n",
      "Epoch 697/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4252 - val_loss: 1.4734\n",
      "Epoch 698/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4227 - val_loss: 1.4595\n",
      "Epoch 699/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4271 - val_loss: 1.4531\n",
      "Epoch 700/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4232 - val_loss: 1.4576\n",
      "Epoch 701/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4322 - val_loss: 1.4327\n",
      "Epoch 702/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4297 - val_loss: 1.5492\n",
      "Epoch 703/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4198 - val_loss: 1.4463\n",
      "Epoch 704/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4236 - val_loss: 1.5033\n",
      "Epoch 705/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4366 - val_loss: 1.4749\n",
      "Epoch 706/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4273 - val_loss: 1.4487\n",
      "Epoch 707/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4348 - val_loss: 1.4810\n",
      "Epoch 708/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4255 - val_loss: 1.4849\n",
      "Epoch 709/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4294 - val_loss: 1.4617\n",
      "Epoch 710/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4228 - val_loss: 1.4411\n",
      "Epoch 711/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4319 - val_loss: 1.4836\n",
      "Epoch 712/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4254 - val_loss: 1.4597\n",
      "Epoch 713/750\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4197 - val_loss: 1.4485\n",
      "Epoch 714/750\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4207 - val_loss: 1.4653\n",
      "Epoch 715/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4228 - val_loss: 1.4452\n",
      "Epoch 716/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4259 - val_loss: 1.4981\n",
      "Epoch 717/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4352 - val_loss: 1.4641\n",
      "Epoch 718/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4224 - val_loss: 1.4868\n",
      "Epoch 719/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4211 - val_loss: 1.4449\n",
      "Epoch 720/750\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 1.4284 - val_loss: 1.4934\n",
      "Epoch 721/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4277 - val_loss: 1.4890\n",
      "Epoch 722/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4277 - val_loss: 1.4605\n",
      "Epoch 723/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4228 - val_loss: 1.4850\n",
      "Epoch 724/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4245 - val_loss: 1.5402\n",
      "Epoch 725/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4214 - val_loss: 1.4968\n",
      "Epoch 726/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4230 - val_loss: 1.5648\n",
      "Epoch 727/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4292 - val_loss: 1.4585\n",
      "Epoch 728/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4230 - val_loss: 1.5018\n",
      "Epoch 729/750\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 1.4277 - val_loss: 1.4548\n",
      "Epoch 730/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4174 - val_loss: 1.4798\n",
      "Epoch 731/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4214 - val_loss: 1.4808\n",
      "Epoch 732/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4298 - val_loss: 1.4683\n",
      "Epoch 733/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4234 - val_loss: 1.4658\n",
      "Epoch 734/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4205 - val_loss: 1.4901\n",
      "Epoch 735/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4225 - val_loss: 1.4709\n",
      "Epoch 736/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4211 - val_loss: 1.5073\n",
      "Epoch 737/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4269 - val_loss: 1.4319\n",
      "Epoch 738/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4228 - val_loss: 1.5622\n",
      "Epoch 739/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4200 - val_loss: 1.4620\n",
      "Epoch 740/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4133 - val_loss: 1.4954\n",
      "Epoch 741/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4229 - val_loss: 1.4446\n",
      "Epoch 742/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4249 - val_loss: 1.4711\n",
      "Epoch 743/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4153 - val_loss: 1.4445\n",
      "Epoch 744/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4245 - val_loss: 1.4161\n",
      "Epoch 745/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4168 - val_loss: 1.4220\n",
      "Epoch 746/750\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.4148 - val_loss: 1.5036\n",
      "Epoch 747/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4205 - val_loss: 1.4535\n",
      "Epoch 748/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4146 - val_loss: 1.4759\n",
      "Epoch 749/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4203 - val_loss: 1.4143\n",
      "Epoch 750/750\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.4135 - val_loss: 1.4315\n",
      "1.4315288541357483\n",
      "0.9684553998582041\n",
      "Epoch 1/750\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 9.6805 - val_loss: 3.9813\n",
      "Epoch 2/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 5.0573 - val_loss: 5.0083\n",
      "Epoch 3/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.5453 - val_loss: 5.3443\n",
      "Epoch 4/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.6691 - val_loss: 4.7102\n",
      "Epoch 5/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.4932 - val_loss: 3.8730\n",
      "Epoch 6/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.2254 - val_loss: 4.5769\n",
      "Epoch 7/750\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 4.1713 - val_loss: 3.8448\n",
      "Epoch 8/750\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 4.0460 - val_loss: 4.1258\n",
      "Epoch 9/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 4.0121 - val_loss: 3.8719\n",
      "Epoch 10/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.8534 - val_loss: 4.2401\n",
      "Epoch 11/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.5153 - val_loss: 3.0520\n",
      "Epoch 12/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.1772 - val_loss: 3.2314\n",
      "Epoch 13/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 3.0932 - val_loss: 3.1210\n",
      "Epoch 14/750\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.9913 - val_loss: 2.7596\n",
      "Epoch 15/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.8217 - val_loss: 2.6817\n",
      "Epoch 16/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.7532 - val_loss: 2.9231\n",
      "Epoch 17/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.7452 - val_loss: 3.0077\n",
      "Epoch 18/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.6620 - val_loss: 3.0443\n",
      "Epoch 19/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.6294 - val_loss: 2.6497\n",
      "Epoch 20/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.5833 - val_loss: 2.4299\n",
      "Epoch 21/750\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 2.5595 - val_loss: 2.6266\n",
      "Epoch 22/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.4989 - val_loss: 2.6392\n",
      "Epoch 23/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.4815 - val_loss: 2.6432\n",
      "Epoch 24/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.4747 - val_loss: 2.3478\n",
      "Epoch 25/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.4529 - val_loss: 2.3799\n",
      "Epoch 26/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.4161 - val_loss: 2.3230\n",
      "Epoch 27/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.4062 - val_loss: 2.3115\n",
      "Epoch 28/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.3916 - val_loss: 2.5306\n",
      "Epoch 29/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.3614 - val_loss: 2.2458\n",
      "Epoch 30/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.3503 - val_loss: 2.2674\n",
      "Epoch 31/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.3260 - val_loss: 2.2788\n",
      "Epoch 32/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2977 - val_loss: 2.2975\n",
      "Epoch 33/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2888 - val_loss: 2.2334\n",
      "Epoch 34/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2548 - val_loss: 2.2234\n",
      "Epoch 35/750\n",
      "576/576 [==============================] - 6s 10ms/step - loss: 2.2210 - val_loss: 2.1885\n",
      "Epoch 36/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.2129 - val_loss: 2.1200\n",
      "Epoch 37/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1844 - val_loss: 2.1123\n",
      "Epoch 38/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1936 - val_loss: 2.1213\n",
      "Epoch 39/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1717 - val_loss: 2.1441\n",
      "Epoch 40/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1346 - val_loss: 2.1200\n",
      "Epoch 41/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1475 - val_loss: 2.6705\n",
      "Epoch 42/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1039 - val_loss: 2.1923\n",
      "Epoch 43/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1120 - val_loss: 2.0168\n",
      "Epoch 44/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.1124 - val_loss: 1.9670\n",
      "Epoch 45/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0668 - val_loss: 2.1155\n",
      "Epoch 46/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0757 - val_loss: 2.2888\n",
      "Epoch 47/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0569 - val_loss: 2.0083\n",
      "Epoch 48/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0477 - val_loss: 2.0824\n",
      "Epoch 49/750\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 2.0634 - val_loss: 2.1324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0298 - val_loss: 2.0029\n",
      "Epoch 51/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0191 - val_loss: 1.9501\n",
      "Epoch 52/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9949 - val_loss: 1.9525\n",
      "Epoch 53/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 2.0025 - val_loss: 1.9910\n",
      "Epoch 54/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9929 - val_loss: 1.9779\n",
      "Epoch 55/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9820 - val_loss: 2.0510\n",
      "Epoch 56/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9798 - val_loss: 1.9517\n",
      "Epoch 57/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9564 - val_loss: 2.0071\n",
      "Epoch 58/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9497 - val_loss: 1.9657\n",
      "Epoch 59/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9532 - val_loss: 1.9269\n",
      "Epoch 60/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9545 - val_loss: 1.9672\n",
      "Epoch 61/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9443 - val_loss: 1.9611\n",
      "Epoch 62/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9233 - val_loss: 1.9939\n",
      "Epoch 63/750\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.9422 - val_loss: 2.0112\n",
      "Epoch 64/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9269 - val_loss: 1.8774\n",
      "Epoch 65/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8955 - val_loss: 1.8459\n",
      "Epoch 66/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8906 - val_loss: 2.0272\n",
      "Epoch 67/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.9047 - val_loss: 1.9533\n",
      "Epoch 68/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8800 - val_loss: 1.8359\n",
      "Epoch 69/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8853 - val_loss: 1.9012\n",
      "Epoch 70/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8793 - val_loss: 1.9361\n",
      "Epoch 71/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8750 - val_loss: 1.8560\n",
      "Epoch 72/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8746 - val_loss: 1.8649\n",
      "Epoch 73/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8587 - val_loss: 1.9010\n",
      "Epoch 74/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8522 - val_loss: 1.7964\n",
      "Epoch 75/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8492 - val_loss: 1.8050\n",
      "Epoch 76/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8480 - val_loss: 1.8097\n",
      "Epoch 77/750\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.8500 - val_loss: 1.8461\n",
      "Epoch 78/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8359 - val_loss: 1.8472\n",
      "Epoch 79/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8303 - val_loss: 1.8539\n",
      "Epoch 80/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8162 - val_loss: 1.7997\n",
      "Epoch 81/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8375 - val_loss: 1.9392\n",
      "Epoch 82/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8009 - val_loss: 1.8078\n",
      "Epoch 83/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8123 - val_loss: 1.7790\n",
      "Epoch 84/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8065 - val_loss: 1.7685\n",
      "Epoch 85/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.8144 - val_loss: 1.9187\n",
      "Epoch 86/750\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7992 - val_loss: 1.7925\n",
      "Epoch 87/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7963 - val_loss: 1.9475\n",
      "Epoch 88/750\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7877 - val_loss: 1.7089\n",
      "Epoch 89/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7777 - val_loss: 1.8246\n",
      "Epoch 90/750\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7898 - val_loss: 1.7441\n",
      "Epoch 91/750\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 1.7677 - val_loss: 1.7811\n",
      "Epoch 92/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7807 - val_loss: 1.7319\n",
      "Epoch 93/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7736 - val_loss: 1.8386\n",
      "Epoch 94/750\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.7751 - val_loss: 1.7876\n",
      "Epoch 95/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7755 - val_loss: 1.9085\n",
      "Epoch 96/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7534 - val_loss: 1.8034\n",
      "Epoch 97/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7581 - val_loss: 1.7351\n",
      "Epoch 98/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7279 - val_loss: 1.8573\n",
      "Epoch 99/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7500 - val_loss: 1.8115\n",
      "Epoch 100/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7459 - val_loss: 1.7882\n",
      "Epoch 101/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7509 - val_loss: 1.7404\n",
      "Epoch 102/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7312 - val_loss: 1.7620\n",
      "Epoch 103/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7179 - val_loss: 1.7310\n",
      "Epoch 104/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7156 - val_loss: 1.7441\n",
      "Epoch 105/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7239 - val_loss: 1.7842\n",
      "Epoch 106/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7210 - val_loss: 1.7263\n",
      "Epoch 107/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7250 - val_loss: 1.7472\n",
      "Epoch 108/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7261 - val_loss: 1.7395\n",
      "Epoch 109/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7133 - val_loss: 1.7448\n",
      "Epoch 110/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7272 - val_loss: 1.6996\n",
      "Epoch 111/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6983 - val_loss: 1.7672\n",
      "Epoch 112/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7079 - val_loss: 1.7467\n",
      "Epoch 113/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7110 - val_loss: 1.7600\n",
      "Epoch 114/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6994 - val_loss: 1.7297\n",
      "Epoch 115/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6829 - val_loss: 1.7211\n",
      "Epoch 116/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6982 - val_loss: 1.7272\n",
      "Epoch 117/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6827 - val_loss: 1.6961\n",
      "Epoch 118/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6868 - val_loss: 1.7187\n",
      "Epoch 119/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6908 - val_loss: 1.7517\n",
      "Epoch 120/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6811 - val_loss: 1.7997\n",
      "Epoch 121/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6772 - val_loss: 1.6628\n",
      "Epoch 122/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6616 - val_loss: 1.6348\n",
      "Epoch 123/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6750 - val_loss: 1.6687\n",
      "Epoch 124/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6672 - val_loss: 1.6816\n",
      "Epoch 125/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6650 - val_loss: 1.6387\n",
      "Epoch 126/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6644 - val_loss: 1.6773\n",
      "Epoch 127/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6758 - val_loss: 1.6844\n",
      "Epoch 128/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6411 - val_loss: 1.6700\n",
      "Epoch 129/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6620 - val_loss: 1.6428\n",
      "Epoch 130/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6528 - val_loss: 1.5912\n",
      "Epoch 131/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6515 - val_loss: 1.7708\n",
      "Epoch 132/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6617 - val_loss: 1.7154\n",
      "Epoch 133/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6335 - val_loss: 1.5973\n",
      "Epoch 134/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6313 - val_loss: 1.6443\n",
      "Epoch 135/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6387 - val_loss: 1.6337\n",
      "Epoch 136/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6448 - val_loss: 1.5999\n",
      "Epoch 137/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6236 - val_loss: 1.6590\n",
      "Epoch 138/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6252 - val_loss: 1.6511\n",
      "Epoch 139/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6366 - val_loss: 1.6439\n",
      "Epoch 140/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6111 - val_loss: 1.7223\n",
      "Epoch 141/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6364 - val_loss: 1.7013\n",
      "Epoch 142/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6126 - val_loss: 1.5702\n",
      "Epoch 143/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6173 - val_loss: 1.6181\n",
      "Epoch 144/750\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.6161 - val_loss: 1.6721\n",
      "Epoch 145/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6065 - val_loss: 1.7455\n",
      "Epoch 146/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6178 - val_loss: 1.6538\n",
      "Epoch 147/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6211 - val_loss: 1.6525\n",
      "Epoch 148/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6027 - val_loss: 1.5822\n",
      "Epoch 149/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5972 - val_loss: 1.6817\n",
      "Epoch 150/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6086 - val_loss: 1.6182\n",
      "Epoch 151/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6177 - val_loss: 1.6911\n",
      "Epoch 152/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6054 - val_loss: 1.5873\n",
      "Epoch 153/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6112 - val_loss: 1.6890\n",
      "Epoch 154/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5874 - val_loss: 1.5788\n",
      "Epoch 155/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5949 - val_loss: 1.6280\n",
      "Epoch 156/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5964 - val_loss: 1.6202\n",
      "Epoch 157/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5844 - val_loss: 1.6445\n",
      "Epoch 158/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5921 - val_loss: 1.5824\n",
      "Epoch 159/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5855 - val_loss: 1.6756\n",
      "Epoch 160/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5867 - val_loss: 1.6476\n",
      "Epoch 161/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5856 - val_loss: 1.6024\n",
      "Epoch 162/750\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5810 - val_loss: 1.5880\n",
      "Epoch 163/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5809 - val_loss: 1.5848\n",
      "Epoch 164/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5792 - val_loss: 1.5911\n",
      "Epoch 165/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5748 - val_loss: 1.5887\n",
      "Epoch 166/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5617 - val_loss: 1.6831\n",
      "Epoch 167/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5898 - val_loss: 1.5905\n",
      "Epoch 168/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5736 - val_loss: 1.5717\n",
      "Epoch 169/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5632 - val_loss: 1.6143\n",
      "Epoch 170/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5742 - val_loss: 1.6012\n",
      "Epoch 171/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5684 - val_loss: 1.5889\n",
      "Epoch 172/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5779 - val_loss: 1.6546\n",
      "Epoch 173/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5639 - val_loss: 1.5607\n",
      "Epoch 174/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5613 - val_loss: 1.6395\n",
      "Epoch 175/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5634 - val_loss: 1.6069\n",
      "Epoch 176/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5584 - val_loss: 1.5482\n",
      "Epoch 177/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5529 - val_loss: 1.6103\n",
      "Epoch 178/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5555 - val_loss: 1.5316\n",
      "Epoch 179/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5540 - val_loss: 1.5542\n",
      "Epoch 180/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5537 - val_loss: 1.6899\n",
      "Epoch 181/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5455 - val_loss: 1.5857\n",
      "Epoch 182/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5639 - val_loss: 1.5718\n",
      "Epoch 183/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5480 - val_loss: 1.5575\n",
      "Epoch 184/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5374 - val_loss: 1.5273\n",
      "Epoch 185/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5462 - val_loss: 1.6751\n",
      "Epoch 186/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5319 - val_loss: 1.5313\n",
      "Epoch 187/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5407 - val_loss: 1.5690\n",
      "Epoch 188/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5297 - val_loss: 1.5974\n",
      "Epoch 189/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5377 - val_loss: 1.6732\n",
      "Epoch 190/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5350 - val_loss: 1.6182\n",
      "Epoch 191/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5349 - val_loss: 1.5641\n",
      "Epoch 192/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5337 - val_loss: 1.5349\n",
      "Epoch 193/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5420 - val_loss: 1.6593\n",
      "Epoch 194/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5459 - val_loss: 1.6570\n",
      "Epoch 195/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5240 - val_loss: 1.5571\n",
      "Epoch 196/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5398 - val_loss: 1.5571\n",
      "Epoch 197/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5311 - val_loss: 1.5558\n",
      "Epoch 198/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5248 - val_loss: 1.5588\n",
      "Epoch 199/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5385 - val_loss: 1.5697\n",
      "Epoch 200/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5122 - val_loss: 1.4991\n",
      "Epoch 201/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5266 - val_loss: 1.5787\n",
      "Epoch 202/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5326 - val_loss: 1.5148\n",
      "Epoch 203/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5202 - val_loss: 1.6732\n",
      "Epoch 204/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5148 - val_loss: 1.5923\n",
      "Epoch 205/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5331 - val_loss: 1.5934\n",
      "Epoch 206/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5149 - val_loss: 1.5553\n",
      "Epoch 207/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5075 - val_loss: 1.5526\n",
      "Epoch 208/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5126 - val_loss: 1.5158\n",
      "Epoch 209/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5074 - val_loss: 1.4969\n",
      "Epoch 210/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5139 - val_loss: 1.5613\n",
      "Epoch 211/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5249 - val_loss: 1.5098\n",
      "Epoch 212/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5032 - val_loss: 1.5335\n",
      "Epoch 213/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5009 - val_loss: 1.5214\n",
      "Epoch 214/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5160 - val_loss: 1.6682\n",
      "Epoch 215/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5090 - val_loss: 1.5810\n",
      "Epoch 216/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5180 - val_loss: 1.5912\n",
      "Epoch 217/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5022 - val_loss: 1.6162\n",
      "Epoch 218/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4980 - val_loss: 1.4954\n",
      "Epoch 219/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5071 - val_loss: 1.5794\n",
      "Epoch 220/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5074 - val_loss: 1.5858\n",
      "Epoch 221/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4960 - val_loss: 1.5629\n",
      "Epoch 222/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5023 - val_loss: 1.5594\n",
      "Epoch 223/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4949 - val_loss: 1.5494\n",
      "Epoch 224/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4910 - val_loss: 1.5270\n",
      "Epoch 225/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4956 - val_loss: 1.6424\n",
      "Epoch 226/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5064 - val_loss: 1.6196\n",
      "Epoch 227/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5013 - val_loss: 1.5920\n",
      "Epoch 228/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4967 - val_loss: 1.5105\n",
      "Epoch 229/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4911 - val_loss: 1.4654\n",
      "Epoch 230/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4881 - val_loss: 1.4988\n",
      "Epoch 231/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5162 - val_loss: 1.6030\n",
      "Epoch 232/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4968 - val_loss: 1.5662\n",
      "Epoch 233/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4823 - val_loss: 1.5877\n",
      "Epoch 234/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4776 - val_loss: 1.5951\n",
      "Epoch 235/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5006 - val_loss: 1.5032\n",
      "Epoch 236/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4731 - val_loss: 1.5432\n",
      "Epoch 237/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4838 - val_loss: 1.5657\n",
      "Epoch 238/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4927 - val_loss: 1.6358\n",
      "Epoch 239/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4802 - val_loss: 1.5442\n",
      "Epoch 240/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4819 - val_loss: 1.4985\n",
      "Epoch 241/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4776 - val_loss: 1.5147\n",
      "Epoch 242/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4708 - val_loss: 1.4659\n",
      "Epoch 243/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4920 - val_loss: 1.5832\n",
      "Epoch 244/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4724 - val_loss: 1.5294\n",
      "Epoch 245/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4802 - val_loss: 1.4701\n",
      "Epoch 246/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4699 - val_loss: 1.5400\n",
      "Epoch 247/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4814 - val_loss: 1.4458\n",
      "Epoch 248/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4786 - val_loss: 1.5239\n",
      "Epoch 249/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4717 - val_loss: 1.4993\n",
      "Epoch 250/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4752 - val_loss: 1.4917\n",
      "Epoch 251/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4783 - val_loss: 1.4716\n",
      "Epoch 252/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4665 - val_loss: 1.4930\n",
      "Epoch 253/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4710 - val_loss: 1.4649\n",
      "Epoch 254/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4731 - val_loss: 1.5793\n",
      "Epoch 255/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4634 - val_loss: 1.4896\n",
      "Epoch 256/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4611 - val_loss: 1.4506\n",
      "Epoch 257/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4793 - val_loss: 1.4517\n",
      "Epoch 258/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4664 - val_loss: 1.4962\n",
      "Epoch 259/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4613 - val_loss: 1.6153\n",
      "Epoch 260/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4758 - val_loss: 1.5015\n",
      "Epoch 261/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4519 - val_loss: 1.4808\n",
      "Epoch 262/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4632 - val_loss: 1.5397\n",
      "Epoch 263/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4588 - val_loss: 1.4973\n",
      "Epoch 264/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4747 - val_loss: 1.5215\n",
      "Epoch 265/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4603 - val_loss: 1.5524\n",
      "Epoch 266/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4577 - val_loss: 1.5285\n",
      "Epoch 267/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4631 - val_loss: 1.4826\n",
      "Epoch 268/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4570 - val_loss: 1.5956\n",
      "Epoch 269/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4505 - val_loss: 1.4512\n",
      "Epoch 270/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4694 - val_loss: 1.5261\n",
      "Epoch 271/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4499 - val_loss: 1.4308\n",
      "Epoch 272/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4399 - val_loss: 1.4792\n",
      "Epoch 273/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4542 - val_loss: 1.5207\n",
      "Epoch 274/750\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4614 - val_loss: 1.5365\n",
      "Epoch 275/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4521 - val_loss: 1.4199\n",
      "Epoch 276/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4521 - val_loss: 1.5355\n",
      "Epoch 277/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4557 - val_loss: 1.6368\n",
      "Epoch 278/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4522 - val_loss: 1.5155\n",
      "Epoch 279/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4582 - val_loss: 1.4390\n",
      "Epoch 280/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4448 - val_loss: 1.5070\n",
      "Epoch 281/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4406 - val_loss: 1.5214\n",
      "Epoch 282/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4463 - val_loss: 1.4565\n",
      "Epoch 283/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4495 - val_loss: 1.5418\n",
      "Epoch 284/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4456 - val_loss: 1.4810\n",
      "Epoch 285/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4402 - val_loss: 1.4815\n",
      "Epoch 286/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4484 - val_loss: 1.5230\n",
      "Epoch 287/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4387 - val_loss: 1.4977\n",
      "Epoch 288/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4452 - val_loss: 1.4495\n",
      "Epoch 289/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4435 - val_loss: 1.4568\n",
      "Epoch 290/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4378 - val_loss: 1.4820\n",
      "Epoch 291/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4471 - val_loss: 1.6029\n",
      "Epoch 292/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4289 - val_loss: 1.4983\n",
      "Epoch 293/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4499 - val_loss: 1.5005\n",
      "Epoch 294/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4255 - val_loss: 1.5585\n",
      "Epoch 295/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4326 - val_loss: 1.4404\n",
      "Epoch 296/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4386 - val_loss: 1.4811\n",
      "Epoch 297/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4396 - val_loss: 1.4835\n",
      "Epoch 298/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4199 - val_loss: 1.4637\n",
      "Epoch 299/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4296 - val_loss: 1.4719\n",
      "Epoch 300/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4552 - val_loss: 1.4643\n",
      "Epoch 301/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4323 - val_loss: 1.4672\n",
      "Epoch 302/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4341 - val_loss: 1.4888\n",
      "Epoch 303/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4262 - val_loss: 1.5461\n",
      "Epoch 304/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4293 - val_loss: 1.4619\n",
      "Epoch 305/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4329 - val_loss: 1.5329\n",
      "Epoch 306/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4391 - val_loss: 1.5688\n",
      "Epoch 307/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4201 - val_loss: 1.4247\n",
      "Epoch 308/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4337 - val_loss: 1.4411\n",
      "Epoch 309/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4209 - val_loss: 1.4762\n",
      "Epoch 310/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4202 - val_loss: 1.4219\n",
      "Epoch 311/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4213 - val_loss: 1.4406\n",
      "Epoch 312/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4327 - val_loss: 1.4862\n",
      "Epoch 313/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4215 - val_loss: 1.4501\n",
      "Epoch 314/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4221 - val_loss: 1.4216\n",
      "Epoch 315/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4203 - val_loss: 1.6318\n",
      "Epoch 316/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4264 - val_loss: 1.5341\n",
      "Epoch 317/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4222 - val_loss: 1.4349\n",
      "Epoch 318/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4330 - val_loss: 1.4930\n",
      "Epoch 319/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4168 - val_loss: 1.5449\n",
      "Epoch 320/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4195 - val_loss: 1.5019\n",
      "Epoch 321/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4193 - val_loss: 1.4330\n",
      "Epoch 322/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4181 - val_loss: 1.4294\n",
      "Epoch 323/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4207 - val_loss: 1.4845\n",
      "Epoch 324/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4139 - val_loss: 1.4662\n",
      "Epoch 325/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4205 - val_loss: 1.5121\n",
      "Epoch 326/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4326 - val_loss: 1.4397\n",
      "Epoch 327/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4091 - val_loss: 1.4298\n",
      "Epoch 328/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4178 - val_loss: 1.4238\n",
      "Epoch 329/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4291 - val_loss: 1.4594\n",
      "Epoch 330/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4083 - val_loss: 1.4532\n",
      "Epoch 331/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4089 - val_loss: 1.4447\n",
      "Epoch 332/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4192 - val_loss: 1.4809\n",
      "Epoch 333/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4298 - val_loss: 1.4974\n",
      "Epoch 334/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4147 - val_loss: 1.4231\n",
      "Epoch 335/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4098 - val_loss: 1.4376\n",
      "Epoch 336/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4103 - val_loss: 1.4919\n",
      "Epoch 337/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4009 - val_loss: 1.4816\n",
      "Epoch 338/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4195 - val_loss: 1.4790\n",
      "Epoch 339/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4128 - val_loss: 1.4255\n",
      "Epoch 340/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4101 - val_loss: 1.5103\n",
      "Epoch 341/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4163 - val_loss: 1.4552\n",
      "Epoch 342/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4067 - val_loss: 1.4872\n",
      "Epoch 343/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4062 - val_loss: 1.4731\n",
      "Epoch 344/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4107 - val_loss: 1.4519\n",
      "Epoch 345/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4182 - val_loss: 1.4929\n",
      "Epoch 346/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3973 - val_loss: 1.5226\n",
      "Epoch 347/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4041 - val_loss: 1.4442\n",
      "Epoch 348/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4060 - val_loss: 1.4316\n",
      "Epoch 349/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3876 - val_loss: 1.5857\n",
      "Epoch 350/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4156 - val_loss: 1.4458\n",
      "Epoch 351/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4178 - val_loss: 1.4874\n",
      "Epoch 352/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4047 - val_loss: 1.4403\n",
      "Epoch 353/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3945 - val_loss: 1.4312\n",
      "Epoch 354/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4035 - val_loss: 1.4568\n",
      "Epoch 355/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4018 - val_loss: 1.4795\n",
      "Epoch 356/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3989 - val_loss: 1.4388\n",
      "Epoch 357/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3985 - val_loss: 1.4504\n",
      "Epoch 358/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4058 - val_loss: 1.4765\n",
      "Epoch 359/750\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.4001 - val_loss: 1.4685\n",
      "Epoch 360/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4006 - val_loss: 1.4739\n",
      "Epoch 361/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4041 - val_loss: 1.5217\n",
      "Epoch 362/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4026 - val_loss: 1.3944\n",
      "Epoch 363/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3982 - val_loss: 1.4365\n",
      "Epoch 364/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3959 - val_loss: 1.4305\n",
      "Epoch 365/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4029 - val_loss: 1.4016\n",
      "Epoch 366/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3908 - val_loss: 1.4048\n",
      "Epoch 367/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3945 - val_loss: 1.4336\n",
      "Epoch 368/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3989 - val_loss: 1.4666\n",
      "Epoch 369/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3846 - val_loss: 1.4695\n",
      "Epoch 370/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3894 - val_loss: 1.4431\n",
      "Epoch 371/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3850 - val_loss: 1.4547\n",
      "Epoch 372/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3890 - val_loss: 1.4119\n",
      "Epoch 373/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3872 - val_loss: 1.4456\n",
      "Epoch 374/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3971 - val_loss: 1.6236\n",
      "Epoch 375/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3860 - val_loss: 1.4330\n",
      "Epoch 376/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3949 - val_loss: 1.4024\n",
      "Epoch 377/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3910 - val_loss: 1.4354\n",
      "Epoch 378/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3934 - val_loss: 1.4429\n",
      "Epoch 379/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3811 - val_loss: 1.4081\n",
      "Epoch 380/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3837 - val_loss: 1.5005\n",
      "Epoch 381/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3884 - val_loss: 1.4376\n",
      "Epoch 382/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3881 - val_loss: 1.4410\n",
      "Epoch 383/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3848 - val_loss: 1.4954\n",
      "Epoch 384/750\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3807 - val_loss: 1.4524\n",
      "Epoch 385/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3905 - val_loss: 1.4103\n",
      "Epoch 386/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3824 - val_loss: 1.4540\n",
      "Epoch 387/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3778 - val_loss: 1.4461\n",
      "Epoch 388/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3752 - val_loss: 1.4896\n",
      "Epoch 389/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3887 - val_loss: 1.4596\n",
      "Epoch 390/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3899 - val_loss: 1.4441\n",
      "Epoch 391/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3845 - val_loss: 1.4418\n",
      "Epoch 392/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3878 - val_loss: 1.4054\n",
      "Epoch 393/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3802 - val_loss: 1.4143\n",
      "Epoch 394/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3702 - val_loss: 1.4085\n",
      "Epoch 395/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3773 - val_loss: 1.3955\n",
      "Epoch 396/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3755 - val_loss: 1.4226\n",
      "Epoch 397/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3852 - val_loss: 1.4494\n",
      "Epoch 398/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3841 - val_loss: 1.4372\n",
      "Epoch 399/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3808 - val_loss: 1.4313\n",
      "Epoch 400/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3711 - val_loss: 1.4391\n",
      "Epoch 401/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3755 - val_loss: 1.4318\n",
      "Epoch 402/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3933 - val_loss: 1.4535\n",
      "Epoch 403/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3864 - val_loss: 1.4016\n",
      "Epoch 404/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3823 - val_loss: 1.4343\n",
      "Epoch 405/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3712 - val_loss: 1.4707\n",
      "Epoch 406/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3712 - val_loss: 1.3764\n",
      "Epoch 407/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3701 - val_loss: 1.4453\n",
      "Epoch 408/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3755 - val_loss: 1.5143\n",
      "Epoch 409/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3736 - val_loss: 1.4375\n",
      "Epoch 410/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3711 - val_loss: 1.4179\n",
      "Epoch 411/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3590 - val_loss: 1.4135\n",
      "Epoch 412/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3747 - val_loss: 1.4017\n",
      "Epoch 413/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3701 - val_loss: 1.3981\n",
      "Epoch 414/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3766 - val_loss: 1.4429\n",
      "Epoch 415/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3860 - val_loss: 1.5897\n",
      "Epoch 416/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3618 - val_loss: 1.5083\n",
      "Epoch 417/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3723 - val_loss: 1.4220\n",
      "Epoch 418/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3649 - val_loss: 1.4038\n",
      "Epoch 419/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3682 - val_loss: 1.4059\n",
      "Epoch 420/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3612 - val_loss: 1.4056\n",
      "Epoch 421/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3692 - val_loss: 1.4276\n",
      "Epoch 422/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3704 - val_loss: 1.4015\n",
      "Epoch 423/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3649 - val_loss: 1.3973\n",
      "Epoch 424/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3710 - val_loss: 1.5886\n",
      "Epoch 425/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3740 - val_loss: 1.3872\n",
      "Epoch 426/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3590 - val_loss: 1.3967\n",
      "Epoch 427/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3775 - val_loss: 1.3897\n",
      "Epoch 428/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3494 - val_loss: 1.3948\n",
      "Epoch 429/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3638 - val_loss: 1.3930\n",
      "Epoch 430/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3495 - val_loss: 1.3825\n",
      "Epoch 431/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3710 - val_loss: 1.3574\n",
      "Epoch 432/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3510 - val_loss: 1.4115\n",
      "Epoch 433/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3550 - val_loss: 1.3663\n",
      "Epoch 434/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3689 - val_loss: 1.3993\n",
      "Epoch 435/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3726 - val_loss: 1.4639\n",
      "Epoch 436/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3530 - val_loss: 1.4489\n",
      "Epoch 437/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3555 - val_loss: 1.5030\n",
      "Epoch 438/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3534 - val_loss: 1.4631\n",
      "Epoch 439/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3625 - val_loss: 1.4243\n",
      "Epoch 440/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3501 - val_loss: 1.3783\n",
      "Epoch 441/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3546 - val_loss: 1.3968\n",
      "Epoch 442/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3622 - val_loss: 1.3702\n",
      "Epoch 443/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3521 - val_loss: 1.4361\n",
      "Epoch 444/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3609 - val_loss: 1.3817\n",
      "Epoch 445/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3575 - val_loss: 1.4285\n",
      "Epoch 446/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3458 - val_loss: 1.3972\n",
      "Epoch 447/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3471 - val_loss: 1.4221\n",
      "Epoch 448/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3557 - val_loss: 1.4561\n",
      "Epoch 449/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3638 - val_loss: 1.3898\n",
      "Epoch 450/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3455 - val_loss: 1.5793\n",
      "Epoch 451/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3616 - val_loss: 1.4241\n",
      "Epoch 452/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3390 - val_loss: 1.3818\n",
      "Epoch 453/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3536 - val_loss: 1.3770\n",
      "Epoch 454/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3448 - val_loss: 1.3449\n",
      "Epoch 455/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3525 - val_loss: 1.3900\n",
      "Epoch 456/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3475 - val_loss: 1.4012\n",
      "Epoch 457/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3478 - val_loss: 1.3586\n",
      "Epoch 458/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3431 - val_loss: 1.3461\n",
      "Epoch 459/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3413 - val_loss: 1.4007\n",
      "Epoch 460/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3587 - val_loss: 1.4544\n",
      "Epoch 461/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3598 - val_loss: 1.3948\n",
      "Epoch 462/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3527 - val_loss: 1.4474\n",
      "Epoch 463/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3497 - val_loss: 1.3736\n",
      "Epoch 464/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3404 - val_loss: 1.4039\n",
      "Epoch 465/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3503 - val_loss: 1.3925\n",
      "Epoch 466/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3459 - val_loss: 1.3881\n",
      "Epoch 467/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3548 - val_loss: 1.4530\n",
      "Epoch 468/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3519 - val_loss: 1.4227\n",
      "Epoch 469/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3499 - val_loss: 1.4557\n",
      "Epoch 470/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3415 - val_loss: 1.3880\n",
      "Epoch 471/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3518 - val_loss: 1.4388\n",
      "Epoch 472/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3364 - val_loss: 1.3852\n",
      "Epoch 473/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3500 - val_loss: 1.3739\n",
      "Epoch 474/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3355 - val_loss: 1.3421\n",
      "Epoch 475/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3371 - val_loss: 1.4518\n",
      "Epoch 476/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3449 - val_loss: 1.3853\n",
      "Epoch 477/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3544 - val_loss: 1.3347\n",
      "Epoch 478/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3334 - val_loss: 1.3951\n",
      "Epoch 479/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3459 - val_loss: 1.3845\n",
      "Epoch 480/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3360 - val_loss: 1.3495\n",
      "Epoch 481/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3340 - val_loss: 1.4040\n",
      "Epoch 482/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3471 - val_loss: 1.3882\n",
      "Epoch 483/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3321 - val_loss: 1.3559\n",
      "Epoch 484/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3355 - val_loss: 1.4215\n",
      "Epoch 485/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3416 - val_loss: 1.3951\n",
      "Epoch 486/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3303 - val_loss: 1.3864\n",
      "Epoch 487/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3328 - val_loss: 1.3919\n",
      "Epoch 488/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3254 - val_loss: 1.4633\n",
      "Epoch 489/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3418 - val_loss: 1.3796\n",
      "Epoch 490/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3401 - val_loss: 1.3664\n",
      "Epoch 491/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3372 - val_loss: 1.3626\n",
      "Epoch 492/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3304 - val_loss: 1.3966\n",
      "Epoch 493/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3353 - val_loss: 1.3507\n",
      "Epoch 494/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3360 - val_loss: 1.3646\n",
      "Epoch 495/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3359 - val_loss: 1.3503\n",
      "Epoch 496/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3348 - val_loss: 1.4239\n",
      "Epoch 497/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3406 - val_loss: 1.4643\n",
      "Epoch 498/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3217 - val_loss: 1.3850\n",
      "Epoch 499/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3231 - val_loss: 1.4390\n",
      "Epoch 500/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3300 - val_loss: 1.3628\n",
      "Epoch 501/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3291 - val_loss: 1.4319\n",
      "Epoch 502/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3333 - val_loss: 1.4124\n",
      "Epoch 503/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3241 - val_loss: 1.3826\n",
      "Epoch 504/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3368 - val_loss: 1.4678\n",
      "Epoch 505/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3320 - val_loss: 1.3681\n",
      "Epoch 506/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3276 - val_loss: 1.3962\n",
      "Epoch 507/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3232 - val_loss: 1.3584\n",
      "Epoch 508/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3405 - val_loss: 1.3643\n",
      "Epoch 509/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3295 - val_loss: 1.3778\n",
      "Epoch 510/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3219 - val_loss: 1.4113\n",
      "Epoch 511/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3325 - val_loss: 1.4123\n",
      "Epoch 512/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3265 - val_loss: 1.3366\n",
      "Epoch 513/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3298 - val_loss: 1.4396\n",
      "Epoch 514/750\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3341 - val_loss: 1.3561\n",
      "Epoch 515/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3330 - val_loss: 1.3967\n",
      "Epoch 516/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3224 - val_loss: 1.4739\n",
      "Epoch 517/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3401 - val_loss: 1.3728\n",
      "Epoch 518/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3195 - val_loss: 1.3506\n",
      "Epoch 519/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3160 - val_loss: 1.3737\n",
      "Epoch 520/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3277 - val_loss: 1.3793\n",
      "Epoch 521/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3270 - val_loss: 1.3922\n",
      "Epoch 522/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3195 - val_loss: 1.4129\n",
      "Epoch 523/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3175 - val_loss: 1.3640\n",
      "Epoch 524/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3285 - val_loss: 1.3321\n",
      "Epoch 525/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3328 - val_loss: 1.3315\n",
      "Epoch 526/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3296 - val_loss: 1.3171\n",
      "Epoch 527/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3232 - val_loss: 1.3683\n",
      "Epoch 528/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3268 - val_loss: 1.3796\n",
      "Epoch 529/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3245 - val_loss: 1.3032\n",
      "Epoch 530/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3176 - val_loss: 1.3524\n",
      "Epoch 531/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3161 - val_loss: 1.3884\n",
      "Epoch 532/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3296 - val_loss: 1.3687\n",
      "Epoch 533/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3225 - val_loss: 1.3627\n",
      "Epoch 534/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3190 - val_loss: 1.3378\n",
      "Epoch 535/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3330 - val_loss: 1.3913\n",
      "Epoch 536/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3230 - val_loss: 1.3607\n",
      "Epoch 537/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3127 - val_loss: 1.4571\n",
      "Epoch 538/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3237 - val_loss: 1.4150\n",
      "Epoch 539/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3094 - val_loss: 1.3808\n",
      "Epoch 540/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3138 - val_loss: 1.4371\n",
      "Epoch 541/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3256 - val_loss: 1.3782\n",
      "Epoch 542/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3180 - val_loss: 1.3467\n",
      "Epoch 543/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3166 - val_loss: 1.3933\n",
      "Epoch 544/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3236 - val_loss: 1.3322\n",
      "Epoch 545/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3295 - val_loss: 1.3627\n",
      "Epoch 546/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3130 - val_loss: 1.3635\n",
      "Epoch 547/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3065 - val_loss: 1.4580\n",
      "Epoch 548/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3139 - val_loss: 1.3904\n",
      "Epoch 549/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3197 - val_loss: 1.3972\n",
      "Epoch 550/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3153 - val_loss: 1.3507\n",
      "Epoch 551/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3095 - val_loss: 1.3018\n",
      "Epoch 552/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3101 - val_loss: 1.3306\n",
      "Epoch 553/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3248 - val_loss: 1.3529\n",
      "Epoch 554/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3122 - val_loss: 1.4715\n",
      "Epoch 555/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3165 - val_loss: 1.3807\n",
      "Epoch 556/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3097 - val_loss: 1.3670\n",
      "Epoch 557/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3115 - val_loss: 1.3409\n",
      "Epoch 558/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3045 - val_loss: 1.3607\n",
      "Epoch 559/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3087 - val_loss: 1.3628\n",
      "Epoch 560/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3100 - val_loss: 1.3484\n",
      "Epoch 561/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3263 - val_loss: 1.3579\n",
      "Epoch 562/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3156 - val_loss: 1.3709\n",
      "Epoch 563/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3091 - val_loss: 1.3683\n",
      "Epoch 564/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3096 - val_loss: 1.3554\n",
      "Epoch 565/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3128 - val_loss: 1.3077\n",
      "Epoch 566/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3215 - val_loss: 1.3438\n",
      "Epoch 567/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3052 - val_loss: 1.3810\n",
      "Epoch 568/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2950 - val_loss: 1.4057\n",
      "Epoch 569/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3088 - val_loss: 1.3986\n",
      "Epoch 570/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3010 - val_loss: 1.3671\n",
      "Epoch 571/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3308 - val_loss: 1.4331\n",
      "Epoch 572/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2977 - val_loss: 1.3375\n",
      "Epoch 573/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3031 - val_loss: 1.3837\n",
      "Epoch 574/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3135 - val_loss: 1.4104\n",
      "Epoch 575/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2979 - val_loss: 1.3539\n",
      "Epoch 576/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3051 - val_loss: 1.3291\n",
      "Epoch 577/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3073 - val_loss: 1.3500\n",
      "Epoch 578/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3022 - val_loss: 1.3696\n",
      "Epoch 579/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2979 - val_loss: 1.3256\n",
      "Epoch 580/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3139 - val_loss: 1.3484\n",
      "Epoch 581/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3133 - val_loss: 1.4121\n",
      "Epoch 582/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2969 - val_loss: 1.3680\n",
      "Epoch 583/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3010 - val_loss: 1.4202\n",
      "Epoch 584/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3114 - val_loss: 1.3550\n",
      "Epoch 585/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2950 - val_loss: 1.3684\n",
      "Epoch 586/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2989 - val_loss: 1.3998\n",
      "Epoch 587/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3012 - val_loss: 1.3903\n",
      "Epoch 588/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3004 - val_loss: 1.3130\n",
      "Epoch 589/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3084 - val_loss: 1.3483\n",
      "Epoch 590/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2983 - val_loss: 1.3454\n",
      "Epoch 591/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2961 - val_loss: 1.3418\n",
      "Epoch 592/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3008 - val_loss: 1.4083\n",
      "Epoch 593/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3002 - val_loss: 1.3085\n",
      "Epoch 594/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3100 - val_loss: 1.4507\n",
      "Epoch 595/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3011 - val_loss: 1.3831\n",
      "Epoch 596/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2898 - val_loss: 1.4361\n",
      "Epoch 597/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2997 - val_loss: 1.3483\n",
      "Epoch 598/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3000 - val_loss: 1.3727\n",
      "Epoch 599/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2977 - val_loss: 1.4003\n",
      "Epoch 600/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2992 - val_loss: 1.3268\n",
      "Epoch 601/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3055 - val_loss: 1.3370\n",
      "Epoch 602/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2945 - val_loss: 1.3123\n",
      "Epoch 603/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2891 - val_loss: 1.3977\n",
      "Epoch 604/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2945 - val_loss: 1.3204\n",
      "Epoch 605/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2931 - val_loss: 1.3600\n",
      "Epoch 606/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3036 - val_loss: 1.3472\n",
      "Epoch 607/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2875 - val_loss: 1.3133\n",
      "Epoch 608/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3067 - val_loss: 1.3586\n",
      "Epoch 609/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2953 - val_loss: 1.3072\n",
      "Epoch 610/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2954 - val_loss: 1.3077\n",
      "Epoch 611/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2995 - val_loss: 1.4668\n",
      "Epoch 612/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2983 - val_loss: 1.3114\n",
      "Epoch 613/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2848 - val_loss: 1.3599\n",
      "Epoch 614/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2969 - val_loss: 1.3130\n",
      "Epoch 615/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3058 - val_loss: 1.3806\n",
      "Epoch 616/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2939 - val_loss: 1.3623\n",
      "Epoch 617/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2914 - val_loss: 1.2646\n",
      "Epoch 618/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2890 - val_loss: 1.3160\n",
      "Epoch 619/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2869 - val_loss: 1.3603\n",
      "Epoch 620/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2944 - val_loss: 1.3648\n",
      "Epoch 621/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2929 - val_loss: 1.4188\n",
      "Epoch 622/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2922 - val_loss: 1.4411\n",
      "Epoch 623/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2907 - val_loss: 1.3201\n",
      "Epoch 624/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2841 - val_loss: 1.3827\n",
      "Epoch 625/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2885 - val_loss: 1.3396\n",
      "Epoch 626/750\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2879 - val_loss: 1.3432\n",
      "Epoch 627/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2938 - val_loss: 1.3137\n",
      "Epoch 628/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2987 - val_loss: 1.3406\n",
      "Epoch 629/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2806 - val_loss: 1.3375\n",
      "Epoch 630/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2859 - val_loss: 1.3691\n",
      "Epoch 631/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2875 - val_loss: 1.3637\n",
      "Epoch 632/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2939 - val_loss: 1.3671\n",
      "Epoch 633/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2921 - val_loss: 1.3524\n",
      "Epoch 634/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2758 - val_loss: 1.3485\n",
      "Epoch 635/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2830 - val_loss: 1.3535\n",
      "Epoch 636/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2916 - val_loss: 1.4597\n",
      "Epoch 637/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2926 - val_loss: 1.2911\n",
      "Epoch 638/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2813 - val_loss: 1.2918\n",
      "Epoch 639/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2840 - val_loss: 1.3533\n",
      "Epoch 640/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2933 - val_loss: 1.5255\n",
      "Epoch 641/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2914 - val_loss: 1.3304\n",
      "Epoch 642/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2848 - val_loss: 1.3441\n",
      "Epoch 643/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2905 - val_loss: 1.2889\n",
      "Epoch 644/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2879 - val_loss: 1.3312\n",
      "Epoch 645/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2799 - val_loss: 1.2882\n",
      "Epoch 646/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2837 - val_loss: 1.2938\n",
      "Epoch 647/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2705 - val_loss: 1.3604\n",
      "Epoch 648/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2782 - val_loss: 1.3345\n",
      "Epoch 649/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2887 - val_loss: 1.3023\n",
      "Epoch 650/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2780 - val_loss: 1.3043\n",
      "Epoch 651/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2812 - val_loss: 1.3001\n",
      "Epoch 652/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2829 - val_loss: 1.3647\n",
      "Epoch 653/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2937 - val_loss: 1.3199\n",
      "Epoch 654/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2755 - val_loss: 1.3107\n",
      "Epoch 655/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2797 - val_loss: 1.2919\n",
      "Epoch 656/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2789 - val_loss: 1.3336\n",
      "Epoch 657/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2758 - val_loss: 1.3438\n",
      "Epoch 658/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2838 - val_loss: 1.3422\n",
      "Epoch 659/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2751 - val_loss: 1.3269\n",
      "Epoch 660/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2919 - val_loss: 1.3073\n",
      "Epoch 661/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2788 - val_loss: 1.3603\n",
      "Epoch 662/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2846 - val_loss: 1.3394\n",
      "Epoch 663/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2811 - val_loss: 1.3016\n",
      "Epoch 664/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2752 - val_loss: 1.4267\n",
      "Epoch 665/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2733 - val_loss: 1.3684\n",
      "Epoch 666/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2810 - val_loss: 1.3413\n",
      "Epoch 667/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2784 - val_loss: 1.3325\n",
      "Epoch 668/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2838 - val_loss: 1.3169\n",
      "Epoch 669/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2703 - val_loss: 1.3079\n",
      "Epoch 670/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2791 - val_loss: 1.4236\n",
      "Epoch 671/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2781 - val_loss: 1.3252\n",
      "Epoch 672/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2701 - val_loss: 1.3929\n",
      "Epoch 673/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2872 - val_loss: 1.3838\n",
      "Epoch 674/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2774 - val_loss: 1.3171\n",
      "Epoch 675/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2768 - val_loss: 1.2957\n",
      "Epoch 676/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2702 - val_loss: 1.4177\n",
      "Epoch 677/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2790 - val_loss: 1.3118\n",
      "Epoch 678/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2725 - val_loss: 1.2948\n",
      "Epoch 679/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2690 - val_loss: 1.3649\n",
      "Epoch 680/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2664 - val_loss: 1.3092\n",
      "Epoch 681/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2779 - val_loss: 1.3643\n",
      "Epoch 682/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2752 - val_loss: 1.2818\n",
      "Epoch 683/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2628 - val_loss: 1.3557\n",
      "Epoch 684/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2771 - val_loss: 1.3048\n",
      "Epoch 685/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2677 - val_loss: 1.3863\n",
      "Epoch 686/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2768 - val_loss: 1.3523\n",
      "Epoch 687/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2749 - val_loss: 1.3074\n",
      "Epoch 688/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2754 - val_loss: 1.2987\n",
      "Epoch 689/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2770 - val_loss: 1.2786\n",
      "Epoch 690/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2704 - val_loss: 1.3772\n",
      "Epoch 691/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2680 - val_loss: 1.3074\n",
      "Epoch 692/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2760 - val_loss: 1.3151\n",
      "Epoch 693/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2671 - val_loss: 1.3280\n",
      "Epoch 694/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2693 - val_loss: 1.3172\n",
      "Epoch 695/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2742 - val_loss: 1.4357\n",
      "Epoch 696/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2685 - val_loss: 1.3464\n",
      "Epoch 697/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2723 - val_loss: 1.2851\n",
      "Epoch 698/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2714 - val_loss: 1.4343\n",
      "Epoch 699/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2613 - val_loss: 1.3229\n",
      "Epoch 700/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2649 - val_loss: 1.2942\n",
      "Epoch 701/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2641 - val_loss: 1.3416\n",
      "Epoch 702/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2633 - val_loss: 1.3404\n",
      "Epoch 703/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2738 - val_loss: 1.3269\n",
      "Epoch 704/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2791 - val_loss: 1.3489\n",
      "Epoch 705/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2685 - val_loss: 1.3357\n",
      "Epoch 706/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2659 - val_loss: 1.2986\n",
      "Epoch 707/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2649 - val_loss: 1.3110\n",
      "Epoch 708/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2704 - val_loss: 1.3091\n",
      "Epoch 709/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2671 - val_loss: 1.3047\n",
      "Epoch 710/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2682 - val_loss: 1.3349\n",
      "Epoch 711/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2676 - val_loss: 1.3863\n",
      "Epoch 712/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2656 - val_loss: 1.2893\n",
      "Epoch 713/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2600 - val_loss: 1.4103\n",
      "Epoch 714/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2809 - val_loss: 1.3456\n",
      "Epoch 715/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2622 - val_loss: 1.3186\n",
      "Epoch 716/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2686 - val_loss: 1.3246\n",
      "Epoch 717/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2612 - val_loss: 1.2938\n",
      "Epoch 718/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2624 - val_loss: 1.3874\n",
      "Epoch 719/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2652 - val_loss: 1.3446\n",
      "Epoch 720/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2655 - val_loss: 1.2986\n",
      "Epoch 721/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2608 - val_loss: 1.2918\n",
      "Epoch 722/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2768 - val_loss: 1.3645\n",
      "Epoch 723/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2540 - val_loss: 1.3417\n",
      "Epoch 724/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2691 - val_loss: 1.3233\n",
      "Epoch 725/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2530 - val_loss: 1.3116\n",
      "Epoch 726/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2660 - val_loss: 1.3184\n",
      "Epoch 727/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2653 - val_loss: 1.3114\n",
      "Epoch 728/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2575 - val_loss: 1.3099\n",
      "Epoch 729/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2657 - val_loss: 1.4717\n",
      "Epoch 730/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2664 - val_loss: 1.3106\n",
      "Epoch 731/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2554 - val_loss: 1.3097\n",
      "Epoch 732/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2665 - val_loss: 1.2918\n",
      "Epoch 733/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2629 - val_loss: 1.3579\n",
      "Epoch 734/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2724 - val_loss: 1.2966\n",
      "Epoch 735/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2622 - val_loss: 1.3014\n",
      "Epoch 736/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2474 - val_loss: 1.2737\n",
      "Epoch 737/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2556 - val_loss: 1.2780\n",
      "Epoch 738/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2630 - val_loss: 1.3412\n",
      "Epoch 739/750\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2509 - val_loss: 1.3410\n",
      "Epoch 740/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2646 - val_loss: 1.2943\n",
      "Epoch 741/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2581 - val_loss: 1.3196\n",
      "Epoch 742/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2624 - val_loss: 1.2992\n",
      "Epoch 743/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2608 - val_loss: 1.3125\n",
      "Epoch 744/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2596 - val_loss: 1.3106\n",
      "Epoch 745/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2550 - val_loss: 1.2911\n",
      "Epoch 746/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2538 - val_loss: 1.3305\n",
      "Epoch 747/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2533 - val_loss: 1.3407\n",
      "Epoch 748/750\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2567 - val_loss: 1.3479\n",
      "Epoch 749/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2531 - val_loss: 1.3044\n",
      "Epoch 750/750\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2586 - val_loss: 1.3320\n",
      "1.3320079439772667\n",
      "0.9749846795813302\n",
      "Epoch 1/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 10.7233 - val_loss: 5.5696\n",
      "Epoch 2/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 6.6978 - val_loss: 5.9878\n",
      "Epoch 3/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 4.5236 - val_loss: 3.9676\n",
      "Epoch 4/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.6267 - val_loss: 4.0929\n",
      "Epoch 5/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 4.6010 - val_loss: 3.8895\n",
      "Epoch 6/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 4.2692 - val_loss: 3.8623\n",
      "Epoch 7/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 4.2505 - val_loss: 8.4355\n",
      "Epoch 8/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 4.1653 - val_loss: 4.1705\n",
      "Epoch 9/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 4.2093 - val_loss: 3.4195\n",
      "Epoch 10/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 3.6399 - val_loss: 4.2249\n",
      "Epoch 11/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 3.5523 - val_loss: 4.2424\n",
      "Epoch 12/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 3s 7ms/step - loss: 3.2734 - val_loss: 3.1289\n",
      "Epoch 13/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 3.2261 - val_loss: 2.8634\n",
      "Epoch 14/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 3.1587 - val_loss: 2.7941\n",
      "Epoch 15/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 3.0011 - val_loss: 2.9278\n",
      "Epoch 16/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.0182 - val_loss: 2.9639\n",
      "Epoch 17/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.8702 - val_loss: 3.1480\n",
      "Epoch 18/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.8068 - val_loss: 2.7845\n",
      "Epoch 19/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.8818 - val_loss: 2.6029\n",
      "Epoch 20/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.7572 - val_loss: 2.6196\n",
      "Epoch 21/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.7376 - val_loss: 2.9692\n",
      "Epoch 22/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.7046 - val_loss: 2.6278\n",
      "Epoch 23/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.6731 - val_loss: 2.5439\n",
      "Epoch 24/750\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.6156 - val_loss: 2.6274\n",
      "Epoch 25/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.6053 - val_loss: 2.4717\n",
      "Epoch 26/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.5936 - val_loss: 2.5728\n",
      "Epoch 27/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.5349 - val_loss: 2.4346\n",
      "Epoch 28/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.4854 - val_loss: 2.5936\n",
      "Epoch 29/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.4726 - val_loss: 2.4490\n",
      "Epoch 30/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.4767 - val_loss: 2.4137\n",
      "Epoch 31/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.4237 - val_loss: 2.4007\n",
      "Epoch 32/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.3959 - val_loss: 2.2908\n",
      "Epoch 33/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.3665 - val_loss: 2.3642\n",
      "Epoch 34/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.3643 - val_loss: 2.3521\n",
      "Epoch 35/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.3624 - val_loss: 2.2861\n",
      "Epoch 36/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.3192 - val_loss: 2.2641\n",
      "Epoch 37/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.3011 - val_loss: 2.1809\n",
      "Epoch 38/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.2992 - val_loss: 2.2888\n",
      "Epoch 39/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.2662 - val_loss: 2.3334\n",
      "Epoch 40/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.2493 - val_loss: 2.2900\n",
      "Epoch 41/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.2472 - val_loss: 2.1612\n",
      "Epoch 42/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.2454 - val_loss: 2.1858\n",
      "Epoch 43/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.2328 - val_loss: 2.1919\n",
      "Epoch 44/750\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 2.1856 - val_loss: 2.2571\n",
      "Epoch 45/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.2055 - val_loss: 2.3114\n",
      "Epoch 46/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.1840 - val_loss: 2.0973\n",
      "Epoch 47/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.1529 - val_loss: 2.1628\n",
      "Epoch 48/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.1578 - val_loss: 2.0873\n",
      "Epoch 49/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.1200 - val_loss: 2.1652\n",
      "Epoch 50/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.1167 - val_loss: 1.9958\n",
      "Epoch 51/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 2.1092 - val_loss: 2.1503\n",
      "Epoch 52/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.1272 - val_loss: 2.3365\n",
      "Epoch 53/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0826 - val_loss: 2.0321\n",
      "Epoch 54/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0649 - val_loss: 2.0741\n",
      "Epoch 55/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0690 - val_loss: 1.9411\n",
      "Epoch 56/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0594 - val_loss: 2.0944\n",
      "Epoch 57/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0434 - val_loss: 2.0075\n",
      "Epoch 58/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0569 - val_loss: 1.9539\n",
      "Epoch 59/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0034 - val_loss: 1.9948\n",
      "Epoch 60/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0313 - val_loss: 1.9451\n",
      "Epoch 61/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0198 - val_loss: 1.9981\n",
      "Epoch 62/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9970 - val_loss: 1.9836\n",
      "Epoch 63/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9977 - val_loss: 1.9708\n",
      "Epoch 64/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9788 - val_loss: 1.9823\n",
      "Epoch 65/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9989 - val_loss: 1.9347\n",
      "Epoch 66/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9720 - val_loss: 2.0450\n",
      "Epoch 67/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9448 - val_loss: 1.9970\n",
      "Epoch 68/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9844 - val_loss: 2.1899\n",
      "Epoch 69/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9507 - val_loss: 1.9012\n",
      "Epoch 70/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9375 - val_loss: 1.9817\n",
      "Epoch 71/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9390 - val_loss: 1.8922\n",
      "Epoch 72/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9469 - val_loss: 2.0060\n",
      "Epoch 73/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9110 - val_loss: 1.8333\n",
      "Epoch 74/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9082 - val_loss: 1.8882\n",
      "Epoch 75/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9070 - val_loss: 2.0110\n",
      "Epoch 76/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9044 - val_loss: 1.9169\n",
      "Epoch 77/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9050 - val_loss: 1.8864\n",
      "Epoch 78/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8968 - val_loss: 2.0794\n",
      "Epoch 79/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8918 - val_loss: 1.8286\n",
      "Epoch 80/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8831 - val_loss: 1.8736\n",
      "Epoch 81/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8846 - val_loss: 1.8756\n",
      "Epoch 82/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8765 - val_loss: 1.8102\n",
      "Epoch 83/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8514 - val_loss: 1.9561\n",
      "Epoch 84/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8496 - val_loss: 1.8388\n",
      "Epoch 85/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8692 - val_loss: 1.8600\n",
      "Epoch 86/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8531 - val_loss: 2.0965\n",
      "Epoch 87/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8476 - val_loss: 1.8764\n",
      "Epoch 88/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8310 - val_loss: 1.9523\n",
      "Epoch 89/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8290 - val_loss: 1.8277\n",
      "Epoch 90/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8353 - val_loss: 1.8485\n",
      "Epoch 91/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8303 - val_loss: 1.9171\n",
      "Epoch 92/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8317 - val_loss: 1.7690\n",
      "Epoch 93/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8067 - val_loss: 1.7993\n",
      "Epoch 94/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8097 - val_loss: 1.8325\n",
      "Epoch 95/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8249 - val_loss: 1.7917\n",
      "Epoch 96/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8155 - val_loss: 1.7724\n",
      "Epoch 97/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8004 - val_loss: 1.7882\n",
      "Epoch 98/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7881 - val_loss: 1.9282\n",
      "Epoch 99/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8009 - val_loss: 1.8895\n",
      "Epoch 100/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7927 - val_loss: 1.8368\n",
      "Epoch 101/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7934 - val_loss: 1.8180\n",
      "Epoch 102/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7859 - val_loss: 1.7906\n",
      "Epoch 103/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7908 - val_loss: 1.7746\n",
      "Epoch 104/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7982 - val_loss: 1.7533\n",
      "Epoch 105/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7706 - val_loss: 1.7405\n",
      "Epoch 106/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7725 - val_loss: 1.7610\n",
      "Epoch 107/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7643 - val_loss: 1.7352\n",
      "Epoch 108/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7644 - val_loss: 1.7888\n",
      "Epoch 109/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7725 - val_loss: 1.7519\n",
      "Epoch 110/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7498 - val_loss: 1.7614\n",
      "Epoch 111/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7528 - val_loss: 1.7592\n",
      "Epoch 112/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7349 - val_loss: 1.7188\n",
      "Epoch 113/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7457 - val_loss: 1.9104\n",
      "Epoch 114/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7554 - val_loss: 1.7314\n",
      "Epoch 115/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7354 - val_loss: 1.7644\n",
      "Epoch 116/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7299 - val_loss: 1.8356\n",
      "Epoch 117/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7127 - val_loss: 1.6972\n",
      "Epoch 118/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7192 - val_loss: 1.7286\n",
      "Epoch 119/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7275 - val_loss: 1.7558\n",
      "Epoch 120/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7141 - val_loss: 1.7029\n",
      "Epoch 121/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6999 - val_loss: 1.7736\n",
      "Epoch 122/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7247 - val_loss: 1.6685\n",
      "Epoch 123/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6936 - val_loss: 1.7571\n",
      "Epoch 124/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.7126 - val_loss: 1.6883\n",
      "Epoch 125/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6905 - val_loss: 1.7384\n",
      "Epoch 126/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6876 - val_loss: 1.7251\n",
      "Epoch 127/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6874 - val_loss: 1.7763\n",
      "Epoch 128/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6951 - val_loss: 1.6785\n",
      "Epoch 129/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6904 - val_loss: 1.6516\n",
      "Epoch 130/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6835 - val_loss: 1.7995\n",
      "Epoch 131/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6720 - val_loss: 1.6940\n",
      "Epoch 132/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6805 - val_loss: 1.8185\n",
      "Epoch 133/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6632 - val_loss: 1.6314\n",
      "Epoch 134/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6927 - val_loss: 1.7515\n",
      "Epoch 135/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6790 - val_loss: 1.6611\n",
      "Epoch 136/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6646 - val_loss: 1.6700\n",
      "Epoch 137/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6621 - val_loss: 1.7482\n",
      "Epoch 138/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6419 - val_loss: 1.6840\n",
      "Epoch 139/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6557 - val_loss: 1.6310\n",
      "Epoch 140/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6382 - val_loss: 1.6977\n",
      "Epoch 141/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6525 - val_loss: 1.6671\n",
      "Epoch 142/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6576 - val_loss: 1.7159\n",
      "Epoch 143/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6371 - val_loss: 1.6794\n",
      "Epoch 144/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.6352 - val_loss: 1.7042\n",
      "Epoch 145/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6414 - val_loss: 1.6353\n",
      "Epoch 146/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6342 - val_loss: 1.5856\n",
      "Epoch 147/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6423 - val_loss: 1.6656\n",
      "Epoch 148/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6214 - val_loss: 1.6980\n",
      "Epoch 149/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6310 - val_loss: 1.5952\n",
      "Epoch 150/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6235 - val_loss: 1.6935\n",
      "Epoch 151/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6075 - val_loss: 1.5872\n",
      "Epoch 152/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6042 - val_loss: 1.6647\n",
      "Epoch 153/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6263 - val_loss: 1.7177\n",
      "Epoch 154/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6024 - val_loss: 1.6226\n",
      "Epoch 155/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6123 - val_loss: 1.6239\n",
      "Epoch 156/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6089 - val_loss: 1.7514\n",
      "Epoch 157/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5990 - val_loss: 1.5611\n",
      "Epoch 158/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6018 - val_loss: 1.5710\n",
      "Epoch 159/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5944 - val_loss: 1.5589\n",
      "Epoch 160/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6065 - val_loss: 1.6191\n",
      "Epoch 161/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5942 - val_loss: 1.6084\n",
      "Epoch 162/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5942 - val_loss: 1.6134\n",
      "Epoch 163/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5914 - val_loss: 1.5885\n",
      "Epoch 164/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5945 - val_loss: 1.5930\n",
      "Epoch 165/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5733 - val_loss: 1.5682\n",
      "Epoch 166/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5730 - val_loss: 1.6056\n",
      "Epoch 167/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5853 - val_loss: 1.5650\n",
      "Epoch 168/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5818 - val_loss: 1.6263\n",
      "Epoch 169/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5744 - val_loss: 1.7171\n",
      "Epoch 170/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5712 - val_loss: 1.5691\n",
      "Epoch 171/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5843 - val_loss: 1.6177\n",
      "Epoch 172/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5771 - val_loss: 1.5979\n",
      "Epoch 173/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5870 - val_loss: 1.6190\n",
      "Epoch 174/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5728 - val_loss: 1.5898\n",
      "Epoch 175/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5766 - val_loss: 1.7818\n",
      "Epoch 176/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5681 - val_loss: 1.6477\n",
      "Epoch 177/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5583 - val_loss: 1.5878\n",
      "Epoch 178/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5553 - val_loss: 1.6284\n",
      "Epoch 179/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5559 - val_loss: 1.5446\n",
      "Epoch 180/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5588 - val_loss: 1.5460\n",
      "Epoch 181/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5395 - val_loss: 1.5669\n",
      "Epoch 182/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5563 - val_loss: 1.5961\n",
      "Epoch 183/750\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.5442 - val_loss: 1.6537\n",
      "Epoch 184/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5565 - val_loss: 1.5609\n",
      "Epoch 185/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5434 - val_loss: 1.5468\n",
      "Epoch 186/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5412 - val_loss: 1.5382\n",
      "Epoch 187/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5382 - val_loss: 1.5693\n",
      "Epoch 188/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5438 - val_loss: 1.5855\n",
      "Epoch 189/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5493 - val_loss: 1.6217\n",
      "Epoch 190/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5556 - val_loss: 1.6098\n",
      "Epoch 191/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5427 - val_loss: 1.5372\n",
      "Epoch 192/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5442 - val_loss: 1.5849\n",
      "Epoch 193/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5434 - val_loss: 1.5569\n",
      "Epoch 194/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5252 - val_loss: 1.6659\n",
      "Epoch 195/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5315 - val_loss: 1.6263\n",
      "Epoch 196/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5435 - val_loss: 1.5592\n",
      "Epoch 197/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5268 - val_loss: 1.5883\n",
      "Epoch 198/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5297 - val_loss: 1.5946\n",
      "Epoch 199/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5320 - val_loss: 1.5791\n",
      "Epoch 200/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5218 - val_loss: 1.5505\n",
      "Epoch 201/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5238 - val_loss: 1.5066\n",
      "Epoch 202/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5137 - val_loss: 1.5611\n",
      "Epoch 203/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5197 - val_loss: 1.5373\n",
      "Epoch 204/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5203 - val_loss: 1.5182\n",
      "Epoch 205/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5138 - val_loss: 1.5081\n",
      "Epoch 206/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5213 - val_loss: 1.5541\n",
      "Epoch 207/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5132 - val_loss: 1.5788\n",
      "Epoch 208/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5204 - val_loss: 1.5178\n",
      "Epoch 209/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5169 - val_loss: 1.5907\n",
      "Epoch 210/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5030 - val_loss: 1.5289\n",
      "Epoch 211/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4981 - val_loss: 1.5017\n",
      "Epoch 212/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5011 - val_loss: 1.5881\n",
      "Epoch 213/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5111 - val_loss: 1.5003\n",
      "Epoch 214/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5056 - val_loss: 1.5099\n",
      "Epoch 215/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5083 - val_loss: 1.4910\n",
      "Epoch 216/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5079 - val_loss: 1.5664\n",
      "Epoch 217/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4998 - val_loss: 1.6311\n",
      "Epoch 218/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4988 - val_loss: 1.5043\n",
      "Epoch 219/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4828 - val_loss: 1.5496\n",
      "Epoch 220/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4995 - val_loss: 1.4817\n",
      "Epoch 221/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5004 - val_loss: 1.5248\n",
      "Epoch 222/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5073 - val_loss: 1.4953\n",
      "Epoch 223/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4960 - val_loss: 1.5012\n",
      "Epoch 224/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4835 - val_loss: 1.4774\n",
      "Epoch 225/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4946 - val_loss: 1.5089\n",
      "Epoch 226/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4810 - val_loss: 1.5289\n",
      "Epoch 227/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4953 - val_loss: 1.5155\n",
      "Epoch 228/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4815 - val_loss: 1.4972\n",
      "Epoch 229/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4743 - val_loss: 1.4844\n",
      "Epoch 230/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4825 - val_loss: 1.5332\n",
      "Epoch 231/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4867 - val_loss: 1.5717\n",
      "Epoch 232/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4869 - val_loss: 1.4814\n",
      "Epoch 233/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4803 - val_loss: 1.5317\n",
      "Epoch 234/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4807 - val_loss: 1.5491\n",
      "Epoch 235/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4766 - val_loss: 1.5115\n",
      "Epoch 236/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4670 - val_loss: 1.4549\n",
      "Epoch 237/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4720 - val_loss: 1.5298\n",
      "Epoch 238/750\n",
      "432/432 [==============================] - 7s 15ms/step - loss: 1.4761 - val_loss: 1.5050\n",
      "Epoch 239/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4665 - val_loss: 1.5230\n",
      "Epoch 240/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4720 - val_loss: 1.5407\n",
      "Epoch 241/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4818 - val_loss: 1.5446\n",
      "Epoch 242/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4690 - val_loss: 1.5649\n",
      "Epoch 243/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4659 - val_loss: 1.4930\n",
      "Epoch 244/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4837 - val_loss: 1.4894\n",
      "Epoch 245/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4522 - val_loss: 1.5320\n",
      "Epoch 246/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4800 - val_loss: 1.5060\n",
      "Epoch 247/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4695 - val_loss: 1.5687\n",
      "Epoch 248/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4681 - val_loss: 1.4954\n",
      "Epoch 249/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4591 - val_loss: 1.5122\n",
      "Epoch 250/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4570 - val_loss: 1.5083\n",
      "Epoch 251/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4603 - val_loss: 1.5603\n",
      "Epoch 252/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4633 - val_loss: 1.4751\n",
      "Epoch 253/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4582 - val_loss: 1.4922\n",
      "Epoch 254/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4596 - val_loss: 1.4728\n",
      "Epoch 255/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4644 - val_loss: 1.5157\n",
      "Epoch 256/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4652 - val_loss: 1.5510\n",
      "Epoch 257/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4449 - val_loss: 1.4665\n",
      "Epoch 258/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4521 - val_loss: 1.5480\n",
      "Epoch 259/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4490 - val_loss: 1.5077\n",
      "Epoch 260/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4453 - val_loss: 1.4453\n",
      "Epoch 261/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4622 - val_loss: 1.4837\n",
      "Epoch 262/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4532 - val_loss: 1.4843\n",
      "Epoch 263/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4485 - val_loss: 1.4981\n",
      "Epoch 264/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4505 - val_loss: 1.5048\n",
      "Epoch 265/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4438 - val_loss: 1.5090\n",
      "Epoch 266/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4686 - val_loss: 1.5808\n",
      "Epoch 267/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4587 - val_loss: 1.4694\n",
      "Epoch 268/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4360 - val_loss: 1.4847\n",
      "Epoch 269/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4669 - val_loss: 1.4969\n",
      "Epoch 270/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4560 - val_loss: 1.4658\n",
      "Epoch 271/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4390 - val_loss: 1.4889\n",
      "Epoch 272/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4481 - val_loss: 1.4909\n",
      "Epoch 273/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4454 - val_loss: 1.4420\n",
      "Epoch 274/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4471 - val_loss: 1.5013\n",
      "Epoch 275/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4331 - val_loss: 1.4906\n",
      "Epoch 276/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4327 - val_loss: 1.4680\n",
      "Epoch 277/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4472 - val_loss: 1.4420\n",
      "Epoch 278/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4494 - val_loss: 1.6252\n",
      "Epoch 279/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4342 - val_loss: 1.4712\n",
      "Epoch 280/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4475 - val_loss: 1.4578\n",
      "Epoch 281/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4384 - val_loss: 1.4808\n",
      "Epoch 282/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4419 - val_loss: 1.4852\n",
      "Epoch 283/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4272 - val_loss: 1.4607\n",
      "Epoch 284/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4430 - val_loss: 1.4916\n",
      "Epoch 285/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4341 - val_loss: 1.4818\n",
      "Epoch 286/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4348 - val_loss: 1.5310\n",
      "Epoch 287/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4358 - val_loss: 1.4455\n",
      "Epoch 288/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4369 - val_loss: 1.5339\n",
      "Epoch 289/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4306 - val_loss: 1.5200\n",
      "Epoch 290/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4324 - val_loss: 1.4244\n",
      "Epoch 291/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4332 - val_loss: 1.4786\n",
      "Epoch 292/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4202 - val_loss: 1.4660\n",
      "Epoch 293/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4297 - val_loss: 1.4734\n",
      "Epoch 294/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4383 - val_loss: 1.4340\n",
      "Epoch 295/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4247 - val_loss: 1.4568\n",
      "Epoch 296/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4483 - val_loss: 1.5018\n",
      "Epoch 297/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4223 - val_loss: 1.4371\n",
      "Epoch 298/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4198 - val_loss: 1.5071\n",
      "Epoch 299/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4236 - val_loss: 1.5224\n",
      "Epoch 300/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4257 - val_loss: 1.5284\n",
      "Epoch 301/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4293 - val_loss: 1.4887\n",
      "Epoch 302/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4231 - val_loss: 1.4188\n",
      "Epoch 303/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4264 - val_loss: 1.5090\n",
      "Epoch 304/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4247 - val_loss: 1.4673\n",
      "Epoch 305/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4291 - val_loss: 1.5180\n",
      "Epoch 306/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4254 - val_loss: 1.4401\n",
      "Epoch 307/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4162 - val_loss: 1.4764\n",
      "Epoch 308/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4190 - val_loss: 1.4280\n",
      "Epoch 309/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4300 - val_loss: 1.4276\n",
      "Epoch 310/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4197 - val_loss: 1.5269\n",
      "Epoch 311/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4147 - val_loss: 1.4538\n",
      "Epoch 312/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4089 - val_loss: 1.4825\n",
      "Epoch 313/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4127 - val_loss: 1.4576\n",
      "Epoch 314/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4205 - val_loss: 1.4631\n",
      "Epoch 315/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4322 - val_loss: 1.4532\n",
      "Epoch 316/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4182 - val_loss: 1.4103\n",
      "Epoch 317/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4093 - val_loss: 1.4605\n",
      "Epoch 318/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4180 - val_loss: 1.4744\n",
      "Epoch 319/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4160 - val_loss: 1.3933\n",
      "Epoch 320/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4212 - val_loss: 1.4395\n",
      "Epoch 321/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4209 - val_loss: 1.4643\n",
      "Epoch 322/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4084 - val_loss: 1.4155\n",
      "Epoch 323/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3932 - val_loss: 1.4118\n",
      "Epoch 324/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4124 - val_loss: 1.4499\n",
      "Epoch 325/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3972 - val_loss: 1.4181\n",
      "Epoch 326/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4213 - val_loss: 1.4434\n",
      "Epoch 327/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4073 - val_loss: 1.4873\n",
      "Epoch 328/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4036 - val_loss: 1.4327\n",
      "Epoch 329/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4090 - val_loss: 1.4552\n",
      "Epoch 330/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4156 - val_loss: 1.4964\n",
      "Epoch 331/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3997 - val_loss: 1.4579\n",
      "Epoch 332/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3953 - val_loss: 1.4584\n",
      "Epoch 333/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4026 - val_loss: 1.4860\n",
      "Epoch 334/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4044 - val_loss: 1.5928\n",
      "Epoch 335/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4070 - val_loss: 1.4406\n",
      "Epoch 336/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4113 - val_loss: 1.4844\n",
      "Epoch 337/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4068 - val_loss: 1.4779\n",
      "Epoch 338/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3971 - val_loss: 1.4467\n",
      "Epoch 339/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4048 - val_loss: 1.4796\n",
      "Epoch 340/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4103 - val_loss: 1.4146\n",
      "Epoch 341/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3949 - val_loss: 1.4187\n",
      "Epoch 342/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3919 - val_loss: 1.4255\n",
      "Epoch 343/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3962 - val_loss: 1.4775\n",
      "Epoch 344/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3978 - val_loss: 1.5188\n",
      "Epoch 345/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4070 - val_loss: 1.4092\n",
      "Epoch 346/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3897 - val_loss: 1.4503\n",
      "Epoch 347/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3997 - val_loss: 1.4294\n",
      "Epoch 348/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3956 - val_loss: 1.4594\n",
      "Epoch 349/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4082 - val_loss: 1.4849\n",
      "Epoch 350/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3865 - val_loss: 1.4621\n",
      "Epoch 351/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3952 - val_loss: 1.3951\n",
      "Epoch 352/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3971 - val_loss: 1.4147\n",
      "Epoch 353/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3900 - val_loss: 1.4273\n",
      "Epoch 354/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3750 - val_loss: 1.4530\n",
      "Epoch 355/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3907 - val_loss: 1.4497\n",
      "Epoch 356/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4024 - val_loss: 1.3993\n",
      "Epoch 357/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3877 - val_loss: 1.4309\n",
      "Epoch 358/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3955 - val_loss: 1.4359\n",
      "Epoch 359/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3956 - val_loss: 1.4083\n",
      "Epoch 360/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3815 - val_loss: 1.5003\n",
      "Epoch 361/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3891 - val_loss: 1.3934\n",
      "Epoch 362/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3879 - val_loss: 1.4829\n",
      "Epoch 363/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3868 - val_loss: 1.4035\n",
      "Epoch 364/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3923 - val_loss: 1.4439\n",
      "Epoch 365/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3932 - val_loss: 1.4951\n",
      "Epoch 366/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3800 - val_loss: 1.4398\n",
      "Epoch 367/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3920 - val_loss: 1.4269\n",
      "Epoch 368/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3887 - val_loss: 1.4156\n",
      "Epoch 369/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3720 - val_loss: 1.3933\n",
      "Epoch 370/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3774 - val_loss: 1.4069\n",
      "Epoch 371/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3803 - val_loss: 1.4046\n",
      "Epoch 372/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3676 - val_loss: 1.4345\n",
      "Epoch 373/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3810 - val_loss: 1.4081\n",
      "Epoch 374/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3815 - val_loss: 1.4113\n",
      "Epoch 375/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3886 - val_loss: 1.4254\n",
      "Epoch 376/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3757 - val_loss: 1.3811\n",
      "Epoch 377/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3731 - val_loss: 1.3912\n",
      "Epoch 378/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3793 - val_loss: 1.3880\n",
      "Epoch 379/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3841 - val_loss: 1.4537\n",
      "Epoch 380/750\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3735 - val_loss: 1.5033\n",
      "Epoch 381/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3641 - val_loss: 1.4247\n",
      "Epoch 382/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3791 - val_loss: 1.4121\n",
      "Epoch 383/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3648 - val_loss: 1.4398\n",
      "Epoch 384/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3875 - val_loss: 1.4110\n",
      "Epoch 385/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3849 - val_loss: 1.4901\n",
      "Epoch 386/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3689 - val_loss: 1.5222\n",
      "Epoch 387/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3770 - val_loss: 1.3971\n",
      "Epoch 388/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3800 - val_loss: 1.3941\n",
      "Epoch 389/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3697 - val_loss: 1.4456\n",
      "Epoch 390/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3685 - val_loss: 1.4009\n",
      "Epoch 391/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3694 - val_loss: 1.3921\n",
      "Epoch 392/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3784 - val_loss: 1.4408\n",
      "Epoch 393/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3723 - val_loss: 1.4222\n",
      "Epoch 394/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3641 - val_loss: 1.4044\n",
      "Epoch 395/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3753 - val_loss: 1.4364\n",
      "Epoch 396/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3738 - val_loss: 1.4202\n",
      "Epoch 397/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3649 - val_loss: 1.4090\n",
      "Epoch 398/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3768 - val_loss: 1.3875\n",
      "Epoch 399/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3698 - val_loss: 1.3870\n",
      "Epoch 400/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3763 - val_loss: 1.4221\n",
      "Epoch 401/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3635 - val_loss: 1.4056\n",
      "Epoch 402/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3797 - val_loss: 1.4525\n",
      "Epoch 403/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3634 - val_loss: 1.3699\n",
      "Epoch 404/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3493 - val_loss: 1.4024\n",
      "Epoch 405/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3698 - val_loss: 1.4449\n",
      "Epoch 406/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3649 - val_loss: 1.4151\n",
      "Epoch 407/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3668 - val_loss: 1.4745\n",
      "Epoch 408/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3779 - val_loss: 1.3609\n",
      "Epoch 409/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3597 - val_loss: 1.4526\n",
      "Epoch 410/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3508 - val_loss: 1.3847\n",
      "Epoch 411/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3617 - val_loss: 1.3896\n",
      "Epoch 412/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3671 - val_loss: 1.5155\n",
      "Epoch 413/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3651 - val_loss: 1.3769\n",
      "Epoch 414/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3616 - val_loss: 1.4799\n",
      "Epoch 415/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3640 - val_loss: 1.3971\n",
      "Epoch 416/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3722 - val_loss: 1.4055\n",
      "Epoch 417/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3514 - val_loss: 1.3925\n",
      "Epoch 418/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3589 - val_loss: 1.4028\n",
      "Epoch 419/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3567 - val_loss: 1.4399\n",
      "Epoch 420/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3545 - val_loss: 1.3880\n",
      "Epoch 421/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3676 - val_loss: 1.4123\n",
      "Epoch 422/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3517 - val_loss: 1.3778\n",
      "Epoch 423/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3574 - val_loss: 1.4024\n",
      "Epoch 424/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3539 - val_loss: 1.3860\n",
      "Epoch 425/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3598 - val_loss: 1.3963\n",
      "Epoch 426/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3509 - val_loss: 1.4417\n",
      "Epoch 427/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3578 - val_loss: 1.3562\n",
      "Epoch 428/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3563 - val_loss: 1.3988\n",
      "Epoch 429/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3501 - val_loss: 1.4515\n",
      "Epoch 430/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3496 - val_loss: 1.4302\n",
      "Epoch 431/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3626 - val_loss: 1.4237\n",
      "Epoch 432/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3515 - val_loss: 1.3908\n",
      "Epoch 433/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3537 - val_loss: 1.4395\n",
      "Epoch 434/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3622 - val_loss: 1.3835\n",
      "Epoch 435/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3409 - val_loss: 1.4382\n",
      "Epoch 436/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3600 - val_loss: 1.3704\n",
      "Epoch 437/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3497 - val_loss: 1.5380\n",
      "Epoch 438/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3528 - val_loss: 1.3926\n",
      "Epoch 439/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3491 - val_loss: 1.3819\n",
      "Epoch 440/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3504 - val_loss: 1.4640\n",
      "Epoch 441/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3491 - val_loss: 1.4620\n",
      "Epoch 442/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3443 - val_loss: 1.3923\n",
      "Epoch 443/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3493 - val_loss: 1.3803\n",
      "Epoch 444/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3412 - val_loss: 1.4985\n",
      "Epoch 445/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3500 - val_loss: 1.4203\n",
      "Epoch 446/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3363 - val_loss: 1.3363\n",
      "Epoch 447/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3377 - val_loss: 1.4386\n",
      "Epoch 448/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3486 - val_loss: 1.3740\n",
      "Epoch 449/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3408 - val_loss: 1.4094\n",
      "Epoch 450/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3554 - val_loss: 1.3989\n",
      "Epoch 451/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3395 - val_loss: 1.3647\n",
      "Epoch 452/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3406 - val_loss: 1.4125\n",
      "Epoch 453/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3459 - val_loss: 1.4203\n",
      "Epoch 454/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3358 - val_loss: 1.3689\n",
      "Epoch 455/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3369 - val_loss: 1.4410\n",
      "Epoch 456/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3411 - val_loss: 1.3700\n",
      "Epoch 457/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3417 - val_loss: 1.3697\n",
      "Epoch 458/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3440 - val_loss: 1.4146\n",
      "Epoch 459/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3459 - val_loss: 1.3772\n",
      "Epoch 460/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3428 - val_loss: 1.4377\n",
      "Epoch 461/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3333 - val_loss: 1.3971\n",
      "Epoch 462/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3484 - val_loss: 1.3619\n",
      "Epoch 463/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3398 - val_loss: 1.4727\n",
      "Epoch 464/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3450 - val_loss: 1.4384\n",
      "Epoch 465/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3328 - val_loss: 1.3431\n",
      "Epoch 466/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3273 - val_loss: 1.4527\n",
      "Epoch 467/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3324 - val_loss: 1.3806\n",
      "Epoch 468/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3371 - val_loss: 1.3954\n",
      "Epoch 469/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3333 - val_loss: 1.3878\n",
      "Epoch 470/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3318 - val_loss: 1.3971\n",
      "Epoch 471/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3467 - val_loss: 1.4166\n",
      "Epoch 472/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3362 - val_loss: 1.3726\n",
      "Epoch 473/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3348 - val_loss: 1.3658\n",
      "Epoch 474/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3364 - val_loss: 1.4407\n",
      "Epoch 475/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3369 - val_loss: 1.3645\n",
      "Epoch 476/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3326 - val_loss: 1.3608\n",
      "Epoch 477/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3276 - val_loss: 1.3579\n",
      "Epoch 478/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3484 - val_loss: 1.3644\n",
      "Epoch 479/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3268 - val_loss: 1.3924\n",
      "Epoch 480/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3432 - val_loss: 1.4478\n",
      "Epoch 481/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3276 - val_loss: 1.3711\n",
      "Epoch 482/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3314 - val_loss: 1.3840\n",
      "Epoch 483/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3291 - val_loss: 1.4215\n",
      "Epoch 484/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3309 - val_loss: 1.3759\n",
      "Epoch 485/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3330 - val_loss: 1.3518\n",
      "Epoch 486/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3332 - val_loss: 1.3611\n",
      "Epoch 487/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3276 - val_loss: 1.4452\n",
      "Epoch 488/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3396 - val_loss: 1.4218\n",
      "Epoch 489/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3254 - val_loss: 1.3690\n",
      "Epoch 490/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3181 - val_loss: 1.5534\n",
      "Epoch 491/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3364 - val_loss: 1.4188\n",
      "Epoch 492/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3240 - val_loss: 1.4241\n",
      "Epoch 493/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3211 - val_loss: 1.3711\n",
      "Epoch 494/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3247 - val_loss: 1.3656\n",
      "Epoch 495/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3185 - val_loss: 1.4192\n",
      "Epoch 496/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3312 - val_loss: 1.4522\n",
      "Epoch 497/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3274 - val_loss: 1.3748\n",
      "Epoch 498/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3350 - val_loss: 1.3760\n",
      "Epoch 499/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3275 - val_loss: 1.3886\n",
      "Epoch 500/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3180 - val_loss: 1.3422\n",
      "Epoch 501/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3185 - val_loss: 1.4010\n",
      "Epoch 502/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3285 - val_loss: 1.4170\n",
      "Epoch 503/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3309 - val_loss: 1.3521\n",
      "Epoch 504/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3364 - val_loss: 1.3577\n",
      "Epoch 505/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3246 - val_loss: 1.3739\n",
      "Epoch 506/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3363 - val_loss: 1.4483\n",
      "Epoch 507/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3162 - val_loss: 1.3349\n",
      "Epoch 508/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3221 - val_loss: 1.3935\n",
      "Epoch 509/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3157 - val_loss: 1.3553\n",
      "Epoch 510/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3152 - val_loss: 1.3839\n",
      "Epoch 511/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3168 - val_loss: 1.3259\n",
      "Epoch 512/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3315 - val_loss: 1.3876\n",
      "Epoch 513/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3251 - val_loss: 1.3537\n",
      "Epoch 514/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3253 - val_loss: 1.3852\n",
      "Epoch 515/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3152 - val_loss: 1.3428\n",
      "Epoch 516/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3214 - val_loss: 1.3830\n",
      "Epoch 517/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3121 - val_loss: 1.3685\n",
      "Epoch 518/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3160 - val_loss: 1.3978\n",
      "Epoch 519/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3213 - val_loss: 1.3432\n",
      "Epoch 520/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3402 - val_loss: 1.3956\n",
      "Epoch 521/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3144 - val_loss: 1.3622\n",
      "Epoch 522/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3301 - val_loss: 1.3649\n",
      "Epoch 523/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3132 - val_loss: 1.3478\n",
      "Epoch 524/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3197 - val_loss: 1.3781\n",
      "Epoch 525/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3113 - val_loss: 1.3765\n",
      "Epoch 526/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3229 - val_loss: 1.3771\n",
      "Epoch 527/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3188 - val_loss: 1.3750\n",
      "Epoch 528/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3227 - val_loss: 1.4272\n",
      "Epoch 529/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3082 - val_loss: 1.3855\n",
      "Epoch 530/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3178 - val_loss: 1.3139\n",
      "Epoch 531/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3179 - val_loss: 1.3830\n",
      "Epoch 532/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3168 - val_loss: 1.3318\n",
      "Epoch 533/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3183 - val_loss: 1.4611\n",
      "Epoch 534/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3167 - val_loss: 1.2969\n",
      "Epoch 535/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3177 - val_loss: 1.3426\n",
      "Epoch 536/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3248 - val_loss: 1.3463\n",
      "Epoch 537/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3230 - val_loss: 1.3923\n",
      "Epoch 538/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3213 - val_loss: 1.3612\n",
      "Epoch 539/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3090 - val_loss: 1.4225\n",
      "Epoch 540/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3209 - val_loss: 1.3436\n",
      "Epoch 541/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3140 - val_loss: 1.3166\n",
      "Epoch 542/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2998 - val_loss: 1.3514\n",
      "Epoch 543/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3148 - val_loss: 1.3422\n",
      "Epoch 544/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3106 - val_loss: 1.3725\n",
      "Epoch 545/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3075 - val_loss: 1.4593\n",
      "Epoch 546/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3137 - val_loss: 1.3425\n",
      "Epoch 547/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3188 - val_loss: 1.3884\n",
      "Epoch 548/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3133 - val_loss: 1.3429\n",
      "Epoch 549/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3092 - val_loss: 1.3340\n",
      "Epoch 550/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3101 - val_loss: 1.3639\n",
      "Epoch 551/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2948 - val_loss: 1.3448\n",
      "Epoch 552/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3267 - val_loss: 1.3350\n",
      "Epoch 553/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3164 - val_loss: 1.3743\n",
      "Epoch 554/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3045 - val_loss: 1.3232\n",
      "Epoch 555/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3103 - val_loss: 1.3143\n",
      "Epoch 556/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3002 - val_loss: 1.3529\n",
      "Epoch 557/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2972 - val_loss: 1.3108\n",
      "Epoch 558/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3102 - val_loss: 1.3736\n",
      "Epoch 559/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3081 - val_loss: 1.3593\n",
      "Epoch 560/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3018 - val_loss: 1.3786\n",
      "Epoch 561/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3075 - val_loss: 1.3676\n",
      "Epoch 562/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3125 - val_loss: 1.3277\n",
      "Epoch 563/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3079 - val_loss: 1.4231\n",
      "Epoch 564/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3053 - val_loss: 1.4541\n",
      "Epoch 565/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3077 - val_loss: 1.3255\n",
      "Epoch 566/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3181 - val_loss: 1.3864\n",
      "Epoch 567/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3174 - val_loss: 1.3297\n",
      "Epoch 568/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3018 - val_loss: 1.3266\n",
      "Epoch 569/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2993 - val_loss: 1.3597\n",
      "Epoch 570/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2966 - val_loss: 1.3314\n",
      "Epoch 571/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2984 - val_loss: 1.3791\n",
      "Epoch 572/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3016 - val_loss: 1.3641\n",
      "Epoch 573/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3055 - val_loss: 1.3673\n",
      "Epoch 574/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3018 - val_loss: 1.3884\n",
      "Epoch 575/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3108 - val_loss: 1.3290\n",
      "Epoch 576/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3116 - val_loss: 1.3241\n",
      "Epoch 577/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2973 - val_loss: 1.3273\n",
      "Epoch 578/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2973 - val_loss: 1.3026\n",
      "Epoch 579/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3174 - val_loss: 1.3085\n",
      "Epoch 580/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2947 - val_loss: 1.3561\n",
      "Epoch 581/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3076 - val_loss: 1.3823\n",
      "Epoch 582/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2993 - val_loss: 1.3867\n",
      "Epoch 583/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3035 - val_loss: 1.3537\n",
      "Epoch 584/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3006 - val_loss: 1.3015\n",
      "Epoch 585/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3072 - val_loss: 1.3722\n",
      "Epoch 586/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3014 - val_loss: 1.3477\n",
      "Epoch 587/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3053 - val_loss: 1.3132\n",
      "Epoch 588/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3020 - val_loss: 1.3425\n",
      "Epoch 589/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3113 - val_loss: 1.3606\n",
      "Epoch 590/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2898 - val_loss: 1.3373\n",
      "Epoch 591/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2951 - val_loss: 1.3248\n",
      "Epoch 592/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2963 - val_loss: 1.3152\n",
      "Epoch 593/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3050 - val_loss: 1.3058\n",
      "Epoch 594/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3008 - val_loss: 1.3684\n",
      "Epoch 595/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2944 - val_loss: 1.3217\n",
      "Epoch 596/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3009 - val_loss: 1.3868\n",
      "Epoch 597/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2959 - val_loss: 1.3358\n",
      "Epoch 598/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2897 - val_loss: 1.3320\n",
      "Epoch 599/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3037 - val_loss: 1.3055\n",
      "Epoch 600/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2900 - val_loss: 1.4274\n",
      "Epoch 601/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3052 - val_loss: 1.3033\n",
      "Epoch 602/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2967 - val_loss: 1.3656\n",
      "Epoch 603/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2975 - val_loss: 1.3519\n",
      "Epoch 604/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2997 - val_loss: 1.3367\n",
      "Epoch 605/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2890 - val_loss: 1.3494\n",
      "Epoch 606/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3072 - val_loss: 1.3762\n",
      "Epoch 607/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3029 - val_loss: 1.3388\n",
      "Epoch 608/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2983 - val_loss: 1.3341\n",
      "Epoch 609/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3074 - val_loss: 1.3069\n",
      "Epoch 610/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2983 - val_loss: 1.3173\n",
      "Epoch 611/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3024 - val_loss: 1.3329\n",
      "Epoch 612/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2853 - val_loss: 1.3363\n",
      "Epoch 613/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2949 - val_loss: 1.3258\n",
      "Epoch 614/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2916 - val_loss: 1.3129\n",
      "Epoch 615/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2997 - val_loss: 1.3127\n",
      "Epoch 616/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2962 - val_loss: 1.3559\n",
      "Epoch 617/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2876 - val_loss: 1.3123\n",
      "Epoch 618/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2810 - val_loss: 1.3241\n",
      "Epoch 619/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2987 - val_loss: 1.3482\n",
      "Epoch 620/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2860 - val_loss: 1.3396\n",
      "Epoch 621/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2892 - val_loss: 1.3338\n",
      "Epoch 622/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2930 - val_loss: 1.3576\n",
      "Epoch 623/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2966 - val_loss: 1.3388\n",
      "Epoch 624/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2832 - val_loss: 1.2985\n",
      "Epoch 625/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2996 - val_loss: 1.3134\n",
      "Epoch 626/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2914 - val_loss: 1.3496\n",
      "Epoch 627/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2990 - val_loss: 1.3648\n",
      "Epoch 628/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2813 - val_loss: 1.3086\n",
      "Epoch 629/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2882 - val_loss: 1.2900\n",
      "Epoch 630/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2845 - val_loss: 1.3086\n",
      "Epoch 631/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2866 - val_loss: 1.4304\n",
      "Epoch 632/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2884 - val_loss: 1.3632\n",
      "Epoch 633/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2922 - val_loss: 1.2908\n",
      "Epoch 634/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2909 - val_loss: 1.3480\n",
      "Epoch 635/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2720 - val_loss: 1.3421\n",
      "Epoch 636/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2937 - val_loss: 1.3310\n",
      "Epoch 637/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2886 - val_loss: 1.3475\n",
      "Epoch 638/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2935 - val_loss: 1.3079\n",
      "Epoch 639/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2969 - val_loss: 1.3669\n",
      "Epoch 640/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2851 - val_loss: 1.3280\n",
      "Epoch 641/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2840 - val_loss: 1.3256\n",
      "Epoch 642/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2770 - val_loss: 1.3017\n",
      "Epoch 643/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2895 - val_loss: 1.3507\n",
      "Epoch 644/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2828 - val_loss: 1.3040\n",
      "Epoch 645/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2701 - val_loss: 1.4487\n",
      "Epoch 646/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2877 - val_loss: 1.3007\n",
      "Epoch 647/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2863 - val_loss: 1.3630\n",
      "Epoch 648/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2963 - val_loss: 1.3326\n",
      "Epoch 649/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2929 - val_loss: 1.3024\n",
      "Epoch 650/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2721 - val_loss: 1.3185\n",
      "Epoch 651/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2858 - val_loss: 1.4166\n",
      "Epoch 652/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2816 - val_loss: 1.3334\n",
      "Epoch 653/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2866 - val_loss: 1.3395\n",
      "Epoch 654/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2860 - val_loss: 1.3514\n",
      "Epoch 655/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2749 - val_loss: 1.3430\n",
      "Epoch 656/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2804 - val_loss: 1.3497\n",
      "Epoch 657/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2847 - val_loss: 1.4016\n",
      "Epoch 658/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2798 - val_loss: 1.3142\n",
      "Epoch 659/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2815 - val_loss: 1.3927\n",
      "Epoch 660/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2805 - val_loss: 1.3473\n",
      "Epoch 661/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2794 - val_loss: 1.3138\n",
      "Epoch 662/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2849 - val_loss: 1.3064\n",
      "Epoch 663/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2824 - val_loss: 1.3737\n",
      "Epoch 664/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2812 - val_loss: 1.3709\n",
      "Epoch 665/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2808 - val_loss: 1.3534\n",
      "Epoch 666/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2663 - val_loss: 1.3115\n",
      "Epoch 667/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2788 - val_loss: 1.3120\n",
      "Epoch 668/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2759 - val_loss: 1.3114\n",
      "Epoch 669/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2719 - val_loss: 1.3248\n",
      "Epoch 670/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2734 - val_loss: 1.3046\n",
      "Epoch 671/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2876 - val_loss: 1.3421\n",
      "Epoch 672/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2821 - val_loss: 1.4123\n",
      "Epoch 673/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2855 - val_loss: 1.3293\n",
      "Epoch 674/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2790 - val_loss: 1.3127\n",
      "Epoch 675/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2819 - val_loss: 1.3488\n",
      "Epoch 676/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2757 - val_loss: 1.3619\n",
      "Epoch 677/750\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2751 - val_loss: 1.3266\n",
      "Epoch 678/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2767 - val_loss: 1.3514\n",
      "Epoch 679/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2687 - val_loss: 1.2984\n",
      "Epoch 680/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2717 - val_loss: 1.3087\n",
      "Epoch 681/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2837 - val_loss: 1.3528\n",
      "Epoch 682/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2755 - val_loss: 1.2998\n",
      "Epoch 683/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2727 - val_loss: 1.2871\n",
      "Epoch 684/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2783 - val_loss: 1.3576\n",
      "Epoch 685/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2736 - val_loss: 1.3464\n",
      "Epoch 686/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2804 - val_loss: 1.3061\n",
      "Epoch 687/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2787 - val_loss: 1.3358\n",
      "Epoch 688/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2755 - val_loss: 1.3228\n",
      "Epoch 689/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2726 - val_loss: 1.3326\n",
      "Epoch 690/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2798 - val_loss: 1.3308\n",
      "Epoch 691/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2754 - val_loss: 1.2985\n",
      "Epoch 692/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2646 - val_loss: 1.3334\n",
      "Epoch 693/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2849 - val_loss: 1.3543\n",
      "Epoch 694/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2816 - val_loss: 1.3044\n",
      "Epoch 695/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2734 - val_loss: 1.3313\n",
      "Epoch 696/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2767 - val_loss: 1.3154\n",
      "Epoch 697/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2602 - val_loss: 1.3362\n",
      "Epoch 698/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2816 - val_loss: 1.3118\n",
      "Epoch 699/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2752 - val_loss: 1.3180\n",
      "Epoch 700/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2710 - val_loss: 1.3020\n",
      "Epoch 701/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2745 - val_loss: 1.3101\n",
      "Epoch 702/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2703 - val_loss: 1.3339\n",
      "Epoch 703/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2669 - val_loss: 1.3298\n",
      "Epoch 704/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2705 - val_loss: 1.3003\n",
      "Epoch 705/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2637 - val_loss: 1.3493\n",
      "Epoch 706/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2750 - val_loss: 1.3404\n",
      "Epoch 707/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2673 - val_loss: 1.3358\n",
      "Epoch 708/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2698 - val_loss: 1.3462\n",
      "Epoch 709/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2682 - val_loss: 1.3126\n",
      "Epoch 710/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2698 - val_loss: 1.3402\n",
      "Epoch 711/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2854 - val_loss: 1.3317\n",
      "Epoch 712/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2671 - val_loss: 1.2618\n",
      "Epoch 713/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2668 - val_loss: 1.3359\n",
      "Epoch 714/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2795 - val_loss: 1.4224\n",
      "Epoch 715/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2714 - val_loss: 1.3366\n",
      "Epoch 716/750\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2743 - val_loss: 1.3385\n",
      "Epoch 717/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2703 - val_loss: 1.3347\n",
      "Epoch 718/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2726 - val_loss: 1.4079\n",
      "Epoch 719/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2656 - val_loss: 1.3201\n",
      "Epoch 720/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2787 - val_loss: 1.3463\n",
      "Epoch 721/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2681 - val_loss: 1.3176\n",
      "Epoch 722/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2667 - val_loss: 1.2909\n",
      "Epoch 723/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2689 - val_loss: 1.3489\n",
      "Epoch 724/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2764 - val_loss: 1.3145\n",
      "Epoch 725/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2720 - val_loss: 1.3778\n",
      "Epoch 726/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2675 - val_loss: 1.2926\n",
      "Epoch 727/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2666 - val_loss: 1.3818\n",
      "Epoch 728/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2790 - val_loss: 1.3053\n",
      "Epoch 729/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2817 - val_loss: 1.3275\n",
      "Epoch 730/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2675 - val_loss: 1.3369\n",
      "Epoch 731/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2613 - val_loss: 1.2705\n",
      "Epoch 732/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2620 - val_loss: 1.3388\n",
      "Epoch 733/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2635 - val_loss: 1.2793\n",
      "Epoch 734/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2667 - val_loss: 1.3152\n",
      "Epoch 735/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2694 - val_loss: 1.3171\n",
      "Epoch 736/750\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.2629 - val_loss: 1.3463\n",
      "Epoch 737/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2694 - val_loss: 1.3162\n",
      "Epoch 738/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2706 - val_loss: 1.3111\n",
      "Epoch 739/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2599 - val_loss: 1.3035\n",
      "Epoch 740/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2662 - val_loss: 1.3279\n",
      "Epoch 741/750\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2656 - val_loss: 1.2895\n",
      "Epoch 742/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2688 - val_loss: 1.3132\n",
      "Epoch 743/750\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2733 - val_loss: 1.2972\n",
      "Epoch 744/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2490 - val_loss: 1.2886\n",
      "Epoch 745/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2670 - val_loss: 1.3009\n",
      "Epoch 746/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2583 - val_loss: 1.3385\n",
      "Epoch 747/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2617 - val_loss: 1.2890\n",
      "Epoch 748/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2702 - val_loss: 1.3197\n",
      "Epoch 749/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2480 - val_loss: 1.3206\n",
      "Epoch 750/750\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2697 - val_loss: 1.3912\n",
      "1.3911769009236061\n",
      "0.9722363513076944\n",
      "Epoch 1/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 8.6660 - val_loss: 9.4579\n",
      "Epoch 2/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 4.9669 - val_loss: 4.1218\n",
      "Epoch 3/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 4.4483 - val_loss: 3.8911\n",
      "Epoch 4/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 4.2815 - val_loss: 4.6579\n",
      "Epoch 5/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 4.2374 - val_loss: 3.9063\n",
      "Epoch 6/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 4.0080 - val_loss: 4.8599\n",
      "Epoch 7/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 3.6231 - val_loss: 3.1844\n",
      "Epoch 8/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 3.3141 - val_loss: 3.2494\n",
      "Epoch 9/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 3.1479 - val_loss: 3.1364\n",
      "Epoch 10/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 3.0556 - val_loss: 2.9200\n",
      "Epoch 11/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.8926 - val_loss: 3.1717\n",
      "Epoch 12/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.7684 - val_loss: 2.7513\n",
      "Epoch 13/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.6648 - val_loss: 3.0127\n",
      "Epoch 14/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.6118 - val_loss: 2.5168\n",
      "Epoch 15/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.5606 - val_loss: 2.5667\n",
      "Epoch 16/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.5358 - val_loss: 2.6263\n",
      "Epoch 17/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.5070 - val_loss: 2.4270\n",
      "Epoch 18/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.4766 - val_loss: 2.3855\n",
      "Epoch 19/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.4311 - val_loss: 2.4239\n",
      "Epoch 20/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 2.3913 - val_loss: 2.5071\n",
      "Epoch 21/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3678 - val_loss: 2.3157\n",
      "Epoch 22/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3393 - val_loss: 2.2713\n",
      "Epoch 23/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.3183 - val_loss: 2.4324\n",
      "Epoch 24/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.2870 - val_loss: 2.3063\n",
      "Epoch 25/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.2971 - val_loss: 2.3498\n",
      "Epoch 26/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.2280 - val_loss: 2.1936\n",
      "Epoch 27/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.2156 - val_loss: 2.1882\n",
      "Epoch 28/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1848 - val_loss: 2.6661\n",
      "Epoch 29/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1957 - val_loss: 2.2367\n",
      "Epoch 30/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1609 - val_loss: 2.1516\n",
      "Epoch 31/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1488 - val_loss: 2.1031\n",
      "Epoch 32/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1502 - val_loss: 2.1526\n",
      "Epoch 33/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1368 - val_loss: 2.1152\n",
      "Epoch 34/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1058 - val_loss: 2.1761\n",
      "Epoch 35/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.1087 - val_loss: 2.0690\n",
      "Epoch 36/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0897 - val_loss: 2.0767\n",
      "Epoch 37/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1117 - val_loss: 2.2400\n",
      "Epoch 38/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0768 - val_loss: 1.9764\n",
      "Epoch 39/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0740 - val_loss: 2.0971\n",
      "Epoch 40/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0614 - val_loss: 2.0291\n",
      "Epoch 41/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0519 - val_loss: 2.0315\n",
      "Epoch 42/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0513 - val_loss: 2.0132\n",
      "Epoch 43/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.0461 - val_loss: 2.0259\n",
      "Epoch 44/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0294 - val_loss: 1.9682\n",
      "Epoch 45/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0109 - val_loss: 2.0697\n",
      "Epoch 46/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0254 - val_loss: 1.9787\n",
      "Epoch 47/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0042 - val_loss: 2.0839\n",
      "Epoch 48/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0196 - val_loss: 2.0255\n",
      "Epoch 49/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 2.0018 - val_loss: 2.0173\n",
      "Epoch 50/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9987 - val_loss: 2.1009\n",
      "Epoch 51/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9875 - val_loss: 1.9054\n",
      "Epoch 52/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9744 - val_loss: 1.9642\n",
      "Epoch 53/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9700 - val_loss: 2.0349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9751 - val_loss: 1.9015\n",
      "Epoch 55/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9589 - val_loss: 1.9520\n",
      "Epoch 56/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9609 - val_loss: 1.9649\n",
      "Epoch 57/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9470 - val_loss: 1.9961\n",
      "Epoch 58/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9631 - val_loss: 1.9443\n",
      "Epoch 59/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9215 - val_loss: 1.9493\n",
      "Epoch 60/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9313 - val_loss: 1.9610\n",
      "Epoch 61/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9397 - val_loss: 1.9005\n",
      "Epoch 62/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9346 - val_loss: 1.9222\n",
      "Epoch 63/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9285 - val_loss: 1.8893\n",
      "Epoch 64/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9195 - val_loss: 1.9017\n",
      "Epoch 65/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9148 - val_loss: 1.9636\n",
      "Epoch 66/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9031 - val_loss: 1.8511\n",
      "Epoch 67/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9162 - val_loss: 1.8617\n",
      "Epoch 68/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.9045 - val_loss: 1.9184\n",
      "Epoch 69/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8978 - val_loss: 1.9956\n",
      "Epoch 70/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8994 - val_loss: 1.9918\n",
      "Epoch 71/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8836 - val_loss: 1.9926\n",
      "Epoch 72/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8846 - val_loss: 1.8364\n",
      "Epoch 73/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8856 - val_loss: 1.9348\n",
      "Epoch 74/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8848 - val_loss: 1.9649\n",
      "Epoch 75/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8650 - val_loss: 1.8250\n",
      "Epoch 76/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8668 - val_loss: 1.9299\n",
      "Epoch 77/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8717 - val_loss: 1.8773\n",
      "Epoch 78/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8676 - val_loss: 1.8407\n",
      "Epoch 79/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8578 - val_loss: 1.8520\n",
      "Epoch 80/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8473 - val_loss: 1.8217\n",
      "Epoch 81/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8582 - val_loss: 1.8545\n",
      "Epoch 82/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8536 - val_loss: 1.8174\n",
      "Epoch 83/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8503 - val_loss: 1.9085\n",
      "Epoch 84/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8431 - val_loss: 1.8365\n",
      "Epoch 85/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8280 - val_loss: 1.8092\n",
      "Epoch 86/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8470 - val_loss: 1.9007\n",
      "Epoch 87/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8342 - val_loss: 1.8231\n",
      "Epoch 88/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8299 - val_loss: 1.9651\n",
      "Epoch 89/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.8266 - val_loss: 1.9089\n",
      "Epoch 90/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.8336 - val_loss: 1.7983\n",
      "Epoch 91/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8241 - val_loss: 1.8225\n",
      "Epoch 92/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8076 - val_loss: 1.8277\n",
      "Epoch 93/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8195 - val_loss: 1.8481\n",
      "Epoch 94/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8111 - val_loss: 1.7622\n",
      "Epoch 95/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8272 - val_loss: 1.8510\n",
      "Epoch 96/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8104 - val_loss: 1.7924\n",
      "Epoch 97/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8288 - val_loss: 1.8084\n",
      "Epoch 98/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8031 - val_loss: 1.9768\n",
      "Epoch 99/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8056 - val_loss: 1.7600\n",
      "Epoch 100/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7833 - val_loss: 1.8000\n",
      "Epoch 101/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8079 - val_loss: 1.7985\n",
      "Epoch 102/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8036 - val_loss: 1.9614\n",
      "Epoch 103/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8027 - val_loss: 1.8854\n",
      "Epoch 104/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.8007 - val_loss: 1.7665\n",
      "Epoch 105/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7929 - val_loss: 1.7908\n",
      "Epoch 106/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7698 - val_loss: 1.8774\n",
      "Epoch 107/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7770 - val_loss: 1.8735\n",
      "Epoch 108/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7802 - val_loss: 1.8151\n",
      "Epoch 109/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7731 - val_loss: 1.7749\n",
      "Epoch 110/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7872 - val_loss: 1.7916\n",
      "Epoch 111/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7678 - val_loss: 1.7866\n",
      "Epoch 112/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7742 - val_loss: 1.7638\n",
      "Epoch 113/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7887 - val_loss: 1.7492\n",
      "Epoch 114/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7565 - val_loss: 1.7698\n",
      "Epoch 115/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7671 - val_loss: 1.7300\n",
      "Epoch 116/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7694 - val_loss: 1.7753\n",
      "Epoch 117/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7535 - val_loss: 1.8341\n",
      "Epoch 118/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7690 - val_loss: 1.7847\n",
      "Epoch 119/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7576 - val_loss: 1.7705\n",
      "Epoch 120/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7649 - val_loss: 1.7233\n",
      "Epoch 121/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7453 - val_loss: 1.7161\n",
      "Epoch 122/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7489 - val_loss: 1.7557\n",
      "Epoch 123/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7427 - val_loss: 1.7706\n",
      "Epoch 124/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7612 - val_loss: 1.7363\n",
      "Epoch 125/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7470 - val_loss: 1.7904\n",
      "Epoch 126/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7493 - val_loss: 1.8058\n",
      "Epoch 127/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7419 - val_loss: 1.7476\n",
      "Epoch 128/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7457 - val_loss: 1.7834\n",
      "Epoch 129/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7334 - val_loss: 1.8036\n",
      "Epoch 130/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7472 - val_loss: 1.8345\n",
      "Epoch 131/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7390 - val_loss: 1.7401\n",
      "Epoch 132/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7272 - val_loss: 1.8379\n",
      "Epoch 133/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7334 - val_loss: 1.7295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7267 - val_loss: 1.6922\n",
      "Epoch 135/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7250 - val_loss: 1.6526\n",
      "Epoch 136/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7196 - val_loss: 1.7580\n",
      "Epoch 137/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7194 - val_loss: 1.7242\n",
      "Epoch 138/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7336 - val_loss: 1.6844\n",
      "Epoch 139/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7175 - val_loss: 1.8084\n",
      "Epoch 140/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7236 - val_loss: 1.7441\n",
      "Epoch 141/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7203 - val_loss: 1.7230\n",
      "Epoch 142/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7199 - val_loss: 1.6985\n",
      "Epoch 143/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7162 - val_loss: 1.7588\n",
      "Epoch 144/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7193 - val_loss: 1.7033\n",
      "Epoch 145/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7093 - val_loss: 1.7413\n",
      "Epoch 146/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7086 - val_loss: 1.7278\n",
      "Epoch 147/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7170 - val_loss: 1.9108\n",
      "Epoch 148/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7163 - val_loss: 1.7871\n",
      "Epoch 149/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7100 - val_loss: 1.8685\n",
      "Epoch 150/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6974 - val_loss: 1.6780\n",
      "Epoch 151/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7046 - val_loss: 1.6984\n",
      "Epoch 152/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6975 - val_loss: 1.7321\n",
      "Epoch 153/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6971 - val_loss: 1.6635\n",
      "Epoch 154/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7026 - val_loss: 1.6660\n",
      "Epoch 155/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.7043 - val_loss: 1.6590\n",
      "Epoch 156/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6910 - val_loss: 1.6333\n",
      "Epoch 157/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6955 - val_loss: 1.7104\n",
      "Epoch 158/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6989 - val_loss: 1.7382\n",
      "Epoch 159/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6851 - val_loss: 1.7011\n",
      "Epoch 160/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6812 - val_loss: 1.6738\n",
      "Epoch 161/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6851 - val_loss: 1.7353\n",
      "Epoch 162/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6845 - val_loss: 1.6685\n",
      "Epoch 163/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6913 - val_loss: 1.7050\n",
      "Epoch 164/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6801 - val_loss: 1.6750\n",
      "Epoch 165/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6915 - val_loss: 1.6618\n",
      "Epoch 166/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6759 - val_loss: 1.6929\n",
      "Epoch 167/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6812 - val_loss: 1.8193\n",
      "Epoch 168/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6900 - val_loss: 1.7086\n",
      "Epoch 169/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6764 - val_loss: 1.6476\n",
      "Epoch 170/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6795 - val_loss: 1.6842\n",
      "Epoch 171/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6738 - val_loss: 1.6596\n",
      "Epoch 172/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6719 - val_loss: 1.6559\n",
      "Epoch 173/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6693 - val_loss: 1.6815\n",
      "Epoch 174/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6749 - val_loss: 1.6939\n",
      "Epoch 175/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.6686 - val_loss: 1.6888\n",
      "Epoch 176/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6659 - val_loss: 1.6539\n",
      "Epoch 177/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6682 - val_loss: 1.7195\n",
      "Epoch 178/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6684 - val_loss: 1.6649\n",
      "Epoch 179/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6605 - val_loss: 1.6806\n",
      "Epoch 180/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6673 - val_loss: 1.6707\n",
      "Epoch 181/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6589 - val_loss: 1.9844\n",
      "Epoch 182/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6680 - val_loss: 1.7353\n",
      "Epoch 183/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6526 - val_loss: 1.6888\n",
      "Epoch 184/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6517 - val_loss: 1.6823\n",
      "Epoch 185/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6641 - val_loss: 1.7974\n",
      "Epoch 186/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6605 - val_loss: 1.7922\n",
      "Epoch 187/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6408 - val_loss: 1.6633\n",
      "Epoch 188/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6559 - val_loss: 1.6231\n",
      "Epoch 189/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6522 - val_loss: 1.6695\n",
      "Epoch 190/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6517 - val_loss: 1.6680\n",
      "Epoch 191/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6498 - val_loss: 1.7012\n",
      "Epoch 192/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6557 - val_loss: 1.6775\n",
      "Epoch 193/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6516 - val_loss: 1.7521\n",
      "Epoch 194/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6345 - val_loss: 1.6934\n",
      "Epoch 195/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6417 - val_loss: 1.6595\n",
      "Epoch 196/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6468 - val_loss: 1.6412\n",
      "Epoch 197/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6440 - val_loss: 1.7844\n",
      "Epoch 198/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6480 - val_loss: 1.7625\n",
      "Epoch 199/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6378 - val_loss: 1.6855\n",
      "Epoch 200/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6427 - val_loss: 1.6374\n",
      "Epoch 201/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6367 - val_loss: 1.8002\n",
      "Epoch 202/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6384 - val_loss: 1.6879\n",
      "Epoch 203/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6404 - val_loss: 1.7490\n",
      "Epoch 204/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6364 - val_loss: 1.6618\n",
      "Epoch 205/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6334 - val_loss: 1.6686\n",
      "Epoch 206/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6323 - val_loss: 1.6698\n",
      "Epoch 207/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6323 - val_loss: 1.7833\n",
      "Epoch 208/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6317 - val_loss: 1.6618\n",
      "Epoch 209/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6383 - val_loss: 1.6501\n",
      "Epoch 210/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6267 - val_loss: 1.6859\n",
      "Epoch 211/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6366 - val_loss: 1.6642\n",
      "Epoch 212/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6251 - val_loss: 1.6504\n",
      "Epoch 213/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6243 - val_loss: 1.7565\n",
      "Epoch 214/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6244 - val_loss: 1.6627\n",
      "Epoch 215/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6255 - val_loss: 1.6352\n",
      "Epoch 216/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6360 - val_loss: 1.6740\n",
      "Epoch 217/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6237 - val_loss: 1.6453\n",
      "Epoch 218/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6319 - val_loss: 1.6239\n",
      "Epoch 219/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6253 - val_loss: 1.7413\n",
      "Epoch 220/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6286 - val_loss: 1.6364\n",
      "Epoch 221/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6159 - val_loss: 1.6158\n",
      "Epoch 222/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6190 - val_loss: 1.7661\n",
      "Epoch 223/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6282 - val_loss: 1.6679\n",
      "Epoch 224/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6196 - val_loss: 1.6146\n",
      "Epoch 225/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6144 - val_loss: 1.6205\n",
      "Epoch 226/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6121 - val_loss: 1.6060\n",
      "Epoch 227/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.6175 - val_loss: 1.7091\n",
      "Epoch 228/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6247 - val_loss: 1.7307\n",
      "Epoch 229/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6122 - val_loss: 1.6025\n",
      "Epoch 230/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6127 - val_loss: 1.7195\n",
      "Epoch 231/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6223 - val_loss: 1.6399\n",
      "Epoch 232/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6073 - val_loss: 1.6275\n",
      "Epoch 233/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6142 - val_loss: 1.5869\n",
      "Epoch 234/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6185 - val_loss: 1.6842\n",
      "Epoch 235/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6153 - val_loss: 1.6449\n",
      "Epoch 236/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6097 - val_loss: 1.6247\n",
      "Epoch 237/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6047 - val_loss: 1.6053\n",
      "Epoch 238/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6130 - val_loss: 1.6117\n",
      "Epoch 239/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5960 - val_loss: 1.6072\n",
      "Epoch 240/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6094 - val_loss: 1.6150\n",
      "Epoch 241/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6022 - val_loss: 1.6060\n",
      "Epoch 242/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6077 - val_loss: 1.6363\n",
      "Epoch 243/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6117 - val_loss: 1.6476\n",
      "Epoch 244/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5985 - val_loss: 1.5526\n",
      "Epoch 245/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6011 - val_loss: 1.6063\n",
      "Epoch 246/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5995 - val_loss: 1.6115\n",
      "Epoch 247/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5972 - val_loss: 1.6131\n",
      "Epoch 248/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6108 - val_loss: 1.6297\n",
      "Epoch 249/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5991 - val_loss: 1.5882\n",
      "Epoch 250/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6024 - val_loss: 1.6627\n",
      "Epoch 251/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6046 - val_loss: 1.6566\n",
      "Epoch 252/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5974 - val_loss: 1.6449\n",
      "Epoch 253/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6018 - val_loss: 1.7183\n",
      "Epoch 254/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6004 - val_loss: 1.5916\n",
      "Epoch 255/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5951 - val_loss: 1.6816\n",
      "Epoch 256/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.6032 - val_loss: 1.5727\n",
      "Epoch 257/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5859 - val_loss: 1.6056\n",
      "Epoch 258/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5977 - val_loss: 1.6062\n",
      "Epoch 259/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5956 - val_loss: 1.6093\n",
      "Epoch 260/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5912 - val_loss: 1.5988\n",
      "Epoch 261/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5956 - val_loss: 1.7161\n",
      "Epoch 262/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5913 - val_loss: 1.6492\n",
      "Epoch 263/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5944 - val_loss: 1.6219\n",
      "Epoch 264/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5891 - val_loss: 1.6274\n",
      "Epoch 265/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5870 - val_loss: 1.6946\n",
      "Epoch 266/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5877 - val_loss: 1.5810\n",
      "Epoch 267/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5923 - val_loss: 1.5951\n",
      "Epoch 268/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5845 - val_loss: 1.5766\n",
      "Epoch 269/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5851 - val_loss: 1.5719\n",
      "Epoch 270/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5910 - val_loss: 1.6230\n",
      "Epoch 271/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5861 - val_loss: 1.6093\n",
      "Epoch 272/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5848 - val_loss: 1.6336\n",
      "Epoch 273/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5804 - val_loss: 1.6373\n",
      "Epoch 274/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5746 - val_loss: 1.6078\n",
      "Epoch 275/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5787 - val_loss: 1.6244\n",
      "Epoch 276/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5837 - val_loss: 1.6196\n",
      "Epoch 277/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5745 - val_loss: 1.7912\n",
      "Epoch 278/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5848 - val_loss: 1.6237\n",
      "Epoch 279/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5838 - val_loss: 1.6294\n",
      "Epoch 280/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5865 - val_loss: 1.6004\n",
      "Epoch 281/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5774 - val_loss: 1.5945\n",
      "Epoch 282/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5763 - val_loss: 1.5363\n",
      "Epoch 283/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5715 - val_loss: 1.6185\n",
      "Epoch 284/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5760 - val_loss: 1.6179\n",
      "Epoch 285/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5749 - val_loss: 1.6050\n",
      "Epoch 286/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5705 - val_loss: 1.6049\n",
      "Epoch 287/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5690 - val_loss: 1.5466\n",
      "Epoch 288/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5719 - val_loss: 1.5625\n",
      "Epoch 289/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5859 - val_loss: 1.5754\n",
      "Epoch 290/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5675 - val_loss: 1.6102\n",
      "Epoch 291/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5750 - val_loss: 1.7616\n",
      "Epoch 292/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5751 - val_loss: 1.7534\n",
      "Epoch 293/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5709 - val_loss: 1.5876\n",
      "Epoch 294/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5741 - val_loss: 1.6346\n",
      "Epoch 295/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5663 - val_loss: 1.5934\n",
      "Epoch 296/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5679 - val_loss: 1.6208\n",
      "Epoch 297/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5612 - val_loss: 1.5766\n",
      "Epoch 298/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5621 - val_loss: 1.6549\n",
      "Epoch 299/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5684 - val_loss: 1.7052\n",
      "Epoch 300/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5669 - val_loss: 1.6181\n",
      "Epoch 301/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5636 - val_loss: 1.5955\n",
      "Epoch 302/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5689 - val_loss: 1.6893\n",
      "Epoch 303/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5643 - val_loss: 1.6006\n",
      "Epoch 304/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5633 - val_loss: 1.5720\n",
      "Epoch 305/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5568 - val_loss: 1.6554\n",
      "Epoch 306/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5655 - val_loss: 1.5586\n",
      "Epoch 307/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5611 - val_loss: 1.5960\n",
      "Epoch 308/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5543 - val_loss: 1.6001\n",
      "Epoch 309/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5664 - val_loss: 1.5967\n",
      "Epoch 310/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5559 - val_loss: 1.7256\n",
      "Epoch 311/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5574 - val_loss: 1.5438\n",
      "Epoch 312/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5643 - val_loss: 1.5853\n",
      "Epoch 313/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5614 - val_loss: 1.5361\n",
      "Epoch 314/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5494 - val_loss: 1.5830\n",
      "Epoch 315/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5515 - val_loss: 1.5340\n",
      "Epoch 316/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5489 - val_loss: 1.5609\n",
      "Epoch 317/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5482 - val_loss: 1.6118\n",
      "Epoch 318/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5625 - val_loss: 1.5782\n",
      "Epoch 319/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5479 - val_loss: 1.5997\n",
      "Epoch 320/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5528 - val_loss: 1.6023\n",
      "Epoch 321/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5534 - val_loss: 1.6389\n",
      "Epoch 322/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5545 - val_loss: 1.6020\n",
      "Epoch 323/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5536 - val_loss: 1.6406\n",
      "Epoch 324/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5545 - val_loss: 1.5920\n",
      "Epoch 325/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5448 - val_loss: 1.5807\n",
      "Epoch 326/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5557 - val_loss: 1.6004\n",
      "Epoch 327/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5532 - val_loss: 1.5545\n",
      "Epoch 328/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5492 - val_loss: 1.6740\n",
      "Epoch 329/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5463 - val_loss: 1.6170\n",
      "Epoch 330/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5409 - val_loss: 1.6245\n",
      "Epoch 331/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5461 - val_loss: 1.5771\n",
      "Epoch 332/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5426 - val_loss: 1.5570\n",
      "Epoch 333/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5397 - val_loss: 1.5342\n",
      "Epoch 334/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5417 - val_loss: 1.5671\n",
      "Epoch 335/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5429 - val_loss: 1.5857\n",
      "Epoch 336/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5457 - val_loss: 1.6252\n",
      "Epoch 337/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5279 - val_loss: 1.6027\n",
      "Epoch 338/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5437 - val_loss: 1.5633\n",
      "Epoch 339/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5348 - val_loss: 1.6074\n",
      "Epoch 340/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5360 - val_loss: 1.5448\n",
      "Epoch 341/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5457 - val_loss: 1.5431\n",
      "Epoch 342/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5272 - val_loss: 1.5155\n",
      "Epoch 343/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5281 - val_loss: 1.5476\n",
      "Epoch 344/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5371 - val_loss: 1.5885\n",
      "Epoch 345/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5344 - val_loss: 1.6856\n",
      "Epoch 346/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5403 - val_loss: 1.5628\n",
      "Epoch 347/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.5302 - val_loss: 1.5391\n",
      "Epoch 348/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5271 - val_loss: 1.6341\n",
      "Epoch 349/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5381 - val_loss: 1.6129\n",
      "Epoch 350/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5287 - val_loss: 1.5288\n",
      "Epoch 351/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5344 - val_loss: 1.5270\n",
      "Epoch 352/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5321 - val_loss: 1.5663\n",
      "Epoch 353/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5273 - val_loss: 1.5083\n",
      "Epoch 354/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5282 - val_loss: 1.5135\n",
      "Epoch 355/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5235 - val_loss: 1.5386\n",
      "Epoch 356/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5311 - val_loss: 1.5502\n",
      "Epoch 357/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5316 - val_loss: 1.5994\n",
      "Epoch 358/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5263 - val_loss: 1.5269\n",
      "Epoch 359/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5281 - val_loss: 1.5291\n",
      "Epoch 360/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5333 - val_loss: 1.5654\n",
      "Epoch 361/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5221 - val_loss: 1.5598\n",
      "Epoch 362/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5254 - val_loss: 1.5707\n",
      "Epoch 363/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5312 - val_loss: 1.5184\n",
      "Epoch 364/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5274 - val_loss: 1.5696\n",
      "Epoch 365/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5339 - val_loss: 1.5293\n",
      "Epoch 366/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5218 - val_loss: 1.5272\n",
      "Epoch 367/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5283 - val_loss: 1.5513\n",
      "Epoch 368/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5205 - val_loss: 1.5578\n",
      "Epoch 369/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5211 - val_loss: 1.6758\n",
      "Epoch 370/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5252 - val_loss: 1.5341\n",
      "Epoch 371/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5320 - val_loss: 1.4936\n",
      "Epoch 372/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5210 - val_loss: 1.5231\n",
      "Epoch 373/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5302 - val_loss: 1.5072\n",
      "Epoch 374/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5173 - val_loss: 1.5503\n",
      "Epoch 375/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5195 - val_loss: 1.5827\n",
      "Epoch 376/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5281 - val_loss: 1.5472\n",
      "Epoch 377/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5086 - val_loss: 1.5471\n",
      "Epoch 378/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5166 - val_loss: 1.5359\n",
      "Epoch 379/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5165 - val_loss: 1.5173\n",
      "Epoch 380/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5099 - val_loss: 1.5466\n",
      "Epoch 381/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5188 - val_loss: 1.5260\n",
      "Epoch 382/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5145 - val_loss: 1.5664\n",
      "Epoch 383/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5083 - val_loss: 1.6321\n",
      "Epoch 384/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5139 - val_loss: 1.5369\n",
      "Epoch 385/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5120 - val_loss: 1.5362\n",
      "Epoch 386/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5074 - val_loss: 1.5031\n",
      "Epoch 387/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5124 - val_loss: 1.5158\n",
      "Epoch 388/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5077 - val_loss: 1.5081\n",
      "Epoch 389/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5047 - val_loss: 1.5437\n",
      "Epoch 390/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5175 - val_loss: 1.5524\n",
      "Epoch 391/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5107 - val_loss: 1.6348\n",
      "Epoch 392/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5000 - val_loss: 1.5403\n",
      "Epoch 393/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5125 - val_loss: 1.6667\n",
      "Epoch 394/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5052 - val_loss: 1.5226\n",
      "Epoch 395/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5045 - val_loss: 1.5127\n",
      "Epoch 396/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5113 - val_loss: 1.5871\n",
      "Epoch 397/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5086 - val_loss: 1.5799\n",
      "Epoch 398/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5084 - val_loss: 1.5746\n",
      "Epoch 399/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5059 - val_loss: 1.5532\n",
      "Epoch 400/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5104 - val_loss: 1.5980\n",
      "Epoch 401/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5095 - val_loss: 1.4810\n",
      "Epoch 402/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5136 - val_loss: 1.5134\n",
      "Epoch 403/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5012 - val_loss: 1.4701\n",
      "Epoch 404/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4990 - val_loss: 1.5114\n",
      "Epoch 405/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5050 - val_loss: 1.5979\n",
      "Epoch 406/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5052 - val_loss: 1.4939\n",
      "Epoch 407/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4938 - val_loss: 1.4927\n",
      "Epoch 408/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5123 - val_loss: 1.5008\n",
      "Epoch 409/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5098 - val_loss: 1.5180\n",
      "Epoch 410/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4989 - val_loss: 1.5890\n",
      "Epoch 411/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4990 - val_loss: 1.5413\n",
      "Epoch 412/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4987 - val_loss: 1.4865\n",
      "Epoch 413/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4945 - val_loss: 1.4767\n",
      "Epoch 414/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.5012 - val_loss: 1.5571\n",
      "Epoch 415/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4974 - val_loss: 1.5404\n",
      "Epoch 416/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4908 - val_loss: 1.5131\n",
      "Epoch 417/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5039 - val_loss: 1.4749\n",
      "Epoch 418/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4952 - val_loss: 1.5538\n",
      "Epoch 419/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4923 - val_loss: 1.5499\n",
      "Epoch 420/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4974 - val_loss: 1.5050\n",
      "Epoch 421/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4887 - val_loss: 1.5599\n",
      "Epoch 422/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4930 - val_loss: 1.4686\n",
      "Epoch 423/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4965 - val_loss: 1.4728\n",
      "Epoch 424/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4876 - val_loss: 1.5253\n",
      "Epoch 425/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4898 - val_loss: 1.5024\n",
      "Epoch 426/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4881 - val_loss: 1.5232\n",
      "Epoch 427/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4958 - val_loss: 1.5102\n",
      "Epoch 428/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4906 - val_loss: 1.5532\n",
      "Epoch 429/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4849 - val_loss: 1.5124\n",
      "Epoch 430/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4907 - val_loss: 1.5104\n",
      "Epoch 431/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4880 - val_loss: 1.4971\n",
      "Epoch 432/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4887 - val_loss: 1.4881\n",
      "Epoch 433/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4905 - val_loss: 1.6272\n",
      "Epoch 434/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4999 - val_loss: 1.5497\n",
      "Epoch 435/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4962 - val_loss: 1.5454\n",
      "Epoch 436/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4877 - val_loss: 1.5065\n",
      "Epoch 437/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4825 - val_loss: 1.5259\n",
      "Epoch 438/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4839 - val_loss: 1.5069\n",
      "Epoch 439/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4858 - val_loss: 1.5401\n",
      "Epoch 440/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4930 - val_loss: 1.5771\n",
      "Epoch 441/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4846 - val_loss: 1.5599\n",
      "Epoch 442/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4821 - val_loss: 1.5037\n",
      "Epoch 443/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4824 - val_loss: 1.5447\n",
      "Epoch 444/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4815 - val_loss: 1.4778\n",
      "Epoch 445/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4826 - val_loss: 1.4869\n",
      "Epoch 446/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4892 - val_loss: 1.5676\n",
      "Epoch 447/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4792 - val_loss: 1.5269\n",
      "Epoch 448/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4794 - val_loss: 1.5926\n",
      "Epoch 449/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4847 - val_loss: 1.4804\n",
      "Epoch 450/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4884 - val_loss: 1.5046\n",
      "Epoch 451/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4812 - val_loss: 1.5991\n",
      "Epoch 452/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4782 - val_loss: 1.4824\n",
      "Epoch 453/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4712 - val_loss: 1.5185\n",
      "Epoch 454/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4681 - val_loss: 1.4946\n",
      "Epoch 455/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4886 - val_loss: 1.5860\n",
      "Epoch 456/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4823 - val_loss: 1.4775\n",
      "Epoch 457/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4708 - val_loss: 1.4868\n",
      "Epoch 458/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4783 - val_loss: 1.4840\n",
      "Epoch 459/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4868 - val_loss: 1.5045\n",
      "Epoch 460/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4787 - val_loss: 1.5601\n",
      "Epoch 461/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4747 - val_loss: 1.5010\n",
      "Epoch 462/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4812 - val_loss: 1.4744\n",
      "Epoch 463/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4769 - val_loss: 1.5091\n",
      "Epoch 464/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4685 - val_loss: 1.5228\n",
      "Epoch 465/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4870 - val_loss: 1.6154\n",
      "Epoch 466/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4755 - val_loss: 1.5379\n",
      "Epoch 467/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4721 - val_loss: 1.5000\n",
      "Epoch 468/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4697 - val_loss: 1.5256\n",
      "Epoch 469/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4643 - val_loss: 1.4808\n",
      "Epoch 470/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4835 - val_loss: 1.5467\n",
      "Epoch 471/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4782 - val_loss: 1.5183\n",
      "Epoch 472/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4715 - val_loss: 1.5030\n",
      "Epoch 473/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4702 - val_loss: 1.4792\n",
      "Epoch 474/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4667 - val_loss: 1.5304\n",
      "Epoch 475/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4798 - val_loss: 1.5005\n",
      "Epoch 476/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4703 - val_loss: 1.5433\n",
      "Epoch 477/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4592 - val_loss: 1.4757\n",
      "Epoch 478/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4689 - val_loss: 1.5555\n",
      "Epoch 479/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4670 - val_loss: 1.5182\n",
      "Epoch 480/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4603 - val_loss: 1.5479\n",
      "Epoch 481/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4657 - val_loss: 1.5261\n",
      "Epoch 482/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4555 - val_loss: 1.4698\n",
      "Epoch 483/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4686 - val_loss: 1.4657\n",
      "Epoch 484/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4583 - val_loss: 1.5007\n",
      "Epoch 485/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4669 - val_loss: 1.4740\n",
      "Epoch 486/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4598 - val_loss: 1.4604\n",
      "Epoch 487/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4622 - val_loss: 1.4732\n",
      "Epoch 488/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4688 - val_loss: 1.4822\n",
      "Epoch 489/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4590 - val_loss: 1.5531\n",
      "Epoch 490/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4557 - val_loss: 1.4585\n",
      "Epoch 491/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4599 - val_loss: 1.4826\n",
      "Epoch 492/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4599 - val_loss: 1.5073\n",
      "Epoch 493/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4576 - val_loss: 1.4979\n",
      "Epoch 494/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4551 - val_loss: 1.4936\n",
      "Epoch 495/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4588 - val_loss: 1.5374\n",
      "Epoch 496/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4640 - val_loss: 1.4350\n",
      "Epoch 497/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4453 - val_loss: 1.5270\n",
      "Epoch 498/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4595 - val_loss: 1.5186\n",
      "Epoch 499/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4569 - val_loss: 1.6395\n",
      "Epoch 500/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4548 - val_loss: 1.5231\n",
      "Epoch 501/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4531 - val_loss: 1.4764\n",
      "Epoch 502/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4515 - val_loss: 1.4982\n",
      "Epoch 503/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4666 - val_loss: 1.4886\n",
      "Epoch 504/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4627 - val_loss: 1.4619\n",
      "Epoch 505/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4487 - val_loss: 1.4939\n",
      "Epoch 506/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4441 - val_loss: 1.5374\n",
      "Epoch 507/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4602 - val_loss: 1.5056\n",
      "Epoch 508/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4536 - val_loss: 1.4692\n",
      "Epoch 509/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4543 - val_loss: 1.4474\n",
      "Epoch 510/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4497 - val_loss: 1.5242\n",
      "Epoch 511/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4439 - val_loss: 1.4666\n",
      "Epoch 512/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4494 - val_loss: 1.4602\n",
      "Epoch 513/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4521 - val_loss: 1.5283\n",
      "Epoch 514/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4542 - val_loss: 1.5265\n",
      "Epoch 515/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4518 - val_loss: 1.5209\n",
      "Epoch 516/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4544 - val_loss: 1.4192\n",
      "Epoch 517/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4481 - val_loss: 1.4815\n",
      "Epoch 518/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4589 - val_loss: 1.4514\n",
      "Epoch 519/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4412 - val_loss: 1.5446\n",
      "Epoch 520/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4464 - val_loss: 1.5230\n",
      "Epoch 521/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4490 - val_loss: 1.5252\n",
      "Epoch 522/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4390 - val_loss: 1.4746\n",
      "Epoch 523/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4419 - val_loss: 1.5060\n",
      "Epoch 524/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4454 - val_loss: 1.4613\n",
      "Epoch 525/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4454 - val_loss: 1.4478\n",
      "Epoch 526/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4469 - val_loss: 1.5567\n",
      "Epoch 527/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4474 - val_loss: 1.4260\n",
      "Epoch 528/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4475 - val_loss: 1.4538\n",
      "Epoch 529/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4461 - val_loss: 1.4498\n",
      "Epoch 530/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4479 - val_loss: 1.6650\n",
      "Epoch 531/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4510 - val_loss: 1.4530\n",
      "Epoch 532/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4493 - val_loss: 1.5055\n",
      "Epoch 533/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4519 - val_loss: 1.4500\n",
      "Epoch 534/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4456 - val_loss: 1.4939\n",
      "Epoch 535/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4468 - val_loss: 1.5638\n",
      "Epoch 536/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4490 - val_loss: 1.5822\n",
      "Epoch 537/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4459 - val_loss: 1.5574\n",
      "Epoch 538/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4410 - val_loss: 1.4700\n",
      "Epoch 539/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4501 - val_loss: 1.5264\n",
      "Epoch 540/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4415 - val_loss: 1.4590\n",
      "Epoch 541/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4455 - val_loss: 1.4608\n",
      "Epoch 542/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4455 - val_loss: 1.4951\n",
      "Epoch 543/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4427 - val_loss: 1.5414\n",
      "Epoch 544/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4414 - val_loss: 1.4624\n",
      "Epoch 545/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4445 - val_loss: 1.5464\n",
      "Epoch 546/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4464 - val_loss: 1.4321\n",
      "Epoch 547/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4376 - val_loss: 1.5158\n",
      "Epoch 548/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4385 - val_loss: 1.4306\n",
      "Epoch 549/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4404 - val_loss: 1.4102\n",
      "Epoch 550/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4368 - val_loss: 1.4512\n",
      "Epoch 551/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4300 - val_loss: 1.4770\n",
      "Epoch 552/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4440 - val_loss: 1.4926\n",
      "Epoch 553/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4320 - val_loss: 1.5185\n",
      "Epoch 554/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4394 - val_loss: 1.5232\n",
      "Epoch 555/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4391 - val_loss: 1.4242\n",
      "Epoch 556/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4410 - val_loss: 1.4819\n",
      "Epoch 557/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4339 - val_loss: 1.4777\n",
      "Epoch 558/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4352 - val_loss: 1.4228\n",
      "Epoch 559/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4376 - val_loss: 1.4469\n",
      "Epoch 560/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4268 - val_loss: 1.5123\n",
      "Epoch 561/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4430 - val_loss: 1.5103\n",
      "Epoch 562/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4284 - val_loss: 1.4270\n",
      "Epoch 563/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4321 - val_loss: 1.4638\n",
      "Epoch 564/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4363 - val_loss: 1.4817\n",
      "Epoch 565/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4365 - val_loss: 1.4762\n",
      "Epoch 566/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4298 - val_loss: 1.4136\n",
      "Epoch 567/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4283 - val_loss: 1.4585\n",
      "Epoch 568/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4305 - val_loss: 1.5072\n",
      "Epoch 569/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4285 - val_loss: 1.4953\n",
      "Epoch 570/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4375 - val_loss: 1.4295\n",
      "Epoch 571/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4364 - val_loss: 1.4371\n",
      "Epoch 572/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4270 - val_loss: 1.4623\n",
      "Epoch 573/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4330 - val_loss: 1.5030\n",
      "Epoch 574/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4270 - val_loss: 1.4941\n",
      "Epoch 575/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4290 - val_loss: 1.4867\n",
      "Epoch 576/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4281 - val_loss: 1.4247\n",
      "Epoch 577/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4324 - val_loss: 1.4652\n",
      "Epoch 578/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4397 - val_loss: 1.4931\n",
      "Epoch 579/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4284 - val_loss: 1.4347\n",
      "Epoch 580/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4305 - val_loss: 1.4152\n",
      "Epoch 581/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4296 - val_loss: 1.5540\n",
      "Epoch 582/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4331 - val_loss: 1.5403\n",
      "Epoch 583/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4268 - val_loss: 1.4889\n",
      "Epoch 584/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4281 - val_loss: 1.4819\n",
      "Epoch 585/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4263 - val_loss: 1.4995\n",
      "Epoch 586/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4334 - val_loss: 1.4548\n",
      "Epoch 587/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4240 - val_loss: 1.4656\n",
      "Epoch 588/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4296 - val_loss: 1.4554\n",
      "Epoch 589/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4178 - val_loss: 1.4407\n",
      "Epoch 590/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4267 - val_loss: 1.4195\n",
      "Epoch 591/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4285 - val_loss: 1.4646\n",
      "Epoch 592/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4246 - val_loss: 1.4214\n",
      "Epoch 593/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4204 - val_loss: 1.4869\n",
      "Epoch 594/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4219 - val_loss: 1.4191\n",
      "Epoch 595/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4248 - val_loss: 1.4319\n",
      "Epoch 596/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4165 - val_loss: 1.4323\n",
      "Epoch 597/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4210 - val_loss: 1.4531\n",
      "Epoch 598/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4275 - val_loss: 1.4956\n",
      "Epoch 599/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4111 - val_loss: 1.4173\n",
      "Epoch 600/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4222 - val_loss: 1.4302\n",
      "Epoch 601/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4235 - val_loss: 1.4612\n",
      "Epoch 602/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4285 - val_loss: 1.4944\n",
      "Epoch 603/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4343 - val_loss: 1.5830\n",
      "Epoch 604/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4231 - val_loss: 1.4284\n",
      "Epoch 605/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4235 - val_loss: 1.5879\n",
      "Epoch 606/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4226 - val_loss: 1.4878\n",
      "Epoch 607/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4218 - val_loss: 1.5092\n",
      "Epoch 608/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4140 - val_loss: 1.4878\n",
      "Epoch 609/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4187 - val_loss: 1.4285\n",
      "Epoch 610/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4211 - val_loss: 1.4189\n",
      "Epoch 611/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4209 - val_loss: 1.4166\n",
      "Epoch 612/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4221 - val_loss: 1.4864\n",
      "Epoch 613/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4169 - val_loss: 1.4420\n",
      "Epoch 614/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4175 - val_loss: 1.5239\n",
      "Epoch 615/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4241 - val_loss: 1.5527\n",
      "Epoch 616/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4245 - val_loss: 1.5061\n",
      "Epoch 617/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4256 - val_loss: 1.4194\n",
      "Epoch 618/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4220 - val_loss: 1.4364\n",
      "Epoch 619/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4195 - val_loss: 1.4164\n",
      "Epoch 620/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4198 - val_loss: 1.4538\n",
      "Epoch 621/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4244 - val_loss: 1.5792\n",
      "Epoch 622/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4146 - val_loss: 1.5056\n",
      "Epoch 623/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4203 - val_loss: 1.4505\n",
      "Epoch 624/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4148 - val_loss: 1.4899\n",
      "Epoch 625/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4158 - val_loss: 1.4484\n",
      "Epoch 626/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4262 - val_loss: 1.5172\n",
      "Epoch 627/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4232 - val_loss: 1.4568\n",
      "Epoch 628/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4166 - val_loss: 1.4449\n",
      "Epoch 629/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4131 - val_loss: 1.5278\n",
      "Epoch 630/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4192 - val_loss: 1.4890\n",
      "Epoch 631/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4118 - val_loss: 1.4344\n",
      "Epoch 632/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4060 - val_loss: 1.5174\n",
      "Epoch 633/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4122 - val_loss: 1.4616\n",
      "Epoch 634/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4099 - val_loss: 1.4264\n",
      "Epoch 635/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4152 - val_loss: 1.4398\n",
      "Epoch 636/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4197 - val_loss: 1.4361\n",
      "Epoch 637/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4123 - val_loss: 1.4159\n",
      "Epoch 638/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4164 - val_loss: 1.4094\n",
      "Epoch 639/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4017 - val_loss: 1.4402\n",
      "Epoch 640/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4186 - val_loss: 1.5397\n",
      "Epoch 641/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4177 - val_loss: 1.4792\n",
      "Epoch 642/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4104 - val_loss: 1.4058\n",
      "Epoch 643/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4080 - val_loss: 1.4427\n",
      "Epoch 644/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4182 - val_loss: 1.4628\n",
      "Epoch 645/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4129 - val_loss: 1.4556\n",
      "Epoch 646/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4126 - val_loss: 1.4503\n",
      "Epoch 647/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4051 - val_loss: 1.4046\n",
      "Epoch 648/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4128 - val_loss: 1.4063\n",
      "Epoch 649/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4163 - val_loss: 1.4565\n",
      "Epoch 650/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4073 - val_loss: 1.4521\n",
      "Epoch 651/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4118 - val_loss: 1.5166\n",
      "Epoch 652/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4155 - val_loss: 1.4551\n",
      "Epoch 653/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4125 - val_loss: 1.3999\n",
      "Epoch 654/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4121 - val_loss: 1.4528\n",
      "Epoch 655/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4006 - val_loss: 1.4654\n",
      "Epoch 656/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4124 - val_loss: 1.4972\n",
      "Epoch 657/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4083 - val_loss: 1.5163\n",
      "Epoch 658/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4165 - val_loss: 1.4258\n",
      "Epoch 659/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4060 - val_loss: 1.4745\n",
      "Epoch 660/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4081 - val_loss: 1.4823\n",
      "Epoch 661/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4049 - val_loss: 1.4623\n",
      "Epoch 662/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3975 - val_loss: 1.4175\n",
      "Epoch 663/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4093 - val_loss: 1.6447\n",
      "Epoch 664/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4046 - val_loss: 1.4368\n",
      "Epoch 665/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4130 - val_loss: 1.4317\n",
      "Epoch 666/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4040 - val_loss: 1.4860\n",
      "Epoch 667/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4134 - val_loss: 1.4676\n",
      "Epoch 668/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4024 - val_loss: 1.4575\n",
      "Epoch 669/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4001 - val_loss: 1.4290\n",
      "Epoch 670/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4043 - val_loss: 1.4524\n",
      "Epoch 671/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4077 - val_loss: 1.4330\n",
      "Epoch 672/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4029 - val_loss: 1.4440\n",
      "Epoch 673/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4035 - val_loss: 1.4250\n",
      "Epoch 674/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4066 - val_loss: 1.4471\n",
      "Epoch 675/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3961 - val_loss: 1.4131\n",
      "Epoch 676/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.4115 - val_loss: 1.5299\n",
      "Epoch 677/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4026 - val_loss: 1.4644\n",
      "Epoch 678/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3910 - val_loss: 1.5126\n",
      "Epoch 679/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4014 - val_loss: 1.4499\n",
      "Epoch 680/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4017 - val_loss: 1.4386\n",
      "Epoch 681/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3956 - val_loss: 1.4548\n",
      "Epoch 682/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4084 - val_loss: 1.4308\n",
      "Epoch 683/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4076 - val_loss: 1.4462\n",
      "Epoch 684/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4050 - val_loss: 1.4187\n",
      "Epoch 685/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4075 - val_loss: 1.4549\n",
      "Epoch 686/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3961 - val_loss: 1.4390\n",
      "Epoch 687/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4031 - val_loss: 1.5046\n",
      "Epoch 688/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3955 - val_loss: 1.4322\n",
      "Epoch 689/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4005 - val_loss: 1.4262\n",
      "Epoch 690/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4049 - val_loss: 1.4711\n",
      "Epoch 691/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3939 - val_loss: 1.4539\n",
      "Epoch 692/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3977 - val_loss: 1.4198\n",
      "Epoch 693/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.4012 - val_loss: 1.4080\n",
      "Epoch 694/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3965 - val_loss: 1.4309\n",
      "Epoch 695/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4040 - val_loss: 1.4246\n",
      "Epoch 696/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3975 - val_loss: 1.4272\n",
      "Epoch 697/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3900 - val_loss: 1.4082\n",
      "Epoch 698/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4032 - val_loss: 1.4301\n",
      "Epoch 699/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3888 - val_loss: 1.4392\n",
      "Epoch 700/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3946 - val_loss: 1.5291\n",
      "Epoch 701/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3992 - val_loss: 1.4655\n",
      "Epoch 702/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3988 - val_loss: 1.4111\n",
      "Epoch 703/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3906 - val_loss: 1.3977\n",
      "Epoch 704/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4038 - val_loss: 1.4745\n",
      "Epoch 705/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4018 - val_loss: 1.4240\n",
      "Epoch 706/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3998 - val_loss: 1.3998\n",
      "Epoch 707/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3990 - val_loss: 1.4310\n",
      "Epoch 708/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.4017 - val_loss: 1.3923\n",
      "Epoch 709/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3919 - val_loss: 1.3903\n",
      "Epoch 710/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3920 - val_loss: 1.4023\n",
      "Epoch 711/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3936 - val_loss: 1.4714\n",
      "Epoch 712/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3937 - val_loss: 1.3939\n",
      "Epoch 713/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3825 - val_loss: 1.4587\n",
      "Epoch 714/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3974 - val_loss: 1.4689\n",
      "Epoch 715/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3980 - val_loss: 1.4171\n",
      "Epoch 716/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3896 - val_loss: 1.4725\n",
      "Epoch 717/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3943 - val_loss: 1.4086\n",
      "Epoch 718/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3889 - val_loss: 1.4314\n",
      "Epoch 719/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3863 - val_loss: 1.3848\n",
      "Epoch 720/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3847 - val_loss: 1.4581\n",
      "Epoch 721/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3862 - val_loss: 1.4092\n",
      "Epoch 722/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3892 - val_loss: 1.3985\n",
      "Epoch 723/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3913 - val_loss: 1.3821\n",
      "Epoch 724/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3908 - val_loss: 1.4001\n",
      "Epoch 725/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3790 - val_loss: 1.4746\n",
      "Epoch 726/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3949 - val_loss: 1.4299\n",
      "Epoch 727/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3941 - val_loss: 1.3989\n",
      "Epoch 728/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3819 - val_loss: 1.3918\n",
      "Epoch 729/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3962 - val_loss: 1.5086\n",
      "Epoch 730/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3843 - val_loss: 1.4022\n",
      "Epoch 731/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3906 - val_loss: 1.4078\n",
      "Epoch 732/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3910 - val_loss: 1.3927\n",
      "Epoch 733/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3828 - val_loss: 1.4693\n",
      "Epoch 734/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3917 - val_loss: 1.4445\n",
      "Epoch 735/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3924 - val_loss: 1.4366\n",
      "Epoch 736/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3895 - val_loss: 1.4396\n",
      "Epoch 737/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3870 - val_loss: 1.4240\n",
      "Epoch 738/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3959 - val_loss: 1.4368\n",
      "Epoch 739/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3892 - val_loss: 1.4204\n",
      "Epoch 740/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3858 - val_loss: 1.4168\n",
      "Epoch 741/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3887 - val_loss: 1.4364\n",
      "Epoch 742/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3794 - val_loss: 1.3770\n",
      "Epoch 743/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3892 - val_loss: 1.4398\n",
      "Epoch 744/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3806 - val_loss: 1.3795\n",
      "Epoch 745/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3811 - val_loss: 1.3927\n",
      "Epoch 746/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3832 - val_loss: 1.3711\n",
      "Epoch 747/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3848 - val_loss: 1.4471\n",
      "Epoch 748/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3771 - val_loss: 1.3914\n",
      "Epoch 749/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3840 - val_loss: 1.4849\n",
      "Epoch 750/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3788 - val_loss: 1.4223\n",
      "Epoch 751/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3935 - val_loss: 1.4444\n",
      "Epoch 752/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3781 - val_loss: 1.4700\n",
      "Epoch 753/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3988 - val_loss: 1.3988\n",
      "Epoch 754/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3834 - val_loss: 1.4923\n",
      "Epoch 755/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3773 - val_loss: 1.4181\n",
      "Epoch 756/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3760 - val_loss: 1.3961\n",
      "Epoch 757/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3876 - val_loss: 1.3952\n",
      "Epoch 758/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3837 - val_loss: 1.4187\n",
      "Epoch 759/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3956 - val_loss: 1.4008\n",
      "Epoch 760/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3825 - val_loss: 1.4000\n",
      "Epoch 761/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3848 - val_loss: 1.4185\n",
      "Epoch 762/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3855 - val_loss: 1.3778\n",
      "Epoch 763/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3821 - val_loss: 1.3908\n",
      "Epoch 764/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3783 - val_loss: 1.3705\n",
      "Epoch 765/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3819 - val_loss: 1.5056\n",
      "Epoch 766/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3885 - val_loss: 1.4645\n",
      "Epoch 767/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3787 - val_loss: 1.4585\n",
      "Epoch 768/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3710 - val_loss: 1.3685\n",
      "Epoch 769/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3851 - val_loss: 1.4542\n",
      "Epoch 770/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3811 - val_loss: 1.4359\n",
      "Epoch 771/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3777 - val_loss: 1.4175\n",
      "Epoch 772/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3823 - val_loss: 1.4838\n",
      "Epoch 773/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3848 - val_loss: 1.4017\n",
      "Epoch 774/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3834 - val_loss: 1.3780\n",
      "Epoch 775/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3735 - val_loss: 1.4039\n",
      "Epoch 776/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3750 - val_loss: 1.4971\n",
      "Epoch 777/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3816 - val_loss: 1.3810\n",
      "Epoch 778/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3844 - val_loss: 1.3962\n",
      "Epoch 779/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3810 - val_loss: 1.4603\n",
      "Epoch 780/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3801 - val_loss: 1.4381\n",
      "Epoch 781/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3726 - val_loss: 1.4301\n",
      "Epoch 782/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3765 - val_loss: 1.4369\n",
      "Epoch 783/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3823 - val_loss: 1.4340\n",
      "Epoch 784/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3804 - val_loss: 1.3913\n",
      "Epoch 785/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3824 - val_loss: 1.4065\n",
      "Epoch 786/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3885 - val_loss: 1.4560\n",
      "Epoch 787/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3720 - val_loss: 1.3794\n",
      "Epoch 788/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3729 - val_loss: 1.4261\n",
      "Epoch 789/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3870 - val_loss: 1.4196\n",
      "Epoch 790/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3768 - val_loss: 1.4157\n",
      "Epoch 791/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3883 - val_loss: 1.3936\n",
      "Epoch 792/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3717 - val_loss: 1.4181\n",
      "Epoch 793/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3719 - val_loss: 1.4119\n",
      "Epoch 794/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3763 - val_loss: 1.4418\n",
      "Epoch 795/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3743 - val_loss: 1.3790\n",
      "Epoch 796/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3765 - val_loss: 1.4434\n",
      "Epoch 797/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3772 - val_loss: 1.4669\n",
      "Epoch 798/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3851 - val_loss: 1.4436\n",
      "Epoch 799/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3762 - val_loss: 1.4488\n",
      "Epoch 800/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3773 - val_loss: 1.3929\n",
      "Epoch 801/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3773 - val_loss: 1.4064\n",
      "Epoch 802/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3749 - val_loss: 1.4074\n",
      "Epoch 803/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3776 - val_loss: 1.4101\n",
      "Epoch 804/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3727 - val_loss: 1.3756\n",
      "Epoch 805/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3725 - val_loss: 1.3960\n",
      "Epoch 806/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3729 - val_loss: 1.3609\n",
      "Epoch 807/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3798 - val_loss: 1.3655\n",
      "Epoch 808/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3762 - val_loss: 1.4562\n",
      "Epoch 809/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3752 - val_loss: 1.4600\n",
      "Epoch 810/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3735 - val_loss: 1.3894\n",
      "Epoch 811/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3715 - val_loss: 1.4031\n",
      "Epoch 812/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3895 - val_loss: 1.4425\n",
      "Epoch 813/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3732 - val_loss: 1.3843\n",
      "Epoch 814/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3697 - val_loss: 1.3739\n",
      "Epoch 815/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3765 - val_loss: 1.5639\n",
      "Epoch 816/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3743 - val_loss: 1.4439\n",
      "Epoch 817/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3787 - val_loss: 1.4011\n",
      "Epoch 818/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3722 - val_loss: 1.4027\n",
      "Epoch 819/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3752 - val_loss: 1.3984\n",
      "Epoch 820/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3780 - val_loss: 1.3968\n",
      "Epoch 821/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3718 - val_loss: 1.4083\n",
      "Epoch 822/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3729 - val_loss: 1.4452\n",
      "Epoch 823/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3732 - val_loss: 1.4579\n",
      "Epoch 824/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3698 - val_loss: 1.4103\n",
      "Epoch 825/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3668 - val_loss: 1.3837\n",
      "Epoch 826/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3772 - val_loss: 1.3857\n",
      "Epoch 827/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3812 - val_loss: 1.3937\n",
      "Epoch 828/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3694 - val_loss: 1.3983\n",
      "Epoch 829/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3687 - val_loss: 1.3786\n",
      "Epoch 830/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3733 - val_loss: 1.3747\n",
      "Epoch 831/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3702 - val_loss: 1.4072\n",
      "Epoch 832/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3702 - val_loss: 1.4636\n",
      "Epoch 833/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3699 - val_loss: 1.4085\n",
      "Epoch 834/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3750 - val_loss: 1.3776\n",
      "Epoch 835/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3721 - val_loss: 1.4577\n",
      "Epoch 836/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3702 - val_loss: 1.3767\n",
      "Epoch 837/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3590 - val_loss: 1.4389\n",
      "Epoch 838/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3780 - val_loss: 1.4325\n",
      "Epoch 839/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3745 - val_loss: 1.4140\n",
      "Epoch 840/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3674 - val_loss: 1.3688\n",
      "Epoch 841/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3690 - val_loss: 1.3807\n",
      "Epoch 842/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3662 - val_loss: 1.3961\n",
      "Epoch 843/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3689 - val_loss: 1.3931\n",
      "Epoch 844/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3724 - val_loss: 1.4368\n",
      "Epoch 845/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3662 - val_loss: 1.4663\n",
      "Epoch 846/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3627 - val_loss: 1.4372\n",
      "Epoch 847/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3706 - val_loss: 1.4188\n",
      "Epoch 848/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3749 - val_loss: 1.3837\n",
      "Epoch 849/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3601 - val_loss: 1.3711\n",
      "Epoch 850/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3716 - val_loss: 1.4095\n",
      "Epoch 851/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3680 - val_loss: 1.4611\n",
      "Epoch 852/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3646 - val_loss: 1.4511\n",
      "Epoch 853/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3715 - val_loss: 1.3835\n",
      "Epoch 854/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3691 - val_loss: 1.3828\n",
      "Epoch 855/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3746 - val_loss: 1.4520\n",
      "Epoch 856/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3786 - val_loss: 1.3667\n",
      "Epoch 857/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3669 - val_loss: 1.3698\n",
      "Epoch 858/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3667 - val_loss: 1.5084\n",
      "Epoch 859/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3709 - val_loss: 1.3834\n",
      "Epoch 860/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3668 - val_loss: 1.3641\n",
      "Epoch 861/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3587 - val_loss: 1.5497\n",
      "Epoch 862/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3757 - val_loss: 1.4651\n",
      "Epoch 863/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3615 - val_loss: 1.4412\n",
      "Epoch 864/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3714 - val_loss: 1.4233\n",
      "Epoch 865/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3570 - val_loss: 1.4085\n",
      "Epoch 866/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3699 - val_loss: 1.4011\n",
      "Epoch 867/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3588 - val_loss: 1.5041\n",
      "Epoch 868/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3677 - val_loss: 1.4069\n",
      "Epoch 869/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3696 - val_loss: 1.4323\n",
      "Epoch 870/900\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 1.3708 - val_loss: 1.4432\n",
      "Epoch 871/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3569 - val_loss: 1.4224\n",
      "Epoch 872/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3655 - val_loss: 1.4231\n",
      "Epoch 873/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3675 - val_loss: 1.3736\n",
      "Epoch 874/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3681 - val_loss: 1.4323\n",
      "Epoch 875/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3666 - val_loss: 1.6079\n",
      "Epoch 876/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3665 - val_loss: 1.3673\n",
      "Epoch 877/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3656 - val_loss: 1.4078\n",
      "Epoch 878/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3624 - val_loss: 1.6257\n",
      "Epoch 879/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3648 - val_loss: 1.5211\n",
      "Epoch 880/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3718 - val_loss: 1.4779\n",
      "Epoch 881/900\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 1.3565 - val_loss: 1.4142\n",
      "Epoch 882/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3715 - val_loss: 1.3679\n",
      "Epoch 883/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3614 - val_loss: 1.4807\n",
      "Epoch 884/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3656 - val_loss: 1.4532\n",
      "Epoch 885/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3557 - val_loss: 1.4047\n",
      "Epoch 886/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3654 - val_loss: 1.3772\n",
      "Epoch 887/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3642 - val_loss: 1.4274\n",
      "Epoch 888/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3625 - val_loss: 1.4244\n",
      "Epoch 889/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3663 - val_loss: 1.3905\n",
      "Epoch 890/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3673 - val_loss: 1.4533\n",
      "Epoch 891/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3657 - val_loss: 1.5040\n",
      "Epoch 892/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3621 - val_loss: 1.3745\n",
      "Epoch 893/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3634 - val_loss: 1.4513\n",
      "Epoch 894/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3582 - val_loss: 1.3934\n",
      "Epoch 895/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3610 - val_loss: 1.3835\n",
      "Epoch 896/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3553 - val_loss: 1.4449\n",
      "Epoch 897/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3628 - val_loss: 1.3693\n",
      "Epoch 898/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3596 - val_loss: 1.3628\n",
      "Epoch 899/900\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3616 - val_loss: 1.4142\n",
      "Epoch 900/900\n",
      "864/864 [==============================] - 4s 4ms/step - loss: 1.3611 - val_loss: 1.3862\n",
      "1.3862307746924905\n",
      "0.9715491129982659\n",
      "Epoch 1/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 6.9969 - val_loss: 8.5665\n",
      "Epoch 2/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 5.4965 - val_loss: 4.0555\n",
      "Epoch 3/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 5.0495 - val_loss: 4.7828\n",
      "Epoch 4/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 4.2760 - val_loss: 5.7466\n",
      "Epoch 5/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 4.2571 - val_loss: 3.5239\n",
      "Epoch 6/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 4.0505 - val_loss: 3.9399\n",
      "Epoch 7/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 3.6315 - val_loss: 3.3501\n",
      "Epoch 8/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 3.5927 - val_loss: 3.2091\n",
      "Epoch 9/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 3.3968 - val_loss: 3.2816\n",
      "Epoch 10/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 3.3273 - val_loss: 3.2500\n",
      "Epoch 11/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 3.1749 - val_loss: 3.2738\n",
      "Epoch 12/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 3.0553 - val_loss: 3.0276\n",
      "Epoch 13/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.9167 - val_loss: 3.0340\n",
      "Epoch 14/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.8102 - val_loss: 3.2424\n",
      "Epoch 15/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.8234 - val_loss: 3.0010\n",
      "Epoch 16/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 2.7653 - val_loss: 2.8972\n",
      "Epoch 17/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.7303 - val_loss: 2.5500\n",
      "Epoch 18/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.6643 - val_loss: 2.4867\n",
      "Epoch 19/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.6552 - val_loss: 2.6905\n",
      "Epoch 20/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.5816 - val_loss: 2.7647\n",
      "Epoch 21/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.6001 - val_loss: 2.7001\n",
      "Epoch 22/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.5352 - val_loss: 2.5331\n",
      "Epoch 23/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.5221 - val_loss: 2.6609\n",
      "Epoch 24/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 3s 6ms/step - loss: 2.5078 - val_loss: 2.4320\n",
      "Epoch 25/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.4780 - val_loss: 2.3987\n",
      "Epoch 26/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.4631 - val_loss: 2.5524\n",
      "Epoch 27/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.4224 - val_loss: 2.8668\n",
      "Epoch 28/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.4126 - val_loss: 2.8067\n",
      "Epoch 29/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.3881 - val_loss: 2.3262\n",
      "Epoch 30/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.3580 - val_loss: 2.3879\n",
      "Epoch 31/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.3300 - val_loss: 2.3496\n",
      "Epoch 32/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.3238 - val_loss: 2.2142\n",
      "Epoch 33/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.3172 - val_loss: 2.4315\n",
      "Epoch 34/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.2644 - val_loss: 2.3147\n",
      "Epoch 35/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.2627 - val_loss: 2.3369\n",
      "Epoch 36/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.2513 - val_loss: 2.2132\n",
      "Epoch 37/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.2321 - val_loss: 2.3461\n",
      "Epoch 38/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.2189 - val_loss: 2.1595\n",
      "Epoch 39/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.2077 - val_loss: 2.0933\n",
      "Epoch 40/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.1579 - val_loss: 2.0811\n",
      "Epoch 41/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.1835 - val_loss: 2.1621\n",
      "Epoch 42/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.1507 - val_loss: 2.1275\n",
      "Epoch 43/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.1604 - val_loss: 2.0584\n",
      "Epoch 44/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.1052 - val_loss: 2.0496\n",
      "Epoch 45/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.1336 - val_loss: 2.0362\n",
      "Epoch 46/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.1033 - val_loss: 2.3335\n",
      "Epoch 47/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.0997 - val_loss: 2.1185\n",
      "Epoch 48/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.1001 - val_loss: 2.0705\n",
      "Epoch 49/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.0924 - val_loss: 2.0008\n",
      "Epoch 50/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.0734 - val_loss: 2.0744\n",
      "Epoch 51/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.0923 - val_loss: 2.0570\n",
      "Epoch 52/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.0392 - val_loss: 2.0046\n",
      "Epoch 53/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 2.0541 - val_loss: 2.0625\n",
      "Epoch 54/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.0385 - val_loss: 1.9401\n",
      "Epoch 55/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.0351 - val_loss: 1.9771\n",
      "Epoch 56/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.0204 - val_loss: 2.0040\n",
      "Epoch 57/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.0191 - val_loss: 1.9396\n",
      "Epoch 58/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 2.0019 - val_loss: 1.9981\n",
      "Epoch 59/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.9964 - val_loss: 2.0092\n",
      "Epoch 60/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 2.0072 - val_loss: 1.9778\n",
      "Epoch 61/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.9775 - val_loss: 2.0013\n",
      "Epoch 62/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.9914 - val_loss: 1.9395\n",
      "Epoch 63/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.9535 - val_loss: 2.0159\n",
      "Epoch 64/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.9460 - val_loss: 2.0247\n",
      "Epoch 65/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.9433 - val_loss: 2.1475\n",
      "Epoch 66/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.9441 - val_loss: 1.9303\n",
      "Epoch 67/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.9327 - val_loss: 1.9552\n",
      "Epoch 68/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.9006 - val_loss: 1.8593\n",
      "Epoch 69/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.9130 - val_loss: 2.0601\n",
      "Epoch 70/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.9083 - val_loss: 1.9193\n",
      "Epoch 71/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.9133 - val_loss: 1.9443\n",
      "Epoch 72/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8862 - val_loss: 1.8943\n",
      "Epoch 73/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8780 - val_loss: 1.8128\n",
      "Epoch 74/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8720 - val_loss: 1.9312\n",
      "Epoch 75/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8650 - val_loss: 1.8769\n",
      "Epoch 76/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8713 - val_loss: 1.9582\n",
      "Epoch 77/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8529 - val_loss: 1.8626\n",
      "Epoch 78/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8605 - val_loss: 1.8041\n",
      "Epoch 79/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8550 - val_loss: 2.0089\n",
      "Epoch 80/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8444 - val_loss: 1.8999\n",
      "Epoch 81/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8413 - val_loss: 1.7957\n",
      "Epoch 82/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8382 - val_loss: 1.9989\n",
      "Epoch 83/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8243 - val_loss: 1.8390\n",
      "Epoch 84/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8232 - val_loss: 1.8393\n",
      "Epoch 85/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.8091 - val_loss: 1.7589\n",
      "Epoch 86/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8120 - val_loss: 1.8246\n",
      "Epoch 87/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8112 - val_loss: 1.8560\n",
      "Epoch 88/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8162 - val_loss: 1.8125\n",
      "Epoch 89/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.8073 - val_loss: 1.8864\n",
      "Epoch 90/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.8043 - val_loss: 1.8058\n",
      "Epoch 91/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7848 - val_loss: 1.7439\n",
      "Epoch 92/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7731 - val_loss: 1.7687\n",
      "Epoch 93/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7688 - val_loss: 1.7678\n",
      "Epoch 94/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7791 - val_loss: 1.7693\n",
      "Epoch 95/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7660 - val_loss: 1.8296\n",
      "Epoch 96/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7893 - val_loss: 1.8049\n",
      "Epoch 97/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7561 - val_loss: 1.7858\n",
      "Epoch 98/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7644 - val_loss: 1.8662\n",
      "Epoch 99/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7538 - val_loss: 1.7429\n",
      "Epoch 100/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7431 - val_loss: 1.8364\n",
      "Epoch 101/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7409 - val_loss: 1.7704\n",
      "Epoch 102/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7489 - val_loss: 1.7120\n",
      "Epoch 103/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7376 - val_loss: 1.6997\n",
      "Epoch 104/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7242 - val_loss: 1.7933\n",
      "Epoch 105/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7288 - val_loss: 1.7456\n",
      "Epoch 106/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7187 - val_loss: 1.6805\n",
      "Epoch 107/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7152 - val_loss: 1.7327\n",
      "Epoch 108/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7112 - val_loss: 1.6707\n",
      "Epoch 109/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.7138 - val_loss: 1.6910\n",
      "Epoch 110/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.7123 - val_loss: 1.7862\n",
      "Epoch 111/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7133 - val_loss: 1.6777\n",
      "Epoch 112/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6876 - val_loss: 1.7651\n",
      "Epoch 113/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7190 - val_loss: 1.7557\n",
      "Epoch 114/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.7004 - val_loss: 1.7094\n",
      "Epoch 115/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6862 - val_loss: 1.7803\n",
      "Epoch 116/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6835 - val_loss: 1.6974\n",
      "Epoch 117/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6790 - val_loss: 1.7222\n",
      "Epoch 118/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6758 - val_loss: 1.6486\n",
      "Epoch 119/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6935 - val_loss: 1.7243\n",
      "Epoch 120/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6707 - val_loss: 1.8706\n",
      "Epoch 121/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6753 - val_loss: 1.6680\n",
      "Epoch 122/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6832 - val_loss: 1.6462\n",
      "Epoch 123/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6697 - val_loss: 1.7665\n",
      "Epoch 124/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6542 - val_loss: 1.7113\n",
      "Epoch 125/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6570 - val_loss: 1.7360\n",
      "Epoch 126/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6550 - val_loss: 1.6164\n",
      "Epoch 127/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6535 - val_loss: 1.6650\n",
      "Epoch 128/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6389 - val_loss: 1.7638\n",
      "Epoch 129/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6564 - val_loss: 1.6885\n",
      "Epoch 130/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6329 - val_loss: 1.6797\n",
      "Epoch 131/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6382 - val_loss: 1.6559\n",
      "Epoch 132/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6479 - val_loss: 1.6239\n",
      "Epoch 133/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6351 - val_loss: 1.6418\n",
      "Epoch 134/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6328 - val_loss: 1.6615\n",
      "Epoch 135/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6337 - val_loss: 1.6914\n",
      "Epoch 136/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6252 - val_loss: 1.7199\n",
      "Epoch 137/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6382 - val_loss: 1.7221\n",
      "Epoch 138/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6251 - val_loss: 1.6545\n",
      "Epoch 139/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6268 - val_loss: 1.6878\n",
      "Epoch 140/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6236 - val_loss: 1.6607\n",
      "Epoch 141/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6251 - val_loss: 1.6368\n",
      "Epoch 142/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6186 - val_loss: 1.6250\n",
      "Epoch 143/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6118 - val_loss: 1.6454\n",
      "Epoch 144/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6143 - val_loss: 1.6006\n",
      "Epoch 145/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.6128 - val_loss: 1.6545\n",
      "Epoch 146/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6095 - val_loss: 1.6563\n",
      "Epoch 147/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6023 - val_loss: 1.5779\n",
      "Epoch 148/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5966 - val_loss: 1.5725\n",
      "Epoch 149/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5973 - val_loss: 1.6185\n",
      "Epoch 150/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.6155 - val_loss: 1.5741\n",
      "Epoch 151/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5958 - val_loss: 1.6313\n",
      "Epoch 152/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5936 - val_loss: 1.5980\n",
      "Epoch 153/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5878 - val_loss: 1.5908\n",
      "Epoch 154/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5850 - val_loss: 1.6789\n",
      "Epoch 155/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.6079 - val_loss: 1.5849\n",
      "Epoch 156/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5836 - val_loss: 1.5884\n",
      "Epoch 157/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5856 - val_loss: 1.6796\n",
      "Epoch 158/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5872 - val_loss: 1.5921\n",
      "Epoch 159/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5725 - val_loss: 1.6997\n",
      "Epoch 160/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5756 - val_loss: 1.5625\n",
      "Epoch 161/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5765 - val_loss: 1.7775\n",
      "Epoch 162/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5785 - val_loss: 1.6103\n",
      "Epoch 163/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5765 - val_loss: 1.6256\n",
      "Epoch 164/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5700 - val_loss: 1.6255\n",
      "Epoch 165/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5638 - val_loss: 1.5815\n",
      "Epoch 166/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5595 - val_loss: 1.6410\n",
      "Epoch 167/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5594 - val_loss: 1.5544\n",
      "Epoch 168/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5574 - val_loss: 1.5502\n",
      "Epoch 169/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5680 - val_loss: 1.5894\n",
      "Epoch 170/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5710 - val_loss: 1.5955\n",
      "Epoch 171/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5830 - val_loss: 1.7218\n",
      "Epoch 172/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5511 - val_loss: 1.6030\n",
      "Epoch 173/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5624 - val_loss: 1.7056\n",
      "Epoch 174/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5661 - val_loss: 1.5920\n",
      "Epoch 175/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5493 - val_loss: 1.5611\n",
      "Epoch 176/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5536 - val_loss: 1.6034\n",
      "Epoch 177/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5388 - val_loss: 1.5665\n",
      "Epoch 178/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5557 - val_loss: 1.5699\n",
      "Epoch 179/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5508 - val_loss: 1.6057\n",
      "Epoch 180/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5395 - val_loss: 1.5737\n",
      "Epoch 181/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5454 - val_loss: 1.5793\n",
      "Epoch 182/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5501 - val_loss: 1.6355\n",
      "Epoch 183/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5352 - val_loss: 1.5872\n",
      "Epoch 184/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.5573 - val_loss: 1.5653\n",
      "Epoch 185/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5388 - val_loss: 1.5784\n",
      "Epoch 186/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5375 - val_loss: 1.5689\n",
      "Epoch 187/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5298 - val_loss: 1.6094\n",
      "Epoch 188/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5300 - val_loss: 1.7486\n",
      "Epoch 189/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5284 - val_loss: 1.5756\n",
      "Epoch 190/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5350 - val_loss: 1.5918\n",
      "Epoch 191/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5245 - val_loss: 1.6071\n",
      "Epoch 192/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5336 - val_loss: 1.5509\n",
      "Epoch 193/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5134 - val_loss: 1.5549\n",
      "Epoch 194/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5279 - val_loss: 1.5153\n",
      "Epoch 195/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5194 - val_loss: 1.5417\n",
      "Epoch 196/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5215 - val_loss: 1.4861\n",
      "Epoch 197/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5263 - val_loss: 1.5948\n",
      "Epoch 198/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5034 - val_loss: 1.5314\n",
      "Epoch 199/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5194 - val_loss: 1.5342\n",
      "Epoch 200/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5079 - val_loss: 1.5461\n",
      "Epoch 201/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5104 - val_loss: 1.6514\n",
      "Epoch 202/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5136 - val_loss: 1.5239\n",
      "Epoch 203/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5234 - val_loss: 1.5110\n",
      "Epoch 204/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5085 - val_loss: 1.5398\n",
      "Epoch 205/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.5115 - val_loss: 1.6892\n",
      "Epoch 206/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5055 - val_loss: 1.6889\n",
      "Epoch 207/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5109 - val_loss: 1.5421\n",
      "Epoch 208/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5060 - val_loss: 1.5373\n",
      "Epoch 209/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5073 - val_loss: 1.5481\n",
      "Epoch 210/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5011 - val_loss: 1.5513\n",
      "Epoch 211/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5096 - val_loss: 1.5564\n",
      "Epoch 212/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5078 - val_loss: 1.5052\n",
      "Epoch 213/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4959 - val_loss: 1.5798\n",
      "Epoch 214/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4945 - val_loss: 1.4957\n",
      "Epoch 215/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5112 - val_loss: 1.5578\n",
      "Epoch 216/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4969 - val_loss: 1.5223\n",
      "Epoch 217/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4897 - val_loss: 1.5634\n",
      "Epoch 218/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5015 - val_loss: 1.4692\n",
      "Epoch 219/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.5004 - val_loss: 1.5296\n",
      "Epoch 220/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4896 - val_loss: 1.5350\n",
      "Epoch 221/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.5014 - val_loss: 1.5199\n",
      "Epoch 222/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4826 - val_loss: 1.4905\n",
      "Epoch 223/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4872 - val_loss: 1.5279\n",
      "Epoch 224/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4843 - val_loss: 1.5420\n",
      "Epoch 225/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4836 - val_loss: 1.4830\n",
      "Epoch 226/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4949 - val_loss: 1.4995\n",
      "Epoch 227/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4876 - val_loss: 1.4837\n",
      "Epoch 228/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4783 - val_loss: 1.4533\n",
      "Epoch 229/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4835 - val_loss: 1.4731\n",
      "Epoch 230/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4893 - val_loss: 1.5286\n",
      "Epoch 231/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4852 - val_loss: 1.6096\n",
      "Epoch 232/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4775 - val_loss: 1.6390\n",
      "Epoch 233/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4839 - val_loss: 1.6112\n",
      "Epoch 234/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4780 - val_loss: 1.5367\n",
      "Epoch 235/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4874 - val_loss: 1.5075\n",
      "Epoch 236/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4781 - val_loss: 1.4831\n",
      "Epoch 237/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4666 - val_loss: 1.5347\n",
      "Epoch 238/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4820 - val_loss: 1.5129\n",
      "Epoch 239/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4812 - val_loss: 1.5259\n",
      "Epoch 240/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4861 - val_loss: 1.5213\n",
      "Epoch 241/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4648 - val_loss: 1.5136\n",
      "Epoch 242/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4813 - val_loss: 1.4925\n",
      "Epoch 243/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4662 - val_loss: 1.4939\n",
      "Epoch 244/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4553 - val_loss: 1.5824\n",
      "Epoch 245/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4795 - val_loss: 1.7304\n",
      "Epoch 246/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4714 - val_loss: 1.5361\n",
      "Epoch 247/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4639 - val_loss: 1.5377\n",
      "Epoch 248/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4613 - val_loss: 1.4637\n",
      "Epoch 249/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4678 - val_loss: 1.4954\n",
      "Epoch 250/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4690 - val_loss: 1.4626\n",
      "Epoch 251/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4609 - val_loss: 1.4857\n",
      "Epoch 252/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4632 - val_loss: 1.5759\n",
      "Epoch 253/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4596 - val_loss: 1.5420\n",
      "Epoch 254/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4715 - val_loss: 1.5742\n",
      "Epoch 255/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4593 - val_loss: 1.4769\n",
      "Epoch 256/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4640 - val_loss: 1.4683\n",
      "Epoch 257/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4612 - val_loss: 1.4980\n",
      "Epoch 258/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4696 - val_loss: 1.5289\n",
      "Epoch 259/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4505 - val_loss: 1.4998\n",
      "Epoch 260/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4567 - val_loss: 1.5296\n",
      "Epoch 261/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4562 - val_loss: 1.4917\n",
      "Epoch 262/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4594 - val_loss: 1.5290\n",
      "Epoch 263/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4595 - val_loss: 1.5559\n",
      "Epoch 264/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4505 - val_loss: 1.5743\n",
      "Epoch 265/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4616 - val_loss: 1.4632\n",
      "Epoch 266/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4557 - val_loss: 1.4516\n",
      "Epoch 267/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4498 - val_loss: 1.5027\n",
      "Epoch 268/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4470 - val_loss: 1.5339\n",
      "Epoch 269/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4478 - val_loss: 1.4594\n",
      "Epoch 270/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4551 - val_loss: 1.5261\n",
      "Epoch 271/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4478 - val_loss: 1.5399\n",
      "Epoch 272/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4433 - val_loss: 1.5064\n",
      "Epoch 273/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4465 - val_loss: 1.4668\n",
      "Epoch 274/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4527 - val_loss: 1.5158\n",
      "Epoch 275/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4564 - val_loss: 1.5289\n",
      "Epoch 276/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4418 - val_loss: 1.4576\n",
      "Epoch 277/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4470 - val_loss: 1.5501\n",
      "Epoch 278/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4508 - val_loss: 1.5463\n",
      "Epoch 279/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4372 - val_loss: 1.4666\n",
      "Epoch 280/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4424 - val_loss: 1.5038\n",
      "Epoch 281/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4366 - val_loss: 1.5056\n",
      "Epoch 282/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4471 - val_loss: 1.4977\n",
      "Epoch 283/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4416 - val_loss: 1.4389\n",
      "Epoch 284/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4531 - val_loss: 1.4681\n",
      "Epoch 285/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4341 - val_loss: 1.4577\n",
      "Epoch 286/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4398 - val_loss: 1.4144\n",
      "Epoch 287/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4342 - val_loss: 1.4887\n",
      "Epoch 288/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4369 - val_loss: 1.4987\n",
      "Epoch 289/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4397 - val_loss: 1.4843\n",
      "Epoch 290/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4417 - val_loss: 1.5157\n",
      "Epoch 291/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4380 - val_loss: 1.5073\n",
      "Epoch 292/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4388 - val_loss: 1.4056\n",
      "Epoch 293/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4287 - val_loss: 1.4467\n",
      "Epoch 294/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4317 - val_loss: 1.4718\n",
      "Epoch 295/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4196 - val_loss: 1.5025\n",
      "Epoch 296/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4288 - val_loss: 1.5111\n",
      "Epoch 297/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4236 - val_loss: 1.5430\n",
      "Epoch 298/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4267 - val_loss: 1.4780\n",
      "Epoch 299/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4348 - val_loss: 1.4848\n",
      "Epoch 300/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4297 - val_loss: 1.5335\n",
      "Epoch 301/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4382 - val_loss: 1.4685\n",
      "Epoch 302/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4333 - val_loss: 1.4985\n",
      "Epoch 303/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4281 - val_loss: 1.4987\n",
      "Epoch 304/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4273 - val_loss: 1.4387\n",
      "Epoch 305/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4136 - val_loss: 1.8731\n",
      "Epoch 306/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4399 - val_loss: 1.5473\n",
      "Epoch 307/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4243 - val_loss: 1.4263\n",
      "Epoch 308/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4241 - val_loss: 1.4739\n",
      "Epoch 309/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4231 - val_loss: 1.4686\n",
      "Epoch 310/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4146 - val_loss: 1.4803\n",
      "Epoch 311/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4110 - val_loss: 1.4447\n",
      "Epoch 312/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4271 - val_loss: 1.4000\n",
      "Epoch 313/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4260 - val_loss: 1.5001\n",
      "Epoch 314/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4273 - val_loss: 1.4954\n",
      "Epoch 315/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4250 - val_loss: 1.4620\n",
      "Epoch 316/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4075 - val_loss: 1.4439\n",
      "Epoch 317/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4136 - val_loss: 1.5044\n",
      "Epoch 318/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4215 - val_loss: 1.4927\n",
      "Epoch 319/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4318 - val_loss: 1.5115\n",
      "Epoch 320/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4199 - val_loss: 1.4349\n",
      "Epoch 321/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4031 - val_loss: 1.4215\n",
      "Epoch 322/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4182 - val_loss: 1.5019\n",
      "Epoch 323/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4101 - val_loss: 1.4938\n",
      "Epoch 324/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4321 - val_loss: 1.4957\n",
      "Epoch 325/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4097 - val_loss: 1.4487\n",
      "Epoch 326/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4196 - val_loss: 1.5508\n",
      "Epoch 327/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4062 - val_loss: 1.5651\n",
      "Epoch 328/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4081 - val_loss: 1.4872\n",
      "Epoch 329/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4228 - val_loss: 1.4961\n",
      "Epoch 330/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4088 - val_loss: 1.4436\n",
      "Epoch 331/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4123 - val_loss: 1.4900\n",
      "Epoch 332/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4162 - val_loss: 1.4669\n",
      "Epoch 333/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4196 - val_loss: 1.4237\n",
      "Epoch 334/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4144 - val_loss: 1.4500\n",
      "Epoch 335/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4154 - val_loss: 1.4191\n",
      "Epoch 336/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4033 - val_loss: 1.4608\n",
      "Epoch 337/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4033 - val_loss: 1.4340\n",
      "Epoch 338/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4210 - val_loss: 1.4055\n",
      "Epoch 339/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4194 - val_loss: 1.5362\n",
      "Epoch 340/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4134 - val_loss: 1.4963\n",
      "Epoch 341/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4097 - val_loss: 1.4711\n",
      "Epoch 342/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4016 - val_loss: 1.4506\n",
      "Epoch 343/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4059 - val_loss: 1.4867\n",
      "Epoch 344/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4126 - val_loss: 1.4932\n",
      "Epoch 345/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4032 - val_loss: 1.4329\n",
      "Epoch 346/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4073 - val_loss: 1.4217\n",
      "Epoch 347/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3997 - val_loss: 1.4352\n",
      "Epoch 348/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3980 - val_loss: 1.4314\n",
      "Epoch 349/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3985 - val_loss: 1.4305\n",
      "Epoch 350/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4099 - val_loss: 1.4220\n",
      "Epoch 351/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4066 - val_loss: 1.4645\n",
      "Epoch 352/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.4058 - val_loss: 1.4686\n",
      "Epoch 353/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3936 - val_loss: 1.4077\n",
      "Epoch 354/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.4034 - val_loss: 1.4586\n",
      "Epoch 355/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3990 - val_loss: 1.4955\n",
      "Epoch 356/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3942 - val_loss: 1.4522\n",
      "Epoch 357/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4087 - val_loss: 1.4381\n",
      "Epoch 358/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3934 - val_loss: 1.4043\n",
      "Epoch 359/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4115 - val_loss: 1.4418\n",
      "Epoch 360/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4136 - val_loss: 1.4476\n",
      "Epoch 361/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3932 - val_loss: 1.3942\n",
      "Epoch 362/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3988 - val_loss: 1.4213\n",
      "Epoch 363/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3937 - val_loss: 1.4256\n",
      "Epoch 364/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3955 - val_loss: 1.4483\n",
      "Epoch 365/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3882 - val_loss: 1.4504\n",
      "Epoch 366/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4070 - val_loss: 1.4532\n",
      "Epoch 367/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4036 - val_loss: 1.5216\n",
      "Epoch 368/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3912 - val_loss: 1.4277\n",
      "Epoch 369/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3915 - val_loss: 1.4292\n",
      "Epoch 370/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3886 - val_loss: 1.4318\n",
      "Epoch 371/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3888 - val_loss: 1.4383\n",
      "Epoch 372/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3953 - val_loss: 1.4179\n",
      "Epoch 373/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3931 - val_loss: 1.4548\n",
      "Epoch 374/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3888 - val_loss: 1.5185\n",
      "Epoch 375/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3824 - val_loss: 1.4243\n",
      "Epoch 376/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3979 - val_loss: 1.4415\n",
      "Epoch 377/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3981 - val_loss: 1.4022\n",
      "Epoch 378/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3844 - val_loss: 1.3874\n",
      "Epoch 379/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3845 - val_loss: 1.4024\n",
      "Epoch 380/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3809 - val_loss: 1.4358\n",
      "Epoch 381/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3911 - val_loss: 1.4069\n",
      "Epoch 382/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3940 - val_loss: 1.4263\n",
      "Epoch 383/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3887 - val_loss: 1.4386\n",
      "Epoch 384/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3896 - val_loss: 1.4054\n",
      "Epoch 385/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3856 - val_loss: 1.4388\n",
      "Epoch 386/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3802 - val_loss: 1.4556\n",
      "Epoch 387/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3906 - val_loss: 1.4378\n",
      "Epoch 388/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3780 - val_loss: 1.4784\n",
      "Epoch 389/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3870 - val_loss: 1.5387\n",
      "Epoch 390/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3878 - val_loss: 1.4236\n",
      "Epoch 391/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3930 - val_loss: 1.4732\n",
      "Epoch 392/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3773 - val_loss: 1.4951\n",
      "Epoch 393/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.4040 - val_loss: 1.4688\n",
      "Epoch 394/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3811 - val_loss: 1.4153\n",
      "Epoch 395/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3824 - val_loss: 1.3797\n",
      "Epoch 396/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3779 - val_loss: 1.4477\n",
      "Epoch 397/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3910 - val_loss: 1.3968\n",
      "Epoch 398/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3782 - val_loss: 1.3978\n",
      "Epoch 399/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3886 - val_loss: 1.5584\n",
      "Epoch 400/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3814 - val_loss: 1.4018\n",
      "Epoch 401/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3893 - val_loss: 1.4262\n",
      "Epoch 402/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3736 - val_loss: 1.4270\n",
      "Epoch 403/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3807 - val_loss: 1.3927\n",
      "Epoch 404/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3914 - val_loss: 1.5982\n",
      "Epoch 405/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3879 - val_loss: 1.3931\n",
      "Epoch 406/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3803 - val_loss: 1.3655\n",
      "Epoch 407/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3817 - val_loss: 1.4570\n",
      "Epoch 408/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3787 - val_loss: 1.4775\n",
      "Epoch 409/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3819 - val_loss: 1.4908\n",
      "Epoch 410/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3796 - val_loss: 1.5151\n",
      "Epoch 411/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3854 - val_loss: 1.3990\n",
      "Epoch 412/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3803 - val_loss: 1.4031\n",
      "Epoch 413/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3756 - val_loss: 1.4543\n",
      "Epoch 414/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3769 - val_loss: 1.3919\n",
      "Epoch 415/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3706 - val_loss: 1.3953\n",
      "Epoch 416/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3676 - val_loss: 1.5064\n",
      "Epoch 417/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3769 - val_loss: 1.4014\n",
      "Epoch 418/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3699 - val_loss: 1.4152\n",
      "Epoch 419/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3768 - val_loss: 1.4204\n",
      "Epoch 420/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3790 - val_loss: 1.4810\n",
      "Epoch 421/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3797 - val_loss: 1.4485\n",
      "Epoch 422/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3777 - val_loss: 1.3765\n",
      "Epoch 423/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3770 - val_loss: 1.4375\n",
      "Epoch 424/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3733 - val_loss: 1.4215\n",
      "Epoch 425/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3725 - val_loss: 1.4241\n",
      "Epoch 426/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3724 - val_loss: 1.5240\n",
      "Epoch 427/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3880 - val_loss: 1.4217\n",
      "Epoch 428/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3642 - val_loss: 1.3946\n",
      "Epoch 429/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3684 - val_loss: 1.5054\n",
      "Epoch 430/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3757 - val_loss: 1.3997\n",
      "Epoch 431/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3688 - val_loss: 1.4415\n",
      "Epoch 432/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3875 - val_loss: 1.4231\n",
      "Epoch 433/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3672 - val_loss: 1.3914\n",
      "Epoch 434/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3726 - val_loss: 1.4061\n",
      "Epoch 435/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3823 - val_loss: 1.3962\n",
      "Epoch 436/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3585 - val_loss: 1.4243\n",
      "Epoch 437/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3617 - val_loss: 1.4317\n",
      "Epoch 438/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3789 - val_loss: 1.4120\n",
      "Epoch 439/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3636 - val_loss: 1.4113\n",
      "Epoch 440/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3688 - val_loss: 1.4017\n",
      "Epoch 441/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3601 - val_loss: 1.4506\n",
      "Epoch 442/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3718 - val_loss: 1.4566\n",
      "Epoch 443/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3710 - val_loss: 1.4105\n",
      "Epoch 444/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3664 - val_loss: 1.4600\n",
      "Epoch 445/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3639 - val_loss: 1.3934\n",
      "Epoch 446/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3602 - val_loss: 1.4151\n",
      "Epoch 447/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3663 - val_loss: 1.3929\n",
      "Epoch 448/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3673 - val_loss: 1.4379\n",
      "Epoch 449/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3720 - val_loss: 1.4363\n",
      "Epoch 450/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3698 - val_loss: 1.3898\n",
      "Epoch 451/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.3637 - val_loss: 1.4265\n",
      "Epoch 452/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3547 - val_loss: 1.4169\n",
      "Epoch 453/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3592 - val_loss: 1.3835\n",
      "Epoch 454/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3586 - val_loss: 1.3880\n",
      "Epoch 455/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3727 - val_loss: 1.6691\n",
      "Epoch 456/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3651 - val_loss: 1.4521\n",
      "Epoch 457/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3715 - val_loss: 1.3961\n",
      "Epoch 458/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3620 - val_loss: 1.3730\n",
      "Epoch 459/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3595 - val_loss: 1.3925\n",
      "Epoch 460/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3630 - val_loss: 1.4214\n",
      "Epoch 461/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3613 - val_loss: 1.3652\n",
      "Epoch 462/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3634 - val_loss: 1.4357\n",
      "Epoch 463/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3574 - val_loss: 1.4758\n",
      "Epoch 464/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3654 - val_loss: 1.4230\n",
      "Epoch 465/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3559 - val_loss: 1.5498\n",
      "Epoch 466/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3565 - val_loss: 1.3637\n",
      "Epoch 467/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3655 - val_loss: 1.4535\n",
      "Epoch 468/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3615 - val_loss: 1.3821\n",
      "Epoch 469/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3610 - val_loss: 1.4062\n",
      "Epoch 470/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3653 - val_loss: 1.3951\n",
      "Epoch 471/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3594 - val_loss: 1.4371\n",
      "Epoch 472/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3489 - val_loss: 1.4094\n",
      "Epoch 473/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3701 - val_loss: 1.3870\n",
      "Epoch 474/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3548 - val_loss: 1.3819\n",
      "Epoch 475/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3695 - val_loss: 1.3750\n",
      "Epoch 476/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3528 - val_loss: 1.3942\n",
      "Epoch 477/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3629 - val_loss: 1.3832\n",
      "Epoch 478/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3581 - val_loss: 1.4039\n",
      "Epoch 479/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3588 - val_loss: 1.4906\n",
      "Epoch 480/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3647 - val_loss: 1.4363\n",
      "Epoch 481/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3562 - val_loss: 1.3994\n",
      "Epoch 482/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3595 - val_loss: 1.3860\n",
      "Epoch 483/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3570 - val_loss: 1.3708\n",
      "Epoch 484/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3535 - val_loss: 1.3944\n",
      "Epoch 485/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3501 - val_loss: 1.4033\n",
      "Epoch 486/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3588 - val_loss: 1.4287\n",
      "Epoch 487/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3514 - val_loss: 1.3757\n",
      "Epoch 488/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3495 - val_loss: 1.4307\n",
      "Epoch 489/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3502 - val_loss: 1.3904\n",
      "Epoch 490/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3554 - val_loss: 1.4228\n",
      "Epoch 491/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3589 - val_loss: 1.4565\n",
      "Epoch 492/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3550 - val_loss: 1.4750\n",
      "Epoch 493/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3502 - val_loss: 1.3635\n",
      "Epoch 494/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3542 - val_loss: 1.3913\n",
      "Epoch 495/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3429 - val_loss: 1.4123\n",
      "Epoch 496/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3518 - val_loss: 1.3937\n",
      "Epoch 497/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3546 - val_loss: 1.4276\n",
      "Epoch 498/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3491 - val_loss: 1.4052\n",
      "Epoch 499/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3600 - val_loss: 1.3858\n",
      "Epoch 500/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3513 - val_loss: 1.3983\n",
      "Epoch 501/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3635 - val_loss: 1.3756\n",
      "Epoch 502/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3466 - val_loss: 1.4284\n",
      "Epoch 503/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3503 - val_loss: 1.3957\n",
      "Epoch 504/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3449 - val_loss: 1.4521\n",
      "Epoch 505/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3533 - val_loss: 1.3659\n",
      "Epoch 506/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3500 - val_loss: 1.3675\n",
      "Epoch 507/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3464 - val_loss: 1.5179\n",
      "Epoch 508/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3483 - val_loss: 1.3847\n",
      "Epoch 509/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3423 - val_loss: 1.4465\n",
      "Epoch 510/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3414 - val_loss: 1.3809\n",
      "Epoch 511/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3436 - val_loss: 1.4051\n",
      "Epoch 512/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3504 - val_loss: 1.4476\n",
      "Epoch 513/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3450 - val_loss: 1.4443\n",
      "Epoch 514/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3483 - val_loss: 1.4188\n",
      "Epoch 515/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3494 - val_loss: 1.3747\n",
      "Epoch 516/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3466 - val_loss: 1.4255\n",
      "Epoch 517/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3506 - val_loss: 1.3868\n",
      "Epoch 518/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3479 - val_loss: 1.3869\n",
      "Epoch 519/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3507 - val_loss: 1.4750\n",
      "Epoch 520/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3531 - val_loss: 1.3748\n",
      "Epoch 521/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3397 - val_loss: 1.3916\n",
      "Epoch 522/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3506 - val_loss: 1.4044\n",
      "Epoch 523/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3482 - val_loss: 1.4148\n",
      "Epoch 524/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3361 - val_loss: 1.3951\n",
      "Epoch 525/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3481 - val_loss: 1.3970\n",
      "Epoch 526/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3434 - val_loss: 1.3779\n",
      "Epoch 527/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3421 - val_loss: 1.3565\n",
      "Epoch 528/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3487 - val_loss: 1.4247\n",
      "Epoch 529/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3308 - val_loss: 1.3696\n",
      "Epoch 530/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3349 - val_loss: 1.3717\n",
      "Epoch 531/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3392 - val_loss: 1.4251\n",
      "Epoch 532/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3531 - val_loss: 1.3967\n",
      "Epoch 533/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3481 - val_loss: 1.4134\n",
      "Epoch 534/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3406 - val_loss: 1.4004\n",
      "Epoch 535/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3390 - val_loss: 1.3687\n",
      "Epoch 536/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3403 - val_loss: 1.3919\n",
      "Epoch 537/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3375 - val_loss: 1.3823\n",
      "Epoch 538/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3509 - val_loss: 1.3609\n",
      "Epoch 539/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3357 - val_loss: 1.3897\n",
      "Epoch 540/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3356 - val_loss: 1.3971\n",
      "Epoch 541/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3302 - val_loss: 1.3817\n",
      "Epoch 542/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3380 - val_loss: 1.3984\n",
      "Epoch 543/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3402 - val_loss: 1.4019\n",
      "Epoch 544/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3410 - val_loss: 1.3939\n",
      "Epoch 545/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3323 - val_loss: 1.3611\n",
      "Epoch 546/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3455 - val_loss: 1.4031\n",
      "Epoch 547/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3404 - val_loss: 1.4218\n",
      "Epoch 548/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3377 - val_loss: 1.4183\n",
      "Epoch 549/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3400 - val_loss: 1.3874\n",
      "Epoch 550/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3364 - val_loss: 1.3433\n",
      "Epoch 551/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3324 - val_loss: 1.3453\n",
      "Epoch 552/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3419 - val_loss: 1.3397\n",
      "Epoch 553/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3398 - val_loss: 1.4263\n",
      "Epoch 554/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3278 - val_loss: 1.3516\n",
      "Epoch 555/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3362 - val_loss: 1.4456\n",
      "Epoch 556/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3407 - val_loss: 1.3678\n",
      "Epoch 557/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3355 - val_loss: 1.4276\n",
      "Epoch 558/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3374 - val_loss: 1.3936\n",
      "Epoch 559/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3472 - val_loss: 1.4735\n",
      "Epoch 560/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3433 - val_loss: 1.3519\n",
      "Epoch 561/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3300 - val_loss: 1.4646\n",
      "Epoch 562/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3408 - val_loss: 1.4591\n",
      "Epoch 563/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3294 - val_loss: 1.3722\n",
      "Epoch 564/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3300 - val_loss: 1.5075\n",
      "Epoch 565/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3354 - val_loss: 1.3584\n",
      "Epoch 566/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3309 - val_loss: 1.4071\n",
      "Epoch 567/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3278 - val_loss: 1.4374\n",
      "Epoch 568/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3300 - val_loss: 1.3758\n",
      "Epoch 569/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3407 - val_loss: 1.3605\n",
      "Epoch 570/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3266 - val_loss: 1.3814\n",
      "Epoch 571/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3418 - val_loss: 1.3730\n",
      "Epoch 572/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3278 - val_loss: 1.3525\n",
      "Epoch 573/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3327 - val_loss: 1.4030\n",
      "Epoch 574/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3312 - val_loss: 1.4728\n",
      "Epoch 575/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3372 - val_loss: 1.4008\n",
      "Epoch 576/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3262 - val_loss: 1.3720\n",
      "Epoch 577/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3299 - val_loss: 1.3862\n",
      "Epoch 578/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3222 - val_loss: 1.3738\n",
      "Epoch 579/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3309 - val_loss: 1.3976\n",
      "Epoch 580/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3355 - val_loss: 1.4259\n",
      "Epoch 581/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3223 - val_loss: 1.3805\n",
      "Epoch 582/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3235 - val_loss: 1.4623\n",
      "Epoch 583/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3290 - val_loss: 1.4055\n",
      "Epoch 584/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3324 - val_loss: 1.4031\n",
      "Epoch 585/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3339 - val_loss: 1.3509\n",
      "Epoch 586/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3319 - val_loss: 1.3582\n",
      "Epoch 587/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3326 - val_loss: 1.3236\n",
      "Epoch 588/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3300 - val_loss: 1.3651\n",
      "Epoch 589/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3330 - val_loss: 1.3675\n",
      "Epoch 590/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3300 - val_loss: 1.3949\n",
      "Epoch 591/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3242 - val_loss: 1.4305\n",
      "Epoch 592/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3306 - val_loss: 1.3420\n",
      "Epoch 593/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3295 - val_loss: 1.3896\n",
      "Epoch 594/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3359 - val_loss: 1.3686\n",
      "Epoch 595/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3270 - val_loss: 1.3896\n",
      "Epoch 596/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3200 - val_loss: 1.3724\n",
      "Epoch 597/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3359 - val_loss: 1.3789\n",
      "Epoch 598/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3274 - val_loss: 1.3859\n",
      "Epoch 599/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3174 - val_loss: 1.4083\n",
      "Epoch 600/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3312 - val_loss: 1.4383\n",
      "Epoch 601/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3315 - val_loss: 1.4692\n",
      "Epoch 602/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3162 - val_loss: 1.3970\n",
      "Epoch 603/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3245 - val_loss: 1.4146\n",
      "Epoch 604/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3318 - val_loss: 1.3606\n",
      "Epoch 605/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3315 - val_loss: 1.3420\n",
      "Epoch 606/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3251 - val_loss: 1.3652\n",
      "Epoch 607/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3182 - val_loss: 1.3254\n",
      "Epoch 608/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3219 - val_loss: 1.3386\n",
      "Epoch 609/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3193 - val_loss: 1.3869\n",
      "Epoch 610/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3195 - val_loss: 1.3379\n",
      "Epoch 611/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3186 - val_loss: 1.3968\n",
      "Epoch 612/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3266 - val_loss: 1.3497\n",
      "Epoch 613/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3145 - val_loss: 1.3527\n",
      "Epoch 614/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3165 - val_loss: 1.3491\n",
      "Epoch 615/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3290 - val_loss: 1.4302\n",
      "Epoch 616/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3190 - val_loss: 1.3876\n",
      "Epoch 617/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3177 - val_loss: 1.4342\n",
      "Epoch 618/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3253 - val_loss: 1.3675\n",
      "Epoch 619/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3207 - val_loss: 1.4303\n",
      "Epoch 620/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3220 - val_loss: 1.4067\n",
      "Epoch 621/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3065 - val_loss: 1.4242\n",
      "Epoch 622/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3155 - val_loss: 1.3459\n",
      "Epoch 623/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3275 - val_loss: 1.3963\n",
      "Epoch 624/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3294 - val_loss: 1.3641\n",
      "Epoch 625/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3180 - val_loss: 1.3829\n",
      "Epoch 626/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3260 - val_loss: 1.3928\n",
      "Epoch 627/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3220 - val_loss: 1.3902\n",
      "Epoch 628/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3292 - val_loss: 1.3865\n",
      "Epoch 629/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3173 - val_loss: 1.3333\n",
      "Epoch 630/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3104 - val_loss: 1.3308\n",
      "Epoch 631/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3217 - val_loss: 1.5648\n",
      "Epoch 632/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3159 - val_loss: 1.3744\n",
      "Epoch 633/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3234 - val_loss: 1.3601\n",
      "Epoch 634/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3079 - val_loss: 1.3229\n",
      "Epoch 635/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3266 - val_loss: 1.4093\n",
      "Epoch 636/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3156 - val_loss: 1.3636\n",
      "Epoch 637/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3172 - val_loss: 1.4404\n",
      "Epoch 638/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3153 - val_loss: 1.3482\n",
      "Epoch 639/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3115 - val_loss: 1.3405\n",
      "Epoch 640/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3114 - val_loss: 1.3974\n",
      "Epoch 641/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3151 - val_loss: 1.3911\n",
      "Epoch 642/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3252 - val_loss: 1.3594\n",
      "Epoch 643/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3189 - val_loss: 1.3358\n",
      "Epoch 644/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3153 - val_loss: 1.3770\n",
      "Epoch 645/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3112 - val_loss: 1.3693\n",
      "Epoch 646/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3269 - val_loss: 1.4098\n",
      "Epoch 647/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3235 - val_loss: 1.4203\n",
      "Epoch 648/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3105 - val_loss: 1.3643\n",
      "Epoch 649/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3100 - val_loss: 1.3887\n",
      "Epoch 650/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3167 - val_loss: 1.3326\n",
      "Epoch 651/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2994 - val_loss: 1.3504\n",
      "Epoch 652/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3162 - val_loss: 1.3437\n",
      "Epoch 653/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3145 - val_loss: 1.3527\n",
      "Epoch 654/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3160 - val_loss: 1.3948\n",
      "Epoch 655/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3230 - val_loss: 1.3653\n",
      "Epoch 656/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3101 - val_loss: 1.3460\n",
      "Epoch 657/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3141 - val_loss: 1.3865\n",
      "Epoch 658/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3194 - val_loss: 1.4091\n",
      "Epoch 659/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3045 - val_loss: 1.3539\n",
      "Epoch 660/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3118 - val_loss: 1.4593\n",
      "Epoch 661/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3207 - val_loss: 1.4195\n",
      "Epoch 662/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3162 - val_loss: 1.4104\n",
      "Epoch 663/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3180 - val_loss: 1.2911\n",
      "Epoch 664/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3198 - val_loss: 1.4100\n",
      "Epoch 665/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3087 - val_loss: 1.3297\n",
      "Epoch 666/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3098 - val_loss: 1.3726\n",
      "Epoch 667/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3193 - val_loss: 1.4169\n",
      "Epoch 668/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3113 - val_loss: 1.3697\n",
      "Epoch 669/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3109 - val_loss: 1.3836\n",
      "Epoch 670/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3055 - val_loss: 1.3518\n",
      "Epoch 671/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3174 - val_loss: 1.3426\n",
      "Epoch 672/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3156 - val_loss: 1.4420\n",
      "Epoch 673/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3052 - val_loss: 1.3381\n",
      "Epoch 674/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3084 - val_loss: 1.3796\n",
      "Epoch 675/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3238 - val_loss: 1.3499\n",
      "Epoch 676/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3134 - val_loss: 1.3222\n",
      "Epoch 677/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3119 - val_loss: 1.3043\n",
      "Epoch 678/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3154 - val_loss: 1.3610\n",
      "Epoch 679/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3083 - val_loss: 1.3913\n",
      "Epoch 680/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3120 - val_loss: 1.3729\n",
      "Epoch 681/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3133 - val_loss: 1.4276\n",
      "Epoch 682/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3093 - val_loss: 1.3758\n",
      "Epoch 683/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3101 - val_loss: 1.3505\n",
      "Epoch 684/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3098 - val_loss: 1.4988\n",
      "Epoch 685/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3032 - val_loss: 1.3341\n",
      "Epoch 686/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3090 - val_loss: 1.3014\n",
      "Epoch 687/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3107 - val_loss: 1.3403\n",
      "Epoch 688/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3058 - val_loss: 1.3596\n",
      "Epoch 689/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3051 - val_loss: 1.3726\n",
      "Epoch 690/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3070 - val_loss: 1.3356\n",
      "Epoch 691/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3021 - val_loss: 1.4143\n",
      "Epoch 692/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2999 - val_loss: 1.4424\n",
      "Epoch 693/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3127 - val_loss: 1.3258\n",
      "Epoch 694/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3120 - val_loss: 1.4056\n",
      "Epoch 695/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3115 - val_loss: 1.3481\n",
      "Epoch 696/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3174 - val_loss: 1.3635\n",
      "Epoch 697/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3050 - val_loss: 1.3889\n",
      "Epoch 698/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3050 - val_loss: 1.3662\n",
      "Epoch 699/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3168 - val_loss: 1.3760\n",
      "Epoch 700/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2964 - val_loss: 1.3558\n",
      "Epoch 701/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3104 - val_loss: 1.3851\n",
      "Epoch 702/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2999 - val_loss: 1.3237\n",
      "Epoch 703/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3034 - val_loss: 1.3361\n",
      "Epoch 704/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3058 - val_loss: 1.3508\n",
      "Epoch 705/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3061 - val_loss: 1.3823\n",
      "Epoch 706/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3062 - val_loss: 1.3339\n",
      "Epoch 707/900\n",
      "576/576 [==============================] - 5s 8ms/step - loss: 1.3132 - val_loss: 1.4068\n",
      "Epoch 708/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2965 - val_loss: 1.3481\n",
      "Epoch 709/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3011 - val_loss: 1.3669\n",
      "Epoch 710/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3042 - val_loss: 1.3153\n",
      "Epoch 711/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3042 - val_loss: 1.3941\n",
      "Epoch 712/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3012 - val_loss: 1.3731\n",
      "Epoch 713/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3070 - val_loss: 1.3307\n",
      "Epoch 714/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3023 - val_loss: 1.3670\n",
      "Epoch 715/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2977 - val_loss: 1.3545\n",
      "Epoch 716/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3092 - val_loss: 1.3052\n",
      "Epoch 717/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2974 - val_loss: 1.3492\n",
      "Epoch 718/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3063 - val_loss: 1.3663\n",
      "Epoch 719/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3021 - val_loss: 1.3709\n",
      "Epoch 720/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3008 - val_loss: 1.3322\n",
      "Epoch 721/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3087 - val_loss: 1.3153\n",
      "Epoch 722/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3003 - val_loss: 1.3650\n",
      "Epoch 723/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2999 - val_loss: 1.3501\n",
      "Epoch 724/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3035 - val_loss: 1.3895\n",
      "Epoch 725/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3121 - val_loss: 1.3636\n",
      "Epoch 726/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2989 - val_loss: 1.3812\n",
      "Epoch 727/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2945 - val_loss: 1.3405\n",
      "Epoch 728/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3004 - val_loss: 1.3604\n",
      "Epoch 729/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3023 - val_loss: 1.3622\n",
      "Epoch 730/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2992 - val_loss: 1.3897\n",
      "Epoch 731/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2989 - val_loss: 1.3714\n",
      "Epoch 732/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3066 - val_loss: 1.3018\n",
      "Epoch 733/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3002 - val_loss: 1.4273\n",
      "Epoch 734/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2933 - val_loss: 1.3449\n",
      "Epoch 735/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3027 - val_loss: 1.3627\n",
      "Epoch 736/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3024 - val_loss: 1.3437\n",
      "Epoch 737/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3025 - val_loss: 1.3558\n",
      "Epoch 738/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3032 - val_loss: 1.3938\n",
      "Epoch 739/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2984 - val_loss: 1.4066\n",
      "Epoch 740/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2980 - val_loss: 1.3640\n",
      "Epoch 741/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2933 - val_loss: 1.3493\n",
      "Epoch 742/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2959 - val_loss: 1.4031\n",
      "Epoch 743/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2929 - val_loss: 1.3600\n",
      "Epoch 744/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3024 - val_loss: 1.3405\n",
      "Epoch 745/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.3025 - val_loss: 1.3541\n",
      "Epoch 746/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2895 - val_loss: 1.3680\n",
      "Epoch 747/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2941 - val_loss: 1.3671\n",
      "Epoch 748/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2959 - val_loss: 1.3553\n",
      "Epoch 749/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3001 - val_loss: 1.3660\n",
      "Epoch 750/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.3031 - val_loss: 1.3493\n",
      "Epoch 751/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2988 - val_loss: 1.3218\n",
      "Epoch 752/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3003 - val_loss: 1.3479\n",
      "Epoch 753/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2908 - val_loss: 1.3490\n",
      "Epoch 754/900\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 1.2954 - val_loss: 1.3024\n",
      "Epoch 755/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2971 - val_loss: 1.4065\n",
      "Epoch 756/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2900 - val_loss: 1.3940\n",
      "Epoch 757/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2974 - val_loss: 1.3060\n",
      "Epoch 758/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3019 - val_loss: 1.3367\n",
      "Epoch 759/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2867 - val_loss: 1.3763\n",
      "Epoch 760/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2986 - val_loss: 1.3727\n",
      "Epoch 761/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2952 - val_loss: 1.4026\n",
      "Epoch 762/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2926 - val_loss: 1.3040\n",
      "Epoch 763/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2993 - val_loss: 1.3366\n",
      "Epoch 764/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2947 - val_loss: 1.3272\n",
      "Epoch 765/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2915 - val_loss: 1.4026\n",
      "Epoch 766/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2989 - val_loss: 1.3822\n",
      "Epoch 767/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2948 - val_loss: 1.3521\n",
      "Epoch 768/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2992 - val_loss: 1.3517\n",
      "Epoch 769/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2915 - val_loss: 1.3459\n",
      "Epoch 770/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2963 - val_loss: 1.3586\n",
      "Epoch 771/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2945 - val_loss: 1.3809\n",
      "Epoch 772/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3014 - val_loss: 1.3673\n",
      "Epoch 773/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3008 - val_loss: 1.4007\n",
      "Epoch 774/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2957 - val_loss: 1.3576\n",
      "Epoch 775/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2798 - val_loss: 1.3081\n",
      "Epoch 776/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3051 - val_loss: 1.3612\n",
      "Epoch 777/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3001 - val_loss: 1.3096\n",
      "Epoch 778/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2892 - val_loss: 1.3189\n",
      "Epoch 779/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2966 - val_loss: 1.3523\n",
      "Epoch 780/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2849 - val_loss: 1.3987\n",
      "Epoch 781/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2996 - val_loss: 1.3128\n",
      "Epoch 782/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2919 - val_loss: 1.3529\n",
      "Epoch 783/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2915 - val_loss: 1.3569\n",
      "Epoch 784/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2901 - val_loss: 1.4065\n",
      "Epoch 785/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.3007 - val_loss: 1.3530\n",
      "Epoch 786/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2941 - val_loss: 1.3226\n",
      "Epoch 787/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2956 - val_loss: 1.3568\n",
      "Epoch 788/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2954 - val_loss: 1.3183\n",
      "Epoch 789/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2832 - val_loss: 1.3019\n",
      "Epoch 790/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2993 - val_loss: 1.3225\n",
      "Epoch 791/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2876 - val_loss: 1.4704\n",
      "Epoch 792/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2943 - val_loss: 1.3300\n",
      "Epoch 793/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2909 - val_loss: 1.3730\n",
      "Epoch 794/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2802 - val_loss: 1.3321\n",
      "Epoch 795/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2889 - val_loss: 1.3541\n",
      "Epoch 796/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2971 - val_loss: 1.3455\n",
      "Epoch 797/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2847 - val_loss: 1.3025\n",
      "Epoch 798/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2908 - val_loss: 1.4068\n",
      "Epoch 799/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2994 - val_loss: 1.4328\n",
      "Epoch 800/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2801 - val_loss: 1.3267\n",
      "Epoch 801/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2891 - val_loss: 1.3436\n",
      "Epoch 802/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2886 - val_loss: 1.3420\n",
      "Epoch 803/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2876 - val_loss: 1.3193\n",
      "Epoch 804/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2865 - val_loss: 1.3248\n",
      "Epoch 805/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2812 - val_loss: 1.3540\n",
      "Epoch 806/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2812 - val_loss: 1.3171\n",
      "Epoch 807/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2901 - val_loss: 1.3287\n",
      "Epoch 808/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2883 - val_loss: 1.2950\n",
      "Epoch 809/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2877 - val_loss: 1.3053\n",
      "Epoch 810/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2834 - val_loss: 1.3233\n",
      "Epoch 811/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2929 - val_loss: 1.4004\n",
      "Epoch 812/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2950 - val_loss: 1.3449\n",
      "Epoch 813/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2884 - val_loss: 1.3481\n",
      "Epoch 814/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2897 - val_loss: 1.3592\n",
      "Epoch 815/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2899 - val_loss: 1.3600\n",
      "Epoch 816/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2902 - val_loss: 1.3546\n",
      "Epoch 817/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2871 - val_loss: 1.3296\n",
      "Epoch 818/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2773 - val_loss: 1.3185\n",
      "Epoch 819/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2909 - val_loss: 1.3616\n",
      "Epoch 820/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2820 - val_loss: 1.2904\n",
      "Epoch 821/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2899 - val_loss: 1.3528\n",
      "Epoch 822/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2952 - val_loss: 1.3838\n",
      "Epoch 823/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2830 - val_loss: 1.3224\n",
      "Epoch 824/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2803 - val_loss: 1.3147\n",
      "Epoch 825/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2906 - val_loss: 1.3763\n",
      "Epoch 826/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2803 - val_loss: 1.3295\n",
      "Epoch 827/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2844 - val_loss: 1.3157\n",
      "Epoch 828/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2846 - val_loss: 1.3737\n",
      "Epoch 829/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2885 - val_loss: 1.3587\n",
      "Epoch 830/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2843 - val_loss: 1.2988\n",
      "Epoch 831/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2915 - val_loss: 1.3356\n",
      "Epoch 832/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2820 - val_loss: 1.3655\n",
      "Epoch 833/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2825 - val_loss: 1.3420\n",
      "Epoch 834/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2914 - val_loss: 1.2926\n",
      "Epoch 835/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2887 - val_loss: 1.3856\n",
      "Epoch 836/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2811 - val_loss: 1.2999\n",
      "Epoch 837/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2751 - val_loss: 1.3069\n",
      "Epoch 838/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2808 - val_loss: 1.4027\n",
      "Epoch 839/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2809 - val_loss: 1.3145\n",
      "Epoch 840/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2806 - val_loss: 1.3473\n",
      "Epoch 841/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2794 - val_loss: 1.3351\n",
      "Epoch 842/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2808 - val_loss: 1.3990\n",
      "Epoch 843/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2764 - val_loss: 1.3229\n",
      "Epoch 844/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2811 - val_loss: 1.4319\n",
      "Epoch 845/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2790 - val_loss: 1.3575\n",
      "Epoch 846/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2852 - val_loss: 1.3007\n",
      "Epoch 847/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2850 - val_loss: 1.3834\n",
      "Epoch 848/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2940 - val_loss: 1.3395\n",
      "Epoch 849/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2736 - val_loss: 1.3688\n",
      "Epoch 850/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2849 - val_loss: 1.3608\n",
      "Epoch 851/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2813 - val_loss: 1.3104\n",
      "Epoch 852/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2847 - val_loss: 1.4638\n",
      "Epoch 853/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2928 - val_loss: 1.3775\n",
      "Epoch 854/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2725 - val_loss: 1.3728\n",
      "Epoch 855/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2872 - val_loss: 1.3988\n",
      "Epoch 856/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2903 - val_loss: 1.3738\n",
      "Epoch 857/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2800 - val_loss: 1.3420\n",
      "Epoch 858/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2823 - val_loss: 1.3170\n",
      "Epoch 859/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2833 - val_loss: 1.3376\n",
      "Epoch 860/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2793 - val_loss: 1.3368\n",
      "Epoch 861/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2785 - val_loss: 1.3923\n",
      "Epoch 862/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2887 - val_loss: 1.3664\n",
      "Epoch 863/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2856 - val_loss: 1.3703\n",
      "Epoch 864/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2740 - val_loss: 1.3522\n",
      "Epoch 865/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2822 - val_loss: 1.2962\n",
      "Epoch 866/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2768 - val_loss: 1.3361\n",
      "Epoch 867/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2789 - val_loss: 1.4413\n",
      "Epoch 868/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2779 - val_loss: 1.3127\n",
      "Epoch 869/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2773 - val_loss: 1.2906\n",
      "Epoch 870/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2741 - val_loss: 1.3711\n",
      "Epoch 871/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2808 - val_loss: 1.4531\n",
      "Epoch 872/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2753 - val_loss: 1.3011\n",
      "Epoch 873/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2740 - val_loss: 1.3149\n",
      "Epoch 874/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2804 - val_loss: 1.3388\n",
      "Epoch 875/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2749 - val_loss: 1.3795\n",
      "Epoch 876/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2875 - val_loss: 1.3498\n",
      "Epoch 877/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2749 - val_loss: 1.3325\n",
      "Epoch 878/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2740 - val_loss: 1.3520\n",
      "Epoch 879/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2778 - val_loss: 1.3208\n",
      "Epoch 880/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2835 - val_loss: 1.3131\n",
      "Epoch 881/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2871 - val_loss: 1.3013\n",
      "Epoch 882/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2705 - val_loss: 1.3189\n",
      "Epoch 883/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2777 - val_loss: 1.2973\n",
      "Epoch 884/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2814 - val_loss: 1.2982\n",
      "Epoch 885/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2777 - val_loss: 1.3894\n",
      "Epoch 886/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2759 - val_loss: 1.3530\n",
      "Epoch 887/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2771 - val_loss: 1.3446\n",
      "Epoch 888/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2804 - val_loss: 1.3340\n",
      "Epoch 889/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2811 - val_loss: 1.3099\n",
      "Epoch 890/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2662 - val_loss: 1.3261\n",
      "Epoch 891/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2796 - val_loss: 1.3368\n",
      "Epoch 892/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2761 - val_loss: 1.2913\n",
      "Epoch 893/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2834 - val_loss: 1.3547\n",
      "Epoch 894/900\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 1.2694 - val_loss: 1.3112\n",
      "Epoch 895/900\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 1.2746 - val_loss: 1.3545\n",
      "Epoch 896/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2791 - val_loss: 1.3261\n",
      "Epoch 897/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2698 - val_loss: 1.2940\n",
      "Epoch 898/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2699 - val_loss: 1.3292\n",
      "Epoch 899/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2790 - val_loss: 1.3424\n",
      "Epoch 900/900\n",
      "576/576 [==============================] - 3s 6ms/step - loss: 1.2769 - val_loss: 1.3048\n",
      "1.3047996598503457\n",
      "0.9747511190063081\n",
      "Epoch 1/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 8.5471 - val_loss: 4.8310\n",
      "Epoch 2/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 5.0308 - val_loss: 4.4786\n",
      "Epoch 3/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 4.7528 - val_loss: 3.9486\n",
      "Epoch 4/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 4.9473 - val_loss: 4.2818\n",
      "Epoch 5/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 4.4339 - val_loss: 5.2638\n",
      "Epoch 6/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 4.3749 - val_loss: 3.8495\n",
      "Epoch 7/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 4.1608 - val_loss: 3.8314\n",
      "Epoch 8/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 4.1330 - val_loss: 6.8831\n",
      "Epoch 9/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 3.8616 - val_loss: 3.7737\n",
      "Epoch 10/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 3.7068 - val_loss: 3.3249\n",
      "Epoch 11/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 3.5575 - val_loss: 3.1413\n",
      "Epoch 12/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 3.3791 - val_loss: 3.0078\n",
      "Epoch 13/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 3.1919 - val_loss: 3.6405\n",
      "Epoch 14/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 3.1381 - val_loss: 3.0071\n",
      "Epoch 15/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 3.1205 - val_loss: 3.1264\n",
      "Epoch 16/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 3.0498 - val_loss: 2.8014\n",
      "Epoch 17/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.9338 - val_loss: 3.0085\n",
      "Epoch 18/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.8863 - val_loss: 3.0881\n",
      "Epoch 19/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.7815 - val_loss: 2.8742\n",
      "Epoch 20/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.7338 - val_loss: 2.7711\n",
      "Epoch 21/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.6610 - val_loss: 2.6215\n",
      "Epoch 22/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.6493 - val_loss: 2.7328\n",
      "Epoch 23/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.5749 - val_loss: 2.4665\n",
      "Epoch 24/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.5364 - val_loss: 2.4092\n",
      "Epoch 25/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.4708 - val_loss: 2.4385\n",
      "Epoch 26/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.4976 - val_loss: 2.3945\n",
      "Epoch 27/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.4341 - val_loss: 2.3854\n",
      "Epoch 28/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.4313 - val_loss: 2.5869\n",
      "Epoch 29/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.3977 - val_loss: 3.1115\n",
      "Epoch 30/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.4081 - val_loss: 2.8130\n",
      "Epoch 31/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.3637 - val_loss: 2.2956\n",
      "Epoch 32/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.3606 - val_loss: 2.2136\n",
      "Epoch 33/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.3302 - val_loss: 2.3576\n",
      "Epoch 34/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.2952 - val_loss: 2.3699\n",
      "Epoch 35/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.2633 - val_loss: 2.2993\n",
      "Epoch 36/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.2371 - val_loss: 2.4797\n",
      "Epoch 37/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.2376 - val_loss: 2.2553\n",
      "Epoch 38/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.2580 - val_loss: 2.2407\n",
      "Epoch 39/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.1845 - val_loss: 2.1479\n",
      "Epoch 40/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.2273 - val_loss: 2.1366\n",
      "Epoch 41/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.1607 - val_loss: 2.1183\n",
      "Epoch 42/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.1406 - val_loss: 2.0817\n",
      "Epoch 43/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.1377 - val_loss: 2.0080\n",
      "Epoch 44/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.1195 - val_loss: 2.0863\n",
      "Epoch 45/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.1070 - val_loss: 2.0312\n",
      "Epoch 46/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.0873 - val_loss: 1.9958\n",
      "Epoch 47/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0978 - val_loss: 2.0890\n",
      "Epoch 48/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.0888 - val_loss: 2.1726\n",
      "Epoch 49/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0615 - val_loss: 2.0875\n",
      "Epoch 50/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.0561 - val_loss: 2.3762\n",
      "Epoch 51/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.0619 - val_loss: 2.0675\n",
      "Epoch 52/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 2.0482 - val_loss: 2.0677\n",
      "Epoch 53/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0349 - val_loss: 2.2161\n",
      "Epoch 54/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.0332 - val_loss: 2.0521\n",
      "Epoch 55/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 2.0294 - val_loss: 2.0424\n",
      "Epoch 56/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0090 - val_loss: 1.9578\n",
      "Epoch 57/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 2.0079 - val_loss: 2.0152\n",
      "Epoch 58/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9834 - val_loss: 1.9959\n",
      "Epoch 59/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9789 - val_loss: 2.0528\n",
      "Epoch 60/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9626 - val_loss: 1.9662\n",
      "Epoch 61/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9787 - val_loss: 1.8944\n",
      "Epoch 62/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9516 - val_loss: 1.9082\n",
      "Epoch 63/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9661 - val_loss: 1.9779\n",
      "Epoch 64/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9444 - val_loss: 1.9349\n",
      "Epoch 65/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.9213 - val_loss: 1.9010\n",
      "Epoch 66/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9338 - val_loss: 1.9321\n",
      "Epoch 67/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9211 - val_loss: 1.8779\n",
      "Epoch 68/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.9050 - val_loss: 1.9376\n",
      "Epoch 69/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.9212 - val_loss: 1.9270\n",
      "Epoch 70/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8857 - val_loss: 2.1898\n",
      "Epoch 71/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8964 - val_loss: 1.8537\n",
      "Epoch 72/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.8899 - val_loss: 1.9295\n",
      "Epoch 73/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8680 - val_loss: 1.8858\n",
      "Epoch 74/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8775 - val_loss: 1.8853\n",
      "Epoch 75/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8577 - val_loss: 1.8313\n",
      "Epoch 76/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8501 - val_loss: 1.8927\n",
      "Epoch 77/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8507 - val_loss: 2.0181\n",
      "Epoch 78/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8356 - val_loss: 1.8693\n",
      "Epoch 79/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8322 - val_loss: 1.8575\n",
      "Epoch 80/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8509 - val_loss: 1.8441\n",
      "Epoch 81/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8249 - val_loss: 1.8498\n",
      "Epoch 82/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8480 - val_loss: 1.7609\n",
      "Epoch 83/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8186 - val_loss: 1.8004\n",
      "Epoch 84/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7901 - val_loss: 1.8099\n",
      "Epoch 85/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8176 - val_loss: 1.8466\n",
      "Epoch 86/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.8024 - val_loss: 1.7744\n",
      "Epoch 87/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.8003 - val_loss: 1.7408\n",
      "Epoch 88/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7802 - val_loss: 1.7732\n",
      "Epoch 89/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7796 - val_loss: 1.9128\n",
      "Epoch 90/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7925 - val_loss: 1.8054\n",
      "Epoch 91/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7789 - val_loss: 1.7409\n",
      "Epoch 92/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7710 - val_loss: 1.7749\n",
      "Epoch 93/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7747 - val_loss: 1.7224\n",
      "Epoch 94/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7608 - val_loss: 1.8097\n",
      "Epoch 95/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7448 - val_loss: 1.7514\n",
      "Epoch 96/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7554 - val_loss: 1.7280\n",
      "Epoch 97/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7516 - val_loss: 1.9157\n",
      "Epoch 98/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7485 - val_loss: 1.6897\n",
      "Epoch 99/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7389 - val_loss: 1.7528\n",
      "Epoch 100/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7320 - val_loss: 1.7359\n",
      "Epoch 101/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7239 - val_loss: 1.7589\n",
      "Epoch 102/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7312 - val_loss: 1.6900\n",
      "Epoch 103/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7336 - val_loss: 1.8276\n",
      "Epoch 104/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7430 - val_loss: 1.7828\n",
      "Epoch 105/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7088 - val_loss: 1.7329\n",
      "Epoch 106/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7106 - val_loss: 1.7794\n",
      "Epoch 107/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7218 - val_loss: 1.7349\n",
      "Epoch 108/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7060 - val_loss: 1.6790\n",
      "Epoch 109/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6968 - val_loss: 1.7040\n",
      "Epoch 110/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.7088 - val_loss: 1.6950\n",
      "Epoch 111/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.7171 - val_loss: 1.7182\n",
      "Epoch 112/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.6826 - val_loss: 1.6712\n",
      "Epoch 113/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6889 - val_loss: 1.6783\n",
      "Epoch 114/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.7001 - val_loss: 1.7000\n",
      "Epoch 115/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6835 - val_loss: 1.7168\n",
      "Epoch 116/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6763 - val_loss: 1.6657\n",
      "Epoch 117/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6816 - val_loss: 1.6277\n",
      "Epoch 118/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6758 - val_loss: 1.6814\n",
      "Epoch 119/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6771 - val_loss: 1.6648\n",
      "Epoch 120/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6720 - val_loss: 1.7733\n",
      "Epoch 121/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6937 - val_loss: 1.6307\n",
      "Epoch 122/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6786 - val_loss: 1.7412\n",
      "Epoch 123/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6659 - val_loss: 1.6460\n",
      "Epoch 124/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6627 - val_loss: 1.6742\n",
      "Epoch 125/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6646 - val_loss: 1.7131\n",
      "Epoch 126/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6711 - val_loss: 1.7352\n",
      "Epoch 127/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6591 - val_loss: 1.6550\n",
      "Epoch 128/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6595 - val_loss: 1.6824\n",
      "Epoch 129/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6545 - val_loss: 1.7634\n",
      "Epoch 130/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6391 - val_loss: 1.6440\n",
      "Epoch 131/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.6372 - val_loss: 1.6110\n",
      "Epoch 132/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.6382 - val_loss: 1.6804\n",
      "Epoch 133/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6374 - val_loss: 1.6231\n",
      "Epoch 134/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6256 - val_loss: 1.7231\n",
      "Epoch 135/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6416 - val_loss: 1.6185\n",
      "Epoch 136/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6232 - val_loss: 1.7036\n",
      "Epoch 137/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6205 - val_loss: 1.6084\n",
      "Epoch 138/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6286 - val_loss: 1.6415\n",
      "Epoch 139/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6099 - val_loss: 1.6298\n",
      "Epoch 140/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6078 - val_loss: 1.5892\n",
      "Epoch 141/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6289 - val_loss: 1.6792\n",
      "Epoch 142/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6185 - val_loss: 1.6506\n",
      "Epoch 143/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.6220 - val_loss: 1.6053\n",
      "Epoch 144/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6176 - val_loss: 1.6792\n",
      "Epoch 145/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6139 - val_loss: 1.5618\n",
      "Epoch 146/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5960 - val_loss: 1.5488\n",
      "Epoch 147/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6076 - val_loss: 1.5841\n",
      "Epoch 148/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.6079 - val_loss: 1.6087\n",
      "Epoch 149/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5901 - val_loss: 1.6536\n",
      "Epoch 150/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5987 - val_loss: 1.6341\n",
      "Epoch 151/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5939 - val_loss: 1.6320\n",
      "Epoch 152/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.6156 - val_loss: 1.6990\n",
      "Epoch 153/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5970 - val_loss: 1.5666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5976 - val_loss: 1.5769\n",
      "Epoch 155/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5887 - val_loss: 1.7976\n",
      "Epoch 156/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5989 - val_loss: 1.6269\n",
      "Epoch 157/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5822 - val_loss: 1.6103\n",
      "Epoch 158/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.6007 - val_loss: 1.6191\n",
      "Epoch 159/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5839 - val_loss: 1.5904\n",
      "Epoch 160/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5695 - val_loss: 1.5690\n",
      "Epoch 161/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5767 - val_loss: 1.6264\n",
      "Epoch 162/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5791 - val_loss: 1.5874\n",
      "Epoch 163/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5698 - val_loss: 1.6847\n",
      "Epoch 164/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5745 - val_loss: 1.6006\n",
      "Epoch 165/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5775 - val_loss: 1.6331\n",
      "Epoch 166/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5643 - val_loss: 1.6176\n",
      "Epoch 167/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5638 - val_loss: 1.6610\n",
      "Epoch 168/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5592 - val_loss: 1.5700\n",
      "Epoch 169/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5694 - val_loss: 1.5841\n",
      "Epoch 170/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5490 - val_loss: 1.6501\n",
      "Epoch 171/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5540 - val_loss: 1.5640\n",
      "Epoch 172/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.5545 - val_loss: 1.5938\n",
      "Epoch 173/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5647 - val_loss: 1.5383\n",
      "Epoch 174/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5653 - val_loss: 1.5643\n",
      "Epoch 175/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5571 - val_loss: 1.6069\n",
      "Epoch 176/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5355 - val_loss: 1.5331\n",
      "Epoch 177/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5454 - val_loss: 1.5720\n",
      "Epoch 178/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5470 - val_loss: 1.5489\n",
      "Epoch 179/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5309 - val_loss: 1.5460\n",
      "Epoch 180/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5542 - val_loss: 1.5523\n",
      "Epoch 181/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5355 - val_loss: 1.6124\n",
      "Epoch 182/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5343 - val_loss: 1.6614\n",
      "Epoch 183/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5479 - val_loss: 1.5758\n",
      "Epoch 184/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5320 - val_loss: 1.5321\n",
      "Epoch 185/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5296 - val_loss: 1.5304\n",
      "Epoch 186/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5286 - val_loss: 1.6337\n",
      "Epoch 187/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5375 - val_loss: 1.5719\n",
      "Epoch 188/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5446 - val_loss: 1.6060\n",
      "Epoch 189/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5263 - val_loss: 1.5800\n",
      "Epoch 190/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5283 - val_loss: 1.5093\n",
      "Epoch 191/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5385 - val_loss: 1.5573\n",
      "Epoch 192/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5392 - val_loss: 1.5221\n",
      "Epoch 193/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5076 - val_loss: 1.6438\n",
      "Epoch 194/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5084 - val_loss: 1.5908\n",
      "Epoch 195/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5147 - val_loss: 1.5539\n",
      "Epoch 196/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5238 - val_loss: 1.5252\n",
      "Epoch 197/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5138 - val_loss: 1.5035\n",
      "Epoch 198/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5184 - val_loss: 1.6155\n",
      "Epoch 199/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5178 - val_loss: 1.4914\n",
      "Epoch 200/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5200 - val_loss: 1.4947\n",
      "Epoch 201/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5070 - val_loss: 1.5400\n",
      "Epoch 202/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4972 - val_loss: 1.5705\n",
      "Epoch 203/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4947 - val_loss: 1.5611\n",
      "Epoch 204/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5070 - val_loss: 1.5364\n",
      "Epoch 205/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.5084 - val_loss: 1.6641\n",
      "Epoch 206/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5222 - val_loss: 1.5537\n",
      "Epoch 207/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4913 - val_loss: 1.5140\n",
      "Epoch 208/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4926 - val_loss: 1.4715\n",
      "Epoch 209/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4886 - val_loss: 1.5830\n",
      "Epoch 210/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.5021 - val_loss: 1.5470\n",
      "Epoch 211/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5075 - val_loss: 1.5294\n",
      "Epoch 212/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.5090 - val_loss: 1.6248\n",
      "Epoch 213/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4890 - val_loss: 1.5552\n",
      "Epoch 214/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4874 - val_loss: 1.4897\n",
      "Epoch 215/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4945 - val_loss: 1.5007\n",
      "Epoch 216/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4872 - val_loss: 1.4668\n",
      "Epoch 217/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4878 - val_loss: 1.5164\n",
      "Epoch 218/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4902 - val_loss: 1.5225\n",
      "Epoch 219/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4828 - val_loss: 1.5076\n",
      "Epoch 220/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4771 - val_loss: 1.4985\n",
      "Epoch 221/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4866 - val_loss: 1.5326\n",
      "Epoch 222/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4843 - val_loss: 1.5948\n",
      "Epoch 223/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4827 - val_loss: 1.5007\n",
      "Epoch 224/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4848 - val_loss: 1.4908\n",
      "Epoch 225/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4905 - val_loss: 1.5208\n",
      "Epoch 226/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4749 - val_loss: 1.5134\n",
      "Epoch 227/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4673 - val_loss: 1.4517\n",
      "Epoch 228/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4885 - val_loss: 1.5050\n",
      "Epoch 229/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4667 - val_loss: 1.5167\n",
      "Epoch 230/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4734 - val_loss: 1.4620\n",
      "Epoch 231/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4600 - val_loss: 1.5149\n",
      "Epoch 232/900\n",
      "432/432 [==============================] - 4s 10ms/step - loss: 1.4896 - val_loss: 1.5007\n",
      "Epoch 233/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4772 - val_loss: 1.5380\n",
      "Epoch 234/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4687 - val_loss: 1.5756\n",
      "Epoch 235/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4540 - val_loss: 1.5190\n",
      "Epoch 236/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4777 - val_loss: 1.4933\n",
      "Epoch 237/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4744 - val_loss: 1.4953\n",
      "Epoch 238/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4759 - val_loss: 1.4878\n",
      "Epoch 239/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4631 - val_loss: 1.4626\n",
      "Epoch 240/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4584 - val_loss: 1.5105\n",
      "Epoch 241/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4632 - val_loss: 1.4945\n",
      "Epoch 242/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4674 - val_loss: 1.5436\n",
      "Epoch 243/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4650 - val_loss: 1.5471\n",
      "Epoch 244/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4600 - val_loss: 1.4639\n",
      "Epoch 245/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4639 - val_loss: 1.4828\n",
      "Epoch 246/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4542 - val_loss: 1.5938\n",
      "Epoch 247/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4528 - val_loss: 1.4601\n",
      "Epoch 248/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4406 - val_loss: 1.5530\n",
      "Epoch 249/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4532 - val_loss: 1.4813\n",
      "Epoch 250/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4731 - val_loss: 1.4703\n",
      "Epoch 251/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4546 - val_loss: 1.5229\n",
      "Epoch 252/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4556 - val_loss: 1.5332\n",
      "Epoch 253/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4511 - val_loss: 1.5128\n",
      "Epoch 254/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4547 - val_loss: 1.4621\n",
      "Epoch 255/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4563 - val_loss: 1.4309\n",
      "Epoch 256/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4494 - val_loss: 1.4727\n",
      "Epoch 257/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4446 - val_loss: 1.4377\n",
      "Epoch 258/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4623 - val_loss: 1.5248\n",
      "Epoch 259/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4508 - val_loss: 1.5054\n",
      "Epoch 260/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4566 - val_loss: 1.4658\n",
      "Epoch 261/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4413 - val_loss: 1.4563\n",
      "Epoch 262/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4454 - val_loss: 1.4409\n",
      "Epoch 263/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4400 - val_loss: 1.4141\n",
      "Epoch 264/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4495 - val_loss: 1.4907\n",
      "Epoch 265/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4405 - val_loss: 1.6370\n",
      "Epoch 266/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4482 - val_loss: 1.4993\n",
      "Epoch 267/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4326 - val_loss: 1.5280\n",
      "Epoch 268/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4534 - val_loss: 1.4328\n",
      "Epoch 269/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4433 - val_loss: 1.4995\n",
      "Epoch 270/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4456 - val_loss: 1.5096\n",
      "Epoch 271/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4273 - val_loss: 1.4273\n",
      "Epoch 272/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4385 - val_loss: 1.4468\n",
      "Epoch 273/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4402 - val_loss: 1.4527\n",
      "Epoch 274/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4307 - val_loss: 1.4784\n",
      "Epoch 275/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4283 - val_loss: 1.5138\n",
      "Epoch 276/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4353 - val_loss: 1.4439\n",
      "Epoch 277/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4278 - val_loss: 1.4331\n",
      "Epoch 278/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4282 - val_loss: 1.5252\n",
      "Epoch 279/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4390 - val_loss: 1.4537\n",
      "Epoch 280/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4286 - val_loss: 1.5089\n",
      "Epoch 281/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4322 - val_loss: 1.4634\n",
      "Epoch 282/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4287 - val_loss: 1.4933\n",
      "Epoch 283/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4191 - val_loss: 1.5232\n",
      "Epoch 284/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4336 - val_loss: 1.4651\n",
      "Epoch 285/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4292 - val_loss: 1.4763\n",
      "Epoch 286/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4294 - val_loss: 1.4767\n",
      "Epoch 287/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4222 - val_loss: 1.4585\n",
      "Epoch 288/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4189 - val_loss: 1.4567\n",
      "Epoch 289/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4203 - val_loss: 1.5650\n",
      "Epoch 290/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4186 - val_loss: 1.4745\n",
      "Epoch 291/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4226 - val_loss: 1.5058\n",
      "Epoch 292/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4218 - val_loss: 1.4460\n",
      "Epoch 293/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4198 - val_loss: 1.4440\n",
      "Epoch 294/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4237 - val_loss: 1.4308\n",
      "Epoch 295/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4144 - val_loss: 1.4587\n",
      "Epoch 296/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4280 - val_loss: 1.4567\n",
      "Epoch 297/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4153 - val_loss: 1.4241\n",
      "Epoch 298/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4187 - val_loss: 1.4518\n",
      "Epoch 299/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4133 - val_loss: 1.4295\n",
      "Epoch 300/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4150 - val_loss: 1.4932\n",
      "Epoch 301/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4208 - val_loss: 1.4624\n",
      "Epoch 302/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4192 - val_loss: 1.3967\n",
      "Epoch 303/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4073 - val_loss: 1.4445\n",
      "Epoch 304/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4025 - val_loss: 1.4163\n",
      "Epoch 305/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4003 - val_loss: 1.4501\n",
      "Epoch 306/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4041 - val_loss: 1.4293\n",
      "Epoch 307/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4049 - val_loss: 1.4563\n",
      "Epoch 308/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4189 - val_loss: 1.3959\n",
      "Epoch 309/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4096 - val_loss: 1.4235\n",
      "Epoch 310/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3893 - val_loss: 1.4141\n",
      "Epoch 311/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.4162 - val_loss: 1.5013\n",
      "Epoch 312/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 4s 10ms/step - loss: 1.3964 - val_loss: 1.4291\n",
      "Epoch 313/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4129 - val_loss: 1.5024\n",
      "Epoch 314/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4074 - val_loss: 1.4258\n",
      "Epoch 315/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3967 - val_loss: 1.4444\n",
      "Epoch 316/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4127 - val_loss: 1.4543\n",
      "Epoch 317/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3918 - val_loss: 1.4101\n",
      "Epoch 318/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3947 - val_loss: 1.4178\n",
      "Epoch 319/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3939 - val_loss: 1.4194\n",
      "Epoch 320/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4024 - val_loss: 1.4757\n",
      "Epoch 321/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3938 - val_loss: 1.4741\n",
      "Epoch 322/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4077 - val_loss: 1.4773\n",
      "Epoch 323/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3867 - val_loss: 1.4769\n",
      "Epoch 324/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3898 - val_loss: 1.4471\n",
      "Epoch 325/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4127 - val_loss: 1.4220\n",
      "Epoch 326/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3901 - val_loss: 1.4474\n",
      "Epoch 327/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.4007 - val_loss: 1.4600\n",
      "Epoch 328/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3992 - val_loss: 1.4324\n",
      "Epoch 329/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3982 - val_loss: 1.4325\n",
      "Epoch 330/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3964 - val_loss: 1.5632\n",
      "Epoch 331/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4021 - val_loss: 1.4256\n",
      "Epoch 332/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.4010 - val_loss: 1.4642\n",
      "Epoch 333/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3932 - val_loss: 1.4577\n",
      "Epoch 334/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3932 - val_loss: 1.4334\n",
      "Epoch 335/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3845 - val_loss: 1.4203\n",
      "Epoch 336/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3938 - val_loss: 1.3944\n",
      "Epoch 337/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3951 - val_loss: 1.3833\n",
      "Epoch 338/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3974 - val_loss: 1.3990\n",
      "Epoch 339/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3867 - val_loss: 1.3999\n",
      "Epoch 340/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.4040 - val_loss: 1.4275\n",
      "Epoch 341/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3848 - val_loss: 1.5325\n",
      "Epoch 342/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3886 - val_loss: 1.4751\n",
      "Epoch 343/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3815 - val_loss: 1.4130\n",
      "Epoch 344/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3923 - val_loss: 1.4594\n",
      "Epoch 345/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3913 - val_loss: 1.4383\n",
      "Epoch 346/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3914 - val_loss: 1.3839\n",
      "Epoch 347/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3855 - val_loss: 1.4117\n",
      "Epoch 348/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3809 - val_loss: 1.4866\n",
      "Epoch 349/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3884 - val_loss: 1.4381\n",
      "Epoch 350/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3739 - val_loss: 1.4325\n",
      "Epoch 351/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3742 - val_loss: 1.4326\n",
      "Epoch 352/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3700 - val_loss: 1.4779\n",
      "Epoch 353/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3786 - val_loss: 1.5319\n",
      "Epoch 354/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3836 - val_loss: 1.4433\n",
      "Epoch 355/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3777 - val_loss: 1.3707\n",
      "Epoch 356/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3829 - val_loss: 1.4497\n",
      "Epoch 357/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3822 - val_loss: 1.4548\n",
      "Epoch 358/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3843 - val_loss: 1.3910\n",
      "Epoch 359/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3823 - val_loss: 1.4333\n",
      "Epoch 360/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3882 - val_loss: 1.3907\n",
      "Epoch 361/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3757 - val_loss: 1.4103\n",
      "Epoch 362/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3757 - val_loss: 1.4882\n",
      "Epoch 363/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3705 - val_loss: 1.4237\n",
      "Epoch 364/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3729 - val_loss: 1.3949\n",
      "Epoch 365/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3791 - val_loss: 1.3836\n",
      "Epoch 366/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3751 - val_loss: 1.4049\n",
      "Epoch 367/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3801 - val_loss: 1.4353\n",
      "Epoch 368/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3641 - val_loss: 1.4200\n",
      "Epoch 369/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3703 - val_loss: 1.4120\n",
      "Epoch 370/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3755 - val_loss: 1.4297\n",
      "Epoch 371/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3726 - val_loss: 1.3939\n",
      "Epoch 372/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3692 - val_loss: 1.4342\n",
      "Epoch 373/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3746 - val_loss: 1.5574\n",
      "Epoch 374/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3743 - val_loss: 1.3966\n",
      "Epoch 375/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3647 - val_loss: 1.3862\n",
      "Epoch 376/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3501 - val_loss: 1.3823\n",
      "Epoch 377/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3689 - val_loss: 1.5422\n",
      "Epoch 378/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3640 - val_loss: 1.3855\n",
      "Epoch 379/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3593 - val_loss: 1.3865\n",
      "Epoch 380/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3690 - val_loss: 1.3626\n",
      "Epoch 381/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3594 - val_loss: 1.4963\n",
      "Epoch 382/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3713 - val_loss: 1.3816\n",
      "Epoch 383/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3668 - val_loss: 1.3577\n",
      "Epoch 384/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3605 - val_loss: 1.5332\n",
      "Epoch 385/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3575 - val_loss: 1.3865\n",
      "Epoch 386/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3650 - val_loss: 1.4480\n",
      "Epoch 387/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3665 - val_loss: 1.3695\n",
      "Epoch 388/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3665 - val_loss: 1.5118\n",
      "Epoch 389/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3662 - val_loss: 1.4231\n",
      "Epoch 390/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3613 - val_loss: 1.4158\n",
      "Epoch 391/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3564 - val_loss: 1.4068\n",
      "Epoch 392/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3610 - val_loss: 1.4199\n",
      "Epoch 393/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3725 - val_loss: 1.4078\n",
      "Epoch 394/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3607 - val_loss: 1.3823\n",
      "Epoch 395/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3520 - val_loss: 1.3891\n",
      "Epoch 396/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3740 - val_loss: 1.4440\n",
      "Epoch 397/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3589 - val_loss: 1.3987\n",
      "Epoch 398/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3588 - val_loss: 1.4174\n",
      "Epoch 399/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3545 - val_loss: 1.4060\n",
      "Epoch 400/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3496 - val_loss: 1.4361\n",
      "Epoch 401/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3583 - val_loss: 1.5689\n",
      "Epoch 402/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3502 - val_loss: 1.4623\n",
      "Epoch 403/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3546 - val_loss: 1.3949\n",
      "Epoch 404/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3615 - val_loss: 1.4117\n",
      "Epoch 405/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3613 - val_loss: 1.3841\n",
      "Epoch 406/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3561 - val_loss: 1.3854\n",
      "Epoch 407/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3567 - val_loss: 1.4523\n",
      "Epoch 408/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3620 - val_loss: 1.4244\n",
      "Epoch 409/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3564 - val_loss: 1.3994\n",
      "Epoch 410/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3522 - val_loss: 1.4826\n",
      "Epoch 411/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3615 - val_loss: 1.3794\n",
      "Epoch 412/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3544 - val_loss: 1.4122\n",
      "Epoch 413/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3425 - val_loss: 1.4180\n",
      "Epoch 414/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3597 - val_loss: 1.3497\n",
      "Epoch 415/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3559 - val_loss: 1.4618\n",
      "Epoch 416/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3591 - val_loss: 1.4233\n",
      "Epoch 417/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3418 - val_loss: 1.4273\n",
      "Epoch 418/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3511 - val_loss: 1.3894\n",
      "Epoch 419/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3521 - val_loss: 1.3987\n",
      "Epoch 420/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3427 - val_loss: 1.4254\n",
      "Epoch 421/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3588 - val_loss: 1.4191\n",
      "Epoch 422/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3537 - val_loss: 1.4447\n",
      "Epoch 423/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3437 - val_loss: 1.3672\n",
      "Epoch 424/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3450 - val_loss: 1.3617\n",
      "Epoch 425/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3476 - val_loss: 1.4134\n",
      "Epoch 426/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3497 - val_loss: 1.3471\n",
      "Epoch 427/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3339 - val_loss: 1.4569\n",
      "Epoch 428/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3530 - val_loss: 1.4105\n",
      "Epoch 429/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3448 - val_loss: 1.4597\n",
      "Epoch 430/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3535 - val_loss: 1.3731\n",
      "Epoch 431/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3341 - val_loss: 1.3687\n",
      "Epoch 432/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3449 - val_loss: 1.3859\n",
      "Epoch 433/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3364 - val_loss: 1.3897\n",
      "Epoch 434/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3438 - val_loss: 1.4216\n",
      "Epoch 435/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3416 - val_loss: 1.3863\n",
      "Epoch 436/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3576 - val_loss: 1.5981\n",
      "Epoch 437/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3374 - val_loss: 1.3586\n",
      "Epoch 438/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3475 - val_loss: 1.3665\n",
      "Epoch 439/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3400 - val_loss: 1.3626\n",
      "Epoch 440/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3414 - val_loss: 1.4452\n",
      "Epoch 441/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3547 - val_loss: 1.3692\n",
      "Epoch 442/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3408 - val_loss: 1.3696\n",
      "Epoch 443/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3404 - val_loss: 1.4122\n",
      "Epoch 444/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3338 - val_loss: 1.4465\n",
      "Epoch 445/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3292 - val_loss: 1.4128\n",
      "Epoch 446/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3299 - val_loss: 1.3659\n",
      "Epoch 447/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3270 - val_loss: 1.4058\n",
      "Epoch 448/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3302 - val_loss: 1.4140\n",
      "Epoch 449/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3445 - val_loss: 1.3913\n",
      "Epoch 450/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3423 - val_loss: 1.3778\n",
      "Epoch 451/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3228 - val_loss: 1.3730\n",
      "Epoch 452/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3295 - val_loss: 1.3679\n",
      "Epoch 453/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3365 - val_loss: 1.3866\n",
      "Epoch 454/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3246 - val_loss: 1.4046\n",
      "Epoch 455/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3470 - val_loss: 1.3678\n",
      "Epoch 456/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3250 - val_loss: 1.4078\n",
      "Epoch 457/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3316 - val_loss: 1.3647\n",
      "Epoch 458/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3347 - val_loss: 1.3633\n",
      "Epoch 459/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3250 - val_loss: 1.3608\n",
      "Epoch 460/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3254 - val_loss: 1.5256\n",
      "Epoch 461/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3351 - val_loss: 1.3824\n",
      "Epoch 462/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3459 - val_loss: 1.4123\n",
      "Epoch 463/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3240 - val_loss: 1.3425\n",
      "Epoch 464/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3301 - val_loss: 1.3736\n",
      "Epoch 465/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3159 - val_loss: 1.3608\n",
      "Epoch 466/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3290 - val_loss: 1.3698\n",
      "Epoch 467/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3216 - val_loss: 1.3590\n",
      "Epoch 468/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3260 - val_loss: 1.3903\n",
      "Epoch 469/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3302 - val_loss: 1.3779\n",
      "Epoch 470/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3168 - val_loss: 1.4294\n",
      "Epoch 471/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3239 - val_loss: 1.4026\n",
      "Epoch 472/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3262 - val_loss: 1.3758\n",
      "Epoch 473/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3304 - val_loss: 1.4219\n",
      "Epoch 474/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3328 - val_loss: 1.4128\n",
      "Epoch 475/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3286 - val_loss: 1.3725\n",
      "Epoch 476/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3255 - val_loss: 1.3792\n",
      "Epoch 477/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3292 - val_loss: 1.3779\n",
      "Epoch 478/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3281 - val_loss: 1.4302\n",
      "Epoch 479/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3231 - val_loss: 1.3631\n",
      "Epoch 480/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3191 - val_loss: 1.3782\n",
      "Epoch 481/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3311 - val_loss: 1.3741\n",
      "Epoch 482/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3308 - val_loss: 1.3747\n",
      "Epoch 483/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3241 - val_loss: 1.3516\n",
      "Epoch 484/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3288 - val_loss: 1.3310\n",
      "Epoch 485/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3183 - val_loss: 1.3505\n",
      "Epoch 486/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3123 - val_loss: 1.3838\n",
      "Epoch 487/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3100 - val_loss: 1.3564\n",
      "Epoch 488/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3197 - val_loss: 1.3801\n",
      "Epoch 489/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3201 - val_loss: 1.3839\n",
      "Epoch 490/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3040 - val_loss: 1.3488\n",
      "Epoch 491/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3081 - val_loss: 1.4682\n",
      "Epoch 492/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3107 - val_loss: 1.3385\n",
      "Epoch 493/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3149 - val_loss: 1.3948\n",
      "Epoch 494/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3112 - val_loss: 1.3484\n",
      "Epoch 495/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3213 - val_loss: 1.4124\n",
      "Epoch 496/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3210 - val_loss: 1.3823\n",
      "Epoch 497/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3133 - val_loss: 1.3355\n",
      "Epoch 498/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3166 - val_loss: 1.3178\n",
      "Epoch 499/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3312 - val_loss: 1.4185\n",
      "Epoch 500/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3157 - val_loss: 1.3172\n",
      "Epoch 501/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3098 - val_loss: 1.3680\n",
      "Epoch 502/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3064 - val_loss: 1.3753\n",
      "Epoch 503/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3051 - val_loss: 1.3404\n",
      "Epoch 504/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3088 - val_loss: 1.3727\n",
      "Epoch 505/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3160 - val_loss: 1.3544\n",
      "Epoch 506/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3009 - val_loss: 1.3421\n",
      "Epoch 507/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3120 - val_loss: 1.3790\n",
      "Epoch 508/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3080 - val_loss: 1.3566\n",
      "Epoch 509/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3059 - val_loss: 1.4206\n",
      "Epoch 510/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3159 - val_loss: 1.3068\n",
      "Epoch 511/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.3076 - val_loss: 1.3562\n",
      "Epoch 512/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.3174 - val_loss: 1.3231\n",
      "Epoch 513/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3076 - val_loss: 1.3870\n",
      "Epoch 514/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3062 - val_loss: 1.3441\n",
      "Epoch 515/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3068 - val_loss: 1.3689\n",
      "Epoch 516/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3197 - val_loss: 1.3368\n",
      "Epoch 517/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3111 - val_loss: 1.3372\n",
      "Epoch 518/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2963 - val_loss: 1.3329\n",
      "Epoch 519/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3130 - val_loss: 1.3950\n",
      "Epoch 520/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3113 - val_loss: 1.3374\n",
      "Epoch 521/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3087 - val_loss: 1.3276\n",
      "Epoch 522/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3035 - val_loss: 1.3907\n",
      "Epoch 523/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2978 - val_loss: 1.3549\n",
      "Epoch 524/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3018 - val_loss: 1.4273\n",
      "Epoch 525/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2969 - val_loss: 1.3554\n",
      "Epoch 526/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3112 - val_loss: 1.3848\n",
      "Epoch 527/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3092 - val_loss: 1.3529\n",
      "Epoch 528/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3035 - val_loss: 1.3695\n",
      "Epoch 529/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3010 - val_loss: 1.3286\n",
      "Epoch 530/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2975 - val_loss: 1.4216\n",
      "Epoch 531/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3028 - val_loss: 1.3361\n",
      "Epoch 532/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2890 - val_loss: 1.3164\n",
      "Epoch 533/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3142 - val_loss: 1.3680\n",
      "Epoch 534/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3085 - val_loss: 1.3771\n",
      "Epoch 535/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2997 - val_loss: 1.3455\n",
      "Epoch 536/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3053 - val_loss: 1.3186\n",
      "Epoch 537/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2936 - val_loss: 1.3320\n",
      "Epoch 538/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3088 - val_loss: 1.3516\n",
      "Epoch 539/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2921 - val_loss: 1.3386\n",
      "Epoch 540/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2999 - val_loss: 1.3797\n",
      "Epoch 541/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2925 - val_loss: 1.3233\n",
      "Epoch 542/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2954 - val_loss: 1.3437\n",
      "Epoch 543/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3026 - val_loss: 1.3317\n",
      "Epoch 544/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2886 - val_loss: 1.3424\n",
      "Epoch 545/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3019 - val_loss: 1.2912\n",
      "Epoch 546/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2949 - val_loss: 1.3557\n",
      "Epoch 547/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2908 - val_loss: 1.3420\n",
      "Epoch 548/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2955 - val_loss: 1.3868\n",
      "Epoch 549/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2992 - val_loss: 1.3185\n",
      "Epoch 550/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2940 - val_loss: 1.3687\n",
      "Epoch 551/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2924 - val_loss: 1.3229\n",
      "Epoch 552/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2924 - val_loss: 1.3344\n",
      "Epoch 553/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.3000 - val_loss: 1.3529\n",
      "Epoch 554/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2970 - val_loss: 1.3334\n",
      "Epoch 555/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2958 - val_loss: 1.3435\n",
      "Epoch 556/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2897 - val_loss: 1.3430\n",
      "Epoch 557/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3042 - val_loss: 1.3300\n",
      "Epoch 558/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2984 - val_loss: 1.3210\n",
      "Epoch 559/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2925 - val_loss: 1.3148\n",
      "Epoch 560/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2958 - val_loss: 1.3648\n",
      "Epoch 561/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2939 - val_loss: 1.3467\n",
      "Epoch 562/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2958 - val_loss: 1.3778\n",
      "Epoch 563/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2914 - val_loss: 1.3147\n",
      "Epoch 564/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.3017 - val_loss: 1.3262\n",
      "Epoch 565/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2954 - val_loss: 1.3535\n",
      "Epoch 566/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2963 - val_loss: 1.3955\n",
      "Epoch 567/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2905 - val_loss: 1.3158\n",
      "Epoch 568/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2916 - val_loss: 1.3209\n",
      "Epoch 569/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2833 - val_loss: 1.3175\n",
      "Epoch 570/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2889 - val_loss: 1.3421\n",
      "Epoch 571/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2917 - val_loss: 1.2990\n",
      "Epoch 572/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2929 - val_loss: 1.3316\n",
      "Epoch 573/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2810 - val_loss: 1.4047\n",
      "Epoch 574/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2930 - val_loss: 1.3132\n",
      "Epoch 575/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2938 - val_loss: 1.3498\n",
      "Epoch 576/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2936 - val_loss: 1.3609\n",
      "Epoch 577/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2838 - val_loss: 1.3986\n",
      "Epoch 578/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2938 - val_loss: 1.3620\n",
      "Epoch 579/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2977 - val_loss: 1.3357\n",
      "Epoch 580/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2934 - val_loss: 1.3535\n",
      "Epoch 581/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2853 - val_loss: 1.3192\n",
      "Epoch 582/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2974 - val_loss: 1.3880\n",
      "Epoch 583/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2993 - val_loss: 1.2930\n",
      "Epoch 584/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2819 - val_loss: 1.4157\n",
      "Epoch 585/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2894 - val_loss: 1.3179\n",
      "Epoch 586/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2933 - val_loss: 1.3267\n",
      "Epoch 587/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2980 - val_loss: 1.3281\n",
      "Epoch 588/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2785 - val_loss: 1.3105\n",
      "Epoch 589/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2877 - val_loss: 1.3960\n",
      "Epoch 590/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2924 - val_loss: 1.3677\n",
      "Epoch 591/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2809 - val_loss: 1.3323\n",
      "Epoch 592/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2841 - val_loss: 1.3425\n",
      "Epoch 593/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2968 - val_loss: 1.4469\n",
      "Epoch 594/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2879 - val_loss: 1.3693\n",
      "Epoch 595/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2837 - val_loss: 1.3506\n",
      "Epoch 596/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2923 - val_loss: 1.3334\n",
      "Epoch 597/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2820 - val_loss: 1.2989\n",
      "Epoch 598/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2794 - val_loss: 1.3366\n",
      "Epoch 599/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2805 - val_loss: 1.3585\n",
      "Epoch 600/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2854 - val_loss: 1.3520\n",
      "Epoch 601/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2872 - val_loss: 1.3243\n",
      "Epoch 602/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2804 - val_loss: 1.2922\n",
      "Epoch 603/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2876 - val_loss: 1.3701\n",
      "Epoch 604/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2880 - val_loss: 1.3327\n",
      "Epoch 605/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2738 - val_loss: 1.3325\n",
      "Epoch 606/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2872 - val_loss: 1.3186\n",
      "Epoch 607/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2751 - val_loss: 1.3863\n",
      "Epoch 608/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2802 - val_loss: 1.3038\n",
      "Epoch 609/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2819 - val_loss: 1.3413\n",
      "Epoch 610/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2749 - val_loss: 1.3052\n",
      "Epoch 611/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2769 - val_loss: 1.3185\n",
      "Epoch 612/900\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 1.2824 - val_loss: 1.4085\n",
      "Epoch 613/900\n",
      "432/432 [==============================] - 4s 8ms/step - loss: 1.2877 - val_loss: 1.3371\n",
      "Epoch 614/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2708 - val_loss: 1.3459\n",
      "Epoch 615/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2801 - val_loss: 1.3759\n",
      "Epoch 616/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2736 - val_loss: 1.3342\n",
      "Epoch 617/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2784 - val_loss: 1.3070\n",
      "Epoch 618/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2875 - val_loss: 1.3417\n",
      "Epoch 619/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2711 - val_loss: 1.3080\n",
      "Epoch 620/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2705 - val_loss: 1.3345\n",
      "Epoch 621/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2848 - val_loss: 1.3097\n",
      "Epoch 622/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2699 - val_loss: 1.3044\n",
      "Epoch 623/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2712 - val_loss: 1.2843\n",
      "Epoch 624/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2864 - val_loss: 1.3863\n",
      "Epoch 625/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2775 - val_loss: 1.3434\n",
      "Epoch 626/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2736 - val_loss: 1.3274\n",
      "Epoch 627/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2836 - val_loss: 1.3286\n",
      "Epoch 628/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2728 - val_loss: 1.3166\n",
      "Epoch 629/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2715 - val_loss: 1.3012\n",
      "Epoch 630/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2719 - val_loss: 1.3447\n",
      "Epoch 631/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2791 - val_loss: 1.3634\n",
      "Epoch 632/900\n",
      "432/432 [==============================] - 4s 9ms/step - loss: 1.2791 - val_loss: 1.3276\n",
      "Epoch 633/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2756 - val_loss: 1.3402\n",
      "Epoch 634/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2700 - val_loss: 1.2977\n",
      "Epoch 635/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2771 - val_loss: 1.3209\n",
      "Epoch 636/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2813 - val_loss: 1.4207\n",
      "Epoch 637/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2821 - val_loss: 1.3303\n",
      "Epoch 638/900\n",
      "432/432 [==============================] - 3s 8ms/step - loss: 1.2720 - val_loss: 1.3168\n",
      "Epoch 639/900\n",
      "432/432 [==============================] - 3s 7ms/step - loss: 1.2703 - val_loss: 1.3157\n",
      "Epoch 640/900\n",
      "334/432 [======================>.......] - ETA: 0s - loss: 1.2689"
     ]
    }
   ],
   "source": [
    "#lstm model\n",
    "epoc=[500,750,900]\n",
    "batch=[100, 150, 200]\n",
    "\n",
    "for e in epoc:\n",
    "    if e==500:\n",
    "        co='orange'\n",
    "    elif e==750:\n",
    "        co='blue'\n",
    "    elif e==900:\n",
    "        co='green'\n",
    "     \n",
    "    for b in batch:\n",
    "        lstm5_model = keras.Sequential([\n",
    "                # the hidden ReLU layers\n",
    "                layers.Dense(units=250, activation='relu', input_shape=[37]),\n",
    "                layers.Dense(units=250, activation='relu'),\n",
    "                # the linear output layer \n",
    "                layers.Dense(units=1),\n",
    "            ])\n",
    "        lstm5_model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"mae\",)\n",
    "        lstm5_model.fit(\n",
    "            train_X5, train_y5,\n",
    "            validation_data=(val_X5, val_y5),\n",
    "            batch_size=b,\n",
    "            epochs=e,)\n",
    "\n",
    "        lstm5_preds=lstm5_model.predict(val_X5)\n",
    "        lstm5_model.reset_states()\n",
    "        print(mean_absolute_error(val_y5, lstm5_preds))\n",
    "        print(r2_score(val_y5, lstm5_preds))\n",
    "        plt.xlabel('Batch size')\n",
    "        plt.ylabel('Mean absolute error')\n",
    "        plt.scatter(b, mean_absolute_error(val_y5, lstm5_preds), c=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c9ab625393f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreg5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#initiating linear regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mreg5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreg5_preds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdtree5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "reg5=LinearRegression()     #initiating linear regression\n",
    "reg5.fit(train_X5,train_y5)\n",
    "reg5_preds=reg5.predict(val_X5)\n",
    "\n",
    "dtree5 = DecisionTreeRegressor(max_depth=40, min_samples_leaf=5, random_state=1)\n",
    "dtree5.fit(train_X5, train_y5)\n",
    "dec5_preds= dtree5.predict(val_X5)\n",
    "        \n",
    "forest_model5 = RandomForestRegressor(n_estimators=350, random_state=1)\n",
    "forest_model5.fit(train_X5, train_y5)\n",
    "forest5_preds = forest_model5.predict(val_X5)\n",
    "\n",
    "grad5=GradientBoostingRegressor(learning_rate=lr, n_estimators=nes, subsample=1)\n",
    "grad5.fit(train_X5, train_y5)\n",
    "grad5_preds=grad5.predict(val_X5)\n",
    "\n",
    "light5 = lgm.LGBMClassifier(num_leaves=50, n_estimators=5)\n",
    "light5.fit(train_X5, train_y5)\n",
    "lpreds5=light5.predict(val_X5)\n",
    "\n",
    "lstm5_model = keras.Sequential([\n",
    "    # the hidden ReLU layers\n",
    "    layers.Dense(units=250, activation='relu', input_shape=[37]),\n",
    "    layers.Dense(units=250, activation='relu'),\n",
    "    # the linear output layer \n",
    "    layers.Dense(units=1)\n",
    "])\n",
    "lstm5_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mae\")\n",
    "\n",
    "lstm5_model.fit(\n",
    "            train_X5, train_y5,\n",
    "            validation_data=(val_X5, val_y5),\n",
    "            batch_size=210,\n",
    "            epochs=950)\n",
    "lstm5_preds=lstm5_model.predict(val_X5)\n",
    "\n",
    "\n",
    "compare5={'model':['multiple regression', 'decision tree', 'random forest', 'gradient boosting regressor', 'lightgbm', 'lstm'],\n",
    "        'MAE':[mean_absolute_error(val_y5, reg5_preds), mean_absolute_error(val_y5, dec5_preds), mean_absolute_error(val_y5, forest5_preds),\n",
    "              mean_absolute_error(val_y5, grad5_preds), mean_absolute_error(val_y5, lpreds5), mean_absolute_error(val_y5, lstm5_preds)],\n",
    "        'R^2':[r2_score(val_y5, reg5_preds), r2_score(val_y5, dec5_preds), r2_score(val_y15, forest5_preds), \n",
    "               r2_score(val_y5, grad5_preds), r2_score(val_y5, lpreds5), r2_score(val_y5, lstm5_preds)]}\n",
    "compare5_df=pd.DataFrame(compare5, columns=['model', 'MAE', 'R^2'])\n",
    "compare5_df=compare1_df.sort_values(by=['MAE'])\n",
    "compare5_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(synetica_data, meter_ID, building, start_predictions_timestamp, prediction_interval, end_predictions_timestamp, check, check_data):\n",
    "\n",
    "\n",
    "    #import all libraries needed\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    import numpy as np\n",
    "    import holidays\n",
    "    import datetime\n",
    "    from datetime import datetime\n",
    "    import statistics\n",
    "    import pickle\n",
    "    #read the synetica data that includes the data needed for input to the model\n",
    "    synetica=pd.read_csv(synetica_data)\n",
    "    synetica=synetica.drop(columns={'units', 'device_id'})\n",
    "    synetica=synetica.rename(columns={'name':'Meter_ID'})\n",
    "    #Read meter sensor information data\n",
    "    meter_list=pd.read_csv('Synetica_meter_list.csv')\n",
    "    meter_list=meter_list.drop(columns={'Unnamed: 6', 'class'})#drop useless columns \n",
    "    meter_list=meter_list.rename(columns={'Meter ID':'Meter_ID'})\n",
    "    #merge the synetica and meter sensor information data based on the meter_id\n",
    "    past_data= pd.merge(synetica, meter_list, how='inner', left_on='Meter_ID', right_on='Meter_ID')#join meter and time series data\n",
    "    #select only the rows which include the data corresponding to the chosen meter id\n",
    "    past_data=past_data.loc[(past_data['Meter_ID']==meter_ID)]\n",
    "    if past_data.shape[0] < 50:\n",
    "        print('Inadequate previous data available')\n",
    "    else:\n",
    "\n",
    "        past_data_df=past_data.reset_index()\n",
    "        past_data_df['Day']=past_data_df['timestamp'].apply(lambda x:pd.Timestamp(x).strftime('%A'))#Create a day of the week column\n",
    "        past_data_df['Date']=past_data_df['timestamp'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d'))#create a date column\n",
    "        past_data_df['Time']=past_data_df['timestamp'].apply(lambda x:pd.Timestamp(x).strftime('%H:%M:%S'))#create a time column\n",
    "        past_data_df['Date']=past_data_df['Date'].astype('str')#change the data type of the date column to string\n",
    "\n",
    "\n",
    "\n",
    "        past_data_df['Date_Hour']=past_data_df['timestamp'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d %H'))\n",
    "        #read the occupancy dataframe\n",
    "        occ_df=pd.read_csv('occupancy_dataframe.csv')\n",
    "        #select only the rows which include the chosen building\n",
    "        build_occ=occ_df.loc[(occ_df['Building']==building)]\n",
    "        #add the counts with the same timestamps in the case of multiple floors\n",
    "        build_occ_total=build_occ.groupby([\"time\"])[['Associated Client Count', 'Authenticated Client Count']].sum()\n",
    "        build_occ_df=pd.DataFrame(data=build_occ_total).reset_index()\n",
    "        #create a date hour and minute number and take the average of the counts if the minute is rounded to the same\n",
    "        build_occ_df['Date_Hour']=build_occ_df['time'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d %H'))\n",
    "        build_occ_df['min']=build_occ_df['time'].apply(lambda x:pd.Timestamp(x).strftime('%M'))\n",
    "        build_occ_df['min']=build_occ_df['min'].astype(int)\n",
    "        build_occ_df['min']=round(build_occ_df['min']/10)*10\n",
    "        build_occ_df=build_occ_df.groupby(['Date_Hour','min'], as_index=False)[['Associated Client Count', 'Authenticated Client Count']].mean()\n",
    "\n",
    "        past_data_df['min']=past_data_df['Time'].apply(lambda x:pd.Timestamp(x).strftime('%M'))\n",
    "        past_data_df['min']=past_data_df['min'].astype(int)\n",
    "        past_data_df['min']=round(past_data_df['min']/10)*10\n",
    "        #merge the occupancy and synetica data based on the date, hour and minute rounded to the nearest 10 minutes\n",
    "        past_data_with_occ=pd.merge(build_occ_df, past_data_df, left_on=['Date_Hour','min'], right_on = ['Date_Hour','min'], how='right')\n",
    "        #read the weather data\n",
    "        weather=pd.read_csv('LA14YW.csv')\n",
    "        weather['Date_Hour']=weather['date_time'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d %H'))\n",
    "        #merge the datasets based on the date and hour\n",
    "        complete_past_data= pd.merge(weather, past_data_with_occ, how='right', left_on='Date_Hour', right_on='Date_Hour')\n",
    "        #create float values of the timestamps\n",
    "        complete_past_data[\"Year\"] = complete_past_data['Date'].apply(lambda x:pd.Timestamp(x).strftime('%Y')).astype(float)\n",
    "        complete_past_data[\"Month\"] = complete_past_data['Date'].apply(lambda x:pd.Timestamp(x).strftime('%m')).astype(float)\n",
    "        complete_past_data[\"Day\"] = complete_past_data['Date'].apply(lambda x:pd.Timestamp(x).strftime('%d')).astype(float)\n",
    "\n",
    "        complete_past_data[\"hour\"] = complete_past_data['Time'].apply(lambda x:pd.Timestamp(x).strftime('%H')).astype(float)\n",
    "        complete_past_data[\"minute\"] = complete_past_data['Time'].apply(lambda x:pd.Timestamp(x).strftime('%M')).astype(float)\n",
    "        complete_past_data[\"second\"] = complete_past_data['Time'].apply(lambda x:pd.Timestamp(x).strftime('%S')).astype(float)\n",
    "\n",
    "        complete_past_data[\"hour\"] = complete_past_data['Time'].apply(lambda x:pd.Timestamp(x).strftime('%H')).astype(float)\n",
    "        complete_past_data[\"minute\"] = complete_past_data['Time'].apply(lambda x:pd.Timestamp(x).strftime('%M')).astype(float)\n",
    "        complete_past_data[\"second\"] = complete_past_data['Time'].apply(lambda x:pd.Timestamp(x).strftime('%S')).astype(float)\n",
    "\n",
    "        complete_past_data[\"sunrise\"]=pd.to_datetime(complete_past_data[\"sunrise\"])\n",
    "        complete_past_data[\"sunrise_hour\"] = complete_past_data['sunrise'].dt.strftime('%H').astype(float)\n",
    "        complete_past_data[\"sunrise_minute\"] = complete_past_data['sunrise'].dt.strftime('%M').astype(float)\n",
    "\n",
    "        complete_past_data[\"sunset\"]=pd.to_datetime(complete_past_data[\"sunset\"])\n",
    "        complete_past_data[\"sunset_hour\"] = complete_past_data['sunset'].dt.strftime('%H').astype(float)\n",
    "        complete_past_data[\"sunset_minute\"] = complete_past_data['sunset'].dt.strftime('%M').astype(float)\n",
    "\n",
    "        complete_past_data['previous_mintempC'] = complete_past_data.groupby(['Meter Type'])['mintempC'].ffill()\n",
    "        complete_past_data['previous_maxtempC'] = complete_past_data.groupby(['Meter Type'])['maxtempC'].ffill()\n",
    "        complete_past_data['previous_totalSnow_cm'] = complete_past_data.groupby(['Meter Type'])['totalSnow_cm'].ffill()\n",
    "        complete_past_data['previous_sunHour'] = complete_past_data.groupby(['Meter Type'])['sunHour'].ffill()\n",
    "        complete_past_data['previous_uvIndex'] = complete_past_data.groupby(['Meter Type'])['uvIndex'].ffill()\n",
    "        complete_past_data['previous_moon_illumination'] = complete_past_data.groupby(['Meter Type'])['moon_illumination'].ffill()\n",
    "        complete_past_data['previous_sunrise_hour'] = complete_past_data.groupby(['Meter Type'])['sunrise_hour'].ffill()\n",
    "        complete_past_data['previous_sunrise_minute'] = complete_past_data.groupby(['Meter Type'])['sunrise_hour'].ffill()\n",
    "        complete_past_data['previous_sunset_hour'] = complete_past_data.groupby(['Meter Type'])['sunset_hour'].ffill()\n",
    "        complete_past_data['previous_sunset_minute'] = complete_past_data.groupby(['Meter Type'])['sunset_minute'].ffill()\n",
    "        complete_past_data['previous_DewPointC'] = complete_past_data.groupby(['Meter Type'])['DewPointC'].ffill()\n",
    "        complete_past_data['previous_FeelsLikeC'] = complete_past_data.groupby(['Meter Type'])['FeelsLikeC'].ffill()\n",
    "        complete_past_data['previous_HeatIndexC'] = complete_past_data.groupby(['Meter Type'])['HeatIndexC'].ffill()\n",
    "        complete_past_data['previous_WindChillC'] = complete_past_data.groupby(['Meter Type'])['WindChillC'].ffill()\n",
    "        complete_past_data['previous_WindGustKmph'] = complete_past_data.groupby(['Meter Type'])['WindGustKmph'].ffill()\n",
    "        complete_past_data['previous_cloudcover'] = complete_past_data.groupby(['Meter Type'])['cloudcover'].ffill()\n",
    "        complete_past_data['previous_humidity'] = complete_past_data.groupby(['Meter Type'])['humidity'].ffill()\n",
    "        complete_past_data['previous_precipMM'] = complete_past_data.groupby(['Meter Type'])['precipMM'].ffill()\n",
    "        complete_past_data['previous_pressure'] = complete_past_data.groupby(['Meter Type'])['pressure'].ffill()\n",
    "        complete_past_data['previous_tempC'] = complete_past_data.groupby(['Meter Type'])['tempC'].ffill()\n",
    "        complete_past_data['previous_visibility'] = complete_past_data.groupby(['Meter Type'])['visibility'].ffill()\n",
    "        complete_past_data['previous_winddirDegree'] = complete_past_data.groupby(['Meter Type'])['winddirDegree'].ffill()\n",
    "        complete_past_data['previous_mintempC'] = complete_past_data.groupby(['Meter Type'])['mintempC'].ffill()\n",
    "        complete_past_data['previous_windspeedKmph'] = complete_past_data.groupby(['Meter Type'])['windspeedKmph'].ffill()\n",
    "        complete_past_data['previous_Associated Client Count'] = complete_past_data.groupby(['Meter Type'])['Associated Client Count'].ffill()\n",
    "        complete_past_data['previous_Authenticated Client Count'] = complete_past_data.groupby(['Meter Type'])['Authenticated Client Count'].ffill()\n",
    "\n",
    "        #create the dataframe of the future timestamps that predictions are required for\n",
    "        future_data=[]\n",
    "        for i in range(0, int(((end_predictions_timestamp-start_predictions_timestamp)/prediction_interval)+1)):\n",
    "            future_data.append(start_predictions_timestamp+(prediction_interval*i))\n",
    "        future_data_df=pd.DataFrame(future_data, columns=['future_date'])\n",
    "        #find the most recent date that data is available from\n",
    "        last_past_date=complete_past_data.timestamp[complete_past_data.index.max()]\n",
    "        #calculate the maximum forecast horizon between the most recent recorded data and the last future timestamp required\n",
    "        maximum_forecast_horizon=pd.to_datetime(future_data_df.future_date[future_data_df.index.max()])-pd.to_datetime(last_past_date)\n",
    "\n",
    "        future_data_df['Day']=future_data_df['future_date'].apply(lambda x:pd.Timestamp(x).strftime('%A'))#Create a day of the week column\n",
    "        future_data_df['Date']=future_data_df['future_date'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d'))#Create a date column\n",
    "        future_data_df['Time']=future_data_df['future_date'].apply(lambda x:pd.Timestamp(x).strftime('%H:%M:%S'))#create a time column\n",
    "        future_data_df['Date']=future_data_df['Date'].astype('str')\n",
    "\n",
    "        future_data_df[\"Year\"] = future_data_df['Date'].apply(lambda x:pd.Timestamp(x).strftime('%Y')).astype(float)\n",
    "        future_data_df[\"Month\"] = future_data_df['Date'].apply(lambda x:pd.Timestamp(x).strftime('%m')).astype(float)\n",
    "        future_data_df[\"Day\"] = future_data_df['Date'].apply(lambda x:pd.Timestamp(x).strftime('%d')).astype(float)\n",
    "\n",
    "        future_data_df[\"hour\"] = future_data_df['Time'].apply(lambda x:pd.Timestamp(x).strftime('%H')).astype(float)\n",
    "        future_data_df[\"minute\"] = future_data_df['Time'].apply(lambda x:pd.Timestamp(x).strftime('%M')).astype(float)\n",
    "        future_data_df[\"second\"] = future_data_df['Time'].apply(lambda x:pd.Timestamp(x).strftime('%S')).astype(float)\n",
    "\n",
    "        #create term dates calander\n",
    "        rng = pd.date_range('2018-01-11', periods=1200, freq='D')\n",
    "        term_dates = pd.DataFrame({'Date': rng}) \n",
    "        term=[]\n",
    "        term_as_int=[]\n",
    "        welcome_week_int=0\n",
    "        term_int=1\n",
    "        holiday_int=2\n",
    "\n",
    "\n",
    "        for i in range(0, (term_dates.index.max()+1)):\n",
    "            if np.datetime64('2018-10-01')<=term_dates.Date[i]<=np.datetime64('2018-10-07') or np.datetime64('2019-09-30')<=term_dates.Date[i]<np.datetime64('2019-10-05') or np.datetime64('2020-09-21')<=term_dates.Date[i]<=np.datetime64('2020-10-02'):\n",
    "                term.append('welcome_week')\n",
    "                term_as_int.append(welcome_week_int)\n",
    "            elif np.datetime64('2018-10-07')<term_dates.Date[i]<=np.datetime64('2018-12-14') or np.datetime64('2019-10-05')<=term_dates.Date[i]<=np.datetime64('2019-12-14') or np.datetime64('2020-10-02')<=term_dates.Date[i]<=np.datetime64('2020-12-11'):\n",
    "                term.append('michelmas_term')\n",
    "                term_as_int.append(term_int)       \n",
    "            elif np.datetime64('2017-12-15')<=term_dates.Date[i]<=np.datetime64('2018-01-15') or np.datetime64('2018-12-14')<term_dates.Date[i]<np.datetime64('2019-01-14') or np.datetime64('2019-12-14')<term_dates.Date[i]<np.datetime64('2020-01-13') or np.datetime64('2020-12-11')<=term_dates.Date[i]<=np.datetime64('2021-01-08'):\n",
    "                term.append('Christmas_break')\n",
    "                term_as_int.append(holiday_int)\n",
    "            elif np.datetime64('2018-01-15')<term_dates.Date[i]<=np.datetime64('2018-03-30') or np.datetime64('2019-01-14')<=term_dates.Date[i]<=np.datetime64('2019-03-29') or np.datetime64('2020-01-13')<=term_dates.Date[i]<=np.datetime64('2020-03-20') or np.datetime64('2021-01-08')<=term_dates.Date[i]<=np.datetime64('2021-03-19'):\n",
    "                term.append('lent_term')\n",
    "                term_as_int.append(term_int)\n",
    "            elif np.datetime64('2018-03-30')<term_dates.Date[i]<np.datetime64('2018-04-23') or np.datetime64('2019-03-29')<=term_dates.Date[i]<np.datetime64('2019-04-29') or np.datetime64('2020-03-20')<term_dates.Date[i]<np.datetime64('2020-04-20') or np.datetime64('2021-03-19')<term_dates.Date[i]<np.datetime64('2021-04-16'):\n",
    "                term.append('Easter_break')\n",
    "                term_as_int.append(holiday_int)\n",
    "            elif np.datetime64('2018-04-23')<=term_dates.Date[i]<=np.datetime64('2018-06-29') or np.datetime64('2019-04-29')<=term_dates.Date[i]<=np.datetime64('2019-06-28') or np.datetime64('2020-04-20')<=term_dates.Date[i]<=np.datetime64('2020-06-26') or  np.datetime64('2021-04-16')<=term_dates.Date[i]<=np.datetime64('2025-06-25'):\n",
    "                term.append('summer_term')\n",
    "                term_as_int.append(term_int)\n",
    "            elif np.datetime64('2018-06-29')<term_dates.Date[i]<=np.datetime64('2018-10-01') or np.datetime64('2019-06-28')<term_dates.Date[i]<=np.datetime64('2019-09-30') or np.datetime64('2020-06-26')<term_dates.Date[i]<np.datetime64('2020-09-21'):\n",
    "                term.append('summer_break')\n",
    "                term_as_int.append(holiday_int)\n",
    "            else:\n",
    "                term.append(None)\n",
    "\n",
    "        term_dates['Term']=term        \n",
    "        term_dates.Term.unique()       \n",
    "        term_dates['Term_as_int']=term_as_int\n",
    "        term_dates[\"Date\"]=pd.to_datetime(term_dates[\"Date\"])\n",
    "        term_dates['Date']=term_dates['Date'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d'))\n",
    "\n",
    "\n",
    "\n",
    "        uk_holidays=holidays.UnitedKingdom()\n",
    "\n",
    "\n",
    "        future_holidaydf=[]\n",
    "        for i in range((future_data_df.index.min()), (future_data_df.index.max()+1)):\n",
    "            date=str(future_data_df.Date[i])\n",
    "            holiday=uk_holidays.get(date)\n",
    "            future_holidaydf.append(holiday)\n",
    "\n",
    "        future_data_df['Holiday']=future_holidaydf\n",
    "\n",
    "        #create a type of day column where 0=workday, 1=weekend, 2=bank holiday\n",
    "        f_day_type_int=[]\n",
    "        f_day_type=[]\n",
    "        bank_holiday=2\n",
    "        weekend=1\n",
    "        weekday=0\n",
    "\n",
    "        for i in range((future_data_df.index.min()), (future_data_df.index.max()+1)):\n",
    "            if future_data_df['Holiday'][i]==\"New Year's Day\" or future_data_df['Holiday'][i]== \"Good Friday\" or future_data_df['Holiday'][i]== \"Easter Monday [England, Wales, Northern Ireland]\" or future_data_df['Holiday'][i]== \"May Day\" or future_data_df['Holiday'][i]==\"Spring Bank Holiday\" or future_data_df['Holiday'][i]==\"Late Summer Bank Holiday [England, Wales, Northern Ireland]\" or future_data_df['Holiday'][i]== \"Christmas Day\" or future_data_df['Holiday'][i]== \"Boxing Day\" or future_data_df['Holiday'][i]==\"Boxing Day (Observed)\" :\n",
    "                f_day_type_int.append(bank_holiday)\n",
    "                f_day_type.append('Bank_holiday')\n",
    "            else: #post_office_df['Holiday'][i]== None or post_office_df['Holiday'][i]=='New Year Holiday [Scotland] (Observed)' or post_office_df['Holiday'][i]=='New Year Holiday [Scotland]' or post_office_df['Holiday'][i]==\"St. Patrick's Day [Northern Ireland]\" or post_office_df['Holiday'][i]==\"Battle of the Boyne [Northern Ireland]\" or post_office_df['Holiday'][i]==\"Summer Bank Holiday [Scotland]\" or post_office_df['Holiday'][i]==\"St. Andrew's Day [Scotland]\":\n",
    "                if future_data_df.Day[i]=='Saturday' or future_data_df.Day[i]=='Sunday':\n",
    "                    f_day_type_int.append(weekend)\n",
    "                    f_day_type.append('Weekend')\n",
    "                else:\n",
    "                    f_day_type_int.append(weekday)\n",
    "                    f_day_type.append('Weekday')\n",
    "\n",
    "        future_data_df['Day_type_as_int']=f_day_type_int\n",
    "        future_data_df['Day_type']=f_day_type\n",
    "\n",
    "        complete_future_data= pd.merge(future_data_df, term_dates, how='inner', left_on='Date', right_on='Date')\n",
    "        input_future_data=complete_future_data[['Day', 'Day_type_as_int', 'Year', 'Month', 'hour', 'minute', 'Term_as_int']]\n",
    "\n",
    "        past_features=['timestamp','reading','previous_maxtempC','previous_mintempC','previous_totalSnow_cm',\n",
    "                    'previous_sunHour','previous_uvIndex','previous_moon_illumination','previous_sunrise_hour','previous_sunrise_minute',\n",
    "                    'previous_sunset_hour','previous_sunset_minute','previous_DewPointC','previous_FeelsLikeC','previous_HeatIndexC','previous_WindChillC',\n",
    "                    'previous_WindGustKmph','previous_cloudcover','previous_humidity','previous_precipMM','previous_pressure',\n",
    "                    'previous_tempC','previous_visibility','previous_winddirDegree','previous_windspeedKmph',\n",
    "                    'previous_Associated Client Count','previous_Authenticated Client Count']\n",
    "        complete_past_data=complete_past_data[past_features]\n",
    "        complete_future_data['future_date']=complete_future_data['future_date'].apply(lambda x:pd.Timestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        #merged_past_future= pd.merge(complete_past_data, complete_future_data, how='outer', left_on='timestamp', right_on='future_date')\n",
    "\n",
    "        day_avg_reading=statistics.mean(complete_past_data.reading[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_reading'] = pd.Series([day_avg_reading for x in range(len(input_future_data.index))])\n",
    "        week_avg_reading=statistics.mean(complete_past_data.reading[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_reading'] = pd.Series([week_avg_reading for x in range(len(input_future_data.index))]) \n",
    "\n",
    "        day_avg_maxtemp=statistics.mean(complete_past_data.previous_maxtempC[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_maxtemp'] = pd.Series([day_avg_maxtemp for x in range(len(input_future_data.index))])\n",
    "        week_avg_maxtemp=statistics.mean(complete_past_data.previous_maxtempC[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_maxtemp'] = pd.Series([week_avg_maxtemp for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_mintemp=statistics.mean(complete_past_data.previous_mintempC[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_mintemp'] = pd.Series([day_avg_mintemp for x in range(len(input_future_data.index))])\n",
    "        week_avg_mintemp=statistics.mean(complete_past_data.previous_mintempC[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_mintemp'] = pd.Series([week_avg_mintemp for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_maxtemp=statistics.mean(complete_past_data.previous_maxtempC[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_maxtemp'] = pd.Series([day_avg_maxtemp for x in range(len(input_future_data.index))])\n",
    "        week_avg_maxtemp=statistics.mean(complete_past_data.previous_maxtempC[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_maxtemp'] = pd.Series([week_avg_maxtemp for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_snow=statistics.mean(complete_past_data.previous_totalSnow_cm[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_snow'] = pd.Series([day_avg_snow for x in range(len(input_future_data.index))])\n",
    "        week_avg_snow=statistics.mean(complete_past_data.previous_totalSnow_cm[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_snow'] = pd.Series([week_avg_snow for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_sunhour=statistics.mean(complete_past_data.previous_sunHour[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_sunhour'] = pd.Series([day_avg_sunhour for x in range(len(input_future_data.index))])\n",
    "        week_avg_sunhour=statistics.mean(complete_past_data.previous_sunHour[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_sunhour'] = pd.Series([week_avg_sunhour for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_uvindex=statistics.mean(complete_past_data.previous_uvIndex[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_uvindex'] = pd.Series([day_avg_uvindex for x in range(len(input_future_data.index))])\n",
    "        week_avg_uvindex=statistics.mean(complete_past_data.previous_uvIndex[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_uvindex'] = pd.Series([week_avg_uvindex for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_moonillumination=statistics.mean(complete_past_data.previous_moon_illumination[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_moonillumination'] = pd.Series([day_avg_moonillumination for x in range(len(input_future_data.index))])\n",
    "        week_avg_moonillumination=statistics.mean(complete_past_data.previous_moon_illumination[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_moonillumination'] = pd.Series([week_avg_moonillumination for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_sunrise_hr=statistics.mean(complete_past_data.previous_sunrise_hour[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_sunrise_hr'] = pd.Series([day_avg_sunrise_hr for x in range(len(input_future_data.index))])\n",
    "        week_avg_sunrise_hr=statistics.mean(complete_past_data.previous_sunrise_hour[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_sunrise_hr'] = pd.Series([week_avg_sunrise_hr for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_sunrise_min=statistics.mean(complete_past_data.previous_sunrise_minute[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_sunrise_min'] = pd.Series([day_avg_sunrise_min for x in range(len(input_future_data.index))])\n",
    "        week_avg_sunrise_min=statistics.mean(complete_past_data.previous_sunrise_minute[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_sunrise_min'] = pd.Series([week_avg_sunrise_min for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_sunset_hr=statistics.mean(complete_past_data.previous_sunset_hour[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_sunset_hr'] = pd.Series([day_avg_sunset_hr for x in range(len(input_future_data.index))])\n",
    "        week_avg_sunset_hr=statistics.mean(complete_past_data.previous_sunset_hour[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_sunset_hr'] = pd.Series([week_avg_sunset_hr for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_sunset_min=statistics.mean(complete_past_data.previous_sunset_minute[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_sunset_min'] = pd.Series([day_avg_sunset_min for x in range(len(input_future_data.index))])\n",
    "        week_avg_sunset_min=statistics.mean(complete_past_data.previous_sunset_minute[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_sunset_min'] = pd.Series([week_avg_sunset_min for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_dewpoint=statistics.mean(complete_past_data.previous_DewPointC[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_dewpoint'] = pd.Series([day_avg_dewpoint for x in range(len(input_future_data.index))])\n",
    "        week_avg_dewpoint=statistics.mean(complete_past_data.previous_DewPointC[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_dewpoint'] = pd.Series([week_avg_dewpoint for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_feelslike=statistics.mean(complete_past_data.previous_FeelsLikeC[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_feelslike'] = pd.Series([day_avg_feelslike for x in range(len(input_future_data.index))])\n",
    "        week_avg_feelslike=statistics.mean(complete_past_data.previous_FeelsLikeC[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_feelslike'] = pd.Series([week_avg_feelslike for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_heatindex=statistics.mean(complete_past_data.previous_HeatIndexC[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_heatindex'] = pd.Series([day_avg_heatindex for x in range(len(input_future_data.index))])\n",
    "        week_avg_heatindex=statistics.mean(complete_past_data.previous_HeatIndexC[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_heatindex'] = pd.Series([week_avg_heatindex for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_windchill=statistics.mean(complete_past_data.previous_WindChillC[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_windchill'] = pd.Series([day_avg_windchill for x in range(len(input_future_data.index))])\n",
    "        week_avg_windchill=statistics.mean(complete_past_data.previous_WindChillC[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_windchill'] = pd.Series([week_avg_windchill for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_windgust=statistics.mean(complete_past_data.previous_WindGustKmph[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_windgust'] = pd.Series([day_avg_windgust for x in range(len(input_future_data.index))])\n",
    "        week_avg_windgust=statistics.mean(complete_past_data.previous_WindGustKmph[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_windgust'] = pd.Series([week_avg_windgust for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_cloud=statistics.mean(complete_past_data.previous_cloudcover[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_cloud'] = pd.Series([day_avg_cloud for x in range(len(input_future_data.index))])\n",
    "        week_avg_cloud=statistics.mean(complete_past_data.previous_cloudcover[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_cloud'] = pd.Series([week_avg_cloud for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_humidity=statistics.mean(complete_past_data.previous_humidity[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_humidity'] = pd.Series([day_avg_humidity for x in range(len(input_future_data.index))])\n",
    "        week_avg_humidity=statistics.mean(complete_past_data.previous_humidity[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_humidity'] = pd.Series([week_avg_humidity for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_precip=statistics.mean(complete_past_data.previous_precipMM[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_precip'] = pd.Series([day_avg_precip for x in range(len(input_future_data.index))])\n",
    "        week_avg_precip=statistics.mean(complete_past_data.previous_precipMM[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_precip'] = pd.Series([week_avg_precip for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_pressure=statistics.mean(complete_past_data.previous_pressure[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_pressure'] = pd.Series([day_avg_pressure for x in range(len(input_future_data.index))])\n",
    "        week_avg_pressure=statistics.mean(complete_past_data.previous_pressure[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_pressure'] = pd.Series([week_avg_pressure for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_temp=statistics.mean(complete_past_data.previous_tempC[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_temp'] = pd.Series([day_avg_temp for x in range(len(input_future_data.index))])\n",
    "        week_avg_temp=statistics.mean(complete_past_data.previous_tempC[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_temp'] = pd.Series([week_avg_temp for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_visibility=statistics.mean(complete_past_data.previous_visibility[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_visibility'] = pd.Series([day_avg_visibility for x in range(len(input_future_data.index))])\n",
    "        week_avg_visibility=statistics.mean(complete_past_data.previous_visibility[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_visibility'] = pd.Series([week_avg_visibility for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_winddir=statistics.mean(complete_past_data.previous_winddirDegree[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_winddir'] = pd.Series([day_avg_winddir for x in range(len(input_future_data.index))])\n",
    "        week_avg_winddir=statistics.mean(complete_past_data.previous_winddirDegree[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_winddir'] = pd.Series([week_avg_winddir for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_windspeed=statistics.mean(complete_past_data.previous_windspeedKmph[(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_windspeed'] = pd.Series([day_avg_windspeed for x in range(len(input_future_data.index))])\n",
    "        week_avg_windspeed=statistics.mean(complete_past_data.previous_windspeedKmph[(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_windspeed'] = pd.Series([week_avg_windspeed for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_as_client=statistics.mean(complete_past_data['previous_Associated Client Count'][(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_as_client'] = pd.Series([day_avg_as_client for x in range(len(input_future_data.index))])\n",
    "        week_avg_as_client=statistics.mean(complete_past_data['previous_Associated Client Count'][(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_as_client'] = pd.Series([week_avg_as_client for x in range(len(input_future_data.index))])\n",
    "\n",
    "        day_avg_auth_client=statistics.mean(complete_past_data['previous_Authenticated Client Count'][(complete_past_data.index.max()-144):(complete_past_data.index.max())])\n",
    "        input_future_data['day_avg_auth_client'] = pd.Series([day_avg_auth_client for x in range(len(input_future_data.index))])\n",
    "        week_avg_auth_client=statistics.mean(complete_past_data['previous_Authenticated Client Count'][(complete_past_data.index.max()-1008):(complete_past_data.index.max())])\n",
    "        input_future_data['week_avg_auth_client'] = pd.Series([week_avg_auth_client for x in range(len(input_future_data.index))])\n",
    "\n",
    "\n",
    "        if (input_future_data['week_avg_as_client'].isnull().any() == True):\n",
    "            features=['day_avg_reading', 'week_avg_reading', 'hour',\n",
    "              'week_avg_sunset_hr', 'day_avg_sunset_hr', 'week_avg_dewpoint',\n",
    "              'week_avg_windchill', 'week_avg_feelslike', 'week_avg_heatindex',\n",
    "              'week_avg_temp', 'week_avg_mintemp', 'day_avg_mintemp',\n",
    "              'week_avg_maxtemp', 'week_avg_uvindex', 'day_avg_windchill',\n",
    "              'day_avg_feelslike', 'day_avg_heatindex', 'day_avg_temp',\n",
    "              'day_avg_dewpoint', 'week_avg_sunhour', 'day_avg_maxtemp',\n",
    "              'day_avg_uvindex', 'day_avg_sunhour',\n",
    "              'day_avg_sunrise_hr', 'day_avg_sunrise_min', 'week_avg_sunrise_hr',\n",
    "              'week_avg_sunrise_min' ,'Day_type_as_int', \n",
    "              'Month', 'Day','minute', 'Term_as_int', 'Year']\n",
    "        else:\n",
    "\n",
    "            features=['day_avg_reading', 'week_avg_reading', 'hour',\n",
    "              'week_avg_sunset_hr', 'day_avg_sunset_hr', 'week_avg_dewpoint',\n",
    "              'week_avg_windchill', 'week_avg_feelslike', 'week_avg_heatindex',\n",
    "              'week_avg_temp', 'week_avg_mintemp', 'day_avg_mintemp',\n",
    "              'week_avg_maxtemp', 'week_avg_uvindex', 'day_avg_windchill',\n",
    "              'day_avg_feelslike', 'day_avg_heatindex', 'day_avg_temp',\n",
    "              'day_avg_dewpoint', 'week_avg_sunhour', 'day_avg_maxtemp',\n",
    "              'day_avg_uvindex', 'day_avg_sunhour',\n",
    "              'day_avg_sunrise_hr', 'day_avg_sunrise_min', 'week_avg_sunrise_hr',\n",
    "              'week_avg_sunrise_min' ,'day_avg_as_client','week_avg_as_client',\n",
    "              'day_avg_auth_client','week_avg_auth_client','Day_type_as_int', \n",
    "              'Month', 'Day','minute', 'Term_as_int', 'Year']\n",
    "\n",
    "        input_to_model=input_future_data[features]\n",
    "        input_to_model=input_to_model.fillna(0)\n",
    "\n",
    "        if input_future_data.week_avg_as_client.isnull().any()==True :\n",
    "            if maximum_forecast_horizon/'00:10:00' < 5:\n",
    "                model=pickle.load(open('forest_model1no.sav', 'rb'))\n",
    "            elif 5 < maximum_forecast_horizon/'00:10:00' < 30:\n",
    "                model=pickle.load(open('forest_model2no.sav', 'rb'))\n",
    "            elif 30 < maximum_forecast_horizon/'00:10:00' < 70:\n",
    "                model=pickle.load(open('forest_model3no.sav', 'rb'))\n",
    "            elif 70 < maximum_forecast_horizon/'00:10:00' < 110:\n",
    "                model=pickle.load(open('forest_model4no.sav', 'rb'))\n",
    "            elif 110 < maximum_forecast_horizon/'00:10:00' < 160:\n",
    "                model=pickle.load(open('forest_model5no.sav', 'rb'))\n",
    "            elif 160 < maximum_forecast_horizon/'00:10:00' < 240:\n",
    "                model=pickle.load(open('forest_model6no.sav', 'rb'))\n",
    "            elif 240 < maximum_forecast_horizon/'00:10:00' > 310:\n",
    "                model=pickle.load(open('forest_model7no.sav', 'rb'))\n",
    "            elif 310 < maximum_forecast_horizon/'00:10:00' < 390:\n",
    "                model=pickle.load(open('forest_model8no.sav', 'rb'))\n",
    "            elif 390 < maximum_forecast_horizon/'00:10:00' :\n",
    "                model=pickle.load(open('forest_model9no.sav', 'rb'))\n",
    "\n",
    "        else:\n",
    "            if maximum_forecast_horizon/'00:10:00' < 5:\n",
    "                model=pickle.load(open('forest_model1.sav', 'rb'))\n",
    "            elif 5 < maximum_forecast_horizon/'00:10:00' < 30:\n",
    "                model=pickle.load(open('forest_model2.sav', 'rb'))\n",
    "            elif 30 < maximum_forecast_horizon/'00:10:00' < 70:\n",
    "                model=pickle.load(open('forest_model3.sav', 'rb'))\n",
    "            elif 70 < maximum_forecast_horizon/'00:10:00' < 110:\n",
    "                model=pickle.load(open('forest_model4.sav', 'rb'))\n",
    "            elif 110 < maximum_forecast_horizon/'00:10:00' < 160:\n",
    "                model=pickle.load(open('forest_model5.sav', 'rb'))\n",
    "            elif 160 < maximum_forecast_horizon/'00:10:00' < 240:\n",
    "                model=pickle.load(open('forest_model6.sav', 'rb'))\n",
    "            elif 240 < maximum_forecast_horizon/'00:10:00' > 310:\n",
    "                model=pickle.load(open('forest_model7.sav', 'rb'))\n",
    "            elif 310 < maximum_forecast_horizon/'00:10:00' < 390:\n",
    "                model=pickle.load(open('forest_model8.sav', 'rb'))\n",
    "            elif 390 < maximum_forecast_horizon/'00:10:00' :\n",
    "                model=pickle.load(open('forest_model9.sav', 'rb'))\n",
    "\n",
    "        reading_predictions=model.predict(input_to_model)\n",
    "        predictions_df=pd.DataFrame(reading_predictions, columns=['reading_predictions'])\n",
    "        future_preds_df=future_data_df[['future_date']]\n",
    "        future_preds_df=future_preds_df.reset_index(drop=True)\n",
    "        future_preds_df['predicted_reading']=predictions_df['reading_predictions']\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        past_data=past_data.reset_index(drop=True)\n",
    "        small_past=past_data[(past_data.index.max()-50):past_data.index.max()]\n",
    "        small_past.timestamp=pd.to_datetime(small_past.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        future_preds_df.future_date=pd.to_datetime(future_preds_df.future_date, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        if check== True:\n",
    "            real=pd.read_csv(check_data)\n",
    "            real=real.loc[(real['name']==meter_ID)]\n",
    "            real.timestamp=pd.to_datetime(real.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            check=pd.merge(future_preds_df, real, how='left', left_on='future_date', right_on='timestamp')\n",
    "            x=check['future_date']\n",
    "            tickx=x.astype(str)\n",
    "            labels=tickx\n",
    "            plt.figure(figsize=(25, 10))\n",
    "\n",
    "            plt.xticks(rotation='vertical')\n",
    "\n",
    "            plt.plot(x, check['reading'], c='green')\n",
    "\n",
    "            plt.plot(x, check['predicted_reading'], c='red')\n",
    "\n",
    "            plt.plot(small_past.timestamp[10:(small_past.index.max()-10)], small_past.reading[10:(small_past.index.max()-10)], c='blue')\n",
    "            plt.xlabel('Date time')\n",
    "            plt.ylabel('Reading')\n",
    "            plt.legend(['Actual readings', 'predicted readings', 'past readings'])\n",
    "            plt.title('Plots of the past recorded meter readings used to in the model, the predicted readings and the real measured readings')\n",
    "            plt.show()\n",
    "            print(mean_absolute_error(check.reading, check.predicted_reading))\n",
    "        else:\n",
    "            plt.figure(figsize=(25, 10))\n",
    "            plt.xticks(rotation='vertical')\n",
    "\n",
    "            plt.plot(future_preds_df['future_date'], future_preds_df['predicted_reading'], c='red')\n",
    "            plt.plot(small_past.timestamp, small_past.reading, c='blue')\n",
    "            plt.xlabel('Date time')\n",
    "            plt.ylabel('Reading')\n",
    "            plt.legend(['predicted readings', 'past readings'])\n",
    "            plt.show\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-42e9306b0a7e>:223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_future_data['day_avg_reading'] = pd.Series([day_avg_reading for x in range(len(input_future_data.index))])\n",
      "<ipython-input-34-42e9306b0a7e>:225: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_future_data['week_avg_reading'] = pd.Series([week_avg_reading for x in range(len(input_future_data.index))])\n",
      "<ipython-input-34-42e9306b0a7e>:228: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_future_data['day_avg_maxtemp'] = pd.Series([day_avg_maxtemp for x in range(len(input_future_data.index))])\n",
      "<ipython-input-34-42e9306b0a7e>:230: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_future_data['week_avg_maxtemp'] = pd.Series([week_avg_maxtemp for x in range(len(input_future_data.index))])\n",
      "<ipython-input-34-42e9306b0a7e>:233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_future_data['day_avg_mintemp'] = pd.Series([day_avg_mintemp for x in range(len(input_future_data.index))])\n",
      "<ipython-input-34-42e9306b0a7e>:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_future_data['week_avg_mintemp'] = pd.Series([week_avg_mintemp for x in range(len(input_future_data.index))])\n",
      "<ipython-input-34-42e9306b0a7e>:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_future_data['day_avg_maxtemp'] = pd.Series([day_avg_maxtemp for x in range(len(input_future_data.index))])\n",
      "<ipython-input-34-42e9306b0a7e>:240: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_future_data['week_avg_maxtemp'] = pd.Series([week_avg_maxtemp for x in range(len(input_future_data.index))])\n",
      "C:\\Users\\katie\\anaconda3\\envs\\my_environment\\lib\\site-packages\\pandas\\core\\generic.py:5491: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABaMAAAKACAYAAACBnGRzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAD8aklEQVR4nOzdeZxbdb3/8dd39pnOdGYSukLb6ZKwl7IUKBQERcQdEQTBi+hPcWdR8bpekav3chEVURHx4kW9giguiMCVy2VTKUsrtVKWpHsLBdqk0yadfeb8/vjmzGRmkskyyWR7Px+PPDKTnJzzzTJnknc+5/M1juMgIiIiIiIiIiIiIpJPVYUegIiIiIiIiIiIiIiUP4XRIiIiIiIiIiIiIpJ3CqNFREREREREREREJO8URouIiIiIiIiIiIhI3imMFhEREREREREREZG8UxgtIiIiIiIiIiIiInmnMFpEpMIZYx4xxnyowGM42BjzjDEmYoy5LM3bOMaYJfkeWyUwxnTEHs+aqbxtJTDGbDHGnBH7+YvGmP8s9JjyIZ9/j8aY9caY03K0rtOMMTtysa58yuTvyhhziTHmL5PY1m3GmK9ne/upFP//yhhzkTHmgSnYZkH3cfF/W8aYm40xXynEOHIh09fqZF/b+RS/b69EhdxvGGOuNsb8d+zn+caYqDGmuhBjERGR7CiMFhGpALEPTd2xN+yvGmP+yxjTnOE68vmB/HPAI47jtDiOc2OCbRc8MM9UKQU8paIUXwfxHMf5N8dxSnb82Zrs8+Y4zuGO4zyS5bb1pVWcYg73MuU4zi8cxzkz1XLxwVWpcxzno47j/Guhx5EPhQ79pTQ5jrPNcZxmx3EGCz0WERFJn8JoEZHK8XbHcZqBY4DlwJcLPJ54C4D1hR5EIU3VB/BK/qCfqnLKWHpvJDIFynFfVI73qVzpuRqR78dCj7WIiIylD1wiIhXGcZyXgPuBI8ZeZ4ypMsZ82Riz1RjzmjHmZ8aY1tjVj8XOO2MV1iuMMUuMMY8aY/YaY3YbY+5Mtl1jzDtih9t3xiolD41d/hBwOvD92Hr9Y273DeCUuOu/H3f1GcaYoDFmjzHmB8YYE3e7Dxpjno9d9ydjzIIk43KrsS41xrxsjNlpjPlM3PXHG2NWxca90xjzfWNMXew6Y4z5Tuyx2muMWWeMOcIYcylwEfC52JjvSbJtxxjzCWNMEAjGLnubMWZtbHuPG2OWxi0/zxjzW2PMLmNMyH0sJnre4u7f/zPGbAMeMsZUG2Oujz1nm4C3jhlXqzHm1tj9fckY83U3yE112wT3cYsx5qrYY7M/tt5Zxpj7jW3L8qAxpj1u+RNj97vTGPN3E2vPkOx1YIw5xBjzv8aYsDHmRWPMe+LWdZsx5ofGmPuMMfuxr7Ox43vEGPMNY8xfgS5gUYp1vtXYljL7jDHbjTFXj1nfP8Weh5Ax5ktjros/tNh9Xt5vjNkWezy/FLdsozHmp7HX7/PGmM+ZuPYSxph/jj03kdgY35Dk8R9VlWziKmOTvX5j19XHnudtxh5NcbMxpjFuPVfFXh8vG2M+mGjbKZ63k4wxT8e2+7Qx5qQJ1hHf6uRqY8yvYq/xiLH7lOOS3M7dZ/09tu3z4677TOx+7zTGfCDu8gnv95j1X2KM+WvsMew0xmyK3a9LYq+N14wx749bvjU27l2x18iXTezLDzOJv8l0GbvPvRlYEXs8OuOubjfG3Bt7TJ80xiyOu13Sv4cE23jEGPPvxpinYs/t3cYYT+y6cfui2OVJ99XGmDcaY16Irev7QPw+flSVtzHm8LhxvmpsW5yzgC8C58fu899TPZ6pnosE93mLsX+P64D9xpgak2Q/Flv+A7H7G4m9Zj4yZn1J/7ZM3BE3JtZyZoLXstcYc4+x+6qnY/cx5d9+gvuXdLxpjuEPsTE8BSxOtI2Yce8x4tZzfez1sdkY8+a4y9P+uzB233GXMea/jTH7gEtSvA4WG2MeMnZfvtsY8wtjTNsE44/f1m3GmJuM/T8XNXY/MdsYc0PsfrxgjDk6bvm5xpjfGLtv2Gzi2pWZLN6DxK5Luu+P/Z7p+4+jjTF/i70O7gQaJrj/8fvGMHC1mWDfaoxpN8b8MXb/98R+PihufQuNfa8ZMcb8L3BA3HXufqUm7n7/a2z7EWPMA8aY+OUvNiP/o79iRv9/Od4Yszr2en3VGPPtdJ5vERHJguM4Oumkk046lfkJ2AKcEft5HrYK+V9jvz8CfCj28weBDcAioBn4LfDz2HUdgAPUxK33DuBL2C83G4CVSbbvB/YDbwRqsW05NgB1Y8eQ5Pbjro+N5Y9AGzAf2AWcFbvu7Nj6DwVqsFXgjydZt3u/7gCmAUfG1uU+XscCJ8bW0wE8D1wRu+5NwJrYGExse3Ni190GfD3F8+IA/wt4gEZs1fprwAlANfD+2HNXH/v978B3YuMcfrzTfN5+FrtdI/BR4IXYa8EDPBz/3AK/B34UW34m8BTwkdh1E942yWvvCWAWcGDs/v0NODp2vx4Cvhpb9kAgBLwF+5p6Y+z3GYleB7HxbQc+EHt+jgF2A4fHPQd7gZNj62tI8traBhweW0drinWehn2NVAFLgVeBs2PXHQZEgVNj9+3bwAAjr6Wrgf8e87z8OPacHAX0AofGrr8WeBRoBw4C1gE7YtcdHBvj3Lh1LU7nbwe4BPhLGq/fG4A/xJ7jFuAe4N9j150Vu99HxJ6D22P3ZUmaY/AAe4B/ij3G74397k1j/3U10IN9jVQD/w48keJvbEnc76fFnpNrsPuit2C/hGhPdb8TrPuS2Lo+EBvL17GvpR/Env8zgQjQHFv+Z8DdsfV2AAHg/6Xzd8XEf5PDz2ka/wvGLYv9OwkDx8eej18Av0znbyzJc/1S3GvjN4x/zcfvi84myb4aGzjtA86NPVdXxh7vD429L7HHdCfwGey+sQU4YezfXdw4J3o8s9nHrY0t30jq/dhbsaGsAV6Hff0dk87fFnH/V0j9Wv5l7NSE3TdtJ42//QT3b6LxpjOGX8XuyxHY10bC1yqJ32NcAvQDH8b+jX0MeBkwqZ7HBOu/Oraus2PPS2OK18GS2HNXD8zAhuU3JNovJdjWbdi/k2Oxr8eHgM3AxYzsKx6OLVsVey7+BajD/h/fBLwpdn2270EeIcm+P27fmO77jzpgK/ZvsBb7N9lPkvc4jOwbPxUbdyMT/0/xAu/GvlZbgF8Dv49b3yrs/9N67P/XCOP3KzVx93sj9n1nY+z3a2PXuf+jV8bu0/Wx+3FG3Hb+KfZzM3BiOvtVnXTSSSedMj8VfAA66aSTTjrl/xT7QBEFOmMfKG4CGmPXDX9gAf4P+Hjc7Q6OvVF3PwSN/aD4M+AW4KAU2/8K8Ku436uwH0pPGzuGJLcfd31sLCvjfv8V8PnYz/cTC3nittcFLEiwbvd+HRJ32XXArUnGcgXwu9jPr8cGSicCVWOWu430wujXx/3+Q2JfEsRd9iI2AFiBDcnHBSJpPm+L4q5/CPho3O9nus8tNjTudV8fsevfy8gH56S3neC1d1Hc778Bfhj3+6eIfegE/plYiB53/Z+A9yd6HQDnA38es/yPGAm3bwN+luI5eAS4Jt11Jrj9DcB3Yj//C7EQL/b7NKCPicPog+KWfwq4IPbzcBgR+/1DjITRS7ChwRlAbRr3L1kYnfD1iw019hMXcMdef5tjP/+E2If72O9+Mguj/wl4aswyq4BLJngNxT+GD8ZddxjQneJvbGwY3c3o/dhrscdgwvudYN2XAMG434+MbW9W3GUhYBk23OkFDou77iPYXvkwub/J4ec01SnRsti/k/+M+/0twAtZ/j08Mua1cRj2b6CaxPuipPtqbHD3RNx1BthB4jD6vcAzScZ0NXFhdBqPZzb7uA/G/T7hfizB7X8PXJ7O3xbjw+hkr+Vq7P+Ag+Ou+zop/vbTfA3FjzedMcT/b/23sa+/uOvc18fYMHpD3O9NsWVmp3oek7wOHkv3dZDg9mfHv8ZIHUb/OO73TwHPx/1+JNAZ+/kEYNuY238B+K8k676C9N6DPELqMDrd9x+nEvclQOy6x5k4jN4W93um+9ZlwJ7Yz/Oxwfa0uOtvZ+Iw+stxy34c+J/Yz/8C3DHm9RT/P/ox4GvAAZn8Teikk0466ZT5Sf2bREQqx9mO4zyYYpm52LDatZWRMCSRzwH/CjxljNkDfMtxnJ+kWq/jOEPGmO3YCrLJeCXu5y5sJQvYIOO7xphvxV1vYtuLv3/xtsf9vBX7YRFj24Z8GzgO+8GlBluJhOM4Dxl76PgPgPnGmN8Bn3UcZ18G9yF+uwuA9xtjPhV3WR328RsEtjqOM5BgHek8b9vHLD/2/saPoRbYaUa6nlTFLT/RbZN5Ne7n7gS/xz9v5xlj3h53fS22MjGRBcAJZnS7gRrg53G/bye1sc9B0nUaY07AVi0fgX1u6rFVXDDmsXEcZ78xJpRi28lew2Mf5/j1bjDGXIENVw43xvwJ+LTjOC+n2NYoyV6/2Eq+JmBN3GvAYMMld2xr4laVzmsg3tjXq7uOdPcHYx+zBmNMTZK/jURCY5Z1H/cZTHy/Exn7WsZxnESv7wMYqS50xd/nyfxN5sJE+9JUf2Njjb0ftcQdVs/4v7dk++qxf09O7P9GIvOw1ZDpyMc+bux9SrofM7bNxFexQXMV9jX3j7htZ/K3NdFruYbk+5C0/3elGG+mY8h0XwFxr03Hcbpiz1kztsI207+Lsc9T0tsbY2YCN2LbDLXErtuTwbgz+b83d8zfWDXw59g48vkeJN33Hw7wkuM4Ttx1qZ7L+HVPuG81xjRhj/o6C3s0EECLsS1T5mKD6f1jtj1vgm2n9X819nqK/x/9/7BV/i8YYzYDX3Mc548p7qeIiGRBPaNFRCTey9gPJC63IuVV7IeRURzHecVxnA87jjMXW+V3kzFmSar1GvtpZB62Ojod47adwnbsobZtcadGx3Een+A28R9s5sfGDLZa6AXA5zjOdGz/0eFPU47j3Og4zrHYNg9+4KoMxxy/3HbgG2PG3eQ4zh2x6+abxBMBTfS8JdrOTsbf3/gx9GIrg9wxTHcc5/A0bjtZ27EVhfH3f5rjONcmuA/u8o+OWb7ZcZyPxS2TzvMw9jmYaJ23Yw81nuc4Tiu2B6/7ehj12MQ+YHvTueMJ7MS253CN+uDtOM7tjuOsxD7vDvAfSdazHxsCuGaPWU+i1+9ubFhyeNxj0OrYCVDdsWXyGhj7HIx9vbrrSHd/kC+p7vdk193P+L9T9z5P5m8yE9nsS1P9jY019n70Y+9/ojFMtK8e+/dkSB5AbSd5P+JE+41c7+PG3qeE+zFjTD326JDrsRX0bcB9JNmHpLntRHZh/wdMtA9J9r9rWBrjTWcM6d6fbF6bmf5djH2eJrr9v8eWXxr73/8+0rvfmdqOrRCOf720OI7zltj12b4HmXDf7958zDiSvf/YCRxo4pJkMtvvp9q3fgZ7RNcJsft4auxyE9t2uzFmWgbbTmbU/9VYz+rh/9GO4wQdx3kvtmXLfwB3jdmuiIjkiMJoERGJdwdwZWyymGbsIbV3xqqedgFD2H6GABhjzoubZGYP9sPHYIL1/gp4qzHmDcaYWuwHj17sYZ7peDV+u2m4GfiCMebw2DhbjTHnpbjNV4wxTbHbfABwJ2NswfYtjRpjDsH2rCS23uXGmBNi92k/tpete/8zHTPY/sEfja3TGGOmGTthXgu2hcNO4NrY5Q3GmJNjt5voeUvkV8BlxpiDjJ088PPuFY7j7AQeAL5ljJlu7OSIi40xr0t12xz4b+Dtxpg3GTuJWIOxE2S5r7Gxj+kfAb+xkwbWxk7LTWxyzCylWmcLEHYcp8cYczxwYdxt7wLeZoxZaewEU9eQ/XutX2Ffw+3GmAOBT7pXGGMONsa8PhYU9WA/5Cf6uwPby/ac2Gt7Cbbyy11Pwtev4zhD2Nfid2LVgRhjDjTGvClubJcYYw6LBe5fTXFfxj5v92Ef4wuNneztfGw7h3xUoKX9d5jG/c6a4ziD2MftG8aYFmMn6fs09jUPk/ubHMXYCbyuTjKUV4GDYq/PdGTzN/a+uNfGNcBdsfufyET76nuxlf/nxL6Eu4zEgZo7ztnGmCuMnSitxdijGNz73GFik0VOwT5uov2YezTFLmDA2KrjM+Num+nfVkKxx/u32InjmmL/uy52r0/xvyteqvFmMobDsH2Ikxn3HiPF+jP6u8ji9i3E2pvF9sHjwvoceQrYZ+wkmI2x18wRxpjlcePI5j3IWpLs+5OY6P3HKuwXC5fF9tnnYHvMpyWNfWsL9v9Yp7ETnn417rZbgdXA14wxdcaYlcDbyc5d2L/Nk2L7wK8xelLU9xljZsTG2xm7ONm+S0REJkFhtIiIxPsJ9vDrx7CT7fRgex3iOE4X8A3gr8bOtH4isBx40hgTxVaLXu44zuaxK3Uc50VsVdH3sBUybwfe7jhOX5rj+i5wrrGzrN+YamHHcX6HrWr5pTFmH/As8OYUN3sUO5HW/wHXO47zQOzyz2IDxwj2w9SdcbeZHrtsD/aw0RC2ggzgVuCw2GP1+5T30I57NXaipu/H1rkB23vR/WD/dmy/4G3Y3qnnx26a9HlL4sfYHqZ/x04m+Nsx11+MDSGei43jLmBOmrfNmuM424F3Yiu/dmErta5i5P3KqNeB4zgRbDByAbba9hXs814/iTGkWufHgWuMMRFs/8lfxd12PfAJbPX0TuxjtyPLoVwTu+1m4EHsc9Abu64e2ypkd2x8M7GPWSLfwfbEfBX4KXZyOtdEr99/xr7+noj9DT2IrVzDcZz7sb2yH4ot81CK+zL2eQsBb8N+KRXCtvt5m+M4uydaSZauBn4a+zt8TxrLJ73fOfApbGC0CfgL9nXitjWazN/kWPOAvya57iHsBLavGGNSPt5Z/o39HNsz9xVsy5fLJlh/0n117PVwHva1HgJ8ye5XbJxvxO4jXwGCwOmxq902OiFjzN9iP+dtHzfRfiw2zsuw+4092P8tf4i7baZ/WxP5JHZC1lewz8kdjOxDJvrbj78vE443zTE0x8ZwG/BfyRZM8h4jlUz+LjK9/dewk/rtxX4xkrP/dfHi/rcvw+7vdwP/iX3uIPv3IBPt+xONY6L3H33AObHf92Dfe2T6eEy0b70BO9ngbuyEx/8z5rYXYntrh7FB9c8y3DYw/D/6U9iJNXdiH9PXGPm7OAtYH3tP+13sHA492WxLREQm5s5ELCIiUpGMMR3YD4C1E1QSixSUMeZj2A/GaVX9SWWKVd/+2nGcFQXa/iPYicX+sxDbl+SMMf8BzHYcZ6LqZJGKYeyRZJ3YFijjCilERCR/VBktIiIiUmSMMXOMMSfHDh0/GFtF/LtCj0uKm+M4OwoVREtxMcYcYoxZGmu5cDy2TYP2IVLRjDFvj7UumYatIv8HsKWwoxIRqTyJJkESERERkcKqA34ELMRWbv0SuKmQAxKRktKCbc0xF9uK4FvA3QUdkUjhvRPbtsZge1Ff4OhQcRGRKac2HSIiIiIiIiIiIiKSd2rTISIiIiIiIiIiIiJ5pzBaRERERERERERERPKuJHpGH3DAAU5HR0ehhyEiIiIiIiIiIiIiE1izZs1ux3FmJLquJMLojo4OVq9eXehhiIiIiIiIiIiIiMgEjDFbk12nNh0iIiIiIiIiIiIikncKo0VEREREREREREQk7xRGi4iIiIiIiIiIiEjelUTP6ET6+/vZsWMHPT09hR6KFEhDQwMHHXQQtbW1hR6KiIiIiIiIiIiIpFCyYfSOHTtoaWmho6MDY0yhhyNTzHEcQqEQO3bsYOHChYUejoiIiIiIiIiIiKRQsm06enp68Hq9CqIrlDEGr9eryngREREREREREZESUbJhNKAgusLp+RcRERERERERESkdJR1GF4Pf/e53GGN44YUXUi57ww030NXVlfW2brvtNj75yU9mfft0nXbaaaxevRqAt7zlLXR2duZ9myIiIiIiIiIiIlLeFEZP0h133MHKlSv55S9/mXLZyYbR6RgYGMjp+u677z7a2tpyuk4RERERERERERGpPAqjJyEajfLXv/6VW2+9dVQYPTg4yGc/+1mOPPJIli5dyve+9z1uvPFGXn75ZU4//XROP/10AJqbm4dvc9ddd3HJJZcAcM8993DCCSdw9NFHc8YZZ/Dqq69OOI6rr76aSy+9lDPPPJOLL76YXbt28e53v5vly5ezfPly/vrXvwLw1FNPcdJJJ3H00Udz0kkn8eKLLwLQ3d3NBRdcwNKlSzn//PPp7u4eXndHRwe7d+9my5YtHHrooXz4wx/m8MMP58wzzxxe7umnn2bp0qWsWLGCq666iiOOOAKA9evXc/zxx7Ns2TKWLl1KMBic5CMuIiIiIiIiIiIipUph9CT8/ve/56yzzsLv9+PxePjb3/4GwC233MLmzZt55plnWLduHRdddBGXXXYZc+fO5eGHH+bhhx+ecL0rV67kiSee4JlnnuGCCy7guuuuSzmWNWvWcPfdd3P77bdz+eWXc+WVV/L000/zm9/8hg996EMAHHLIITz22GM888wzXHPNNXzxi18E4Ic//CFNTU2sW7eOL33pS6xZsybhNoLBIJ/4xCdYv349bW1t/OY3vwHgAx/4ADfffDOrVq2iurp6ePmbb76Zyy+/nLVr17J69WoOOuig1A+qiIiIiIiIiIiIlKWaQg8gF674nytY+8ranK5z2exl3HDWDRMuc8cdd3DFFVcAcMEFF3DHHXdwzDHH8OCDD/LRj36Umhr78Ho8noy2vWPHDs4//3x27txJX18fCxcuTHmbd7zjHTQ2NgLw4IMP8txzzw1ft2/fPiKRCHv37uX9738/wWAQYwz9/f0APPbYY1x22WUALF26lKVLlybcxsKFC1m2bBkAxx57LFu2bKGzs5NIJMJJJ50EwIUXXsgf//hHAFasWME3vvENduzYwTnnnIPP58vocRAREREREREREZHyocroLIVCIR566CE+9KEP0dHRwTe/+U3uvPNOHMfBcRyMMSnXEb9MT0/P8M+f+tSn+OQnP8k//vEPfvSjH426Lplp06YN/zw0NMSqVatYu3Yta9eu5aWXXqKlpYWvfOUrnH766Tz77LPcc889o9abznjr6+uHf66urmZgYADHcZIuf+GFF/KHP/yBxsZG3vSmN/HQQw+l3IaIiIiIiIiIiIiUp7KojE5VwZwPd911FxdffDE/+tGPhi973etex1/+8hfOPPNMbr75Zk477TRqamoIh8N4PB5aWlqIRCIccMABAMyaNYvnn3+egw8+mN/97ne0tLQAsHfvXg488EAAfvrTn2Y8tjPPPJPvf//7XHXVVQCsXbuWZcuWjVrvbbfdNrz8qaeeyi9+8YvhoHrdunVpb6u9vZ2WlhaeeOIJTjzxxFG9szdt2sSiRYu47LLL2LRpE+vWreP1r399xvdHRERERERERERESp8qo7N0xx138K53vWvUZe9+97u5/fbb+dCHPsT8+fNZunQpRx11FLfffjsAl156KW9+85uHJzC89tpredvb3sbrX/965syZM7yeq6++mvPOO49TTjllOLjOxI033sjq1atZunQphx12GDfffDMAn/vc5/jCF77AySefzODg4PDyH/vYx4hGoyxdupTrrruO448/PqPt3XrrrVx66aWsWLECx3FobW0F4M477+SII45g2bJlvPDCC1x88cUZ3xcREREREREREREpD2aiNgvF4rjjjnNWr1496rLnn3+eQw89tEAjknjRaJTm5mbABuw7d+7ku9/97pRsW68DERERERERERGR4mGMWeM4znGJriuLNh1SWPfeey///u//zsDAAAsWLBjVAkREREREREREREQEFEZLDpx//vmcf/75hR6GiIiIiIiIiIiIFDH1jBYRERERERERERGRvMtbGG2M+Ykx5jVjzLNxl51njFlvjBkyxiTsGyIiIiIiIiIiIiIi5SefldG3AWeNuexZ4BzgsTxuV0RERERERERERESKTN56RjuO85gxpmPMZc8DGGPytVkRERERERERERERKULqGV0kHnnkEd72trcB8Ic//IFrr7026bKdnZ3cdNNNGW/j6quv5vrrr896jOnq6Ohg9+7dAJx00kl5355IMtu2wVlnwZ49k1tPdze87W2wbl1uxiUiIiIiki/fXvVtvrPqO4UehohIStf99Tqufzz/OZUUl6INo40xlxpjVhtjVu/atavQw8na4OBgxrd5xzvewec///mk12cbRqdjYGAgp+t7/PHHc7o+kUw88QT86U8w2ZfhunVw773wxz/mZlwiIiIiIvnyy2d/ya+e+1WhhyEiktJ//u0/ufWZWws9DJliRRtGO45zi+M4xzmOc9yMGTMKPZxxtmzZwiGHHML73/9+li5dyrnnnktXVxdgK4OvueYaVq5cya9//WseeOABVqxYwTHHHMN5551HNBoF4H/+53845JBDWLlyJb/97W+H133bbbfxyU9+EoBXX32Vd73rXRx11FEcddRRPP7443z+859n48aNLFu2jKuuugqAb37zmyxfvpylS5fy1a9+dXhd3/jGNzj44IM544wzePHFFxPel0suuYRPf/rTnH766fzzP/8zGzdu5KyzzuLYY4/llFNO4YUXXgDgnnvu4YQTTuDoo4/mjDPO4NVXXwUgFApx5plncvTRR/ORj3wEx3GG193c3AzYyu/TTjuNc889l0MOOYSLLrpoeLn77rtv+HG47LLLhivEH330UZYtW8ayZcs4+uijiUQik3zWpNLE/tQIBCa3Hvf2k12PiIiIiEi+RfuiRPuihR6GiMiE+gf72bRnExvDGxkYym1hpBS3og2jS8GLL77IpZdeyrp165g+ffqoauWGhgb+8pe/cMYZZ/D1r3+dBx98kL/97W8cd9xxfPvb36anp4cPf/jD3HPPPfz5z3/mlVdeSbiNyy67jNe97nX8/e9/529/+xuHH3441157LYsXL2bt2rV885vf5IEHHiAYDPLUU0+xdu1a1qxZw2OPPcaaNWv45S9/yTPPPMNvf/tbnn766aT3JRAI8OCDD/Ktb32LSy+9lO9973usWbOG66+/no9//OMArFy5kieeeIJnnnmGCy64gOuuuw6Ar33ta6xcuZJnnnmGd7zjHWzbti3hNp555hluuOEGnnvuOTZt2sRf//pXenp6+MhHPsL999/PX/7yF+Kr4K+//np+8IMfsHbtWv785z/T2NiY8XMklc39/iIYnNx63NtPdj0iIiIiIvkW6YsQ6VUhj4gUty2dWxh0Bukf6mfb3sQ5kpSnvE1gaIy5AzgNOMAYswP4KhAGvgfMAO41xqx1HOdNk97YFVfA2rWTXs0oy5bBDTdMuMi8efM4+eSTAXjf+97HjTfeyGc/+1kAzj//fACeeOIJnnvuueHl+vr6WLFiBS+88AILFy7E5/MN3/6WW24Zt42HHnqIn/3sZwBUV1fT2trKnjENcB944AEeeOABjj76aACi0SjBYJBIJMK73vUumpqaANv+I5nzzjuP6upqotEojz/+OOedd97wdb29vQDs2LGD888/n507d9LX18fChQsBeOyxx4Yru9/61rfS3t6ecBvHH388Bx10EADLli1jy5YtNDc3s2jRouF1vfe97x1+HE4++WQ+/elPc9FFF3HOOecM31YkXaqMFhEREZFKE+2LUm2qCz0MEZEJBUKBUT8val9UwNHIVMpbGO04znuTXPW7fG1zqhljkv4+bdo0ABzH4Y1vfCN33HHHqGXXrl077vbZchyHL3zhC3zkIx8ZdfkNN9yQ9jbc8Q4NDdHW1sbaBOH+pz71KT796U/zjne8g0ceeYSrr756+Lp0tlNfXz/8c3V1NQMDA6Naeoz1+c9/nre+9a3cd999nHjiiTz44IMccsghad0fERipjM5VGL17t50MMcn3LSIiIiIiBeU4DpHeCNVVCqNFpLiNDaPPWnJWAUcjUylvYfSUSlHBnC/btm1j1apVrFixgjvuuIOVK1eOW+bEE0/kE5/4BBs2bGDJkiV0dXWxY8cODjnkEDZv3szGjRtZvHjxuLDa9YY3vIEf/vCHXHHFFQwODrJ//35aWlpG9U9+05vexFe+8hUuuugimpubeemll6itreXUU0/lkksu4fOf/zwDAwPcc8894wLrsaZPn87ChQv59a9/zXnnnYfjOKxbt46jjjqKvXv3cuCBBwLw05/+dPg2p556Kr/4xS/48pe/zP333z+ucnsihxxyCJs2bWLLli10dHRw5513Dl+3ceNGjjzySI488khWrVrFCy+8oDBaMuJWRm/fDt3dkE2nF8ex7Tk6OmDLFvvz8cfncpQiIiIiIrnRO9jLoDPI4OAgfYN91FXXFXpIIiIJBcNB2hraGHKGCIbUE7OSqGf0JBx66KH89Kc/ZenSpYTDYT72sY+NW2bGjBncdtttvPe972Xp0qWceOKJvPDCCzQ0NHDLLbfw1re+lZUrV7JgwYKE2/jud7/Lww8/zJFHHsmxxx7L+vXr8Xq9nHzyyRxxxBFcddVVnHnmmVx44YWsWLGCI488knPPPZdIJMIxxxzD+eefz7Jly3j3u9/NKaecktb9+sUvfsGtt97KUUcdxeGHH87dd98NwNVXX815553HKaecwgEHHDC8/Fe/+lUee+wxjjnmGB544AHmz5+f9mPY2NjITTfdxFlnncXKlSuZNWsWra2tgK3sPuKIIzjqqKNobGzkzW9+c9rrFYGRymiADRuyW8crr9hQOzavplp1iIiIiEjRiu8VrUkMRaSYBUIBDvYejN/rJxDWB+1KYiZqk1AsjjvuOGf16tWjLnv++ec59NBDCzQi2LJlC29729t49tlnCzaGchGNRmlubsZxHD7xiU/g8/m48sor07ptoV8HUtzOOQf+8AcYHIS77oJ3vzvzdTz6KJx2GtxzD7zznfClL8E11+R8qCIiIiIik7ZpzyYW37gYgC2Xb2FBW+KiJxGRQpv/nfm8ruN1DA4NsmrHKjZfvrnQQ5IcMsascRznuETXqTJaCu7HP/4xy5Yt4/DDD2fv3r0pW4mIpCsaBbezSzDLo37cSugjjrCtOrJdj4iIiIhIvsVXQ6syWkSKVXd/N9v3bcfv8eP3+tnauZXegd5CD0umSHn0jC6Ajo4OVUXnyJVXXpl2JbRIJiIRmDMHwuHs22sEg1BfD/Pmgd+vNh0iIiIiUrzi23RE+iITLCkiUjgbwraPpt/rZ9AZxMFh456NHDbjsAKPTKaCKqNFpGxFo9DSMrkQORCAxYuhuhp8Pvt7CXQ3EhEREZEKpMpoESkFgZD9gO7z+vB5fKMuk/KnMFpEylYkAs3NNkSeTJsOv9/+7PfbgPvVV3M3RhERERGRXImvho6vkhYRKSbBsP2A7vP48HltGB0MqSdmpVAYLSJlK74y+rXXoLMzs9sPDsLGjaPDaFCrDhEREREpTqqMFpFSEAgFmNM8h5b6Ftoa2pg5baYqoyuIwmgRKVtuZbQbImdaHb1tG/T12cpqGDlXGC0iIiIixUg9o0WkFARCgeGKaLAV0oGwPmhXCoXRBfbII4/w+OOPT8m2TjvtNFavXg3AW97yFjozLRMVKSF9ffbU0jISImcaRruhsxtmz58PdXXZt/wQEREREcmn+ABaldEiUqyC4SB+j3/4d7/XrzYdFURhdIGlG0YPDAzkdLv33XcfbW1tOV2nSDGJxt57NzfbCQiNybyi2Q2d3TC6uhqWLFFltIiIiIgUp2hflGpTjcGoZ7SIFKXOnk5e2/8afu/oMHpndKf2WxVCYXSWtmzZwiGHHML73/9+li5dyrnnnktXVxcA11xzDcuXL+eII47g0ksvxXEcAG688UYOO+wwli5dygUXXMCWLVu4+eab+c53vsOyZcv485//PGobV199NZdeeilnnnkmF198Mbt27eLd7343y5cvZ/ny5fz1r38F4KmnnuKkk07i6KOP5qSTTuLFF18EoLu7mwsuuIClS5dy/vnn093dPbzujo4Odu/ezZYtWzj00EP58Ic/zOGHH86ZZ545vNzTTz/N0qVLWbFiBVdddRVHHHEEAOvXr+f4449n2bJlLF26lKDKRKUIRWL/w1paoL4eOjoyD5EDAXv7WbNGLvP5FEaLiIiISHGK9EZoqW+hua5ZbTpEpCi5FdBj23TAyMSGUt4URk/Ciy++yKWXXsq6deuYPn06N910EwCf/OQnefrpp3n22Wfp7u7mj3/8IwDXXnstzzzzDOvWrePmm2+mo6ODj370o1x55ZWsXbuWU045Zdw21qxZw913383tt9/O5ZdfzpVXXsnTTz/Nb37zGz70oQ8BcMghh/DYY4/xzDPPcM011/DFL34RgB/+8Ic0NTWxbt06vvSlL7FmzZqE9yMYDPKJT3yC9evX09bWxm9+8xsAPvCBD3DzzTezatUqqqurh5e/+eabufzyy1m7di2rV6/moIMOyt2DKpIjbmV0S4s99/mya9Ph89mqapffbyc1HBzMzThFRERERHIl2h+lpa6FlvoWtekQkaLkBs5jK6MBteqoEDWFHkAuXHEFrF2b23UuWwY33DDxMvPmzePkk08G4H3vex833ngjn/3sZ3n44Ye57rrr6OrqIhwOc/jhh/P2t7+dpUuXctFFF3H22Wdz9tlnpzWOd7zjHTQ2NgLw4IMP8txzzw1ft2/fPiKRCHv37uX9738/wWAQYwz9/f0APPbYY1x22WUALF26lKVLlybcxsKFC1m2bBkAxx57LFu2bKGzs5NIJMJJJ50EwIUXXjgcqq9YsYJvfOMb7Nixg3POOQefz5dwvSKF5FZGNzfbc78ffvYzcJzR4fJEgkE4/vjRl/n90NsL27fbamsRERERkWIR6Y3QXNfMoDOoymgRKUqBUACDYXH74uHLlniWDF8n5U+V0ZNgxiRaxhh6enr4+Mc/zl133cU//vEPPvzhD9PT0wPAvffeyyc+8QnWrFnDsccem1Yf6GnTpg3/PDQ0xKpVq1i7di1r167lpZdeoqWlha985SucfvrpPPvss9xzzz3D20s0xkTq6+uHf66urmZgYGC4tUgiF154IX/4wx9obGzkTW96Ew899FDKbYhMtbGV0X4/7NsHr72W3u17e2HLlpF+0S73uxe16hARERGRYhPti9JS30JLnSqjRaQ4BUIBFrQtoL5mJItqrG1k3vR5BML6oF0JyqIyOlUFc75s27aNVatWsWLFCu644w5Wrlw5HAQfcMABRKNR7rrrLs4991yGhobYvn07p59+OitXruT2228nGo3S0tLCvn370tremWeeyfe//32uuuoqANauXcuyZcvYu3cvBx54IAC33Xbb8PKnnnoqv/jFL4aD6nXr1qV939rb22lpaeGJJ57gxBNP5Je//OXwdZs2bWLRokVcdtllbNq0iXXr1vH6178+7XWLTIWxldFuiBwMju4BncymTTA0NHI7lxtOB4Nw5pm5GauIiIiISC5E+iK01LXYymhNBCYiRSgYDo5q0eHye/1q01EhVBk9CYceeig//elPWbp0KeFwmI997GO0tbXx4Q9/mCOPPJKzzz6b5cuXAzA4OMj73vc+jjzySI4++miuvPJK2traePvb387vfve7hBMYjnXjjTeyevVqli5dymGHHcbNN98MwOc+9zm+8IUvcPLJJzMY18j2Yx/7GNFolKVLl3Lddddx/Nh+AynceuutXHrppaxYsQLHcWhtbQXgzjvv5IgjjmDZsmW88MILXHzxxRmtV2QqJKqMhvQrmt3+0mMro2fPtgG3KqNFREREpNhE+6I01zXTXNesymgRKTqO4xAIBfB7EofRL4ZenPBIfSkPphSe5OOOO85ZvXr1qMuef/55Dj300AKNCLZs2cLb3vY2nn322YKNId+i0SjNsbLSa6+9lp07d/Ld7363wKMardCvAyleN90En/gE7NxpA+TBQWhshE9/Gq69NvXtr78erroKwmFobx993THH2Orq++/Pz9hFRERERLKx6LuLOHn+yQwODfL0y08T/JSqDEWkeLwafZXZ35rNd8/6LpedcNmo676z6jt8+oFPs+uqXRzQdECBRii5YoxZ4zjOcYmuK4s2HZIf9957L//+7//OwMAACxYsGNUCRKTYja2Mrq6GJUtGKp5TCQTggAPGB9Fgq6XHfD8mIiIiIlJwkb4IzbV2AkNVRotIsQmG7QfyZG06AIKhoMLoMqcwOksdHR1lXRUNcP7553P++ecXehgiWYlEwBhoahq5zOfLrE3H2BYdLr8ffv1r6OuDurrJj1VEREREJBfcCQwHh9QzWkSKTyBkP5BPFEYHQgFWzFsxpeOSqaWe0SJSliIR29vZmJHL/H7YsMFOTJhKIJA8jPb57Do2bcrNWEVEREREJmtgaICegZ7hntH7+/cz5KTxxldEZIoEQgFqq2qZ3zp/3HUdbR1Um+rhwFrKV0mH0aXQ71ryR8+/TCQaHWnR4fL7oacHduxIfduXX7ahcyJuSJ1uyw8RERERkXxz23K01LXQUm/fCO/v21/IIYmIjBIMB1nsWUxN1fhGDbXVtSxqXzTcykPKV8mG0Q0NDYRCIQWSFcpxHEKhEA0NDYUeihQptzI6nhsup2rV4YbME1VGp7MeEREREZGp4rblaKlvobnOvhGO9KlVh4gUj0AokLBFh8vv9asyugKUbM/ogw46iB07drBr165CD0UKpKGhgYMOOqjQw5AilawyGmyIfMYZyW+bKoz2eMDrVRgtIiIiIsXDrYxurmtmcGhw1GUiIoU25AyxIbyBNy1+U9JlfB4fD295GMdxMPE9N6WslGwYXVtby8KFCws9DBEpUokqo+fMgWnTUrfXcEPmJUuSL+P3q02HiIiIiBQPtwq6pa6FQceG0ZrEUESKxY59O+gZ6ElZGd3V38XLkZc5cPqBUzg6mUol26ZDRGQiiSqjjbEtNlJVNAcCcNBB0NSUfBm/X5XRIiIiIlI84iuj3TYdqowWkWLhtt9IFUbHLyvlSWG0iJSlRJXRkF6IHAwmb9Hh8vngpZds6C0iIiIiUmjxPaNb6mxVhnpGi0ixcANmn8eXdBmf1zdqWSlPCqNFpCwlqowGGzJv3gz9/clvGwiMTFKYjBtWb9iQ/RhFRERERHLFDZ5VGS0ixSgQCtBU28TclrlJlzlo+kE01DQojC5zCqNFpCwlq4z2+WBw0AbSiYRCEA6nrox2r1ffaBEREREpBm7w3FLXQkt9rDJaPaNFpEgEw0H8Xv+EExNWmSp8Hh/BsD5olzOF0SJSdoaGYP/+5JXRkLxVhxsupwqj3ckN1TdaRERERIqBGzzHV0arTYeIFItAKDBhiw6Xz+tTZXSZUxgtImVn/357PlEYnayi2Q2XU4XR06bBgQcqjBYRERGR4uBWRk+rm6Y2HSJSVPoH+9m8Z/OEkxe6/B4/G/dsZGBoYApGJoWgMFpEyk4kVgCSqE2Hx2NPyULkQACqq2HhwtTb8fvVpkNEREREikOkL0JzXTNVpoqaqhoaahrUpkNEisLmzs0MOoPphdFePwNDA2zt3DoFI5NCUBgtImUnGisASVQZDTZEnqhNx8KFUFubejs+nyqjRURERKQ4RPuiwxXRYHtHqzJaRIqB23Yj3TYd8beR8qMwWkTKzkSV0TBxRXMgkLpFR/x63AkPRUREREQKKdIXoaVupBqjpb5FPaNFpCi4wXK6ldHxt5HyozBaRMpOqsponw+2b4eurtGXO44NqX2pv6wFUvefFhERERGZKmMro5vrmlUZLSJFIRgK4mn04G3yplx2RtMMWutbCYb1QbtcKYwWkbKTTmU0wIYNoy/fudNOfphuZbQbWqtVh4iIiIgUWqQ3Qkt9XGV0nSqjRaQ4BMKBtFp0ABhj8Hl9qowuYwqjRaTspNMzGsZXNLuhcrph9KJFUFWlMFpERERECs+dwNClymgRKRaBUCCtFh0uv9evMLqMKYwWkbKTqjJ6yRJ7PjZEdn9Pt01HXZ2d7FBtOkRERESk0KJ90fE9o3tVGS0ihdXV38WOfTsyC6M9frbt3UbPQE8eRyaFojBaRMpOqsro5maYOzdxGF1fD/Pmpb8tn0+V0SIiIiJSeJHe0RMYNtc1q02HiBTchrDtj5lumw4An9eHg8PG8MZ8DUsKSGG0iJSdVJXRYFtxjK1odicvrMpgz+j32zDacTIfp4iIiIhIroydwLClrkVtOkSk4Nx2G5m26Yi/rZQXhdEiUnYiEWhogJqa5MskqmgOBNJv0eHy++2kh6+8kvk4RURERERywXEc26ajfkxldG8ER1UTIlJAwZCtAvN5M6iMjlVRB8PqiVmOFEaLSNmJRpO36HD5/bBrF3R22t8HBmDjxvQnL3S54bVadYiIiIhIoXT1d+HgjKuMHnQG6R3sLeDIRKTSBcIB5jTPGbV/SqW1oZWZ02aqMrpMKYwWkbITiUzcogNGQme3Vce2bdDfn3kY7S6vMFpERERECsXtDT12AkNAkxiKSEEFQoGMWnS4/F6/wugypTBaRMpOOpXRYyua3fNM23TMm2cnPRzbf1pEREREZKq4gXN85aH7s/pGi0ghBUPB7MJoj19tOsqUwmgRKTvpVEYvWmQnKhwbRmdaGV1dDYsXqzJaRERERArHDZzje0a7VdJu1bSIyFTb072HXV27hntAZ8Ln9fFK9BX29e7Lw8ikkBRGi0jZSacyur4eOjpGKpqDQZg+HWbOzHx7fr/CaBEREREpHDdwTlQZrTYdIlIobmVztm06YGQCRCkfCqNFpOxEIqnDaBgdIgcCtkWHMZlvz++3kx8ODmZ+WxERERGRyRqujE7QM1ptOkSkUNwgeVJhtFp1lB2F0SJSdqLR1G06wIbPgQA4jj3PtEVH/Hr6+uwkiCIiIiIiU82tfo5v0zFcGa02HSJSIIFQgCpTxaL2RRnfdnH74uF1SHlRGC0iZSeTyuhIBLZvh61bsw+j3dupVYeIiIiIFIJb/RzfpsOtklZltIgUSiAcYEHrAupr6jO+bWNtI/Nb5yuMLkMKo0WkrDhOehMYwkiIfP/99naTDaODOnpIRERERArArX6Ob9OhntEiUmjBUDCrFh0uv9evNh1lSGG0iJSV3l7buzmdymhfbELfe+8d/XumZs2y4bcqo0VERESkEBJWRqtntIgUkOM4BEIBfJ4sP2gDPo+PQCiA4zg5HJkUmsJoESkrkVjhRzqV0fPnQ10dPPig/T3bMNqY0ZMhioiIiIhMpUhvhPrqemqra4cvq6+up6aqRj2jRaQgXt3/KpG+yKQrozt7OtndtTuHI5NCUxgtImUlGiv8SKcyuroaliyB7m6YORPa2rLfrt+vNh0iIiIiUhiRvsioqmgAYwzNdc2qjBaRggiG7AfkyYbRgFp1lJm8hdHGmJ8YY14zxjwbd5nHGPO/xphg7Lw9X9sXkcqUSWU0jFRDZ1sVHb+eLVtsmxARERERkakU7YsOt+WI11LXospoESkId+JBn3dybTri1yXlIZ+V0bcBZ4257PPA/zmO4wP+L/a7iEjOZFIZDSOTD2Y7eWH8eoaGYNOmya1HRERERCRTiSqjwfaQ1gSGIlIIgVCA2qpaFrQuyHodHW0d1FTVKIwuMzX5WrHjOI8ZYzrGXPxO4LTYzz8FHgH+OV9jEJHK41ZGFyKMBli7FmbPTr6cMZNrByIiIiIiU6erv4vegak59M0YQ1tDW1a3jfZFaalLUBld36I2HSIyrGegh+7+7inZ1nO7n2OJZwnVVdVZr6O2upZF7Yt4btdz7OneM+GyzXXNo/rm59P+vv30DfalXG4qx1RK8hZGJzHLcZydAI7j7DTGzJzi7YtImXMro9Nt03Hoofb8kEMmt12/3wbNF16Yetlrr4V/nuTXcP/0T1BbCz/5yeTWIyIiIiKJbQxv5NAfHEr/UP+UbfO6M67jqpOvyvh2kd4IrQ2t4y5vrmtWmw4RASDUFaLjux1T+gXV2YecPel1HHLAIdz94t14rvNMuNzhMw7n2Y8/O+EyufDEjic4+ScnM+QMpVz23gvv5S2+t+R9TKVmqsPotBljLgUuBZg/f36BRyMipSLTyuiTToLf/Q7e/vbJbbetza5ny5aJl7v+enj88cltC+CRR2DGjMmvR0REREQSW/3yavqH+vnSKV9iRlP+33hd89g1rN+1PqvbRvuiHDj9wHGXt9S1sLtr92SHJiJl4B+v/YNoX5RPHf8pFrcvnpJt5iKI/eYbv8nrO14/4TKPbn2U373wO/b17mN6/fRJb3MiT+54kiFniGvfcC0NNQ0TLnvoAYfmdSylaqrD6FeNMXNiVdFzgNeSLeg4zi3ALQDHHXecM1UDFJHSlukEhsbA2WfnZtvvfGfqZR59FF54YXLb6eqCHTugKp9d/0VEREQqXDAcBOBLp3yJxtrGvG/vtr/fRqg7lNVtI32RhG061DNaRFzBkN2nfWbFZ1jQln0f56nm9/rxeyfuq7mgbQG/e+F3BENBjp17bF7HEwwHaa1v5XMnfw5jTF63Va6mOsr4A/D+2M/vB+6e4u2LSJnLdALDqebzwYYNMDiY/To2bLDnoew+q4iIiIhIGgKhAPOmz5uSIBrA2+gl1JXdG7xoXzThBIYtdeoZLSJWIBSgvrqeea3zCj2UnPN5fABTMtFhIBTA5/UpiJ6EvIXRxpg7gFXAwcaYHcaY/wdcC7zRGBME3hj7XUQkZyIRqK6G+vpCjyQxvx/6+2Hr1uzXEYj9f92/H3qnZj4dERERkYoTCAVSVuPlkrfJm31ldG/iyuiW+hb1jBYRAALhAEs8S6gy5XeI7WLPYgxmysLoqfzfUI7y9gp0HOe9juPMcRyn1nGcgxzHudVxnJDjOG9wHMcXOw/na/siUpmiUVsVXaxfUvpj/7OCwezXEX9bVUeLiIiI5EcwHJzaMDrLyujegV76h/oTVkY31zXTM9DDwNBALoYoIiUsGJrafdpUaqhpYEHbguH2SvnSM9DDtr3b8HvK83GcKuX3dYiIVLRIJP1+0YXgs0cPDVc3ZyP+tgqjRURERHIv1BUi3B0ePvR7Kngbvezp2cOQM5TR7dw2HC31CSqjY9XSatUhUtkGhwbZEN4wpfu0qebz+PJeGb0xvBEHB5+3fB/HqaAwWkTKilsZXaxmzbLjm2wYXVtrfw7r+BIRERGRnHMDjamsIvQ0ehhyhtjbszej27ltOJJNYAhoEkORCrd171b6h/rLtjIa7P46EArgOE7etlGI/w3lSGG0iJSVSKS4w2hjbKuOybbpWLbM/qzKaBEREZHccw/1nuqe0UDGfaPdqueEExjWqzJaRGyLDijvENXv9bO3dy+7u3bnbRvu/4ZyrjCfCgqjRaSsRKPF3aYDbKuObCuj9+yBXbtgxQr7u8JoERERkdwLhAJUm2o62jqmbJvexlgYnWHfaLfqOVGbjuHKaE1iKFLR3Irecm4v4QbE+WzVEQgFmDltJq0NrXnbRiVQGC0iZaXYK6PBVkZv3Qq9vZnf1q2oVhgtIiIikj+BUIBF7Yuora6dsm3mpTJaPaNFBLtPa6lrYda0WYUeSt64Vd/5DqPLubp8qiiMFpGyUuwTGIINo4eGYNOmzG/rhtFHHQUNDQqjRURERPIhGA5OeeCQdWW0ekaLSAruPs0YU+ih5M2CtgXUVtUOt9LIh2A4iN+jMHqyFEaLSFkp9gkMwbbpgOxadQQCUFUFixaB16swWkRERCTXHMchEApMeU9Q9YwWkXwJhAJl3aIDoKaqhkXti/JWGb2vdx+vRF8p+8dxKiiMFpGyUgqV0ZMNoxcsgPp6hdEiIiIi+fBy5GW6+rumvDK6tb4VgyHcHc7odhP1jHarpdUzWqRy9Q70snXv1oqo6PV7/XkLoythEsipojBaRMrGwAD09BR/ZXR7O8yYMdJyIxPBoG3zATaMDmf2WUVEREREUnAP8Z7qwKG6qpr2xvas23Qkqox2L1NltEjl2rRnE0POUEWEqH6vnw3hDQw5Qzlfd6H+N5QjhdEiUjaisffYxV4ZDTZQzrQy2nHsbdww2uNRZbSIiIhIrrlVdYU4FNvb6M2qTUeVqaKxpnHcddPqpgHqGS1Sydx9WiWEqD6Pj+6Bbl7a91LO1+0+jovbF+d83ZVGYbSIlA03jC72ymiwrToyDaNffdW2IXHbfKhNh4iIiEjuBUIBGmoaOGj6QVO+bW9T5mF0pDdCS11LwonJqkwV02qnqU2HSAUr5BdsU80N3PPRqiMQCjC/dT6NteO/+JPMKIwWkbIRib3HLoUw2u+HnTtHxpwOt63H2DYdjpP78YmIiIhUKnfywioz9R+XvY3ejNt0RPuiCVt0uFrqW9SmQ6SCBcNBZjTNoK2hrdBDyTs3jHZbauRSMBysiOryqaAwWkTKRqm16QDYsCH927iV1PFh9MAA7NuX27GJiIiIVLJgOFiwCsKsKqP7IgknL3Q11zWrMlqkggVCgYoJUee2zKWptinnldGO4wx/USmTpzBaRMpGKVVGu602MmnVEQhAXR3Mn29/93rtuVp1iIiIiOTGwNAAG8Mb8XsKE9x4GjyEuzOboTplZXSdKqNFKlkgFKiIFh0Axhh8Hl/Ow+jdXbvp7OmsmFA/3xRGi0jZcMPoUqiMXrLEnmcSRgeDsHgxVFfb390wOpzZ5xURERERSWJr51b6h/oLFjh4m7xE+6L0DfalfZtIn+0ZnUxzXbMmMBSpUNG+KDujOwv2BVsh+L3+nLfpcNenMDo3FEaLSNkopQkMm5pg3ryRPtDpCARGWnQAeDz2XJXRIiIiIrnhBg4Fa9PRaKsNMukbHemNqGe0iCQUDFVeiOrz+Ni0ZxP9g/05W+fwJJBq05ETCqNFpGyUUmU02FYd6VZGDw3Z/tK+uP99atMhIiIikltu4FDIymggo77R0b7ohD2jW+pa1DNapEINh6gV0qYD7P57YGiALZ1bcrbOQChATVUNHW0dOVtnJVMYLSJlo5Qqo8FWOacbRm/fDr29oyujFUaLiIiI5FYgFKC1vpUZTTMKsv2sKqPTaNOhymiRyuQe7bHEs6TAI5k67peJuWzVEQwHWdS+iNrq2pyts5IpjBaRsuFWRk+bVthxpMvvhz170guT3dA6Poxub7fnCqNFREREciMYDuLz+jDGFGT72VZGp5rAUD2jRSpTIBRg3vR5NNU2FXooU8atAs/lJIaBUEAtOnJIYbSIlI1o1AbRVSWyZ3NbbqRTHe0uE9+mo6YG2toURouIiIjkSiAUKGhvVU+jnRQk3J3eDNWDQ4N09XelVRntOE5OxigipSMQClRUiw6wR5i0N7TnLIwecoYIhoIV1Xc730okshERSS0SKZ0WHTBS5ZxOGB0M2qB9zpzRl3u9CqNFREREcqFnoIetnVvxewoXOGTapmN//36AlBMYOjh09XdNfoAiUlKC4WBB92mFYIzB7/XnrE3Hy5GX6R7oVhidQwqjRaRsRKOlM3khwMKFUF1tg+ZUAgEbXo89YtTjgXB6hTMiIiIiMoFNezbh4BS0irCpton66vq023S47TcmmsDQDao1iaFIZQl1hQh3hysyRPV5fTmrjB6eBFJtOnJGYbSIlI1Sq4yurYVFi9Jv0+FL8L9PldEiIiIiueEGDoUMbowxeJu8aVdGuxMTpuoZHb+siFSGYtinFYrf42fb3m1093dPel2V/Djmi8JoESkbkUhpVUaDDZhThdF9fbBly+jJC10Ko0VERERyo1iq37yN3vQro2PVzql6RgOaxFCkwrhtKiqtZzSMBMcb92yc9LqCoSCNNY0cOP3ASa9LLIXRIlI2otHSqowGGzAHgzDRfDKbN8PgoMJoERERkXwKhALMnDaT1obWgo7D25RBGB0LmFP1jAZVRotUmkAoQLWpZmHbwkIPZcq5AXwuWnUEwgGWeJZQZRSh5ooeSREpG6VYGe33Q1cXvPxy8mXcyulkbTr27YP+/vyMT0RERKRSBMPBojgM29PoIdyd3qQgbsA8Uc9ot2paPaNFKksgFGBR+yJqq2sLPZQp5x7hkpMwOhQoiv8N5URhtIiUjVKsjHYD5oladbgTHCarjAZNYigiIiIyWYFQAL+n8IGDtzH9ntGZtOlQZbRIZQmGgxXZogPsF3RzmucQDAUntZ6BoQE27dmkMDrHFEaLSNko1cpomDiMDgRs6OzxjL9OYbSIiIjI5O3r3ccr0VeKIrhxe0Y7E/Vxi0lrAsNY1bR6RotUDsdxiuYLtkLxeX0EwpOrjN7SuYWBoYGCzyVQbhRGi0hZcJzSrIw+6CBoaBipfk4kEEjcogNGAmr1jRYRERHJ3obwBoCiqH7zNnkZGBpIq62GGzBP1KZjeAJDtekQqRgvR16mq7+rKPZpheL3+CfdpsO9fSU/jvmgMFpEykJXlw2kSy2MrqqCJUtSt+lI1KIDRiqjFUaLiIiIZK+YAgdvo32Dl06rDrcyelrttKTLqE2HSOUJhm21UzEc7VEofq+f1/a/xt6evVmvw23zUQz/G8qJwmgRKQvR2HvrUmvTATZoThZG798PO3YojBYRERHJJzeMXty+uMAjsZXRAKHu1G/wIn0RmmqbqK6qTrpMXXUdddV1atMhUkGK6Qu2QnGDeDeYz0YgFKC1vpUDmg7I1bAEhdEiUiYisffWpVYZDTZo3rQJBgbGX7fBHjGatE2HwmgRERGRyQuGg8xvnU9jbWOhh4Kn0fZhC3ennhQk2hedsF+0q6WuRZXRIhUkEArQUNPAQdMPKvRQCsYN4ifTqiMQDuD3+jHG5GpYgsJoESkTbhhdipXRPh/098PWreOvc3tJJ6uMbm6G2lqF0SIiIiKTEQgFiqaCMJM2HZG+CC11qasxmuua1TNapIIEw0GWeJZQZSo39lvcvhiDGW61kY1gKFg0/xvKSeW+KkWkrLhtOkq1MhoSt+pwL1uyJPFtjbHV0eHUhTMiIiIikoDjOARCAXye4uitmlGbjt5IepXR9aqMFqkkxfQFW6HU19SzoG0BgXB2ldHd/d1s27utaP43lBOF0SJSFkq5MtoNo4MJvrANBGDu3Invl8ejymgRERGRbIW6Q3T2dBZNcOO26Uh3AsOW+tTVGC11LaqMFqkQA0MDbAxvxO8pjn1aIfm9/qzbdGzcsxEHp2j+N5QThdEiUhZKuTJ6xgyYPj1xZXQwmLxFh8vrVRgtIiIikq1im+irpqqG1vrWtCcwTLdNhyqjRSrDtr3b6B/qL5p9WiH5PTaMdhwn49sW2/+GcqIwWkTKQilXRhtjA+dkbToURouIiIjkjxs4FNOh2N4mb1phdNoTGNa3EOlVZbRIJRjep3mLZ59WKD6vj329+9jVtSvj27q9pvU45p7CaBEpC6VcGQ02cB7bpmPPHti9205wOBGF0SIiIiLZC4aC1FTV0NHWUeihDPM0egh3p54UJNKrCQxFZDRV9I5wH4NsWnUEQgFmTZvF9PrpuR5WxVMYLSJloZQro8GG0Vu3Qk/PyGVuOJ1uZXQWRx6JiIiIVLxAOMCi9kXUVtcWeijDvI3etHtGp1UZXacJDEUqRTAUpLW+lRlNMwo9lIKbVBgd1iSQ+aIwWkTKQjQKdXX2VIp8Phsmb9w4cpnbtiOdMLqvD/bvz9/4RERERMpVIFR8gUM6bTocx7E9o9OYwLC5rlltOkQqRCAcwOf1YYwp9FAKbkHrAmqraodbbmQiGAoW3f+GcqEwWkTKQiRSui06YCRwjm/VEQhAVRUsWjTxbT12wnXCqY/kFBEREZE4Q84QwVCwqPpFQ3qV0d0D3Qw5Q2lXRvcP9dM32JerIYpIkSrGL9gKpbqqmsWexQTCmVVG7+3Zy6v7Xy26/w3lQmG0iJSFaLR0W3TASF/o+EkMg0Ho6Ehd7e312nP1jRYRERHJzMuRl+ke6M5/cLN3rz2MLc2+at5GL3t79zIwNJB0GbftRro9owFVR4uUud6BXrZ2bsXvURjt8nv9GbfpCIaDw7eV3Ksp9ABERHKh1CujW1th5szRYXQgkLpFByiMFhEREcnWhBN97d4NX/2q/XnePJg/357PmwcHHgi1Y3pMOw5s3w7PPw8vvDD6/LXX7DK1tfawtvZ2e3J/ds8XL4alS5lR2wpAuDvMzGkzE47dDZbTadPhLhPti+Jt8qZcXkRK08Y9G3Fw8HlV0evye/w8sPEBhpwhqkx6NbluWw+F0fmhMFpEykIkUtqV0WCDZzeMdhz788knp76dwmgRERGR7Lhh9LhDsR0HPvQhuPde+yazs3P09cbA7Nk2mJ49G3bsgBdfHD2JR3s7HHoovO1tcPDBdp179tjeanv22NPLL8P69fayffuGb/rRmmpWeqB+/Ydg+SmwdCkcdRTMmmW3zUhldLptOgAifaqMFilnE37BVqF8Xh89Az3s2LeD+a3z07pNIBTAYFjsWZzn0VUmhdEiUhai0dKujAYbRt93n/351VftfVJltIiIiEj+BENBGmsaOXD6gaOv+PGP4e674dvfhiuvtJUPO3bYyuexp82bYe5cOOUUGz4fcog9nzFjODhOS3+/7dO2bh1bHv092//vTg7+y5Pw63tGlpkxA974RvjoR4nEMpVM2nS4AbaIlCe3ole9jke4wXwgFEg/jA7bZRtqGvI5tIqlMFpEykIkAnPmFHoUk+PzwSuv2KIYt0I6nTDancBQYbSIiIhIZgLhAD6vb/Sh2y+8AFdcYUPfyy+3l7W02ID50EPzN5jaWjjsMDjsMMKnLuFts+/k7gt+zDsOOBn+8Q9Ytw7+9jf4/e/h9ts5yreATyyB1nNTr9pt06Ge0SLlLRAKMHPaTFobWgs9lKLhhtHBUJAzFp2R1m2CoaCqy/NIExiKSFkol8posAUxbhjtS+ML7bo6e9/D4fyNTURERKQcBUKB0RWEfX1w4YXQ1AS33QZVhfnI7G20h76FukL2MLjTToPLLrNjeukluPVW+utq+P79cNzyd8KHPwxr1iRd3/AEhmrTIVLWAuGAQtQx5jTPYVrttLQnMXQcZ/z/BskphdEiUhZKfQJDGB1GB4M2ZJ6f3lFEeDyqjBYRERHJxMDQAJv2bBod3HzlK/DMM3Drrbb1RoG4kwyGuhO8wZs2DT74Qe7++Zc47sOw/9y3wy9+AccdB8uX27F3dY26idvKQ206RMpbMBTE71EYHc8Yg8/rIxBOL4ze1bWLvb17FernkcJoESkL0WjpT2C4ODY3QiBgT0uWQHV1erf1ehVGi4iIiGRiS+cWBoYGRgKHhx6Cb34TPvIReOc7Czq2lroWaqpqbGV0EpG+CGsOhL6bb7ITId54ow2hP/QhOPVU6O0dXna4MlptOkTKVqQ3ws7oTnxeVfSO5ff6h/tpp+IupzA6fxRGi0jJ6+uzp1KvjG5stJXQbhidTosOl8JoERERkcy4h2z7PD77Rurii+2hat/6VoFHZiv5PI0ewt3J+7C5wXJzXTO0tcGnPgXPPmurpNesgc99bnhZt2e0KqNFylcwrBA1GZ/Hx6Y9m+gf7E+57PD/BoX6eaMwWkRKXjT2nrrUK6PBfv554QXYuDG9yQtdCqNFREREMjNc/ebx2Wro116D22+3bTCKgLfRm7hNR0y0L0ptVS31NfUjFxpje15ffrmtlP7DHwBorGmkylSpZ7RIGZvSit7t2+0+s0T4vX4GnUE2d25OuWwgFKCmqoaOto78D6xC1RR6ACIikxWJvacu9cposAH0zTfD0JDCaBEREZF8CoQCtDW0ccCd98BvfgPXXQfHHFPoYQ3zNk0cRkf6IsMVz+P8x3/AY4/BBz4Aa9di5s2jua5ZldEiZSwQCmAwLG5fnN8NvfIKHH64/SC+bBmceSa88Y2wciU0NKS/noEB2LIFdu2C/v6RQ57jT+7ls2fb7TQ2ZjVkN6APhoIpw/pgOMji9sXUVCkyzZeCPLLGmMuBDwMG+LHjODcUYhwiUh7cMLocKqN9PhtEuz+ny+uFzk4YHEy/z7SIiIhIJQuEA7y+fx7m8svh9a+Hz3ym0EMaxdvoZdOeTUmvj/ZFh3tBj1NfD3feacP1Cy+Ehx+mpa5FPaNFylggHGBe6zwaa7MLbNP25S9DT489//Of4TvfsV/mNTTA615ng+kzz4QjjrBHa3R1wYsv2kOAn3/enl54wfam7OtLf7vNzbaf//nn2/XX16e+TYzPYz9cB0IB3spbJ1w2EAqoRUeeTXkYbYw5AhtEHw/0Af9jjLnXcZz0OomLiIzhtukol8roRD+n4vGA49hA2uvN+bBEREREys7m1wI8cFsU6urgZz+DquLqYult9PL0y08nvT7SF6GlboI3wD6fPeTufe+Da66heWYz0X5VRouUq0AokP8WHWvXwk9+AldeCf/6r/ayaBQefRT+93/hgQfgs5+1l8+ebQPqrVvth1Ww+9nFi+GQQ+Atb7Hnc+bYYLm21u6P6+rG/7x+vf2C7be/tX3xW1vhXe+ywfQb3mCXmYC3yYun0TPcDzqZIWeIYDjIGxe9cZIPlEykEJXRhwJPOI7TBWCMeRR4F3BdAcYiImWg3Np0gP3Sd/bs9G/nBtChkMJoERERkVS6+7v54N3bWLQRuOsuOPDAQg9pHG+Tl1BXCMdxMMaMu37CymjXRRfBgw/C17/O6Vf62NquymiRcuQ4DoFQgAuPuDCfG4FPf9pWQn3lKyOXNzfDW99qTwA7dthg+v/+zx72+8EPwqGH2uDZ58uoonnY3Lm24vqmm+w+zQ2mb7vNfgA+5xwbTJ92WtJDhf1e//Akj8m8tO8legZ6NAlknhUijH4W+IYxxgt0A28BVhdgHEXvpZdg1Sr7ZY8OuxdJrpwmMOzogJoa+z86wWeOpOLD6Fzr7rbzU2RSqS0iIiKSD9393ezYt2PSh1C/9Jf7+PyfYeO7TmPxu9+dm8HlmLfRS+9gL90D3TTVNo27PtI7Qc/oeN/7Hqxaxddv3cwl89tyP9AU+gb7eGTLI/QNTnw4fmt9K6csOGWKRiVSXkLdITp7OvPbXuIPf4CHH4bvfx/a2pIvd9BBtl/9Bz6Q+zHU1dmK6re8xbYK+dOfbDB9++3w4x/DzJlw7rlwwQVw8smjjnjxeXw8sPEB/hj4Y9LVr39tvV1WbTryasrDaMdxnjfG/Afwv0AU+DswMHY5Y8ylwKUA8+fPn9IxFov77oNLL4XNm21AJSKJlVNldE2NnQNi2bLMbpfPMPrGG+Hqq+26m8Z/DhIRERGZMj9c/UO+/NCX2f253QkD2nT13PM7qoDI176Yu8HlmKfRA0CoK0RT6/j7Gu2LMqt5VuoVNTfDnXfSsvwY/vnHz8Onhqa0Jcl/r/tv/t8f/l9ay/7t0r9x9Jyj8zwikfLj9pfP2+SFfX22/cYhh9igqhg0NNge0u98p+1Lfd99Npj+r/+yFdQHHgjnnWcrpk84gaNmHcXP1/2ct9/x9glXW22qOXzG4VN0JypTQSYwdBznVuBWAGPMvwE7EixzC3ALwHHHHedM6QCLhFuFGAwqjBaZSDlVRoM96qiuLrPb5DOMXrfOfum8YQMsXZr79YuIiIika2vnVroHutkQ3sDSWdm/Mal/+m+86IVF/hNyOLrc8jbZN3ih7hDzWueNuz5lz+h4Rx3Ff7//GD74n6vh298e6ek6BZ597Vkaaxp59JJHE7YbAdi+dzvn/Ooc1u9arzBaJAu7u3YDMHPazPxs4Ac/sB8I7703ZX/mgmhqshXR555rA4J77rHB9E03wQ03wIIFXHneubzlLb9i/8ELJ1yVt9Gb3hd9krWChNHGmJmO47xmjJkPnAOsKMQ4ip0vdlRAIGBb44hIYuVUGQ12LoZM5TOMDgRGzhVGi4iISCGFuu2bnUAokH0Y7TjM+sdm7l/SwMH103M4utzyNsbC6K7Eb/AivRmE0cCTbz+aWU/8g7d+4Qtw6qlw/PE5GWcqgVAAn9fH8gOXJ11m6aylVJmqlJOLiUhi7n7C/RIrtysPwTXXwJlnwpvfnPv151pzM7z3vfa0dy/cfTfceSdVN3yXQ2/AVn+97nWFHmVFK0gYDfwm1jO6H/iE4zh7CjSOojZnDkybNhIEiUhi0ag90rCxsdAjKZzp0+1jEA7ndr2OMzqMFhERESmkcLd9szOp0HLjRqbv7WH74UtyNKr8iK+MTiStCQzjNNe3cOnZVbz0s1m2n+ozz4xUQQwO2tAmHIY9e+wpHLaHvqdSXw8LF8LixbZf65jq50AowFGzj5pwFXXVdXS0dSiMFsmSu59wv8TKqauvhn374Fvfymxio2LQ2goXX2xPr71mQ+hzz4Wnn1YLggIqVJsOzUqQBmNsq47gxJN9ilS8SMR++Vlq/xdzqarKTmqc68roXbvs+w7QvkhEREQKzw1cguFJvDFZtQqA6LFH5mJIeTNRZXT/YD+9g73pTWAY01Lfwss13Qz+4r+pPu10OPJIO2HJnj02iHZy0B2zuRkWLbLB9KJFDC7sYPHqjaw89TT4xz9s39n+fnvunmK/f3DDdP62Zx2cM7U9rUXKQagrRJWporUhi8NsJ/L88/DDH9o+0Ucckdt1T7WZM22V9PHH2z7Tf/1r+fT6LDGFqoyWNPl8sGZNoUchUtzcMLrSeb25D6PdauiaGlVGi4iISOG5wexkKmh7//IovXXQdFTythHFwJ3A0K0Gjxfts5OmZFIZ7bb02L/8KKb/9Kdwxx3Q1gbt7baqIdH5tGmpKz7274fNm2HjxpHTiy/C/fdT3dPD/QA/+zHw4wlX86XYuXN9K+bYY+G44+xp+XIbcFdy5YlICqHuEJ5GD1Umx1/kfPazdj9wzTW5XW+h+P22l/Rb3gKXXAK/+pW+/CoAhdFFzu+Hu+6yXxhnOqGZSKWIRsunX/Rk5DOMPvVUO5GhiIiISCHF94zO1uBf/8yTB4Fv5iG5GlZe1NfUM612WsI2HZE+O2lKJj2j3eA62hdl+kUXwUUX5WagAIceOv6yoSEe/OvPueYnl/Dj477GwbMPtx9qa2vtefyptpZf/u1n/M9vruMHM89l2t+fg+9/H3p77bra2mwwvWIF/PM/23BMRIaFu8PDX2DlzAMPwH33wXXXwYwZuV13Ib3pTfDNb8JnPgP/+q/w1a8WekQVR2F0kfP7YWjIftF88MGFHo1IcYpEFEaDDaO3bcvtOoNB+3nhjW+Ehx6yR3G2t+d2GyIiIiLpGBgaoLOnk5a6FnZ37WZP9x7aGzN8YxKN0vB8kFUr4d1ef34GmkPeJm/CMDqryuhYS49IbwSm4r1zVRXP1u7hzx3g/cDHoemACRf3NLyBn266jg9e8gFOXXCqrchavx5Wr7anVatscHTMMXD22VNwB0RKR6g7lNt+0QMDNqxdtAguuyx36y0WV14Jf/+77Yd95JFwzjmFHlFFUS16kfP57LkOjxdJLhpVmw7IX2X0okUjxS7qGy0iIiKFsqfbznt//IHHA1n2jX76aaqGHJ6YB4s9i3M5vLzwNnoT9oyO9MYqozPoGe0G125V9VQIhAK0NbSlFZL5PL7h2wC2Yvroo+HDH4Yf/Qj+53/s5Tt35mu4IiUr1BUanvQ0J269FZ591lZF19fnbr3Fwhi7XznhBDu5oQ4DnlIKo4ucP/ZlvcJokeRUGW15vXbS81wKBOx+SPsiERERKTS3d/KJB50IZNmqIzZ54Y7DDqKhpiFnY8uXnFZGx1p6uLedCoFQAL/Xj0mj3/P81vnUVdclf17dNgGvvprDEYqUh5xWRu/dC1/5CpxySnlXDDc0wG9/C62tdkLD3bsLPaKKoTC6yHk8NmBSNaJIcqqMtjwe6OqCnp7crG9oCDZssEH0okV2Xgfti0RERKRQ3FB2+dzlGAzBUBZvTFatYvPsBmbPS9DjuAglrYyeRM9ot6p6KgTDQfxptkOprqpmiWdJ8or32lo44AB45ZUcjlCkPIS6chhG/9u/wa5d8O1vl//EoXPnwu9/b4+4OO886O8v9IgqgsLoEuDzqRpRZCKqjLa8sfceuWrVsWOHDbZ9Pntk1oIF2heJiIhI4bih7NyWuXS0dRAIZ/jGxHFwnniCvx44ONwSoth5G73DFeHxsmnT4S47VZXR3f3dbNu7LaPH2ufxTVzxPmuWKqNFxugd6GV///7ctOmIRuG734V/+ic7aWglWL4c/vM/4ZFH4IorCj2aiqAwugT4/QqARCaiymgr12G0u99xW3RoXyQiIiKF5FZGe5u8+LwpQstENmzA7N7No3P7067WLTRPo4c9PXsYcoZGXZ5Nm46p7hm9IbwBIKPH2u/1syG8gcGhwcQLzJ6tymiRMdwvrDyNnsmvbM0a6O2F88+f/LpKyfveB5/9LNx0E/zwh+A4hR5RWVMYXQL8fnjpJdi/v9AjESk+Q0P2b0OV0bkPo92WHPFhdDCo/8siIiJSGG5ltLfRi9/jJxgK4mTyxuTxxwFYdVBmAWkheZu8DDlDdPZ0jro8mzYdU90z2m23kWkY3TfYx/Z92xMvoMpokXGGv6jLRZuOJ5+058cfP/l1lZprr4WzzoKPf9z2qH/9622l9H/9lw3pu7snvn0kAs89B3/6k620/upXYePGKRl6qakp9AAkNV/sqKYNG+Coowo7FpFiE429l1ZldH4qo5uabBstsPuiSMS+/589OzfbEBEREUlXqDtETVUN0+un4/f6ifRFeHX/q8xuTvONyapV9DU38tyMbnze0mnTATaIj696jPZFMRiaapvSXtdU94x2K9czbdPh3rajrWP8Am5ltOOUfy9bkTQNf1GXizYdTz5pJwxyJwytJNXV8Otfw89/Ds88A+vWwY9/bCdmAjuJ0sEHw9KlsGSJ7au9ffvIae/e0eszxrY6Wbx46u9LkVMYXQLcqsRAQGG0yFhuGK3K6PyE0T7fyPv8+H2RwmgRERGZauHuMJ5GD8aY4TA5EApkFEZv9c+iumZH4qCzCLnhUqg7hI+RUDfSG6G5rhmTQSBbXVVNY03jlFVGu89NJn2t3SrqQCjAmYvPHL/ArFm2OjEa1QcAkZicV0afeurk11OqmpvhYx8b+X1wEDZtgr//3YbT69bZx+hXv7ITqs6bZ8Pm006zP8ef5s61E6/KOAqjS8CSJfY8mMVk0SLlLhIr7NB7UfDEimXC4+e4yUowCMuWjfzuhtHBYGW/PxEREZHCCHWPVAe7oWUwFOTUBWm8MYlE4Nlneeacg1ncvpiaqtL4KBxfGR0v2hfNqF+0q6W+Zcp6RgfDwYzbocxunk1zXTPBUJIPv25FxCuv6AOASEzOKqNfesmeTjghB6MqE9XVtkLL54Nzzx25fHDQXidZUc/oEtDcbL9Q0cRhIuOpTceIxkZ7ykVldH+//QLYH/f5Yf58qKvTvkhEREQKI9QVGg5nF7QuoLaqNv1JDJ96CoaGeGh26bTogJFwyZ2gzBXpi2RUcexqrmuesjA6EApk1KIDwBiD3+snEE7yvLphtPpGiwzLWWW02y9aYXRqCqInRWF0ifD7FQCJJKLK6NG83tyE0Zs32y97fXGfH6qr7RFI2heJiIhIIYS6Q8PhbHVVNUs8S5KHlmOtWgXA71t34veUxuSFwHAluBs2uSJ9kewqo+tapqRNx96evby2/7WsJor0eXzJv2SYNcuev/LKJEYnUl7C3WEaahporG2c3IqefNK2lYg/PFYkDxRGlwi/X206RBJRZfRouQqj3f2Nf8znB+2LREREpFDiK6MBfF5f8nYOY61aRf8hPl6t7c0qIC2UtoY2qkxVwjYdLXVZVkZPwQSGwbB9XrJ5rP1eP1s6t9A32Df+SlVGi4wzdt+YtaeeshOVNTRMfl0iE1AYXSJ8Pti9O3e9YEXKhSqjR8tVGO1WP48No30+2LDBVk2LiIiITKVQ9+jAxe/xsyG8gcGhFG9MHAeeeILXltrJeEqpTUeVqaK9oX18ZXRvdm06WuqnpjLarWzOtE0H2DB6yBli055N46884ACoqlJltEic+KNGsjY4CKtXq0WHTAmF0SUifuIwERmhyujRchlGt7fb9cXz+6G3F7Zvn/w2RERERNLV3d9Nz0DPqMDF7/XTO9jL9n0p3pgEAhAOE/CNnvywVHibvOPC6GwnMJyqntGBUACDYbFncca3dQPshK06qqthxgxVRovEGftFXVaee85+uFYYLVNAYXSJUBgtkpgqo0fzenNzBEUwOL4qGrQvEhERkcJww1i3hzKMVDinbNUR6xf91PxqmmqbmNsyNz+DzBNvo3dcm45IXySrNh1T1TM6GA6yoG0BDTWZH+6f8nmdNUuV0SJxQl05qIzW5IUyhRRGl4hFi+zRSJo4TGQ0N4yeNq2w4ygWHo8Nox1ncusJBBKH0e6EhtoXiYiIyFRyw9hRbTpiFc5JJ7tzrVoFbW38pWk3SzxLqDKl9THY2+Ql3D262iDbyuiWupYp6RkdCAWyatEB9guHA5oOSP68zp6tymiRODmpjH7ySXtorK902hhJ6Sqt/8IVrK4OOjoUAImMFY1CYyPU1BR6JMXB67XtvvbuzX4dXV22DUei9yFz5tjgX/siERERmUpuZXR89d+c5jlMq52WOox+/HE44QRe3BMsuRYdYMPZ+DYdQ87QpCYwjPZFcSZbuTABx3EIhAKTeqx9Hh+BcJLnVZXRIsMcxyHcHR511EhWnnwSjj8ejMnNwEQmoDC6hPj9OjReZKxIRC064rk9nifTN3rjRnueqDLaGO2LREREZOolqow2xuDz+giGJ3hjsncvrF/P4AnHs7lzM35P6YXRY9t0dPV3AWRXGV3fwqAzSM9AT87GN9aurl3s6903qTDa7/Unb9PhVkbnMVAXKRWRvggDQwOTq4yORmH9erXokCmjMLqE+Hy2GlH/c0VGRKOavDBeLsJot+o5URgNI/siERERkamSqDIabGg5YWX0U0+B4/DKkQsZGBoY7kdcSryNXvb376d3oBdguM1GS312ldFAXicxdJ+PbNt0gH1eX4q8lLi/9axZdkbtyRwKKFImhr+om0zP6DVrYGhIYbRMGYXRJcTvt8GbjkgSGaHK6NFyGUYvWZL4er8fNm+Gvr7styEiIiKSCbdn8thD0f0eP5s7N9M3mOSNyapVYAzPLrQTjJRimw43ZHIDeTdIznYCQyCvkxi6YfRk23QAbAhvGH/l7Nn2XH2jRUa+qJtMZbQ7eeHy5TkYkUhqCqNLiFulqMPjRUaoMnq0XITRwaDtDZ0s5Pf77Rfnmzdnvw0RERGRTIS6QjTVNtFQ0zDqcp/Xx5AzxOY9Sd6YrFoFhx/O8/0vAyUaRsdCJrcC0g2Ss2nTMVwZncdJDIOhILVVtSxoW5D1OtznKWGrjlmz7LmqtERyUxn95JOwaBHMmJGjUYlMTGF0CXEnE9Ph8SIjVBk9midWLBQOT7zcRAKB5C06QPsiERERmXqh7lDCyj83tEzYqmNoCJ54AlasIBAK0NbQNrnqwQJxQya3OnwybTrc2+S1MjocYFH7Imqqsp9hfInHHqKX8HlVZbTIsJxVRqtFh0whhdElZP58qKtTACQST5XRo7W320kGJ9umY6Iw2r1O+yIRERGZKqHuUMLKvwnD6BdfhM7O4TDa7/VjjMnzSHPPbU3ihk45qYzOc8/oyVagT6ubxoEtBxIIJ3heVRktMsytjB7bwihtL71kTwqjZQopjC4h1dW2h6vadIiMUGX0aNXV0NaWfRjd2Qm7do1UPyfi8dh2INoXiYiIyFQJdSWujPY0evA0egiGE7wxWbXKnq9YQTAcLMkWHTC+TUcx94wecobYEN6Qk8fa7/UnbtPh9do3vaqMFhk+YqK9sT27Fbj9ohVGyxRSGF1ifD5VI4rEi0RUGT2W15t9GO0GzBNVRoP2RSIiIjK1klVGgw0tE1ZGr1oF7e10L5zHtr3bhifFKzVjJzCcTGW026YjXz2jd+zbQc9AT04e66TPa1UVzJypymgR7H6hraEt+7Y4Tz4JtbWwbFlOxyUyEYXRJcbvhw0bYHCw0CMRKTzHsW06VBk92mTCaDdgThVG+/0Ko0VERGTqhLvDSXuiThhGn3giGzo3DS9XityJG4croyfRM9oNsPNVGe0+D7mqjA51h4YrP0eZPVuV0SIk76eftieftEF0Q0PKRUVyRWF0ifH7oa8Ptm8v9EhECq+nx34xozB6tMlWRldV2cmUJ+L329Zi+/dntx0RERGRdA05Q4S7w0l7ovo8Pl6KvMT+vrg3Jp2dsH79cIsOKN0wGmyrjpxURsfadOSrZ7TbViMXj7VbXZ2wVcesWaqMFiHWwijJUSMpDQ7C6tVq0SFTTmF0iXH7uKoiUcRWRYPadIzl8UA4QQFJOgIBWLAA6usnXs7dF23YkN12RERERNK1t2cvQ87QhJXRABvCcW9M3D6osckLgZJt0wG2VYdbIRzpi9BQ05DVYfl11XXUVNXkrU1HIBSgqbaJuS1zJ72uCSenVGW0CDDJyujnnrPVRccfn9tBiaSgMLrEuIfOK4wWsf2iQZXRY022TUeqFh2gfZGIiIhMHbcieKKe0TAmtFy1CoyB448nEAowu3l2Vm0tioWn0TP8OER6I1lNXghgjKGlriV/bTrCAXweH8aYSa9rYftCqk114jB61iwbRjvOpLcjUspCXaGkR42kpMkLpUAURpeY2bNtFWgwwZFKIpVGldGJeb02qO/ry+x2jmP3Lb40ioaWLLHn2heJiIhIvrm9kpNV/y3x2DcmbjsOwIbRRxwB06cTDAdLukUHxNp0xB6HaH80qxYdrua65ry26cjVY11XXUdHW8fo59U1ezb098OePTnZlkipmqiffkpPPgnt7el9ABTJIYXRJcYYu59QNaKIKqOT8cbei2TaquO112DfvvQqo5ubYe5c7YtEREQk/1JVRjfXNTO3Ze5IBe3QkA1ZVqwAbMV0KbfogNE9oyO9kUlVebfU56cyun+wn017NuX0sU46OeWsWfZcfaOlgg0MDbC3d2/2PaOffNK26MjBkQwimVAYXYL8fgVAIqDK6GTcMDrTVh3ufiWdMNpdTvsiERERyTe3V/JE1X+jQsvnn4e9e+Gkk9jbs5fX9r9W+pXRsZ7RjuMQ7SvOyujNnZsZdAZz+li7z6szth3H7Nn2XH2jpYKls29MKhq1k7yqRYcUgMLoEuT3w5YtmR+CL1JuVBmdWLZhtNtyI92jtPx+tekQERGR/HPbU0zUF9Xv8bN7+4vwrW/B2WfbC08+ebjFQ8mH0Y1eBoYG2Ne7j0hf9j2jgbz1jA6Gcv9Y+zw+9vfv55XomApoVUaLjLQwyqYyevVqexSJwmgpAIXRJcjns/uMTZsKPRKRwnLDaFVGj5Ztm45AAGprYcGC9Jb3+WD37sy3IyIiIpKJUHcIg6GtoW38lY4Djz/OZT9Yzbqvh+Gzn7VB5W9/C0uWDFdLl3ybjljYFO4OT7oyuqW+hUhv7iujhx9rb27bdMSve5gqo0WGW/dkNYHhU0/Z8+OPz+GIRNKjMLoEuYfQ6/B4qXRumw5VRo/mib0XyaZNx5IlUF2d3vLuvkjV0SIiIpJPoa4Q7Y3tVFfFvUnZtw9++EM46ig4+WT8f3me/zwG1j3w3/CXv8C73gXYENNgWOxZXKDR54YbNoW6Q5PuGd1c15yXyuhAKEB7Q3v2k6klkDSMbm+3VRSqjJYKlmpy1wk9+SQsXgwHHJDjUYmkpjC6BLmH0CsAkkqnNh2JTaZNRyYTKSuMFhERkakQ6g6NhC2vvAIf+YidSfnjH4eaGrjlFjY9+2c+9VZYN2t0b+FgOMiCtgU01DQUYOS5497/UFeIaF900m068tEzOhgO4vf6MTmcDG1e6zzqq+uH260MM8ZWwKsyWirYcM/obNp0PPmkWnRIwdQUegCSOY/Hhk2qjJZKF43azx91dYUeSXGZNs0+JpmE0UNDNlQ+66z0b7NoEVRVaV8kIiIi+RXqDo2ELbfcYk+XXAIf+xgsXw7GsHCwjypTNa6CNhAKlHyLDhgJm0LdISJ9kclPYJinNh2v63hdTtdZZapY4lkyvjIabBitymipYG6bjowro196yZ7UokMKRJXRJcrvVwAkEonYqugcFl+UBWPsF1aZhNHbt0Nv70i1czrq6qCjQ/siERERya9wd3gkbNm1C9ra4L/+ywYpsTeCddV1dLR1jAotHcchEAqU/OSFMBI2vRx5mYGhgUlXRvcO9tI/2J+r4dHV38X2fdvxe3L/WPu9/sRh9OzZqoyWihbqClFbVZv5l1NPPmnPVRktBaIwukT5/To0XiQa1eSFyWQaRrv7k0zCaHd57YtEREQkn0JdoZEJusLhkQkyxvB7/aPaOezq2sW+3n1lEUa3N7YDsKVzC8CkK6OBnPaN3hjeCJCXx9rv9bNxz0YGhwZHX6HKaKlw7lEjGbfGefJJ23N92bK8jEskFYXRJcrns0dVRHM/74RIyXAro2W8TMNot7o5k57R7vKBgJ3IXkRERCQfRvWMDoVGJsgYw+fxEQgFcGJvTNxq2nJo01FTVUNbQxtb924FmNQEhu5tcxlGDz/W3tw/1j6Pj77BPrbt3Tb6itmz4bXXbL85kQoU6o77oi4TTz5pg+iG0u6lL6VLYXSJcqsXN2wo7DhECkmV0cl5PLZwKF2BgO01PWdOZtvx++3zoKIUERERyYe+wT6ifdGRntEpKqOjfVFeido3Jm5AWg6V0QCeRg9bO20YnYvK6FxOYpjP4N99/sa16pg1CwYHM5+1W6RMhLpCmfeLHhyE1avVokMKSmF0iXLDaB0eL5VMldHJZdOmw+/PvP+29kUiIiKST6GuMRN0TVAZ7YaWbquOYChIbVUtC9oW5H+gU8Db6B2pjJ5kz2jIbWV0MBxkTvOcSVVsJzP2eR02e7Y9V99oqVDh7vDIF3Xpeu452L9fYbQUlMLoErVkiT3XxGFSyVQZnZwbRqfbPiMQyLxFB4zcRvsiERERyYdQdyyMTqMy2q3KdStoA+EAi9oXUVNVk/+BTgFvk5d9vfuAyVVGu4FxpDe3ldH5aNEBMHPaTFrqWhJXRoMO0ZOKNaqFUbo0eaEUAYXRJWraNDjwQAVAUtlUGZ2c1wv9/en1le/vh82bM5+8EGD+fKir075IRERE8iPcbfuOeRu9MDAAnZ1JK6Pnt86nrrpuJIwOBcqmRQcwKnSaTAVyvtp0+D35eayNMfi9/vFhtCqjpYI5jpNdm44nn7Rf6LkVjiIFoDC6hPn9OjReKpvC6OS8cUeyprJ5s20dlk0YXV1t38doXyQiIiL54Lbp8DR6YM8ee2GSyujqqmqWeJYQDAcZcobYEN5QvmF0EbXp6OzpZFfXrrw+1n6vf3ybDlVGSwXr6u+id7A38zYdTz4Jxx+feX9GkRxSGF3C/H5VI0plU5uO5DIJo939SDZtOtzbaV8kIiIi+TCqTYc7O3OSymiwrToCoQA79u2gZ6AnLxPqFUp86JSTCQxz1KYjGLIhcb7adIB9Xrd0bqF3oHfkwtZWqK9XZbRUJHff6GlM/OXcMMeBjRvhzjvhqqtg/XobRosUUHk0z6pQPp8NmiZomyZStgYGoKdHldHJuPsE9zPbRNwgOZvKaPd2999vq6urq7Nbh4iIiEgioyYwDP3dXjjBhx+/18/9G+7nhd0vDP9eLnLVpsO9ba4qo932GfmujB5yhti0ZxOHzjjUXmiMrY5WZbRUoHGTu4INnrdtg9WrR586O+319fU2iD7//KkfsEgchdElzA2OgkH1npfK4/ZCVmV0YplWRnu92X+p5fdDX59937NwYXbrEBEREUkk1B2ivrqeptqmtCqj/V4/fYN9/N+m/xv+vVy4FZDVppr66vqs19NU2wTkrmd0IBTAYFjcvjgn60vEfR6D4eBIGA22b7Qqo6UCjZvcdedOGzTv2GF/r6mBpUvhPe+B446D5cvh8MOhtrZAIxYZoTC6hLlhdCCgMFoqTyT23lmV0YllEkYHg9m36ICR2waDCqNFREQkt0JdIbxNXowxI29sJvgG3W3L8cfgH2mqbWJuy9ypGOaUcEOnlvoW+3hkqcpU0VzXnLPK6GA4yIK2BdTXZB+Qp+K2ABk3ieGsWbB1a962K1KsRk3uCrb9xo4d8PnPwznnwJFHQkNDAUcokpx6RpewhQuhqkq9WqUyqTJ6Yu5ntHQro7Nt0QGjvxgTERERyaVwT3gkbEmzMhrguV3P4fP4JhXaFhv3cZhMv2hXc11zznpGB0KBvFegtzW0MaNpxvgwWpXRUqGG23S4ldG7d9vzf/onWwWtIFqKWEHCaGPMlcaY9caYZ40xdxhj9FeShbo6G0gHg6mXFSk3qoyeWG0tTJ+eOozu6rJfoE8mjJ49234poDBaREREci3UFRqZoCsUstU4ra1Jl5/dPHs4rC2nFh0QVxldN/k3wC11LUT7J18Z7TiODaM9+X+s/V4/wfCYD7+zZsGuXXbyEpEKMm4CQzeMPuCAAo1IJH1THkYbYw4ELgOOcxznCKAauGCqx1Eu/H4FQFKZVBmdmtebOozesMGeT6ZNhzF2X6QvxkRERCTXQt2hkcq/cBja220gnYQxZrhVR9mF0UVYGf3a/teI9EWm5LH2eX2JK6OHhkaCOJEKEeoK0VzXTF11nb1g1y77wSzbiYBEplCh2nTUAI3GmBqgCXi5QOMoeT6fDaMdp9AjEZlaqoxOLZ0w2v0yazKV0TCyLxIRERHJpVBXaKRNRyg0YYsOlxuMuqF0uWiua6a2qpaW+hxURte35GQCQzccdns655Pf4+flyMuje13PmmXPX3kl79sXKSah7rh9I9gvZNrb7cSFIkVuyl+ljuO8ZIy5HtgGdAMPOI7zwFSPo1z4/bB/v/3fO2dOoUcjklowCC+8AG9/++TWozA6NY8H/vEP+OIXky/z1FP2fMmSyW3L74df/xq+8AX7hfxkNDXBlVfCtGmTW4+IiIiUNsdxRgcu4XBaVX9uGF1uldHGGDyNnpy16Vizcw1f/L8J3iimYf2u9cDUPNbuNjaEN7Bs9jJ74ezZ9lx9o6XCjDpqBGwYrRYdUiKmPIw2xrQD7wQWAp3Ar40x73Mc57/HLHcpcCnA/Pnzp3qYJWPhQnu+ZYvCaCkN//Zv8Mtf2i9RJjjCMqVdu+y5jkJK7qST4OGH4frrJ17ulFMm3+7kda+Db38bvvWtya3HcWBgwIbb73nP5NYlIiIipS3SF2FgaGAkcAmFYO7clLc7Y9EZ3PXcXRwx84g8j3Dqnbn4zJzcr+MPPJ4HNj7A9Y+neKOYhkMPOJT5rfn/zO6G0S/ufnEkjFZltFSocHd4fGW0wmgpEYWo3z8D2Ow4zi4AY8xvgZOAUWG04zi3ALcAHHfccWpCkYS7r3EnlhYpdi++CD09sH07LFiQ/XqCQXsUUhpHalasr37VnqbCG94w0sd7Mrq6bEW0Wn6IiIhIuNt+yBlVGX1E6iD21AWn8twnnsvn0ArmZ+/6WU7W8y+v+xf+5XX/kpN1TZXFnsUAoycxVGW0VKhQV4iOto6RC3bvho6OZIuLFJVC9IzeBpxojGkyxhjgDcDzBRhHWfDETSwtUgrcSe4mO9ldIDD5PsdSfJqaYN48TYYoIiIiNmwB8DTGfehRJULFaqptYt70eaPD6OZmaGxUGC0VJ2HP6BkzCjcgkQxMeRjtOM6TwF3A34B/xMZwy1SPo1x4445YEyl24fDIRNeTrXxVGF2+NBmiiIiIgA1bANumo6/PHoalHm0Vze/1D0+aCNjJSmbPVpsOqSiDQ4Ps6d4z8kWd49g+lmrTISWiEJXROI7zVcdxDnEc5wjHcf7JcZzeQoyjHLS22r67CqOlFMRXu04mbOzutm0+fOU1QbrE+P0Ko0VERGSkMtrb6B3pS6jK6Irm8/hGh9Fg+0arMloqSGdPJw7OSGV0JAL9/QqjpWQUJIyW3KmqssUBCqOlFLhhdEvL5MLGDRvsuSqjy5Pfbz9var8mIiJS2UZVRrthtCqjK5rf6yfcHR7+ogJQZbRUnFH7Rhg5/FhhtJQIhdFlwOtVaCOlIRCwX6C84Q2T6wnsBtkKo8uTW/GuvtEiIiKVbVTPaPcDjyqjK5rfaz8AjOobrcpoqTDjJndVGC0lRmF0GfDGFQqIFLNAwE7we/jhsHmzbf2XDTekXLIkZ0OTIuJ+yaBWHSIiIpUt3B2mtb6VmqqakTBaldEVzee1VQujWnXMnm3DuIGBAo1KZGoNtzAaWxmtCQylRCiMLgNq0yGlIhi0QaPfD4ODNpDORiAAc+bYdh9SfhYuhOpqhdEiIiKVLtQdGpmgSz2jBVjYtpBqUz06jJ41a2QCN5EKMNymw62Mdl/7qoyWEqEwugyoTYeUAsex4aIbRkP2bRjc9Uh5qq21gbTadIiIiFS2UHdopPJPldEC1FbXsqh90eg2HbNn23P1jZYKMaqFEahNh5QchdFlQGG0lIJXXoFo1PYDdnsCZ1v5GgiMrEPKk9+vymgREZFKF+oKjVT+hcNQU6ND4wSf1ze+MhrUN1oqRqg7RJWporWh1V6we7fdP06fXtiBiaRJYXQZ8Hqhqwt6ego9EpHk3CpXv9++Zj2e7MLGzk57FJIqo8ub329fM45T6JGIiIhIoYyrjPZ4wJjCDkoKzu/xEwwFcdw3iqqMlgoT6rItjKpMLNLbvdtWRWv/KCVCYXQZ8I45ck2kGLnBsxsiu2FjpuJDbSlfPh/s3w87dxZ6JCIiIlIo4yqj1S9aAL/Xz/7+/eyMxt4oqjJaKky4Jzyyb4SRMFqkRCiMLgMKo6UUBAJQVwfz5tnffb7sKqPd26hNR3lzv2xQqw4REZHKNDA0wN7evSOBSyikMFoA26YDGGnVMW0aNDerMloqRqgr7qgRsGH0jBmFG5BIhhRGlwHPmAmmRYpRMAhLlkB1tf3d74cdO2yLmUzXYwwsXpz7MUrxUBgtIiJS2fZ07wHiJugKhzV5oQC2MhoY3zdaldFSIULdodGV0bt2qTJaSorC6DKgymgpBYHA6NYa7s8bNmS+no4OqK/P2dCkCB10EDQ0ZNfKRUREREpfqNt+uBnVM1qV0QIcNP0gGmoaCIbi3ijOnq3KaKkYbs/oYWrTISVGYXQZUBgtxW5w0IbO8a013J8zrXwNBNSioxJUVdlKelVGi4iIVKZQVyyMju8ZrcpoAapMFUs8SwiEVRktlWlUZfTgoN0/KoyWEqIwugwojJZit20b9PWNrozOJox2HFspq8kLK4PfrzBaRESkUo2qjO7utidVRkuM3+sf3aZDldFSIXoGeujq7xo5amTPHvtBWWG0lBCF0WWgsdGeFEZLsXJbLcSHyM3NMHduZm0YXnsN9u1TGF0pfD7YuNF+2S8iIiKVZVRltDs5jiqjJcbv8bMxvJHBodgbxVmz7Oukr6+wAxPJs3FHjezebc81gaGUEIXRZcLrVRgtxcutbh3bXiPTytdk65Hy5PdDfz9s3VrokYiIiMhUG1UZ7X7QUWW0xPi8PvqH+tm6N/ZGcfZse/7aa4UblMgUCHfbL+eGK6PdMFqV0VJCFEaXCY9npGBApNgEArYS2n2P6PL5MgujE1VYS/lyn2e16hAREak84e4wNVU1tNS1qDJaxvF77RvF4VYds2bZc/WNljI3/EWdWxm9a5c9VxgtJURhdJlQZbQUM7fPszGjL/f77Re5e/akt55AAGprYcGC3I9Rik+2k1yKiIhI6Qt1hfA0ejDGqDJaxnHD6GAoVq3iVr2ob7SUObdNh6cx9uWcKqOlBCmMLhMKo6WYBQKJW2u4la/p9o0OBGDxYqiuzt3YpHjNnAnTp2fWV1xERETKQ6g7NFL5p8poGWNG0wym109XZbRUnFEtjGAkjNaXdVJCFEaXCYXRUqz6+mDLlsStNTKtfHUrrKUyGJN5X3EREREpD6Hu0EjYospoGcMYg9/rJxAeE0arMlrKXMIJDJua7EmkRCiMLhPe2CTTjlPokYiMtmkTDA0lDpEXLYKqqvTCxqEhhdGVSGG0iIhIZQp1xVVGh0JQXw+NjYUdlBQVv9c/Uhnd2GgPqVNltJS5UHeIxppGGmtj+8Pdu2HGjMIOSiRDCqPLhNcLg4Owd2+hRyIymhskJmrTUV8PHR3ptWHYvh16exOvR8qXzwdbt9rnXkRERCrHuDYdXu/4CUikovk8PrZ2bqV3IPZGcfZsVUZL2Qt3h0eOGgE7gaH6RUuJURhdJrxj2qmJFIuJwmj38nQqX93AWpXRlcXvt0d8bNxY6JGIiIjIVAp3h0cm6AqF1C9axvF7/Tg4bNwTe6M4a5Yqo6XsjfqiDmxltMJoKTEKo8uEJ+59mkgxCQbt/8Zknx/cNgypWsy4gbXC6MriPt9q1SEiIlI5uvq76BnoGan+cyujReL4vfaN4nCrDlVGSwUIdYVGvqgDhdFSkhRGlwnvmLk9RIpFIDBxaw2/H6LR1EUMgQBMmwZz5uR2fFLc3NdOOq1cREREpDyMm6ArFFIYLeP4PPaNYjAUe6OoymipAKMmdwWF0VKSFEaXCYXRUqwCgYmrmd2wMVXlazBol1WrwMrS2gozZ6oyWkREpJKEumNhdHxltNp0yBitDa3MnDZzdGV0Zyf09BR0XCL5NGpy195eiEQ0gaGUHIXRZUJhtBSjaBRefnniMDrdNgypQm0pX24rFxEREakMoyqjHUeV0ZKU3+snEI69UZw1y56/9lrhBiSSR47j2AkMG8cEQKqMlhKjMLpMtLfbilGF0VJMNmyw5xO16Zg/H+rqJm7D0N8PmzdPvB4pXz6f2nSIiIhUklGV0fv32zeDqoyWBHwe30ibjtmz7bn6RkuZ2te7j0FncOSokV277LnCaCkxCqPLRHU1tLXZI9hEikU6kw5WV8PixRNXvm7eDIODqoyuVH4/7Nxpj0ATERGR8hfuth9qPI2ekWobVUZLAn6vn53RnUR6IyOV0eobLWVq+Is6tzJ69257rjBaSozC6DLi8agyWoqLW826ZMnEy6Vqw5BOqC3ly33eVR0tIiJSGUa16XCrbVQZLQn4vfaNYjAcVGW0lD133+hpjO0PFUZLiVIYXUa8XoXRUlwCATjwQJg2beLl/H7YuNFWPydbD6hNR6Vyn3eF0SIiIpUh1B1iWu006mvqVRktE/J57BvFYChoZ70GVUZL2Ro3uavCaClRCqPLiMJoKTbpTjro99uJgLdvT3x9MGiLYfQZpDK5lfWaxFBERKQyhLpDI2GLKqNlAks89o1iIBSA+no7mZIqo6VMjTpqBEbCaH1QlhKjMLqMKIyWYhMMphdGu5WvycLGdENtKU+NjXaiS4XRIiIilSHUFRoJW1QZLRNorG1kfut8AuHYG8XZs1UZLWVrXGX0rl32C5iamgKOSiRzCqPLiMJoKSahkD2l01rDDZonCqPVoqOy+XwKo0VERCqFKqMlEz6Pz7bpADuJoSqjpUyFu8MYDO0N7faC3bvVokNKksLoMuL1QiQCfX2FHonISH/fdCqaZ8+G5ubEPYG7umDHDlVGVzp3kkvHKfRIREREJN/C3eGRCbpCITsBSX19YQclRcvv9fNi6EUcx1FltJS1UFeItoY2qquq7QUKo6VEKYwuI26xwJ49hR2HCGQWRhuTvPJ1w4b01yPly++Hzk4d/SEiIlIJxrXpUFW0TMDv9dPZ02lbGKgyWspYqDs08kUdKIyWkqUwuox4x7RVEymkQACqqmDhwvSWdytfE60H1Kaj0qXqKy4iIiLlYcgZYk/PnpEwOhxWv2iZkM9j3ygGQgFbGR2J2MMrRcrMqBZGYMPoGTMKNyCRLCmMLiMKo6WYBAI2iK6rS295vx+2bBnfZsatsFYYXdncyvhErVxERESkfHT2dDLkDI0ELqqMlhT8XvtGMRgK2spoUKsOKUujjhpxHFVGS8lSGF1GFEZLMQkGM2ut4fPB0BBs2jT68kAA5s61PaWlcnV02EmiVRktIiJS3kJd9sOMKqMlXR1tHdRU1YxURoPCaClLoyqjo1Ho7VUYLSVJYXQZURgtxcJxbGiYSTWzG1yPDRszXY+Up9paW2mvMFpERKS8hbpjYbQqoyVNtdW1LGxbSCAcGKmMVt9oKUOjKqN377bnCqOlBNWks5Ax5h7AGXPxXmA18CPHcXpyPTDJnMJoKRY7d8L+/ZlXRsP4NgzBIJx9ds6GJiXM71ebDhERkXIX7g4D2Em6hoZUGS1p8Xv9tk3H6xfY2dH//nd9iJCy0j/YT6QvojBaykK6ldGbgCjw49hpH/Aq4I/9LkVg2jRbPRgOF3okUuncwDCTMNrjsZ8z4itf9+yBXbsyW4+ULzeMHhoq9EhEREQkX0a16di3z/7jVxgtKfi9foLhIEOedli5Eu66q9BDEsmpUV/UgcJoKWnphtFHO45zoeM498RO7wOOdxznE8AxeRyfZMAY+z5NldFSaG6gnGl7Db9/dBityQslns9nJ0Z/+eVCj0RERETyZVSbDrfKRm06JAWfx0dXfxcvR16G97wHnn0Wnnuu0MMSyZlxLYzcMHrGjAKNSCR76YbRM4wx891fYj+7X7/05XxUkjWF0VIMAgGor4d58zK73dg2DNlUWEv5cl8HatUhIiJSvkJdIapMFW0NbSMfbFQZLSn4vfaNYjAUhHe/21Zq/frXBR6VSO6Mm9xVldFSwtINoz8D/MUY87Ax5hHgz8BVxphpwE/zNTjJnMJoKQbBICxZAtXVmd3O54OXXrITA4MNtauqYNGi3I9RSk+ySS5FRESkfIS6Q7Q3tFNlqlQZLWlzw+hAKABz5sAppyiMlrIyrjJ61y77gbu1tYCjEslOWmG04zj3AT7gitjpYMdx7nUcZ7/jODfkbXSSMYXRUgwCgexaa7hh44YNI+tZsMBWWYsceCA0NCiMFhERKWeh7tBI2KLKaEnTgdMPpKGmwYbRYFt1rF+vVh1SNhJWRh9wgD0KQKTEpFsZDXAscDiwFHiPMebi/AxJJkNhtBTa4CBs3Jhda42xbRgCAbXokBFVVfZLDoXRIiIi5SvcHR6ZoEuV0ZKmKlOFz+MjGI59kFCrDikzCScwVIsOKVFphdHGmJ8D1wMrgeWx03F5HJdkyeOx79kcp9AjkUq1bRv09WUXIi9ZYs8DAfsaDgYVRstoY/uKi4iISHkJdYVGKv/cKhuF0ZIGv9c/Uhk9ezaceir86leFHZRIjoS6Q9RW1dJc12wv2L1bkxdKyUq3Mvo44GTHcT7uOM6nYqfL8jkwyY7Xa4PA/fsLPRKpVG7VajZtOqZNs60YAgF49VWIRLJbj5Qvn89W3g8MFHokIiIikg+j2nSEwzB9OtTUFHZQUhJ8Hh8b92xkYCj2RvE977FtOtavL+zARHIg1GX3jcZty6HKaClh6YbRzwKz8zkQyQ3vmCICkanmhtHZVjS7la+TXY+UJ7/fBtFbthR6JCIiIpIP4yqj1S9a0uT3+hkYGmBr51Z7wTnnqFWHlI1Qd9y+EewEhgqjpUSlG0YfADxnjPmTMeYP7imfA5PsKIyWQgsGoaUFZs3K7vZ+vw2i3VYMCqMl3ti+4iIiIlI+egd62d+/fyRwCYfVokPS5vfaN4qjWnW87nVq1SFlYdRRI4ODdv+oMFpKVLph9NXA2cC/Ad+KO0mRURgthRYI2FYK2U7q6/PZ1++qVVBXB/Pn53Z8Utrcti2axFBERKT8hLrth5jhwEWV0ZIBn9e+URwOowHOOw+ef16tOqTkjTpqpLMThoYURkvJSiuMdhzn0USnfA9OMqcwWgotEJhcNbN72/vug8WLobo6N+OS8jBjBrS2KowWEREpR+HuMACexlg1dCikymhJ24ymGbTWt44Oo885B6qqVB0tJS/cHR7ZN+7ebc81gaGUqAnDaGPMX2LnEWPMvrhTxBizb2qGKJnwxh3RJjLVenth69bchNE7d6pFh4xnzEhfcRERESkvoa5YZXR8mw5VRkuajDH4vX6C4bg3ivGtOhyncIMTmQTHcUb3jHbDaFVGS4maMIx2HGdl7LzFcZzpcacWx3GmZ7NBY8zBxpi1cad9xpgrslmXjNfebs9VGS2FsGmTPVrIbaWQjYULbfECTG49Ur58PlVGi4iIlKNRbToGB+2h6KqMlgz4vL7RldFgW3W88IJadUjJ2t+/n77BvpEWRgqjpcSlqoz2THTKZoOO47zoOM4yx3GWAccCXcDvslmXjFdXZyePUxgtheAGhJOpaK6rs4H0ZNcj5cvvh23boKen0CMRERGRXBpVGd3ZaStZVRktGfB7/Gzbu42egbg3imrVISVu3FEju3bZc4XRUqJS9YxeA6yOne8CAkAw9vOaHGz/DcBGx3G25mBdEuP1KoyWwnBbJ0y2otkNoRVGSyJ+v/1sunFjoUciIiIiuTSqMtr9QKMwWjLg9/pxcNgYjnujOGuWbdXx61+rVYeUpHGTu6oyWkpczURXOo6zEMAYczPwB8dx7ov9/mbgjBxs/wLgjhysR+IojJZ8uOmm1MUEGzfa/4duu5hs+Xxw//1q0yGJua+LCy+c+LVWXQ3/9m9wwglTMy4REZFK9cOnf8id6++c9Ho2d26moaaBptqmkUlw1KZDMuDz2jeKL4Ze5PCZh49c8Z73wMc+Bs8+C0cemda6vvLQVzit4zTesOgN+RiqCADrX1vPlX+6kr7BvqTLdPZ0AozuGd3YCE1NUzBCkdxLVRntWu4G0QCO49wPvG4yGzbG1AHvAH6d5PpLjTGrjTGrd7mHIEhaFEZLPnzve7bV2kQWL4Yrr5z8tt73Prj8cpgzZ/LrkvJz5JG29V+qLz0efhj++MepGZOIiEglu/WZW3n2tWcnvZ6FbQv51PGfsr+oMlqy4PfaQyuDoTGzXWfYqqNnoIdv/Pkb/GTtT3I9RJFR7n7xbv530//ikLxqv62hjXcc/A6Omn2UvWD3bpgxY4pGKJJ7E1ZGx9ltjPky8N+AA7wPmGzc+Wbgb47jvJroSsdxbgFuATjuuON0LE0GvF4dvi65NThoX1Of/jRce23+t7d8uT2JJFJfn97niAMO0BdzIiIiUyHUHeLNvjfz83f9PHcrVWW0ZGF6/XRmTZtFMDwmjJ45E047zbbquOYaMGbC9WwMb8TBGR9qi+RYMBxkbstcHr3k0fRvtHu3WnRISUu3Mvq9wAzsRIO/B2bGLpuM96IWHXnh8Yy8dxPJha1bob9fbTOktOgoERERkakR6gqNHD6es5WqMlqy4/P6CIQC4694z3vgxRfhH/9IuQ739oFQAEd9piWPAqEAPk+GH7QVRkuJSyuMdhwn7DjO5Y7jHB07Xe44TtZxpzGmCXgj8Nts1yHJeWOTTw8OFnokUi4CsfdymlBQSonCaBERkfzrG+wj0hfJfRgdDtvq1dbW3K5Xyp7f408cRmfQqsO9/d7evezqUttQyZ9AKDDcXiZtu3YpjJaSllYYbYyZYYz5pjHmPmPMQ+4p2406jtPlOI7XcZy92a5DkvN67STBe/YUeiRSLoKxo9MURkspURgtIiKSf+FuW6PkbcpDZXR7u52RWCQDfq+fV/e/yr7efaOvmDEDTj/dtupIUe0c3+ZDrTokX/Z072F31+7Mw2hVRkuJS7dNxy+AF4CFwNeALcDTeRqTTJJ7JJtCGMmVQABaWmyrNZFSoTBaREQk/0Jd9p9tXiqj1S9asuDz2pYHCUPk97zHfrhZt27CdQRCAeY0zxn+WSQf3C89MmrT0dcH+/ZpAkMpaemG0V7HcW4F+h3HedRxnA8CJ+ZxXDIJCqMl1wIBWxWdYp4PkaKi/vkiIiL551ZGexpzHByHQuoXLVlxq0wThsjvepettv/1rydcRyAU4I2L30hNVY3CaMkb97WVUWW0G/SoMlpKWLphdH/sfKcx5q3GmKOBg/I0JpkkhdGSa8GgWnRI6fF6Yf9+6O0t9EhERETKV6g7Vhmd6zYdqoyWLC1uX4zBjGq1Mcxt1fGrXyVt1bGvdx+v7n+Vww44jMXtixOvRyQHgqEgVaaKRe2L0r/R7t32XGG0lLB0w+ivG2Nagc8AnwX+E7gyb6OSSXHfs6kiUHKhtxe2bAFfhhP8ihSavpgTERHJv7y16VBltGSpsbaRea3zklc0v+c9ttrm739PeLXb3sPn9eH3JpkMUSQHAuEAC1oXUF9Tn/6NdsUm1FQYLSUsrTDacZw/Oo6z13GcZx3HOd1xnGMdx/lDvgcn2VEAI7m0caMtGlBltJQa7QtFRETyL2+V0aGQKqMlaxOGyO96F9TVwec/DwMD466Ob53g8/gIhoMMOUP5HK5UqEAokN3khaAwWkpaWmG0McZvjPk/Y8yzsd+XGmO+nN+hSbZaW20bLAUwkgvB2FFpCqOl1CiMFhERyb9QV4i66jqm1U7L3Ur7+yESUWW0ZM3v8RMMB3ESteI44AD4wQ/gT3+CK64Yd3UwHMRgWNy+GL/XT89ADy/teyn/g5aK4jgOwVBQYbRUpHTbdPwY+AKx3tGO46wDLsjXoGRyjLFFBApgJBcCsYICtemQUqMwWkREJP9C3SG8jV5MLme6dvsNqjJasuTz+ujs6WR31+7EC3zoQ/DZz9pQ+nvfG3VVIBRgXus8GmsbJ54MUWQSXt3/KpG+CD5Phh+03TBaX9ZJCUs3jG5yHOepMZeNP55FiobXqwBGciMQsPN8tLUVeiQimVH/fBERkfwLd4fxNOY4NHb/eStskSylFSJfey2cfbatjr7vvuGL41sn+Ly+1OsRyUJ8O5iM7N5tP5zX1uZ+UCJTJN0wercxZjHgABhjzgV25m1UMmkKoyVXgkG16JDSpMpoERGR/At1h/LTL/r/t3ff8ZGd5d3/v7e6tEWrGW8v3qI5Bhtc13gxxKaXYDCQAAkBAgmYnvAkBExIgJSHmucXQugtQEggBAwGEwyEDsY2xr2e0Xbvru3dM6ttGvX798eto12tNNKUM3POzHzer9e+pJ1yzwU+e6T5znWuW6IzGmULA75sLlv4Qa2t0pe/LJ1/vvSSl0h33ulGJ+Sy8lLu+WuWrFFPe8/86wBlCDfKLCuMZkQH6lyxYfQbJX1K0qOMMfskvUXS66pVFCqXStENiGj4PiM6UJ96eqSuLsJoAACqKRhyYzoiRWc0KrRx2Ua1tbQt3NG8aJH07W9LS5dKV1yhYOc9GhwenO6IbjEtyqQydEYjcn7gq6O1Qxt6N5T2xIMHCaNR94oKo621O6y1T5O0XNKjJD1J0hOrWBcqRGc0onDsmHTgAJ3RqF+cCwEAqK5wZnS0i0798CaMRpnaWtq0uW9zcSHy2rXSd74jBYE6X/hidY/O7FbNpAmjET0/52tL3xa1trSW9kQ6o9EA5g2jjTFLjTHvMMZ81BjzdElDkv5Y0oCkF9eiQJSHAAZRGBhwXwmjUa84FwIAUD3WWtcZHfWYDjYwRAS8tFf8eI0LL5T+8z+1+M779cVvSV5f/8l1Up52Du7U2MRYdQpFU8oG2dJHdEgujF6+PPqCgBpaqDP63yWdJekuSa+R9ANJL5L0fGvtlVWuDRVIp6V83v0ByuVPNQAwpgP1ijAaAIDqOT56XGOTY9XpjG5tdaMTgDJlUhllg6wm7WRxT7jySn3vqifrRfdKm//f56dv9tKexifHtWtwV3UKRdOZmJzQQG5AmVSJb7StpTMaDWGhMHqztfaV1tpPSfpDSVslXWGtvb3qlaEibNyFKIRhdH///I8Dkor5+QAAVE8u737Iproj7mDO5dwPcWOiXRdNxUt7yo/nte/ovqKf8/knL9N/Xdqrlvd/QPrCFyRpen40ozoQlb1H92pkYqT0zuihIWl4mDAadW+hMHr6OhRr7YSkndbaY9UtCVEgjEYUsllp/Xq3ERxQj+iMBgCgeoK8+yEb+ZiOIGBeNCoWBn1Fj+qQlD08oK+87gnSU58qXXWV9MtflrUOMJ9s4I6lksPogwfdV8Jo1LmFwujzjDFHp/4ck3Ru+L0x5mgtCkR5wvFqdASiEr7PiA7Ut3TanQetjbsSAAAaTzA0FUZHPaYj7IwGKhCOQCi2o3nSTiobZLV5xVnS178urVolvetdSnen1dfVR2c0IhMeS2HXfdEOHXJfCaNR5+YNo621rdbapVN/llhr2075ngFeCUZnNKLg+2xeiPqWTkvj49JRPj4FACBydEYjydYuXavutu6iQ+R9R/cpP5533arLlkmvfa30k5/IbN+uTDpDGI3I+IGvRe2LtHrx6tKeSBiNBrFQZzTqFGE0KhUE0uHDhNGob5wLAQCoHjqjkWQtpkWZdKbo8Rrh46ZHJ7zylVJLi/T5z8tLe4zpQGSyuay8tCdT6lz8MIxevjz6ooAaIoxuUAQwqFS4eSFjOlDPOBcCAFA9YWd05BsY0hmNiGRSxXc0T49OmBrvobVrpec8R/q3f9NZS7doz5E9yo/lq1Uqmogf+KWP6JDojEbDIIxuUF1dbtM5AhiUKwyj6YxGPWN+PgAA1ZPL57SkY4naW9ujW3R4WBoaojMakfDSnnYc3qHxyfEFH+sHvrrburV26dqTN7761dJDD+mye49LkgZyA9UqFU1idGJUOwd3ykuV8Ub70CGptVXq7Y2+MKCGCKMbWDpNGI3yZbPu59ymTXFXApSPzmgAAKonyAfRz4sOP0GmMxoR8NKexifHtWtw14KPzeayyqQzajGnxCS/+7vS6tU69zu/mX4MUImdh3dq0k6eHAdTioMH3bmxhSgP9Y0juIERRqMSvu+C6PYIG12AWiOMBgCgeoKhIPp50eEPbTqjEYFw5EYxozr8wD85oiPU1ia98pXq/dEvteZocesA85keB1PumA5GdKABEEY3sFSKS9NRPt9nRAfqX1+f+0oYDQBA9OiMRtKF3acLhcjjk+PacXjH3N2qf/InMpOTetN9SwijUbHwGCqrM/rQITYvREMgjG5gdEajXNa6MR2E0ah3bW3SsmWcCwEAqAY6o5F0Z/ScoWVdy5QN5h+vsWtwl8Ynx+cOCPv7pSc/Wa+4ZUwDhwijUZlsLqt0d7q8jV/pjEaDIIxuYITRKNf+/W7fmEwZVw4BScO5EACA6gjyVQij6YxGhIwxyqQy8nPzh8jToxNOH9MRevWrtfbgsJb/5p6oS0ST8QO/vBEdEmE0GgZhdANLp93vcpOTcVeCeuNP/a5GZzQaASOLAACI3sTkhAaHB8vr7ptP+AkyYTQi4qW9BcdrLDg64YUvVH5Jt37vV4M6Mnwk6hLRRPzAL29Ex+SkOz8SRqMBEEY3sHTana+O8LMSJcpOXcVGGI1GQGc0AADROzx8WJKqMzO6o0Pq6Yl2XTQtL+1p75G9yo/lCz4mG2S1rGuZzugpEPR1dWn/lU/R790n7Rj4TZUqRaM7MXpC+47tk5cq44324KA0MUEYjYZAGN3AwmYCQhiUyvelri5p3bq4KwEqRxgNAED0giH3w7UqM6PTacmYaNdF08qkMrKy2n54e8HH+DnXrWrmO+7+9E/VOSFNfPlLVagSzWAgNyBJ5Y3pOHTIfSWMRgMgjG5g4Z4fXJ6OUvm+26ejhTMEGgBhNAAA0QvyU2F0NTqj2bwQEQpHIsw3qsMP/MLzoqese+Lv6uY10vqvfd/t+A6UaMFxMPMJw+jlyyOsCIgHUVMDozMa5cpmGdGBxpFOS0ePSmNjcVcCAEDjqHpnNBCRsAs1G2TnvD8/ltfeI3sXDAg72zr1rSemtXLnI9JvGNWB0mVz7hjsT/WX/mQ6o9FACKMbGGE0yjE+Lm3fLmXK3OAXSJrwXMhVIgAARIfOaNSLpZ1LtXLRyoKd0dsPb5eVLapb9b6nnad8R4v02c9GXSaagB/4WrNkjRZ3LC79yYTRaCCE0Q2MMBrl2L3bdZDSGY1GwcgiAACil8u7H6yp7oiDYzqjUQVe2pOfmzuMDkPqhcZ0SNK6tWfr649tlf3KV6TjxyOtEY3PD/zyRnRI0sGD7ithNBoAYXQDW7bM7ftBGI1SZKeuXiOMRqPggzkAAKIXDAVqNa3q7eyNblFr6YxGVXhpr+CYjvD2YjaVy6Qz+sR5YzLHj0tf+1qkNaLxZXNZeaky32gfOiR1dUk9PdEWBcSAMLqBtbZKfX0EMCiNP9UwwJgONArCaAAAohfkA6W6UzLGRLfo0JA0MkJnNCLnpT09fOJhHRk+Mus+P/C1avEqLe1cWtQ6v14vDfWfyagOlCSXz+nQ0KGiPvSY06FDbvPCKM+5QEwIoxtcKsWl6SiN70tLl0orVsRdCRANwmgAAKIX5IPqzIuW6IxG5MIRHOEGcqfyc35RIzokF0bLSHc97xLp17+W7rkn0jrRuMIO/LLHdBw6xIgONAzC6AaXThPAoDS+70Z08IErGgVhNAAA0QuGAqW7Iw6jwx/WdEYjYmEAONeojmyQLTog3NC7Qe0t7frB41dK7e3S5z4XaZ1oXOEHIYTRAGF0wyOMRqmyWUZ0oLEsXuzeK3AuBAAgOlXpjA5/WNMZjYhtSW2RkZnerDB0ZPiIHj7xcNEBYVtLm7aktuj2yX3S858vfelLbrQMsAA/8NViWrS5b3N5CxBGo4EQRjc4wmiUYnhY2r2bzQvRWIxhZBEAAFHL5XNKdUccGoc/rOmMRsS62rq0oXeD/NzMMDrsVi12TIfkOlv9wJde/Wr3ZvvaayOtFY3JD3xtXLZRHa0d5S1w8CBhNBoGYXSDI4xGKbZvd5uYE0aj0XAuBAAgWlUd00FnNKrAS3uzxnSUM8fXS3kayA1o8qlPkdatk772tUjrRGPK5oofBzPL2Jh05IjbwBBoAITRDS6dlo4fl0ZH464E9SA79bsZYzrQaAijAQCITn4sr/x4Pvowmg0MUUVhR7O1dvo2P/BlZLQltaXodTLpjIbHh/Xg8f3S4x8v3XprNcpFA7HWyg+K3yhzlvCNDJ3RaBCE0Q0u/D2Oy9NRDH/qqjXCaDQawmgAAKIT5N0P1chnRh86JHV3uz9AxDKpjI6MHNHBoYPTt/k5Xxt6N6irravodcLuVj/wpQsukHbulAYHoy4XDeSh4w/p+OjxyjYvlAij0TAIoxtcOG6NEAbF8H1pxQpp2bK4KwGiRRgNAEB0gqGpMDrqzuhf/lJ67GOjXROYEgaBp47qyAalj06YFUZL0u23R1IjGlM4m5wwGnAIoxscYTRKkc0yLxqNKQyjT7kqEwAAlKkqndH790u/+Y105ZXRrQmcYkaIrJOjE0oNCFcvXq1F7YtcqH3++e5GwmjMIzzmyg6jf/tb93VL8eNkgCQjjG5whNEohe8zogONKZVys/OHhuKuBACA+pfLuxmAqe4IZzt/5zvuK2E0quTMZWeqraVtOhg8OHRQR0aOlDzH1xijTDojP+dLq1a5P7fdVo2S0SD8wFdHa4fWL11f3gLXXOO68DdsiLYwICaE0Q2OMBrFOnpUeughOqPRmDgXAgAQnaqM6bj2WmnzZunss6NbEzhFW0ubtvRtmR6ZEI7rKKdbNdwMUZILCQmjMY9sLqv+VL9aW1pLf/KBA9INN0gvfGH0hQExIYxucAQwKNbAgPtKGI1GxLkQAIDoRD6m4/hx6Uc/cl3RxkSzJjCHU0PkSkYnZFIZ7Ty8U2MTYy6Mvu8+aXg40lrROMoZBzPtW99yXwmj0UAIoxtcT4/U2UkAg4X5Ux/sM6YDjYgwGgCA6ARDgXrae9TV1hXNgt//vpun9bznRbMeUEAmlVE2l9WknZQf+GpradOZy84seR0v7WnCTmjn4E43N3p8XLrnnugLRt2bmJzQQG6g5HEw0665RjrrLOnRj462MCBGhNENzhg3KzWXi7sSJF0YRvf3x1sHUA2E0QAARCfIB9GO6Pj2t6W+PumJT4xuTWAOXtrT8Piw9h3dp2wuqy19W9TW0lbWOtJUd/UFF7gbGdWBOew9ulejE6PldUbnctJPfuK6orlqBA2EMLoJpNMEMFhYNuv2Q+jujrsSIHqE0QAARCfIB9GN6Bgfl667TnrOc6S20kNBoBSnhsiVjE4Iu1yzQdbNOl+yhDAac6pkHIyuu06amJBe8IKIqwLiRRjdBAijUQzfZ0QHGlcq5b5ylQgAAJXL5XPRdUbfcIP7AX3lldGsB8wjk3ZveB4IHlA2ly17dEK6J61Ud8oFjS0t0nnnSbffHmGlaBRhGF3WsXbNNdK6ddLWrRFXBcSLMLoJEEZjIda6MJrNC9GoOjqkxYs5FwIAEIVgKFCqOxXNYtde635QP/OZ0awHzGPNkjXqae/RT3b9RMPjw+VvKqepzRBzU7MOL7hAuuMO18UKnCIbZLW4Y7FWLV5V2hOPH3fz9BnRgQZEGN0ECKOxkCCQBgcJo9HYOBcCABCNyGZGW+vC6Kc8xY05AKqsxbQok8ro+wPfl1Tm6IQpmVTGjemQXBh94oQ0MBBFmWggfs6NgzGlBsrXXy8ND7swGmgwhNFNIAxgrI27EiRVuHkhYzrQyAijAQCo3KSddGM6opgZfd990vbt0vOeV/laQJEy6YyOjR6b/r5cXtrT3qN7NTQ2xCaGKMgP/PJHdCxfzsauaEixhNHGmGXGmK8bY+43xtxnjHl8HHU0i1TK7Qty/HjclSCpwjCazmg0MsJoAAAqd2T4iCbtZDSd0d/+tvv63OdWvhZQJC/l3vT0tPdozZI15a8z1VU9kBuQzj5bam9nbjRmGJ0Y1a7BXaV34I+MuM0Lr7xSam2tTnFAjOLqjP4XSddbax8l6TxJ98VUR1NIT/2eSAiDQrJZt3n5xo1xVwJUD2E0AACVC/Luh2kkndHXXitddJHboAuokTAYzKQyajHlRyLhOtkg6+aen3MOndGYYcfhHZq0k6WH0T/6kXTsGCM60LBqHkYbY5ZKukzS5yTJWjtqrR2sdR3NhDAaC/F9adMm92E+0KgIowEAqFwun5OkyjujH3pIuukmRnSg5sLRHJWM6JCk/lS/JDeGQZIb1XHbbczHxLTw2Ch5TMc110hLl7p5+kADiqMzerOkg5L+zRhzmzHms8aYRTHU0TSWL3dfL7nEfWBb6M/ixdJPfhJvrYje7/zO/P/dOzqkr3+dER1ofKmU26iTTc4BAChfMOQ+2U11pypb6LrrXGh35ZURVAUUL+xSDcd1lGtxx2KtWbJGfu6UMPrgQWn//kpLRMze94v36eXffHnF64QbXJb0wcf4uLtq5IorpM7OimsAkqgtpte8UNKbrbU3GWP+RdLVkv721AcZY66SdJUkbdiwoeZFNpKLL5be/37pyJHCj7FW+sAHpJ//XHryk2tXG6prclK64Qbp0ktdKD2f3//92tQExCWddue6wcGTV4wAAIDSRDam49vfls48Uzr33AiqAop3Rs8Z+s8X/qcu33h5xWt5aW86cNT557uvt98urV1b8dqIz093/1Q37L1B1loZY8pexw98ndFzRmkf3v3yl9KhQ9ILXlD26wJJF0cY/aCkB621N039/etyYfQM1tpPS/q0JG3dupXrXCrQ3i69/e0LP+4rXzm5kR0aw5EjLpB+4Qul//N/4q4GiNepI4sIowEAKE/YGV3RmI4TJ6Qf/lB6zWukCoIeoFx/+Ng/jGSdTCqjb93/LfeX885zX2+7TXrOcyJZH/HI5XM6PnpcDx1/SKuXrC57HT/nlzeio6tLetazyn5dIOlqPqbDWvuQpL3GmLOmbnqqpHtrXQdm8zy3kR0aRzgfl+ANYH4+AABRCPKBjIyWdS0rf5H//V9peJh50ah7XtrTwaGDGhwedDN++/vZxLABhB+6ZXOVBSR+4Je2eeHkpAujn/lMN0cVaFBxzIyWpDdL+g9jzJ2Szpf03pjqwCkyGdcZzX4LjYMwGjiJMBoAgMoFQ4H6uvvU2tJa/iLXXiv19kqXVz4mAYhTGDTOGNVx++2x1YNohOOIpjenLMPx0ePaf2x/aWH0LbdI+/a5S5uBBhZLGG2tvd1au9Vae6619vnW2sNx1IGZPM+NdTh4MO5KEBXCaOAkwmgAACqXG85VNqJjYsJtXvjsZ7t5gkAdC0cwTIeWF1wg7dgx/4ZNSLSxiTEdHTkqqbIweiA3IEmljem45hqprc1tXgg0sLg6o5FA3tQHdsyNbhyE0cBJqal9Q3K5eOsAAKCeBUNBaZtxne7GG133y5VXRlcUEJPNfZvVYlpmhtES3dF1LJc/+WahkjA6fG7RndHWujD6yU8++cYFaFCE0ZiWmfrAjrnRjYMwGjipt1dqaaEzGgCASgT5QOmeCn65/Pa3Xecfm3OhAXS2dWrjso0nZwuHYTRzo+tWOKKj1bRWNDM6HN3Sn+ov7gn33uvCGEZ0oAkQRmPaxo3u90I6oxtHELgNypcti7sSIH4tLa7JgDAaAIDyBUNBZWM6rr1WetKT+AUVDSOTypzsoF21Slq5ks7oOhZuXnjuynM1kBvQxOREWev4OV9rl6zVoo5FxT3hmmvcm3euGkETIIzGtLY2acsWwuhGkstJfX0uhAPgrhIgjAYAoHxBvoIw+oEH3J/nPS/aooAYeWlPfuDLWutuuOACOqPrWDimY9u6bRqdGNWeI3vKWscP/NI2L7zmGunSS6XVq8t6PaCeEFFhBs9jTEcjCQJGdACnIowGAKB8oxOjOj56vPwxHd/5jvtKGI0G4qU9HRs9pkdOPOJuuOACN3JhZCTewlCWcEzHtnXbJKnsUR3ZIFt8GL1jh+umZ0QHmgRhNGbIZFwYPTkZdyWIAmE0MBNhNAAA5Qs7BsvujL72Wum886Qzz4ywKiBemZTbfGl6VMf550vj49Ldd8dXFMoWjul4/LrHSypvE8NgKFCQD6aPjQV985vu6wteUPJrAfWIMBozeJ40PCw9+GDclSAKhNHATKmUG18DAABKF4Y0qe5U6U8+eFC64QbmoaLhhN2v06FluIkhc6PrUpAP1N7Srv5UvxZ3LC4rjA67qYvujL7mGvchxqZNJb8WUI8IozGDN3WuZFRHYyCMBmaiMxoAgPKFl6+XNabju991l18yogMNZkPvBnW0dpwMLbdskZYsYW50nQqGAqV70jLGyEt7ZY3pyAYlhNEHDrgP6hjRgSZCGI0ZMlNXkbCJYWMgjAZmSqeloSF3BQgAAChN2Bld8piOG26Q3vUuaf166cILq1AZEJ/WllZt6dtyMrRsaXHjaAij69Kpm7SGm1OWyg98tZpWbepboNP5wAHpZS9z3xNGo4kQRmOGNWuknh7C6EYwMiKdOOHGEgBwwg9n6I4GAKB0JXdGT0xI//AP0mWXSW1t0je+IRlTxQqBeMwKLc8/X7rjDjZjqkO5fG76HJdJZbRrcJdGJ0ZLWsPP+dq4bKM6WjsKP+i666Rzz5V+/Wvps5+VzjmnkrKBukIYjRlaWk5uYoj6Fs7FpTMaOIkwGgCA8pXUGf3gg9JTn+o6ol/yEjc/9+KLq1sgEBMv7WkgN6BJOxU+X3CB6wwaGIi3MJTs9M7oSTupHYd3lLRGNsgWHtExPCz9+Z9Lz32utHat9NvfSn/6p5WWDdQVwmjMksnQGd0IwrCNMBo4iTAaAIDy5fI5dbZ2qqe9Z/4HfvObruPvllukL35R+vKXpaVLa1MkEINMKqORiRHtPbLX3RBuYsiojroTDAXTm7TO2pyyCNZa+YE/dxh9333Stm3SRz4i/dmfSTfeKD360ZHUDdQTwmjM4nnSjh3S2FjclaAShNHAbOHYmvDKAQAAULwg70IaU2jURj4vvf71bvbp5s0uiHvFKxjNgYY3K7Q85xypvZ0wus5Ya2d0RmdSblOtUsLoA8cP6MTYiennTi3sRnFcdJG0b5/0ne9I//IvUldXpPUD9YIwGrN4nhvvtmtX3JWgEoTRwGx0RgMAUL4gHxSeF3333W4Mxyc/Kb31rW7Twkxm7scCDWZWGN3RIZ19thtPg7pxYuyERidGp89zfd19OqPnDGWD4ueYhsfAdGf04KAbVfSa10iXXupmiV9xRdSlA3WFMBqzhL8zMqqjvhFGA7MRRgMAUL5gKJh7XvR//ZcLog8dkq6/XvrQh1wYBzSJVYtXaXHHYmVzp4SWF1zgOqOtja8wlGSuufhe2pOfKz4cCYNrL+1J998vnXeeG130/vdLP/iBtGZNtEUDdYgwGrN4Ux/gEUbXt3AMQTiWAIDU3e3+EEYDAFC6gp3R73qXdNZZruPvmc+sfWFAzIwxyqQyM8c5XHCB9Mgj0oED8RWGkgT5qTD6lPPcrP+uC/ADX52tnVrfu176+MelgwelX/1KevvbpRYiOEAijMYc0mmpr0/KFn8lChIoCKTOTqlngf1lgGaTThNGAwBQjjk7ow8fdl0sL36xtHJlPIUBCeClvZmh5fnnu6/Mja4bubzr6Dq9M3r/sf06Pnq8qDX8nK/+VL9aTIv0m99IW7dKj3tcVeoF6hVhNGYxxo3qoDO6vgWBC93YLwaYiTAaAIDSnb6x17Tf/MZ9veSS2hcFJEgmldGuwV0anRh1N4RhNHOj60Y4piPVffLy4nD280BuoKg1skHWPWdszH0QcfHF0RcK1DnCaMzJ8wij610YRgOYKZU6OcYGAAAU5/jocY1Pjs8IaSRJN93kuh+2bo2nMCAhvLSnCTuhnYd3uhuWLpW2bKEzuo4UGtMhqahRHROTExrIDbjn3HWXNDJCGA3MgTAac/I8ae9eKZ+PuxKUizAamBud0QAAlG6ukEaSC6Mf9SiptzeGqoDkCDtoZ82NJoyuG3N1Rven+iWd3JhwPruP7NbY5Jg7FsKrRgijgVkIozGnjPvwTwPFXYmCBCKMBuZGGA0AQOnCkGbGmA5rpZtvZkQHICmTdm+is7lTQsvzz5d27JCOHImnKJQkyAda0rFEHa0d07ct6likdUvXyc8t3BkdBtbTYXQqJW3eXLV6gXpFGI05ee5DXUZ11LFczv3sAzBTOu3+fVgbdyUAANSPOTujd+2SDh5kcy5Arps23Z2e3RktSXfcEU9RKEmQD2Zf/SE3qqOYMR3hYzLpjAujL76YTZyAORBGY05hZ3R24StRkEDW0hkNFJJOSxMTNKgAAFCKOTujb77ZfaUzGpDkOmLnDKMZ1VEXcvnc7E1a5f67FjOmww98LelYopVmiXTPPYzoAAogjMacliyRVq2iM7peHTsmjY8TRgNzCf9dMKoDAIDizdkZfdNNUleX9NjHxlQVkCyZ9GkdtKtXSytXEkbXiWAomL1Jq1wYHeSD6Q/lCsnmsvLSnsztt7vuF8JoYE6E0SjI8wij61UYshFGA7OF42tyuXjrAACgnuTy7gdnX1ffyRtvukm68EKpvT2mqoBk8VKe9h3bpxOjJ07eeNFF7t8KEm++MR3SafPA5+AH/skRHRJhNFAAYTQK8jzGdNQrwmigMDqjAQAoXTAUaGnnUrW3TgXPY2PSrbcyogM4hZd2my8N5AZO3njZZdL990uPPBJTVShWMBQUHNMhad5RHSPjI9p9ZLe81NTmhWvXus54ALMQRqOgTMb9vBwcjLsSlIowGiiMMBoAgNIF+dNCmrvukoaHCaOBU2TSroN2xqiOyy5zX3/xixgqQrEmJic0ODw4Zxi9qW+TWk3rvJsY7ji8Q5N20gXX4eaFAOZEGI2CPPfhH93RdYgwGiiMMBoAgNLNunw93LzwcY+LpyAggfpT/ZJOG+dw0UVSd7f0s5/FVBWKcXj4sKzsnGM6Olo7tHHZRvm5wmF0GFQ/um21C1EIo4GCCKNREGF0/Qpn4aZm770ANL2+PskYwmgAAEox6/L1m26Sli+XNm6MrSYgaRZ3LNbaJWtndtB2dEiXXir9/OfxFYYFhZsTztUZLblRHfON6Qj/m3u7jrobCKOBggijUdDmzS6wYRPD+hOGbITRwGytrdKyZYTRAACUYlZn9E03ua5oY+IrCkigTDoze5zDZZdJd94pHT4cT1FYULhJ61yd0ZILo/3Al7V2zvv9wNfynuVafMd97oatW6tSJ9AICKNRUFeXdOaZhNH1KAik3l6prS3uSoBkSqVOXkEAAAAWlsvnlOqa6nQ4csRtyMa8aGAWL+XNHNMhSZdfLlkr/fKX8RSFBQV516mS6p67oyuTyujE2AkdOH5gzvuzuezJedH9/e5yTABzIozGvDyPMR31KAiYFw3MJ52mMxoAgGKNT467jb3CjsFbbnHBGmE0MIuX9nRo6NB0p60kdxVBRwejOhKsmDEdkgqO6vAD321gyeaFwIIIozGvTMZ1Rhe4EgUJRRgNzI8wGgCA4h3Ou9EC0yFNuHkhgQswSyadkXRaaNnd7T68YRPDxAo7o+cb0yFp9ggWScdGjunA8QO6YHKV9OCDnBuBBRBGY16eJx09Kj3ySNyVoBSE0cD8CKMBACjerJDmppvcGwUuQwdmme6gPX1Ux2WXSbfeKh07FkNVWEgwFKjVtKq3s3fO+9f3rldna+ecYfRAbkCStHXfVBff4x5XtTqBRkAYjXl57ucoozrqTC7H5oXAfAijAQAo3ozL1609uXkhgFk2921Wi2mZHVpefrk0MSHdcEM8hWFeQT5QqjslU2BT1hbTov5U/+wPGXSyW3rLjpzbLf2CC6paK1DvCKMxr4y7wohNDOsMndHA/NJp15QyOhp3JQAAJN+MzugHH5Qeeoh50UABHa0d2rhs4+ww+vGPd0Elc6MTKZfPFRzREfLS3pyd0eFtZ9yzUzrnHKmnpyo1Ao2CMBrzOvNMqb2dMLqejI+7Dc4Jo4HCwisHDh+Otw4AAOpBuBFbqjvluqIlwmhgHl7am91Bu3ixtHUrc6MTKuyMnk8mldH2w9s1MTkx4/ZsLqv1S9ap9ZZbmRcNFIEwGvNqa5O2bGFMRz3JTW3aTBgNFBb++2BUBwAAC5sxpuPmm6WODuncc2OuCkguL+U6aK21M++47DL3byifj6cwFBQMBSc3aS3AS3sanRjVniN7ZtzuB74um1zv3owTRgMLIozGgjIZOqPrSRiuEUYDhRFGAwBQvCAfqK2lTUs7l7rO6AsukDo74y4LSKxMOqPjo8f10PGHZt5x2WXS2NjJKwyQGEE+KGpMh6RZozr8wNeTDi5yfyGMBhZEGI0FeZ40MCBNTsZdCYpBGA0sjDAaAIDiBUNTG3tNTEi33MLmhcACwtBy1qiOJz5RMoZRHQlUTGd0Ju021To1jA6GAh0ePqzz9467D+ke+9iq1gk0AsJoLMjzpOFht1cJki8c05Gaf9wV0NQIowEAKF6Qnwpp7r1XGhpiXjSwgEIdtFq2TDrvPDYxTJj8WF758fyCYfTKRSu1pGPJjA8Zwv/GmwYOSuef7zbdAjAvwmgsKOM+/GNUR52gMxpYGGE0AADFm758nc0LgaKsX7peHa0ds8NoSbr8cunXv5ZGR2tfGOYUbtK60JgOY4y8tDfjv6sf+GqZlPru3cmIDqBIhNFYkOc+1CWMrhOE0cDCFi1yTQvhlQQAAKCwXD6nVHfKbbyWSrkdzgEU1NrSqv5U/9xh9GWXuQ0Mb7ml9oVhTkHevYlOdS98eXEmnZnx3zWby+qcoEUtJ4YIo4EiEUZjQWvWSD09Uja78GMRvyCQ2tqkJUvirgRILmPcBzZ0RgMAsLDpWao33eTmRRsTd0lA4nlpb/bMaEn6nd9xX5kbnRjBkHtTsNCYDknyUp52H9mtkfERSa4z+tmDy92dhNFAUQijsSBj3KgOOqPrQxC4kI33CMD8CKMBAChOkA+0Wkuke+5h80KgSJlURgO5AU1MTsy8Y/ly6eyzmRudIGFn9EJjOiT3IcOkndSOwzskuTD6dx7udN1gZ51V1TqBRkEYjaJ4HmF0vQjDaADzI4wGAGBhQ2NDGh4f1tl78tLkJPOigSJ5aU+jE6Pac2TP7Dsvv1z61a+k8fHaF4ZZSumMzqTdplp+4Mtaq2wuq8fuGZG2bpVaiNiAYvAvBUXxPGnnTmlsLO5KsJBczo3yAzA/wmgAABYWhjT92akfmnRGA0Xx0m7zpTlHdVx2mXTsmHT77bUtCnMqpTM6k3JhdDaX1f5j+zWeH9K6HYcY0QGUgDAaRclkpIkJF0gj2eiMBopDGA0AwMLCkGbdA/ulzZulM86IuSKgPoShZcFNDCVGdSREMBSop71HXW1dCz62r7tPZ/ScIT/w5Qe+zn1Yah2fIIwGSkAYjaJ47kNdRnXUAcJooDiplLuSwNq4KwEAILly+ZwkKX3XdkZ0ACVYtXiVFncsnjuMXrNG6u9nE8OEyA3nihrREfLS3nQYffG+qRsJo4GiEUajKGEYnZ3jCiMkh7WE0UCx0mlpdFQ6cSLuSgAASK5gKNDqo1LXgYOM6ABKYIyRl/bmHtMhubnRv/iFm8WOWAVDgVLdxc+6DP+7ZnNZbTvQKrt8ubRhQxUrBBoLYTSKkk5LfX10Rifd0JA0MkIYDRQj/HfCqA4AAAoL8oEeF3b+0RkNlCSTyszdGS25UR2HD0t3313bojBLkA+KmhcdyqQy2n9sv249cKse/1CbzMUXS8ZUsUKgsRBGo2ieRxiddGGoRhgNLIwwGgCAhQVDgS7ZJ9m2NumCC+IuB6grXtrTrsFdGp0YnX0nc6MTIxgKSh7TIUm3Zn+uzQ+NMKIDKBFhNIrmeYzpSDrCaKB4hNEAACwsyAd6/P4WmfPOk7oW3twLwEle2tOkndSOwztm37lxoxvtQBgduyBfXhh97r4JtVoRRgMliiWMNsbsMsbcZYy53RhzSxw1oHSZjLR3rxsFgWTKuf1llCp+3BXQtAijAQBYWO74QV20zzKiAyhDJpWRpPlHdfzsZ+yoHaNJO6lcPlfSmI7+VL8k6eL9UzcQRgMlibMz+snW2vOttVtjrAElCDcxHBiItw4URmc0ULzwQ5vwQxwAADDboh17tWTEsnkhUIZMeoEw+vLLpUceYR5mjI6OHNWknSypM7qnvUfrlq7Txfuk4bUrpRUrqlgh0Hja4i4A9SMMo7NZ6dxz460FcyOMBooXhtF33SXdssA1On190pYt1a8JAICkWXPvg+4bOqOBkqW6Uzqj5wzd+OCNumX/7F84O8/q02Ml7br2i1rypr8sqTt3LuOT47rr4bs0YSfmfVy6O61NfZsqeq1GEQy5N9Gp7tIuL/bSni7e/6B0GV3RQKniCqOtpB8YY6ykT1lrPx1THShBxn2oqwceiLcOFEYYDRSvo8M1MXzyk+7PfF7yEumrX61NXQAAJMmW7CGd6GnXorAzBUBJHrPiMfrGfd/QN+77xuw7rbR/sfTLL79P/7zs+/rtVb+t6LX+5cZ/0Vt/+NYFH9dqWrXvL/Zp5eKVFb1eIwjy7k10qR8EbOvKaMvhH8tue0I1ygIaWlxh9BOstfuNMSsk/dAYc7+1dsbUfmPMVZKukqQNGzbEUSNOs3ixtHo1mxgmWRC4/04dHXFXAtSHn/5U2r594cetWVP1UgAASB5rdaF/XHu81Xp0S5wTHoH69e8v+Hfd/tDtBe+3N39Az7r5t/rTh+/SxOSEWltay36tOx6+QysXrdRnn/fZgo+555F7dPWPrtY9B+8hjNbJzuhSxnRI0l/3PEPSp2S4agQoWSxhtLV2/9TXR4wx35T0OEk/P+0xn5b0aUnaunUr0/wTwvMIo5MsCOiKBkrx6Ee7PwAAYLbJ//6avIMT+sarLhA/LoHyrFu6TuuWriv8gCv2SN/7pdYE0p4jeyoan5HNZfWYFY/RFd4VBR9z3srzdPWPrlY2yOopm55S9ms1inI7oxfddo9kjHTRRdUoC2hoNf942xizyBizJPxe0jMk3V3rOlCeTIa9FZIslzs5BxcAAAAo29iY7DvfqbuXSw8+70lxVwM0rssukyRdvmuejQ6L5Ae+MqnMvI9Zu3Stutq6Kn6tRlFWZ/TkpPQf/+E2dl26tEqVAY0rjmutVkr6pTHmDkk3S/qutfb6GOpAGTxPOnhQGhyMuxLMhc5oAAAAROILX1DrwHb99VOl1OLlcVcDNK6zz9Zkqk+X7a4sjA6GAuXyOXnp+ee7t5gWZVIZ+TnCaMl1RhsZLetaVvyTfvQjt5nWm95UtbqARlbzMNpau8Nae97Un3Ostf+31jWgfOG+JYzqSCbCaAAAAFQsn5fe8x4du+ix+s5ZUqqbS++AqmlpkXnKU/XC+6Ujd95c9jLZnHuTvlAYHT4mG/CmXpJy+ZyWdS0rbVb3v/6r2wn9RS+qXmFAA2MXCpQkM3XFD6M6kokwGgAAABX76Eel/ft191+8TDKlz1IFUBrzwQ9qsr1Nf/I333Bv6soQdlVn0vOP6ZCkTCqj7Ye3a3xyvKzXaiRBPijtHLdjh3TdddJVV0mdndUrDGhghNEoyZYtbkY/YXTyTExIhw8TRgMAAKACg4PS+94nPfvZGjhntaQSZ6kCKN2mTfrw1U9SOjcsveAF0shIyUv4ga9W06pNyxbeANFLexqfHNeuwV1lFNtYgqGgtHPcJz4htbRIr3td9YoCGhxhNErS2Slt3MiYjiQaHJSsJYwGAABABT70Idfh8L73KchPbexFZzRQdebxl+pPni/pF79wXbfWlvR8P/C1uW+z2lvbF3xsOMqDUR0ldkYPDUmf+5z0whdKa9dWtzCggRFGo2SeR2d0EuVy7muKkX4AAAAox4ED0j//s/TSl0rnnadgKFCLaSltYy8AZcmkM/rPx1gdfNubpC99yV2hUIJsLlvUiI7wtaTKNkxsFCV1Rv/Hf7gP69785uoWBTQ4wmiULJNxYXSJH9SiysLRYnRGAwAAoCz/8A/S2Jj0938vyW3s1dfVpxbD20ag2sJu5Rte+VTpj/5Ieuc7pf/+76Kea62VH/jyUgtvXihJy3uWq7ezlzBaU53RxYTR1rqNC887T3riE6tfGNDA+K0CJfM86dgx6ZFH4q4EpyKMBgAAQNkGBqTPfMaNB9iyRZILaVLdXHYH1EIm5bqVs4cHpM9+Vrr0UukVr5BuumnB5+4/tl9DY0PTgfZCjDHy0p6yueYe0zE6Marjo8eLG9Pxi19Id90lvelNbiMtAGUjjEbJvKmfb4zqSBbCaAAAAJTtXe+SOjqkv/mb6ZtKmqUKoCJ93X06o+cM163c1SV961vS6tXSlVdKu3fP+9wwVC52TEf42GbvjM7l3azLoj50+9d/lfr63BgjABUhjEbJMlM/3wijk4UwGgAAAGW5/XbpK1+R3vIWF35NKWmWKoCKeWnvZEC8fLl03XXS8LD03OdKR48WfF74nGI7oyXJS3nac2SPhseHK6q5ngVDU5u0LnSe27tX+uY3pVe/WurpqUFlQGMjjEbJzjxTam+Xss19RU/iBIHU0iL19sZdCQAAAOrKX/+12wX7bW+bcTOd0UBtzRqdcfbZ0te/Lt17r/QHfyCNj8/5PD/w1dXWpXVL15X0WlZW23PbKy27bgX5qTB6ofPcpz4lTU5Kr399DaoCGh9hNErW2ir199MZnTS5nLtqqIV/1QAAACjWz34mfe970jveMaurgc5ooLYyqYz2H9uv46PHT974tKdJH/uY+3f6V3815/Oyuaz6U/0lbTYajvRo5lEdRXVGDw9Ln/60607ftKlGlQGNjdgKZclkCKOTJggY0QEAAIASWCtdfbW0dq30xjfOuGtkfEQnxk4QRgM1FI7ZyAanXYb82tdKr3yl9NGPSvn8rOf5gV/SiA7p5IaJTR1GF9MZ/bWvSQcPSm9+c42qAhofYTTK4nluw+3JybgrQYgwGgAAACX59relG2+U3vMeqbt7xl0lbewFIBLTYXRujpmYz3++G9Nx220zbh6fHNf23HZ5qdLC6N6uXq1ctHLu12oSRXVGf/Sj0qMeJT31qTWqCmh8hNEoi+dJIyNujj+SgTAaAAAAJXn3u6WzznIdl6cpepYqgMj0p/olFehWvuQS9/XGG2fcvOfIHo1Njk2P3ShFJp1p6s7oXD6njtYO9bQX2JTwppuk3/xGetObJGNqWxzQwAijUZbM1M85RnUkB2E0AAAAinb8uHTHHdLLXy61tc26u6iOQQCR6mnv0bql6+YOiFetkjZunBVGh48tdUyHJHkpr6nD6CDv5uKbQkHzv/6rtGSJ9IpX1LYwoMERRqMs3tTPOcLo5CCMBgAAQNEGBtzXs86a8246o4F4eGmv8OiMbduiDaPTnh4+8bCOjhwt+bmNIMgHhc9xDz3k5kW/6lUukAYQGcJolGX1amnRIinbvOOlEmV4WBoaklKM9AMAAEAxwq6SzNyX9tMZDcQjk5pndMa2bW5W5r590zdlg6yWdi7V8p7lpb/W1GiPWRsmNolgKCh8jvvMZ6SxsVmbuwKoHGE0ymKM+72VzuhkyLn9ZeiMBgAAQHHCrpL+/jnvDjcwpDMaqC0v7SmXz01/IDTDtm3u6003Td/k53x5aa/wqIkFXksqMKO6CRTsjB4bkz75SemZzzx5WTiAyBBGo2yeRxidFMHU7ymE0QAAACiK70vr1rnLHecQ5AN1tnaqu627xoUBzS0MiOcc1XH++VJHx4xRHX7glzWiQ5K29G2RkWneMLpQZ/Q110j790tvfnPtiwKaAGE0yuZ50q5d0uho3JWAMBoAAAAl8f2CIzqkqZCmZ56NvQBUxbzdyp2d0oUXTofRI+Mj2j24W16qvDC6u71bG3o3FJ5R3cCstcrlc0p1zzHr8mtfk9avl571rNoXBjQBwmiULZORJiaknTvjrgSE0QAAAChJNjvv5edBfp5ZqgCqZtOyTWo1rfPPjb7lFmlsTNsPb5eVnZ79XI5Mep4Z1Q3s+OhxjU2OzX2eu/9+6aKLpNbW2hcGNAHCaJQt/N2VUR3xI4wGAABA0YLA/VkojGZeNFBz7a3t2tS3qXC38rZtUj4v3XXXdIhc7pgOSfJSnvzAl7W27DXqUZCf2qT19PPcxIQ0MMCsaKCKCKNRtvDcnG2+K3oShzAaAAAARQt/gV9oTAed0UAsvLQ3f2e0JN144/RjMqnyO6O9tKcjI0d0aOhQ2WvUo3CDyFnnuT173CxSwmigagijUbZUyv2hMzp+uZzU1SV1s78MAAAAFhKG0fOELbl8jjAaiEkmlVE2yM7drbxhg7RqlXTjjcoGWa1YtEK9Xb3lv9bUiI9mG9VRsDM6DDjm+bAOQGUIo1ERzyOMToIgoCsaAAAARfJ9Nwt106Y577bWKsgHc2/sBaDqvLSnE2MndOD4gdl3GuO6o2+8UX7Or2hER/haUhOG0YU6o4v4sA5AZQijURHPY0xHEhBGAwAAoGi+L23cKHV0zHn3sdFjGp8cZ2Y0EJMFA+Jt26RsVgf33C8vVVlounHZRrW1tBWeUd2gcvmcJM3+0M33pSVLpJUrY6gKaA6E0ahIJiM9+KB04kTclTQ3wmgAAAAULZudf/PCQh2DAGoinAG90NzojQ88Mj1mo1xtLW3a3Le5+Tqjp8Z0zBlGe57rQAdQFYTRqEj4O+zAQLx1NDvCaAAAABTF2pNhSwEFZ6kCqIn1vevV2dqpbFCgW3nrVtmWFm17UBWP6ZAW2DCxQQVDgZZ2LlV7a/vMOxY4PwKoHGE0KhKeoxnVES/CaAAAABTlwAF3WeM8m3PRGQ3Eq8W0KJPOyM8VCIgXLdJgZn10YXTK00BuQJN2suK16kWQD2af40ZGpN272bwQqDLCaFSkv999ZRPD+Fgr5XJSiv1lAAAAsJAiNueiMxqIXyaVmbdbeYe3XJfsk7b0zr0RaUmvlc4oP57XvqP7Kl6rXgT5YPY5bscOaXKSzmigygijUZHFi6U1awij43T0qDQxQWc0AAAAihD+4j5P2FJwYy8ANeOlPW3PbdfE5MSc9//2zHb1jkjd23dH8lrSPDOqG1AwNEdndBHnRwCVI4xGxTyPMR1xClzjCmE0AAAAFub7UmentH59wYeEYzoIo4H4eGlPY5Nj2n1k7rD5f1ccd9/ceGMkryVJ2VzzvLGfszM6DKMZ0wFUFWE0KpbJ0BkdJ8JoAAAAFC2bdbP2Wgq/FQzygXo7e9XW0lbDwgCcKpNygehc3crWWv1v2x4NLeqIJIxes2SNutu6m6ozOpfPKdV12gduvi+tWCEtWxZLTUCzIIxGxTxPOnRIOnw47kqaE2E0AAAAiub7C16CPmfHIICamu5WDmZ3Kwf5QIdHj+iRx2yOJIye3jCxScLo8clxDQ4Pzt0ZTVc0UHWE0ahY+LssozriQRgNAACAokxMSNu3Lxi2zDlLFUBNrVi0Qks7l84ZEIe3jV18oXT33dKxYxW/npf2mmZMx+G866SbdZ7LZpkXDdQAYTQqFv4uy6iOeOTc/jJKMdIPAAAA89mzRxodpTMaqAPGGGVSGfm52W+0w27pnt95imStdMstFb9eJpXRjsM7NDYxVvFaSRfkXUfXjPPcsWPSgQOE0UANEEajYps3u5FzhNHxCDuj+/rirQMAAAAJF/7CvkDYksvn2LwQSAAv7c05psMPfLW1tGnFk69wN0S0ieH45Lh2De6qeK2kCzdpndEZHV7qTRgNVB1hNCrW2Slt3MiYjrgEgdtfoY39ZQAAADCfMIxmTAdQF7y0p12DuzQyPjLjdj/na3PfZrUvXymddVZkYbSkphjVMWdndJHnRwCVI4xGJDIZOqPjEgTMiwYAAEARsllpyRJp5cqCDxmfHNeRkSOE0UACZFIZWVltP7x9xu1+4CuTmgpNt21zYbS1Fb9WuHajy+XdrMsZV4CEgUZ/fwwVAc2FMBqR8Dx37q7w5x/KQBgNAACAovi++8XdmIIPCUMaZkYD8ZvuVj5lVMekndRAbmD6Pm3bJj3yiLRrV0WvdUbPGVrWtawpwuiCYzo2bJC6u2OqCmgehNGIhOdJx49LDz8cdyXNhzAaAAAARfH9okZ0SKIzGkiATHp2t/L+Y/s1NDY0M4yWKh7VYYxxM6qbZExHW0ublnYuPXlj+GEdgKojjEYkwt9pGdVRe7mclGJ/GQAAAMxnZETavXvBsGXOWaoAYrGsa5mW9yyfEUaH30+P6XjMY6SenkjmRmdSmabpjE51p2TCq0SsJYwGaogwGpEIz9mE0bVHZzQAAAAWtGOHNDm5YNgy5yxVALE5vVs5HNkx3Rnd1iZdfHFkmxjuObJH+bF8xWslWZA/bZPWQ4ekwUE2LwRqhDAakdiwQerocGOWUDtjY9LRo4TRAAAAWEDYNcKYDqCueGlvVmd0d1u31i5de/JB27ZJt90mDQ9X/FqSZm2Y2GiCfDDz6o/w/EhnNFAThNGIRGurtGULndG1lnONK4TRAAAAmF/YNbJQGM2YDiBRMqmMDhw/oGMjxyRJfs5Xf6pfLeaUOGfbNtepdNttFb+WpIYf1RGO6ZhGGA3UFGE0IuN5hNG1Frj3CoTRAAAAmJ/vS8uXS3198z4sGHIbey3pWFKjwgDMJ+xWHsgNSHJjOqZHdIQuucR9rXBUx1wbJjaiXD438+qPbNaNO9m4MbaagGZCGI3IeJ60fbs0MRF3Jc2DMBoAAABF8f2i5qGGs1SnN/YCEKswePYDX+OT49p+ePvsMHr1aunMMysOo5d2LtWqxaum51I3qlkzo33fXerd1hZfUUATIYxGZDIZt0n33r1xV9I8CKMBAABQlGy2qEvQZ81SBRCrLaktklwYvWtwl8Ynx6fHacywbVskmxhmUhn5ucbtjB4aG9Lw+PDsmdFsXgjUDGE0IhP+bsuojtoJZ0an2OwcAAAAhRw/Lu3fX1QYncvnZs5SBRCrnvYerV+6XtlcdrpjeVZntOTC6D173L/1Cpy+YWKjmbVJ6+Rk0R/WAYgGYTQiE567s419RU+i0BkNAACABRW5eaHkgpoZl68DiF0YEIch8ZxhdDg3+qabKn6tR048oiPDRypaJ6lmbdL64IPS8DBhNFBDhNGIzKpV0uLFdEbXUhBI7e3u/3cAAABgTmEYXeyYDsJoIFEyqYweCB6QH/jq7ezVGT1nzH7QBRe4N4eVbmI4NQIkm2vMLrNZndElnB8BRIMwGpExxjVbEEbXThC4rmj2lwEAAEBB4S/o/f3zPsxa6zqjmRkNJIqX9jQ4PKhfP/hreWlv7g1Gu7pcIF1hGH3qhomNKJd3sy6nxxGF50fCaKBmCKMRKc9jTEcthWE0AAAAUJDvS+vWST098z5saGxIIxMjdEYDCRMGxLc9dNvcIzpC27ZJN98s3X9/2a+1JbVFRmZ6PnWjmTWmw/fduXHNmhirAppLbGG0MabVGHObMea6uGpA9DIZaedOaXQ07kqaA2E0AAAAFlTk5lyzQhoAiZBJn5z3Ho7RmNOb3iT19kpPepJ0991lvVZXW5c29G6Qn2vMzuhZYzp83wUZXG4M1EycndF/Lum+GF8fVeB5bjPaHTvirqQ55HJSis3OAQAAMB/fLyqMnnX5OoBE2LRsk1pNq6QCmxeGMhnppz+VWlqkJz9ZuuOOsl4v3DCxEQX5QIvaF6mzrdPdUOT5EUB0YgmjjTHrJD1H0mfjeH1UT3gOZ1RHbdAZDQAAgHkFgetgyMzTTRk+9PSOQQCJ0N7ars19myUtEEZL0qMeJf3851J3twukb7ml5Nfz0p6yQVbW2nLKTbQgf8pc/LExd2k3YTRQU20xve6HJb1N0pKYXh9VEv6O+8UvRtMd/aQnSeedV/k6URgach8y/+7vVraOtdK110pXXCG1VfAv0FrCaAAAACwg7BJhTAdQ1zLpjLK57IyRHQX190s/+5n0lKdIT32q9P3vu3nSxb5WKqMjI0f0wV99UF1tXRVULXW0duhl575MSzori39+uP2HuvfgvRWtIUm3Hrj15AduO3dKExOE0UCN1TyMNsZcIekRa+1vjTFPmudxV0m6SpI2bNhQm+JQsVTKfRD7jW+4P5V6/OOlG26ofJ0ofOEL0hvfKG3fLm3eXP46N9wgveAF0je/KT3/+eWvMzjoZnOvWFH+GgAAAGhw/tSl9sWE0XRGA4l1+ZmXa/+x/VraubS4J2zadDKQfvrTpe99T3riE4t66iXrLlGLadHVP7q6gopnev3Fry/7uZN2Uld+9Urlx/OR1PKyc1/mvgnPj0VcOQIgOnF0Rj9B0vOMMb8rqUvSUmPMl621Lzv1QdbaT0v6tCRt3bq18a4NaWB33ikdP175Om99q/Stb1W+TlTum5pwfv/9lYXRp65TibDJhZ+bAAAAKMj3pdZWF0wtgM5oILne9oS36W1PeFtpT9qwwY3seMpTpGc+U7ruOje6YwHb1m3T0auPanRitMxqHSurDf+8QQ8ED1S0zt4je5Ufz+vDz/ywXnHeKypaS5J6u3rdNyV8WAcgOjUPo62175D0Dkma6ox+6+lBNOpbe7vU11f5OuecI33+88kZRRH+nPL9ykZ1nLpOFPUQRgMAAKCgbNYF0e3tCz40GAq0uGOxOlo7alAYgJpYs8Z1SD/1qe6N7LXXSs94xoJPW9SxSIu0qOKXz6QzFW+GGD7/vFXnqa87grBhemHfXd6dhMABaCKxbGAIFCP8cLLS0DYqUYfIUazT0lJZlzYAAAAanO8X3fWXG84p1Z2qckEAam7lSuknP5HOOkt67nOl7363Zi/tpb3IwugFN28sVTZLVzQQg1jDaGvtT621V8RZA5Ir/JkQjqOI08iItHu3+77SesLnR7HOxo1SZ2dl6wAAAKBBWet+aSzyUrpgKGBeNNColi+Xfvxj6bGPla68Unrzm91lyFXmpTztGtxV0ciPbC6rRe2LtHrx6ggrk/uwjkuNgZqjMxqJtWmTG2+XhM7o7dvd7/Ld3ZXVMzEhDQy4dR55xG1CWC5+bgIAAGBeBw5IJ04U3fkX5APmRQONLJWSfvQj6bWvlT7xCam/X/rnf5ZGK5sNPZ9MOqMJO6Gdh3eWvYYf+MqkMzLGRFfYiRPSgw/SGQ3EgDAaidXe7gLpJITRYQ1Pe5q0Z4+UL3MT3z173M/5pz3N/b3c7mhrS7riEgAAAM2oxM256IwGmkBvr/Sxj0l33CFdcon0F38hPeYxbpa0tZG/XDhao5JRHX7gRz+iY2DAfeVNNVBzhNFINM9LxpiOsIZw48Lt2ytb5znPmfn3Uj38sHT8OD83AQAAMI8Sd7wO8oTRQNM45xzp+uul733PdYI9//luk8Pbb4/0ZcIQOZsr783v6MSodg3ukpeK+M1viR/WAYgOYTQSLZNxPyOq8AFtSXxfWrFCetzjTv693HUk6dnPloypfB3GdAAAAKCgbNZtMLJ+/YIPnZic0OH8YcZ0AM3mWc9yXdIf+5h0553ShRdKr361G/MTgVR3SqnuVNmd0TsP79SEnVAmHfGb37AzrL8/2nUBLKgt7gKA+XieNDQk7d8vrV0bXx3hfOYw/K0kRF6yxL0fOPPMysNoPsQFAABAQeEvsS0L9yAdGTkiK6tUd6oGhQFIlLY26Q1vkF76Uukf/1H6yEekL35R6uuTFi+WFi2a++vq1dJf/qV7kzsPL+2VHUaHz4t8TIfvS2vWuP8dAGqKMBqJFoat2Wy8YXQ26z4wXrJEWrWq/PEa4ZxnY9zXcsPobFbq6JA2bCjv+QAAAGgCvi89+tFFPTQYCiSJMR1AM1u2TPqnf5Je9zrp85+XBgfdfMgTJ05+PXTo5PcPPSQND0vvf/+8y3ppTz/e+eOySgrHe1QljKa7C4gFYTQS7dRO5Cc9KZ4ajh1zVyiFP6cqDZEvueTkOl/6khtBUuqmwL4vbdkitbaWVwcAAAAa3MSE2+jkyiuLeniQnwqjGdMBoL9feu97F37cy14m/eu/uk0QV6wo+LBMKqMv3fElnRg9oUUdi0oqxQ/86VEfkfJ96fd+L9o1ARSFmdFItPXr3Zi7csPfKIRd0GEwHs6xLtXIiLRr18x1jh6VHnmk9LX4EBcAAADz2r1bGhsr+pdGOqMBlOxd73Kd0R/84LwPC7uaB3IDJb+EH/jRd0XnclIQ8KYaiAlhNBKtpcWFtuWOxYhC+NqndkY/8oh05Ehp6+zYIU1OzlxHKj3YDptc+LkJAACAgkrc8ZrOaAAl8zzXHf2xj8274WEYJocjN0qRzWWjD6NPf5MPoKYIo5F45XYiRyV87XCT3VPnWJdirlC7nHX27nVd1kW+rwAAAEAzKjFsoTMaQFn+9m/dVRgf+EDBh/Sn3JvpUjcxPDF6Qg8efVCZVMRvfkv8sA5AtAijkXie5zqBx8fjeX3fd+NCurvd30+dY13qOqc+f8MGqb29/HX4EBcAAAAF+b60dOm8c1xPlcvn1GJa1NvVW+XCADSU/n7pj/9Y+uQnpX375nzI4o7FWrNkTclhdDjWoyqbF7a0SJs3R7sugKIQRiPxPM990LpnTzyvn83ODH63bHEbDpba0ez70vLlboNiSWprc2uVGkZzRREAAAAW5PuuC6LInbKDfKC+rj61GN4iAijR3/yNmyf5vvcVfIiX9koe0xE+viph9KZNUkdHtOsCKAq/aSDxyu1EjoK10gMPzAx+u7qkM88sL0Q+PUD2vPJC7cWLpVWrSnseAAAAmshcv3zOI8gHzIsGUJ5Nm6Q/+RPpM58p2EWWSWVK7owOHx+O+YiM79PdBcSIMBqJV+5Gf1EIAmlwcPYoqXLmWIfNKaevk826jQ1LXafIJhcAAAA0m4cflnbvLi2MHgqYFw2gfO98p+vmeu9757zbS3s6NHRIh/OHi17SD3ytWbJGizsWR1Wlq7HED+sARIswGom3YoUbd1dqB3EUCo3ECDuarS1unePHpf37515nZMRtSlhKTfzcBAAAQEEf+IDrXPijPyr6KXRGA6jIhg3Sa14jfe5z0q5ds+4OR22UMqojm8tGP6LjwAHpxAk2LwRiRBiNxDOmvE7kKBTaLNDzpCNHpIMHi1tnYKDwOlLxQfvoqLRzJz83AQAAUMCBA9InPiG9/OUl/dJIZzSAir3jHVJrq/SP/zjrrkzKnY9KGdXhB/708yJT6E0+gJohjEZd8Lz4wujWVmnjxpm3lzrHOnzc6e8HSh1BsmOHG+nBz00AAADM6f3vd7t//+3flvS0XD5HGA2gMuvWSa99rfSFL0jbt8+4a3PfZrWYlqLD6MP5wzo0dKg6mxdKvKkGYkQYjbrgeW7s3chIbV83m5U2b5ba22fXE95fjPDnXf9p+y6sXi0tWlR8GF1obAgAAACgBx+UPvUp6VWvcr/EFmlkfEQnxk4o1Z2qYnEAmsLVV7s30Kd1R3e2dWrjso1Fj+kIH1eVMLqzU1q/Ptp1ARSNMBp1IZNx85lP+3C16gptsnvmme7naykh8vr1Uk/PzNvDESSlhtqM6QAAAMAs73ufu4zune8s6WlBPpAkZkYDqNzq1dLrXy996Uuz3uhmUpmiO6PDx0U+puOee9wb6hbiMCAu/OtDXSh1nEUUJifdz865gt+2NtdsUsqYjkIBcikjSHxfSqelFE0rAAAAONWePdJnPiP96Z/OnjG3gGBoKoxmTAeAKLz97a77+O//fsbNXtqTH/iy1i64hB/4ajEt2txX/FUeC/rBD6Trr5ee85zo1gRQMsJo1IVSZzRHYf9+aWio8EgMzyuto7nQOpmM25RwbGzhdbJZRnQAAABgDv/3/7rL7v76r0t+Kp3RACK1cqX0pjdJ//mf0n33Td/spT0dHz2uh088vOAS2VxWG5dtVGdbZzQ1HT4s/cmfSI9+tPTud0ezJoCyEEajLixbJi1fXnz4G4WF5jOHYfTk5PzrBIGUy82/zsSEC6QXMl+HNQAAAJrUzp3S5z8vXXVVWXNQ6YwGELm/+iupu3tGd3Q4cqOYUR1+4Ec7ouONb5Qeflj69393dQGIDWE06kYp4yyisNB85kxGGh52+8TMJwy15xvTcerrFXLihLRvH53RAAAAOM0//qPU2iq94x1lPT2Xz0miMxpAhJYvl/7sz6T/+i/prrskndyMcKEw2lorP/Cj27zwv/5L+spXpHe9S7roomjWBFA2wmjUjTjC6K4uad26wvVIC3drhzXPN6bj1McVMjAw/zoAAABoQgMD0he/6DYMW7OmrCXCMR2pbjYmARChv/xLqbdX+vM/l6zVht4N6mjtUDaY/030wyce1vHR49GE0fv3u/Pj4x5X9gd2AKJFGI26kclIDz0kHTtWm9cLNy8stMlusR3Nvu8aVTZtmvv+cEPCYtaRGNMBAACAU/zDP0gdHW7DsDIFQ4G62rrU094TYWEAml46Lb33vdJPfiJ99atqbWnVlr4t8nPzv/kNO6crHtNhrdvUdXhY+tKXpLa2ytYDEAnCaNSNYjuRo7LQfOY1a6SenoVD5GzWBdHt7YUfU8xmiOHr9PfP/zgAAAA0iQcekL78ZekNb5BWrSp7mSAfMC8aQHVcdZW0davrkj56VF7aW3BMR3h/xZ3Rn/qUdP310gc/KJ11VmVrAYgMYTTqRrGdyFEYH5e2b59/JIYxLqwuJkReaLRGJlNcqL12rbR48fyPAwAAQJP4+793c+Xe9raKlgnyAfOiAVRHa6v08Y+7y5zf8x55aU/bc9s1MTlR8CnZIKuO1g5t6N1Q/usODLgA/OlPdx/YAUgMwmjUjbAjuBad0bt3u0B6oRB5oTnW1rp6i1nnwQeloaHCjykm1AYAAECTuPdetyHXm98srVhR0VLBEJ3RAKro4oul17xG+shHdEmuRyMTI9p7dG/Bh/s5X/2pfrW2tJb3euPj0ite4UYYff7zhWdvAogF/yJRN7q7pfXra9MZXex85kxG2rFDGhub+/4DB6QTJxZeJwyZw00KC9XEvGgAAABIkv7u76RFi6S3vrXipeiMBlB1732vtGyZnvZP10hW847q8AO/snnRH/qQ9OtfSx/7mLRuXfnrAKgKwmjUlYU6kaMSvkYxHc0TE9KuXZWtE4bMhf635XJSENAZDQAAAEl33SX9939Lf/7n0hlnVLxcLp9TqisVQWEAUEA6LX3gA+q95S694g43imMuE5MT2p7bXv686Ntvl979bunFL5b+8A/LrxdA1RBGo66EYbS11X2dbFbq7ZWWL1+4HqlwiBxVGB2OJiGMBgAAgP7u76QlS6S/+IuKl7LWKpfP0RkNoPpe9SrZxz9e//RDo7277pzzIXuP7tXIxMjsMPrHP5a++lXppz+V7rvPdWydHgwMD0sve5n7kO7jH3cbPQFInLa4CwBKkclIg4OuSziCJpCCwpEYC/3sOjVEfs5zZt+fzbo9ZRa6MmjxYmnNmsLzsIsdGwIAAIAGd/fd0je+4Tr/UpV3Mx8dOarxyXFmRgOovpYWmY9/XKkLL9ATPnO99OLZDwnHd0yP6Rgakv7sz6TPfW72g9vbpZUrT/45fly65x7pf/7HdWIDSCTCaNSVUzuRqx1GP+EJCz8unZb6+uYPkfv7i9svYb4RJNmsW2Pz5oXXAQAAQAM7+2zpa1+Tnv70SJYL8oEk0RkNoDbOP18/eFZGz7k+K/32t9JFF824Oxzf4aU91wH94he7D+H++q+ll75UevjhmX8eeujk14MHpXe9S3r2s+P4XwagSITRqCthGJ3NSpdeWp3XGB6W9uyRXvWqhR9rzPwhsu+79wvFyGSkb36z8DqbNrnNgAEAANDEWlqkF70osuWCoakwms5oADVy2+ufrwt+8SGteMMb1PLrX8/o3vIDX4s7FmvVNT+Q3vAGt1Hr9ddLz3yme8A558RUNYCoMDMadWXjRqm1tbqbGG7f7kZPFTsSI5OZu56JCbdWset4nnTokHT48Oz7wrEhAAAAQJTojAZQa+s3PFZ/9XSp5eabZ43f2H3gPn35ug6ZV75SuvhityFhGEQDaAiE0agr7e1uVEU1w+hiNx0MeZ60d6+Uz8+8ffduaWystHWk2SM/rHW3sXkhAAAAopbL5yRJqe7K508DQDG8tKcvnysFW8+Rrr7adWVJ0r336kPv/Kme++uc9Dd/I/3v/7rNlQA0FMJo1B3PKzyjOQrh2qV0NEvSwMDM20sNtU/dDPFUDz3k9mEgjAYAAEDUGNMBoNYy6YxkpO/8+bOkI0ekd7xD+sIXZC++WEuPjelLH/wj6R/+QWpjsizQiAijUXcyGRcYT05WZ33fl1askHp7i68nfN6pSg21N292o7JOD9rDdRnTAQAAgKiFYzr6uvtirgRAs0h1p5TuTuvXvcekt7xF+uxnpVe9SkMXPlbnv05qfTpjOYBGxsdMqDueJw0NSfv3S+vWRb++75fWhRyGxHOFyEuXumC7GJ2dbiZ2oVCbzmgAAABELRgKtKxrmdpaeGsIoHa8tKdsLiu9+1rp1lulyy/Xj190nh767xfIS/PmF2hkdEaj7hSarRyVUuczL1kirV49O0QOQ21jil9rrs0Qfd8F1evXF78OAAAAUIwgHzCiA0DNeWlPfuC7N9Q//rH07nfLH9wuaWqMB4CGRRiNulNoLEYUjh51M5pLHYkxV4iczZa+TjgP29qTt/m+tGWL1Npa2loAAADAQoJ8oHQPYTSA2sqkMtp3bJ9OjJ6Yvs0PfKW702yoCjQ4wmjUnXXrpK6u6oTR5Y7EOH1TxZERadeu8tY5dkx6+OGZNTGiAwAAANWQy+cIfgDUXDiKYyA3MH1bNpdlRAfQBAijUXdaWk5uYhi1SsLoRx6RBgfd37dvd93Npa5zetf3xIQ0MEAYDQAAgOoIhhjTAaD2wtDZD052mfmBTxgNNAHCaNSlucZiRCFcc8uW0uuRTobZ4TrljOk49fl79kijo6WvAwAAABSDmdEA4tCf6pd0Mow+MXpC+47tUybFm1+g0RFGoy55nus+Hh+Pdl3flzZskLq7S69HOhlGh19LDZE3bJA6OmavQ2c0AAAAojY2MaajI0eZGQ2g5hZ1LNLaJWuVzbk3veG4DjqjgcZHGI265HkuiN69O9p1y53PvGWLZMzJjmbfl1askJYtK22d1la31qnrSITRAAAAiF4un5MkOqMBxMJLe9Od0eFXwmig8RFGoy6dPls5Cta69coZidHZKZ155swQudzRGp43c53Fi6WVK8tbCwAAACgkyAeSRGc0gFhkUplZYXQ4vgNA4yKMRl06fbZyFA4dchsQltuF7Hkzx2tUss727W7zwnAdY8pbCwAAACgk7IxOdadirgRAM/LSnoJ8oFw+p2wuq7VL1mpRx6K4ywJQZYTRqEvLl0u9vSfD3yhUOp857Gg+dkw6cKD8dTIZaWRE2rvXrceIDgAAAFRDMDTVGc2YDgAxCEdyZIOs/MBnRAfQJAijUZeMcaFtlJ3R4VrljtfIZKSjR6Vf/aqydcLw+e67pV27yl8HAAAAmA9jOgDEKZN2b3b9wJcf+MqkePMLNAPCaNStU2crR8H3pbY2aePG8uuRpO9+d+bfy13n+9+XJifpjAYAAEB10BkNIE6b+zarxbTopn03KcgHdEYDTYIwGnXL86Q9e6Th4WjWy2alzZul9vby65Gk665zX/vL3Hdh1Sq3aWG4DmE0AAAAqiHIB2pvadfijsVxlwKgCXW0dmjTsk36btZ1dBFGA82BMBp1K5ORrHWb/UXB9ysbibFhgwuyd+2S1q+XurvLWyccQbJrl/s7YzoAAABQDcFQoHRPWobdsgHEJJPOaNfgrunvATS+mofRxpguY8zNxpg7jDH3GGP+rtY1oDGEHcNRjOqYnHSd0ZV0Ibe1SVu2zKytXOHzzzhD6uurbC0AAABgLrnhnFLdqbjLANDEvJR789tiWrS5b3PM1QCohTg6o0ckPcVae56k8yU9yxizLYY6UOfCjuFstvK19u+X8vnoQuSkrAMAAAAUEgwFzIsGEKtwNMemZZvU0doRczUAaqHmYbR1jk/9tX3qj611Hah/vb3SihXRdEaHa1Q6EiN8flLWAQAAAAoJ8m5MBwDEJRzNwYgOoHm0xfGixphWSb+V1C/pY9bam+KoA/XP86Tvfld6yUsqW2f37pPrVVpPktYBAABAYzk0dEhv/J83RrLWjsM7dMnaSyJZCwDKEXZGh+M6ADS+WMJoa+2EpPONMcskfdMY8xhr7d2nPsYYc5WkqyRpw4YNtS8SdeGlL5U+8hHpzjsrX+uKK6S1aytb4xnPcH8uvbSydc4919Xz3OdWtg4AAAAay+jEqO58OIJffiWd2Xumnt3/7EjWAoBybOjdoBef82K98NEvjLsUADVirI13QoYx5t2STlhr/6nQY7Zu3WpvueWWGlYFAAAAAAAAACiVMea31tqtc91X85nRxpjlUx3RMsZ0S3qapPtrXQcAAAAAAAAAoHbiGNOxWtIXp+ZGt0j6mrX2uhjqAAAAAAAAAADUSM3DaGvtnZIuqPXrAgAAAAAAAADiU/MxHQAAAAAAAACA5kMYDQAAAAAAAACoOsJoAAAAAAAAAEDVEUYDAAAAAAAAAKqOMBoAAAAAAAAAUHWE0QAAAAAAAACAqiOMBgAAAAAAAABUHWE0AAAAAAAAAKDqCKMBAAAAAAAAAFVHGA0AAAAAAAAAqDrCaAAAAAAAAABA1RFGAwAAAAAAAACqjjAaAAAAAAAAAFB1hNEAAAAAAAAAgKojjAYAAAAAAAAAVB1hNAAAAAAAAACg6gijAQAAAAAAAABVRxgNAAAAAAAAAKg6wmgAAAAAAAAAQNURRgMAAAAAAAAAqs5Ya+OuYUHGmIOSdsddB8pyhqRDcRcBTOF4RFJwLCJJOB6RJByPSAqORSQJxyOShOMRxTjTWrt8rjvqIoxG/TLG3GKt3Rp3HYDE8Yjk4FhEknA8Ikk4HpEUHItIEo5HJAnHIyrFmA4AAAAAAAAAQNURRgMAAAAAAAAAqo4wGtX26bgLAE7B8Yik4FhEknA8Ikk4HpEUHItIEo5HJAnHIyrCzGgAAAAAAAAAQNXRGQ0AAAAAAAAAqDrCaAAAAAAAAABA1bXFXQAaizFmpaS1kqyk/dbah2MuCQBix7kRAObG+REAZuPcCKCRMTMakTDGnC/pk5J6Je2bunmdpEFJb7DW3hpPZWhGxpjHSvqM3C9w35P0dmvt4an7brbWPi7O+tA8ODciSTg3Ikk4PyIpODciSTg3Ikk4P6Ja6IxGVL4g6bXW2ptOvdEYs03Sv0k6L46i0LQ+Iek9km6U9GpJvzTGPM9au11Se5yFoel8QZwbkRycG5EkXxDnRyQD50YkyRfEuRHJwfkRVUEYjagsOv0HpiRZa280xiyKoyA0tcXW2uunvv8nY8xvJV1vjHm53KVuQK1wbkSScG5EknB+RFJwbkSScG5EknB+RFUQRiMq3zPGfFfSlyTtnbptvaRXSLq+4LOA6jDGmF5r7RFJstb+xBjze5K+ISkVb2loMpwbkSScG5EknB+RFJwbkSScG5EknB9RFcyMRmSMMc+WdKXcPCEj6UFJ37bW/k+shaHpGGNeKmmHtfbG027fIOlvrbWviacyNCPOjUgKzo1IGs6PSALOjUgazo1ICs6PqBbCaAAAAAAAAABA1bXEXQAagzGmzRjzWmPM94wxdxpj7pj6/nXGGAbbIzGMMZ+OuwY0D86NqBecG1FrnB9RDzg3otY4N6JecH5EJeiMRiSMMV+RNCjpi3KXEUnSOkl/LCllrX1JTKWhCRljCs2vMpLusNauq2U9aF6cG5EknBuRJJwfkRScG5EknBuRJJwfUS2E0YiEMeYBa+1ZBe7zrbVerWtC8zLGTEjaLfdDMmSn/r7WWtsRS2FoOpwbkSScG5EknB+RFJwbkSScG5EknB9RLW1xF4CGcdgY8yJJ37DWTkqSMaZF0oskHY61MjSjHZKeaq3dc/odxpi9czweqBbOjUgSzo1IEs6PSArOjUgSzo1IEs6PqApmRiMqfyDp9yU9bIzxjTG+pIckvXDqPqCWPiypr8B9H6xhHQDnRiTJh8W5EcnB+RFJ8WFxbkRycG5EknxYnB9RBYzpQOSMMWm5Y+tQ3LUAQFJwbgSAuXF+BIDZODcCaFSE0QAAAAAAAACAqmNMBwAAAAAAAACg6gijAQAAAAAAAABV1xZ3AWgsxpitktZLGpeUtdbeH3NJaGIcj0gCY4yR9DhJayVZSfsl3WyZk4UYcDyiHhhjHsXPbCQBxyLiYoxpt9aOnXbbGcyPRhw4HhE1ZkYjEsaYyyX9P0mDki6S9Cu5XVfHJL3cWrs3vurQbDgekRTGmGdI+rikrKR9Uzevk9Qv6Q3W2h/EVRuaD8cj6oUxZo+1dkPcdQAci6g1Y8yTJf27pE5Jt0m6ylq7a+q+W621F8ZYHpoMxyOqhc5oROXDkp5hrT1ojNkk6f+z1j7BGPN0SZ+T9IxYq0Oz+bA4HpEM/yLpaeEvbaGp4/J/JD06jqLQtDgekRjGmI8UukvSshqWgibHsYiE+aCkZ1pr7zHG/L6kHxpjXm6tvVHumARqieMRVUEYjai0WmsPTn2/R9KZkmSt/aEx5sOxVYVmxfGIpGiT9OAct++T1F7jWgCORyTJqyT9paSROe77wxrXgubGsYgk6bDW3iNJ1tqvG2Puk3SNMeZqufFaQC1xPKIqCKMRlVuMMZ+T9CNJV0r6qSQZY3oktcZYF5oTxyOS4vOSfmOM+aqkcDzMekl/INelD9QSxyOS5DeS7rbW3nD6HcaY99S+HDQxjkUkyZgxZpW19iFJmupIfaqk6yRtibc0NCGOR1QFM6MRCWNMu6TXSDpb0h2SPm+tnTDGdEtaYa3dHWuBaCocj0gSY8zZkp4nt2GcketM/ba19t5YC0NT4nhEUhhjUpKGrbVDcdeC5saxiCQxxjxN0kFr7R2n3b5M0huttf83lsLQlDgeUS2E0QAAAAAAAACAqmuJuwA0BmPMUmPM+4wx/26Meelp9308rrrQnDgekRTGmFXGmE8YYz5mjEkbY95jjLnTGPM1Y8zquOtDc+F4RJIYY3qNMe83xtxvjAmm/tw3dduyuOtD8+BYRJJwPCJJOB5RLYTRiMq/yV3u+w1Jf2CM+YYxpnPqvm3xlYUmxfGIpPiCpHvl5vP+RFJe0hWSfiHpk/GVhSb1BXE8Ijm+JumwpCdZa9PW2rSkJ0/d9t+xVoZmw7GIJOF4RJJwPKIqGNOBSBhjbrfWnn/K398p6Xfl5lL+0Fp7YVy1oflwPCIpjDG3WWsvmPp+j7V2wyn3zThOgWrjeESSGGMesNaeVep9QNQ4FpEkHI9IEo5HVAud0YhKpzFm+niaGmT/aUk/l5SOrSo0K45HJMWpP2e/NM99QC1wPCJJdhtj3maMWRneYIxZaYx5u1z3PlArHItIEo5HJAnHI6qCNx6IynckPeXUG6y1X5T0l5JGY6kIzYzjEUlxrTFmsSRZa/8mvNEY0y/Jj60qNCuORyTJS+Q+IP6ZMSZnjMlJ+qmklKQXx1kYmg7HIpKE4xFJwvGIqmBMBwAAAAAAAACg6uiMRtUYY66LuwYgxPGIpOBYRJJwPCJJOB6RFByLSBKORyQJxyOiQBiNalobdwHAKTgekRQci0gSjkckCccjkoJjEUnC8Ygk4XhExQijUU23xV0AcAqORyQFxyKShOMRScLxiKTgWESScDwiSTgeUTFmRqNqjDErrLWPxF0HIHE8Ijk4FpEkHI8AAAAAaonOaETCGJM67U9a0s3GmD5jTCru+tBcOB6RFByLSBKORySJMeZZp3zfa4z5nDHmTmPMfxpjVsZZG5oLxyKShOMRScLxiGqhMxqRMMZMStp92s3rJD0oyVprN9e+KjQrjkckBccikoTjEUlijLnVWnvh1PeflfSQpM9IeqGky621z4+xPDQRjkUkCccjkoTjEdVCGI1IGGPeKulpkv7KWnvX1G07rbWb4q0MzYjjEUnBsYgk4XhEkpz2Bvd2a+35p9w34+9ANXEsIkk4HpEkHI+olra4C0BjsNb+kzHmq5L+2RizV9K7JfFJB2LB8Yik4FhEknA8ImFWGGP+QpKRtNQYY+zJLhlGCaKWOBaRJByPSBKOR1QFBw8iY6190Fr7Ikk/kfRDST0xl4QmxvGIpOBYRJJwPCJBPiNpiaTFkr4o6QxJMsasknR7fGWhCXEsIkk4HpEkHI+oCsZ0oCqMMd2Stlhr7467FoDjEUnBsYgk4XgEAAAAUGuM6UBkjDGPknSlpLVyl/3uN8ZMWGvvi7cyNCOORyQFxyKShOMRSTLX8Sjp2xyPqDWORSQJxyOShOMR1cCYDkTCGPN2SV+VmyV0s6TfTH3/FWPM1XHWhubD8Yik4FhEknA8Ikk4HpEUHItIEo5HJAnHI6qFMR2IhDHGl3SOtXbstNs7JN1jrc3EUxmaEccjkoJjEUnC8Ygk4XhEUnAsIkk4HpEkHI+oFjqjEZVJSWvmuH311H1ALXE8Iik4FpEkHI9IEo5HJAXHIpKE4xFJwvGIqmBmNKLyFkk/MsZkJe2dum2DpH5Jb4qrKDStt4jjEcnwFnEsIjneIo5HJMdbxPGIZHiLOBaRHG8RxyOS4y3ieEQVMKYDkTHGtEh6nNxgeyPpQUm/sdZOxFoYmhLHI5KCYxFJwvGIJOF4RFJwLCJJOB6RJByPqAbCaAAAAAAAAABA1TEzGgAAAAAAAABQdYTRAAAAAAAAAICqI4wGAAAACjDGTBhjbjfG3GOMucMY8xdT8xPne85GY8xLS3ydZcaYN5zy9zXGmK+XWzcAAACQRITRAAAAQGF5a+351tpzJD1d0u9KevcCz9koqaQwWtIySdNhtLV2v7X290tcAwAAAEg0wmgAAACgCNbaRyRdJelNxtlojPmFMebWqT+XTj30/ZJ+Z6qj+v8YY1qNMR8yxvzGGHOnMea1cyz/fklbpp7zoam175YkY8wrjTHfMsZ8xxiz0xjzpqkO7duMMTcaY1JTj9tijLneGPPbqboeVYv/XwAAAIBitcVdAAAAAFAvrLU7psZ0rJD0iKSnW2uHjTEZSV+RtFXS1ZLeaq29QpKMMVdJOmKtvdgY0ynpV8aYH1hrd56y9NWSHmOtPX/qORtPe+nHSLpAUpekAUlvt9ZeYIz5Z0mvkPRhSZ+W9DprbdYYc4mkj0t6SuT/JwAAAABlIowGAAAASmOmvrZL+qgx5nxJE5K8Ao9/hqRzjTHh2I1eSRlJOws8fi4/sdYek3TMGHNE0nembr9rau3Fki6V9N/GhOWps4T1AQAAgKojjAYAAACKZIzZLBc8PyI3O/phSefJjb8bLvQ0SW+21n6/gpceOeX7yVP+Pin3O32LpMGwsxoAAABIImZGAwAAAEUwxiyX9ElJH7XWWrkO5wPW2klJL5fUOvXQY5KWnPLU70t6vTGmfWodzxiz6LTlT39OSay1RyXtNMa8aOo1jDHmvHLXAwAAAKqBMBoAAAAorHtqU8F7JP2vpB9I+rup+z4u6Y+NMTfKjeg4MXX7nZLGjTF3GGP+j6TPSrpX0q1TmxJ+SqddoWitDeRmSd9tjPlQmbX+kaQ/NcbcIekeSVeWuQ4AAABQFcY1dQAAAAAAAAAAUD10RgMAAAAAAAAAqo4wGgAAAAAAAABQdYTRAAAAAAAAAICqI4wGAAAAAAAAAFQdYTQAAAAAAAAAoOoIowEAAAAAAAAAVUcYDQAAAAAAAACoOsJoAAAAAAAAAEDV/f/Sg4o5ivKLyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.747878787878788\n"
     ]
    }
   ],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "start_predictions_timestamp=pd.to_datetime('2019-05-01 05:30:00') #define the timestamp that predictions are required \n",
    "                                                                    #to start from\n",
    "prediction_interval=pd.to_timedelta('00:40:00') #define the interval between predictions\n",
    "end_predictions_timestamp=pd.to_datetime('2019-05-02 18:00:00')#define the timestamp of the last required timestamp\n",
    "synetica_data='synetica-apr-2019.zip' # provide the filename of the past data that will be used\n",
    "meter_ID='MC062-L01/M7' #provide the meter ID of the meter that predictions are required for\n",
    "building=' Bowland Twr (Old Bowland Annexe) '#provide the name of the building to acquire occupancy data \n",
    "check=True #set to True if the predictions can be checked by recorded data\n",
    "check_data='synetica-may-2019.zip'\n",
    "predictions(synetica_data, meter_ID, building, start_predictions_timestamp, prediction_interval, \n",
    "            end_predictions_timestamp, check, check_data)\n",
    "#future_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>device_id</th>\n",
       "      <th>name</th>\n",
       "      <th>reading</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>{A389C592-4604-4CDA-8A03-035E14168AB3}</td>\n",
       "      <td>MC043-L01/M1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MWh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:40:00</td>\n",
       "      <td>{A389C592-4604-4CDA-8A03-035E14168AB3}</td>\n",
       "      <td>MC043-L01/M1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MWh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 01:20:00</td>\n",
       "      <td>{A389C592-4604-4CDA-8A03-035E14168AB3}</td>\n",
       "      <td>MC043-L01/M1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MWh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>{A389C592-4604-4CDA-8A03-035E14168AB3}</td>\n",
       "      <td>MC043-L01/M1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MWh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 02:40:00</td>\n",
       "      <td>{A389C592-4604-4CDA-8A03-035E14168AB3}</td>\n",
       "      <td>MC043-L01/M1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MWh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                               device_id          name  \\\n",
       "0  2020-01-01 00:00:00  {A389C592-4604-4CDA-8A03-035E14168AB3}  MC043-L01/M1   \n",
       "1  2020-01-01 00:40:00  {A389C592-4604-4CDA-8A03-035E14168AB3}  MC043-L01/M1   \n",
       "2  2020-01-01 01:20:00  {A389C592-4604-4CDA-8A03-035E14168AB3}  MC043-L01/M1   \n",
       "3  2020-01-01 02:00:00  {A389C592-4604-4CDA-8A03-035E14168AB3}  MC043-L01/M1   \n",
       "4  2020-01-01 02:40:00  {A389C592-4604-4CDA-8A03-035E14168AB3}  MC043-L01/M1   \n",
       "\n",
       "   reading units  \n",
       "0      0.0   MWh  \n",
       "1      0.0   MWh  \n",
       "2      0.0   MWh  \n",
       "3      0.0   MWh  \n",
       "4      0.0   MWh  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_df20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_environment",
   "language": "python",
   "name": "my_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
